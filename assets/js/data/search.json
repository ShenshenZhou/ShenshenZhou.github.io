[ { "title": "Webserver压力测试", "url": "/posts/webserver-webbench/", "categories": "项目, MyWebServer", "tags": "项目, webbench, webserver", "date": "2022-07-26 09:28:30 +0800", "snippet": "webbench压力测试==webbench简介==webbench是Linux下使用的一个轻量级（适用于中小型网站）的服务器压力测试工具，通过webbench可以得到以下数据： Speed传输速度，每分钟请求数及每秒请求字节数 Requests请求数量，统计成功和失败次数==测试原理==利用fork建立多个子进程，每个子进程在测试时间内不断发送请求报文，父子进程通过管道进行通信，子进程通过管道写端向父进程传递在若干次请求访问完毕后记录到的总信息，父进程通过管道读端读取子进程发来的相关信息，子进程在测试时间完成后结束，父进程在所有子进程退出后统计并显示最后的测试结果，然后退出。webbench最多可以模拟3万多个并发连接数。==使用webbench== 首先下载webbench-1.5并安装； 进入webbench目录下，使用make命令生成webbench可执行文件； 在进行压测先要先打开网页服务器，然后在终端上执行以下命令： # ./webbench -c 并发数量 -t 测试时间 URL./webbench -c 10000 -t 5 http://192.168.253.128:1316/测试环境：Ubuntu:18.2 cpu:i5-10400 内存:8GQPS：10000+" }, { "title": "C++实现十大排序算法", "url": "/posts/Sort/", "categories": "题解", "tags": "总结, 算法, 排序", "date": "2022-07-25 17:11:12 +0800", "snippet": "参考：十大经典排序算法（C++实现C++实现十大排序算法 n：元素个数。 k：桶的个数。 In-place：原地算法，不占用额外内存。 Out-place：非原地算法，占用额外内存。 稳定性：如果排序前后两个相等元素的相对位置不变，则认为是稳定的。冒泡排序从左到右，依次比较相邻的元素大小，更大（小）的元素交换到右边，这样所有元素比较完之后，最右边的元素一定是最大（小）的，重复此过程就可以完成所有元素的排序。// 冒泡排序void BubbleSort(vector&amp;lt;int&amp;gt;&amp;amp; vec) { int n = vec.size(); for (int i = 0; i &amp;lt; n - 1; ++i) { // 每轮排序都会确定一个最大的元素，所以下轮排序就减少一个元素，需要n-1轮排序 for (int j = 0; j &amp;lt; n - 1 - i; ++j) { // 比较相邻元素的大小 if (vec[j] &amp;gt; vec[j + 1]) { swap(vec[j], vec[j + 1]); } } }}// 优化后的冒泡排序// 优化思路：在每轮排序中设置个标志位表示该轮排序中元素是否发生了交换，// 如果所有元素都没有发生交换，就说明元素已经是正序了，后面就不用再进行比较了void BBubbleSort(vector&amp;lt;int&amp;gt;&amp;amp; vec) { int n = vec.size(); for (int i = 0; i &amp;lt; n - 1; ++i) { bool flag = false; // 交换标志 for (int j = 0; j &amp;lt; n - 1 - i; ++j) { if (vec[j] &amp;gt; vec[j + 1]) { swap(vec[j], vec[j + 1]); flag = true; // 发生交换 } } // 判断每轮排序元素是否发生了交换 if (!flag) { return; // 如果没有发生交换 直接return } }}冒泡排序时间复杂度为 O(n²)，优化后的时间复杂度为O(n)，空间复杂度为 O(1)。快速排序是冒泡排序的改进版，之所以快速是因为每次交换都是跳跃式的，不是交换一个元素值，而是把整个区间交换。首先在序列中选取一个元素作为基准，然后将所有元素分为两部分，一部分是比基准小的，放在基准的左边，一部分是比基准大的，放在基准的右边，然后该基准就处于序列中间的位置了，这个过程就是分区。递归的对每个子分区进行排序。// 快速排序// 递归的对区间进行排序 要有边界参数 区间左闭右闭 边界元素可取void QuickSort(vector&amp;lt;int&amp;gt;&amp;amp; vec, int left, int right) { // 终止条件：直到left &amp;gt;= right，当left = right时只有一个元素，也就不用排了 if (left &amp;gt;= right) { return; } int i = left; // 区间左边界 int j = right; // 区间右边界 int base = vec[left]; // 选取最左边的元素作为基准 while (i &amp;lt; j) { // 先从右向左找比基准小的数 (如果以最右边的元素为基准就要先从左往右查找) while (vec[j] &amp;gt;= base &amp;amp;&amp;amp; i &amp;lt; j) { --j; } // 从左往右找比基准大的数 while (vec[i] &amp;lt;= base &amp;amp;&amp;amp; i &amp;lt; j) { ++i; } // 如果i&amp;lt;j交换两个元素 if (i &amp;lt; j) { swap(vec[i], vec[j]); } } // i=j就是碰头了 需要将基准归位 vec[left] = vec[i]; // 将碰头处的数放在基准处 vec[i] = base; // 将基准放中间 // 递归遍历子区间 QuickSort(vec, left, i - 1); // 左子区间 QuickSort(vec, i + 1, right); // 右子区间}时间复杂度为O(nlogn)，空间复杂度为O(1)。选择排序在为排序的序列中找到最小（大）的元素，放在序列的起始位置，然后在剩余未排序序列中重复此步骤即可。// 选择排序void SelectSort(vector&amp;lt;int&amp;gt;&amp;amp; vec) { int n = vec.size(); // n个元素排序n-1轮 for (int i = 0; i &amp;lt; n - 1; ++i) { int minIndex = i; // 最小元素设置为每轮排序的第一个元素 // 在该轮排序中找最小值 for (int j = i + 1; j &amp;lt; n; ++j) { if (vec[j] &amp;lt; vec[minIndex]) { minIndex = j; // 更新最小值 } } // 把最小值放在序列中的第一个位置 if (i != minIndex) { swap(vec[i], vec[minIndex]); // 如果最小值不是第一个元素 就交换 反之就不用 } }}选择排序时间复杂度为O(n²)，空间复杂度为O(1)。堆排序即通过大根堆和小根堆来排序。// 堆排序// 大根堆void Heapify(vector&amp;lt;int&amp;gt;&amp;amp; tree, int n, int i) { // n 表示序列长度，i 表示父节点下标 if (i &amp;gt;= n) return; // 左侧子节点下标 int left = 2 * i + 1; // 右侧子节点下标 int right = 2 * i + 2; int max = i; if (left &amp;lt; n &amp;amp;&amp;amp; tree[left] &amp;gt; tree[max]) max = left; if (right &amp;lt; n &amp;amp;&amp;amp; tree[right] &amp;gt; tree[max]) max = right; if (max != i) { swap(tree[max], tree[i]); Heapify(tree, n, max); }}// 生成堆void BuildHeap(vector&amp;lt;int&amp;gt;&amp;amp; tree, int n) { // 树最后一个节点的下标 int last_node = n - 1; // 最后一个节点对应的父节点下标 int parent = (last_node - 1) / 2; for (int i = parent; i &amp;gt;= 0; i--) { Heapify(tree, n, i); }}// 调整堆void HeapSort(vector&amp;lt;int&amp;gt;&amp;amp; tree) { int n = tree.size(); BuildHeap(tree, n); for (int i = n - 1; i &amp;gt;= 0; i--) { // 将堆顶元素与最后一个元素交换 swap(tree[i], tree[0]); // 调整成大顶堆 Heapify(tree, i, 0); }}所以时间复杂度为O(nlogn)，空间复杂度为O(1)。插入排序将序列分为已排序序列和未排序序列，对于每一个未排序序列的首元素，在已排序序列中从后往前扫描，找到相应的位置并插入。因为要插入元素，所以所有比它大（小）的已排序序列中的元素都要后移。算法的初始化是将乱序序列中的第一个元素作为已排序序列，剩下的元素作为未排序序列。// 插入排序void InsertSort(vector&amp;lt;int&amp;gt;&amp;amp; vec) { int n = vec.size(); // 算法初始化：第一个元素作为已排序序列，剩下的作为未排序序列 for (int i = 1; i &amp;lt; n; ++i) { int temp = vec[i]; // 未排序序列的首个元素 // 从后往前扫描已排序序列 // j&amp;gt;0是因为要用到j-1 // vec[j - 1] &amp;gt; temp 是因为升序排序，所以大于当前元素的都要后移 int j = 0; for (j = i; j &amp;gt; 0 &amp;amp;&amp;amp; vec[j - 1] &amp;gt; temp; --j) { vec[j] = vec[j - 1]; // 已排序序列元素后移 } vec[j] = temp; // 第一个不大于当前元素的位置，就插入到该位置前面 }}插入排序时间复杂度O(n²)，空间复杂度为O(1)。希尔排序插入排序的改进版，希尔排序在每次循环中把序列分为互不相连的子序列，每个子序列利用插入排序进行排序。子序列是按照一定的增量进行分割，每次增量都会减少，直到最后增量为1，即所有元素是一组序列，然后使用插入排序就完成了排序过程。void ShellSort(vector&amp;lt;int&amp;gt;&amp;amp; vec) { int n = vec.size(); int increment = 0; // 增量 // 增量初始值为n/2，缩小方式一般为increment = increment / 2 for (increment = n / 2; increment &amp;gt; 0; increment /= 2) { // 对每个分组做插入排序 比如增量为5 则分组为 05 16 27 38 49 for (int i = increment; i &amp;lt; n; ++i) { int temp = vec[i]; int j = 0; // i从5-9 j就是i-increment即0-4 // temp &amp;lt; vec[j]是因为做升序排序 // 插入排序是倒序遍历 所以j以increment为间隔递减遍历 for (j = i - increment; j &amp;gt;= 0 &amp;amp;&amp;amp; temp &amp;lt; vec[j]; j -= increment) { vec[j + increment] = vec[j]; // 交换 } // 插入到第一个不大于当前元素(vec[j])的后面 所以要+increment vec[j + increment] = temp; } }}因为每次增量减半，所以时间复杂度为O(nlogn)，空间复杂度为O(1)。归并排序分治法的典型运用，先将数组分割成子数组，然后归并在一起，归并的时候完成排序！// 归并排序void Merge(vector&amp;lt;int&amp;gt;&amp;amp; vec, int left, int mid, int right) { // 构造左右数组 int leftSize = mid - left + 1; // 包含mid 所以+1 int rightSize = right - mid; // 不包含mid 所以不+1 vector&amp;lt;int&amp;gt; leftVec(leftSize, 0); vector&amp;lt;int&amp;gt; rightVec(rightSize, 0); // 以mid为分割点，将元素组分割成左右子数组 for (int i = left; i &amp;lt;= mid; ++i) { // 子数组是新的数组 从下标0开始 所以i-left 原数组只要取对应下标的元素即可 leftVec[i - left] = vec[i]; } for (int i = mid + 1; i &amp;lt;= right; ++i) { rightVec[i - mid - 1] = vec[i]; // 同理 } // 依次合并子数组 // 注意是从最小的子数组合并开始的，最小的数组就是只包含一个元素 // 所以只比较两个数组的第一个元素，如果左边的第一个元素小于右边的第一个元素,那么左边的第一个元素就会小于右边的所有元素 // 如果左边的某个元素大于右边的某个元素，就把右边的放上去，然后相应的下标递增 // 这样左右某个数组的下标达到边界之后，把另一个数组的所有元素直接放上去就行了（本身就是有序的） int i = 0; // 左数组的下标 int j = 0; // 右数组的下标 int k = left; // 原始数组的下标 while (i &amp;lt; leftSize &amp;amp;&amp;amp; j &amp;lt; rightSize) { if (leftVec[i] &amp;lt; rightVec[j]) { vec[k] = leftVec[i]; ++i; } else { vec[k] = rightVec[j]; ++j; } ++k; } while (i &amp;lt; leftSize) { vec[k] = leftVec[i]; ++k; ++i; } while (j &amp;lt; rightSize) { vec[k] = rightVec[j]; ++k; ++j; }}void MergeSort(vector&amp;lt;int&amp;gt;&amp;amp; vec, int left, int right) { // 分治终止条件 if (left == right) { return; } // 开始递归分治 int mid = (left + right) / 2; // 区间左闭右闭 注意不要包含重复元素 MergeSort(vec, left, mid); // 左分治 MergeSort(vec, mid + 1, right); // 右分治 // 归并 Merge(vec, left, mid, right);}间复杂度为O(nlogn)，空间复杂度为O(n)。==上面的都是基于比较的算法，时间复杂度最好情况也只能降到O(nlogn)，下面是几种非比较算法。==计数排序计数排序是对于每个元素x，找出比x小的数的个数，从而确定x在排好序的数组中的位置。此算法需要辅助数组，是以空间换时间。// 计数排序void CountSort(vector&amp;lt;int&amp;gt;&amp;amp; vec) { int n = vec.size(); // 定义计数数组 int maxNum = vec[0]; int minNum = vec[0]; for (int i = 1; i &amp;lt; n; ++i) { // 找最大值最小值就是为了确定计数数组的下标区间，也就是元素的个数 if (maxNum &amp;lt; vec[i]) { maxNum = vec[i]; } if (minNum &amp;gt; vec[i]) { minNum = vec[i]; } } vector&amp;lt;int&amp;gt; count(maxNum - minNum + 1, 0); // 定义辅助数组 vector&amp;lt;int&amp;gt; temp(n, 0); // 统计每个元素出现的次数 for (int i = 0; i &amp;lt; n; ++i) { ++count[vec[i] - minNum]; } // 找出数组中比每个元素小的个数，从而确定元素在拍好序的数组中的位置 for (int i = 1; i &amp;lt; n; ++i) { // 这里从1开始，不然i-1越界 // count数组下标就是元素，本身就是有序的 // 小于等于当前元素的个数的累加值 count[i] += count[i - 1]; } // 反向填充辅助数组 for (int i = n - 1; i &amp;gt;= 0; --i) { // 这里一定要先-1 因为数组的下标从0开始 而小于等于该元素的个数最少为1个 temp[--count[vec[i] - minNum]] = vec[i]; } // 将辅助数组的结果重新赋值给原数组 for (int i = 0; i &amp;lt; n; ++i) { vec[i] = temp[i]; }}时间复杂度为O(n+m)，空间复杂度也是O(n+m)，不适用于数据范围大以及有负数的数列。桶排序桶排序是计数排序的改进，它解决了计数排序只适用于整数排序的限制，也解决了计数排序不适用于数据范围大的限制。原理是：将序列中的最小值和最大值之间的元素分到不同的桶里，前一个桶里的元素全都小于后一个桶里的元素，这样只需要利用别的排序算法对每个桶的元素进行排序，然后把所有桶拼接起来就完成了整个序列的排序。// 捅排序// 分桶后对每个桶使用快排，桶数量为元素数量，便于分桶#include&amp;lt;list&amp;gt;void BucketSort(vector&amp;lt;int&amp;gt;&amp;amp; vec, int bucketNum) { int n = vec.size(); // 根据最大/最小元素和桶数量，计算出每个桶对应的元素范围 int maxNum = vec[0]; int minNum = vec[0]; for (int i = 1; i &amp;lt; n; ++i) { if (maxNum &amp;lt; vec[i]) { maxNum = vec[i]; } if (minNum &amp;gt; vec[i]) { minNum = vec[i]; } } int numSize = maxNum - minNum + 1; // 序列元素的个数 int bucketSize = numSize / bucketNum; // 每个桶的大小 // 初始化桶,因为要频繁插入元素,所以用list,然后所有的桶放在vector容器中 vector&amp;lt;list&amp;lt;int&amp;gt;&amp;gt; buckets; buckets.resize(bucketNum); // 遍历序列，将元素放到对应的桶里 vector&amp;lt;int&amp;gt; sortedBucket; // 存放排序序列 for (int i = 0; i &amp;lt; n; ++i) { int index = (vec[i] - minNum) / bucketSize; // 第i个元素放在第index个桶里 buckets[index].push_back(vec[i]); } // 对每个桶进行排序，这里使用快排（计数排序不能处理非负数） for (auto bucket : buckets) { // 因为快排函数是对vector处理，所以需要一个辅助容器 vector&amp;lt;int&amp;gt; temp(bucket.begin(), bucket.end()); QuickSort(temp, 0, temp.size() - 1); // 将排好序的桶拼接到排序序列后面 sortedBucket.insert(sortedBucket.end(), temp.begin(), temp.end()); } // 将有序序列赋给vec vec = sortedBucket;}时间复杂度为O(n+m)，空间复杂度也是O(n+m)。基数排序使用了桶排序中桶的思想,但它比桶排序更精简,它只需要十个桶,因为它分别对元素中不同位次进行排序。也就是说，首先对所有数的低位数进行排序，然后再对高位数进行排序，排序过程中使得原始序列逐渐趋近有序，等最高位排完之后就完全有序了。 为什么不从高位开始排序呢？因为从低位开始排序可以重复的使用那十个桶；从高位开始排序的话，在对高位相同的数继续排序时，又需要额外创建十个桶对他们进行排序，这样就相当于多少个数需要多少个桶了，空间复杂度更高，尤其是数据量比较大的时候。// 基数排序#include&amp;lt;list&amp;gt;#include&amp;lt;cmath&amp;gt;void RadixSort(vector&amp;lt;int&amp;gt;&amp;amp; vec) { int n = vec.size(); // 遍历待排序序列 找出最大值并计算出其位数 位数就是循环排序的次数 int maxNum = vec[0]; for (int i = 1; i &amp;lt; n; ++i) { if (maxNum &amp;lt; vec[i]) { maxNum = vec[i]; } } int digits = 1; // 最大值位数 while (maxNum / 10 &amp;gt; 0) { ++digits; maxNum /= 10; } // 创建10个桶 因为频繁插入元素 所以使用list容器 vector&amp;lt;list&amp;lt;int&amp;gt;&amp;gt; buckets; buckets.resize(10); // 从最低位（个位）开始每一轮的排序 for (int i = 1; i &amp;lt;= digits; ++i) { // 遍历所有元素 for (int j = 0; j &amp;lt; n; ++j) { // 计算当前元素在本轮中属于哪个桶，pow是因为每提高一位就要/10 int radix = static_cast&amp;lt;int&amp;gt;(vec[j] / pow(10, i - 1)) % 10; buckets[radix].push_back(vec[j]); } // 每完成一轮，就将桶里的元素按顺序合并放入原序列 int k = 0; for (int j = 0; j &amp;lt; 10; ++j) { for (auto elem : buckets[j]) { vec[k] = elem; ++k; } // 需要将桶清空以便下一轮的排序 buckets[j].clear(); } }}时间复杂度O(n*k)，k是最大值的位数，空间复杂度为O(m)，m是捅的个数。查找算法顺序查找查找效率O(n)，不需要额外空间。二分查找查找效率O(logn)，不需要额外空间。插值查找二分查找的改进，不一定非要按1/2处查找。哈希查找查找效率O(1)，需要额外空间，是以空间换时间。" }, { "title": "设计模式之观察者模式", "url": "/posts/Observer/", "categories": "笔记, 设计模式", "tags": "总结, 设计模式, 八股, Observer", "date": "2022-07-23 16:07:57 +0800", "snippet": "观察者（Observer）模式的定义：指多个对象间存在一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。又可以称作发布-订阅模式。优缺点有点： 降低了目标与观察者之间的耦合关系，符合依赖倒置原则。 目标与观察者之间建立了一套触发机制。缺点： 目标与观察者之间的依赖关系并没有完全解除，而且有可能出现循环引用。 当观察者对象很多时，通知的发布会花费很多时间，影响程序的效率。应用场景应用于一个对象的行为改变可能会影响其它对象的行为改变的场景。比如EXCEL中改变数据，则对应的折线图、饼状图、柱状图等都要改变。#include&amp;lt;iostream&amp;gt;#include&amp;lt;vector&amp;gt;#include&amp;lt;memory&amp;gt;using namespace std;// 观察者接口（抽象）class Observer {public: virtual void Update() = 0;};// 被观察者接口（抽象）class Subject {public: virtual void Add(Observer* ober) = 0; // 添加观察者 virtual void Remove(Observer* ober) = 0; // 移除观察者 virtual void Notify() = 0; // 通知观察者};// 具体的被观察者（实现）class ConcreteSubject : public Subject {private: vector&amp;lt;Observer*&amp;gt; observers; // 保存所有的观察者public: // 添加观察者实现 virtual void Add(Observer* ober) { observers.push_back(ober); } // 移除观察者实现 virtual void Remove(Observer* ober) { // 检查是否已经添加 auto pos = find(observers.begin(), observers.end(), ober); if (pos != observers.end()) { // 如果存在则删除 observers.erase(pos); } else { cout &amp;lt;&amp;lt; &quot;不存在该观察者&quot; &amp;lt;&amp;lt; endl; } } // 通知所有观察者更新 virtual void Notify() { for (const auto&amp;amp; ober : observers) { ober-&amp;gt;Update(); } }};// 具体的观察者1（实现）class Observer1 : public Observer {public: virtual void Update() { cout &amp;lt;&amp;lt; &quot;观察者1收到通知，准备更新。。。&quot; &amp;lt;&amp;lt; endl; }};// 具体的观察者2（实现）class Observer2 : public Observer {public: virtual void Update() { cout &amp;lt;&amp;lt; &quot;观察者2收到通知，准备更新。。。&quot; &amp;lt;&amp;lt; endl; }};int main() { // 创建被观察者 ConcreteSubject cs; // 创建观察者 Observer* ober1 = new Observer1; // 观察者1 Observer* ober2 = new Observer2; // 观察者2 // ---------------------------------------- // 使用智能指针管理 注意：所有的Observer*都要变成shared&amp;lt;Observer&amp;gt;类型 //auto ober1 = make_shared&amp;lt;Observer1&amp;gt;(); //auto ober2 = make_shared&amp;lt;Observer2&amp;gt;(); // ---------------------------------------- // 被观察者与观察者建立联系 cs.Add(ober1); cs.Add(ober2); // 通知更新 cs.Notify(); // 释放内存 delete ober1; delete ober2; return 0;}// 运行结果观察者1收到通知，准备更新。。。观察者2收到通知，准备更新。。。" }, { "title": "设计模式之工厂模式", "url": "/posts/Factory/", "categories": "笔记, 设计模式", "tags": "总结, 设计模式, 八股, Factory", "date": "2022-07-23 12:09:16 +0800", "snippet": "简单工厂模式就是创建一个工厂类，让工厂类去实例化产品对象。优缺点优点：可以降低代码的耦合度，当需要产品对象时，让工厂去生产，不必关心生产产品的具体细节，实现了创建与使用相分离。缺点：扩展性差，需要改变工厂类的代码，违反开闭原则（对扩展开放，对修改关闭）。每增加一个产品都要添加一个具体的产品类，并且在工厂类中添加一个匹配项。应用场景对于产品种类相对较少的情况，可以考虑使用简单工厂模式。#include&amp;lt;iostream&amp;gt;#include&amp;lt;string&amp;gt;using namespace std;// 产品接口（抽象）class Car {public: virtual void Show() = 0;};// 具体的产品类1（实现）class MB : public Car {public: virtual void Show() { cout &amp;lt;&amp;lt; &quot;MB Car&quot; &amp;lt;&amp;lt; endl; }};// 具体的产品类2（实现）class BMW : public Car {public: virtual void Show() { cout &amp;lt;&amp;lt; &quot;BMW Car&quot; &amp;lt;&amp;lt; endl; }};// 工厂类（创建具体的产品对象）class Factory {public: static Car* ProduceCar(string name) { if (name == &quot;奔驰&quot;) { return new MB; } else if (name == &quot;宝马&quot;) { return new BMW; } else { cout &amp;lt;&amp;lt; &quot;没有对应车型&quot; &amp;lt;&amp;lt; endl; return nullptr; } }};int main() { // 客户端 Car* car1 = Factory::ProduceCar(&quot;奔驰&quot;); car1-&amp;gt;Show(); Car* car2 = Factory::ProduceCar(&quot;宝马&quot;); car2-&amp;gt;Show(); Car* car3 = Factory::ProduceCar(&quot;奥迪&quot;); car3-&amp;gt;Show(); // 释放内存 delete car1; delete car2; delete car3; return 0;}// 运行结果MB CarBMW Car没有对应车型工厂方法模式定义一个创建对象的工厂接口，而不是一个工厂类，让子类去决定实例化哪一个对象，将实际工作交给子类。优缺点优点：解决了简单工厂模式违反开闭原则的问题。每增加一个产品只需要扩展一个具体的产品实现类和具体的工厂类即可，不用修改其它代码；符合单一职责原则，每个具体工厂类只负责创建对应的产品即可。缺点：每增加一个新产品都需要增加一个具体产品类和具体的工厂类，如果产品种类过多，会使系统变得复杂；而且工厂类只能生产一个种类的产品，想要多个种类的话需要抽象工厂模式。应用场景创建对象的任务由多个具体工厂类的某一个完成，而抽象工厂类只提供创建产品的接口，也就是不关心创建产品的具体细节，只关心是某一类产品就行了。#include&amp;lt;iostream&amp;gt;#include&amp;lt;string&amp;gt;using namespace std;// 产品接口（抽象）class Car {public: virtual void Show() = 0;};// 具体的产品类1（实现）class MB : public Car {public: virtual void Show() { cout &amp;lt;&amp;lt; &quot;MB Car&quot; &amp;lt;&amp;lt; endl; }};// 具体的产品类2（实现）class BMW : public Car {public: virtual void Show() { cout &amp;lt;&amp;lt; &quot;BMW Car&quot; &amp;lt;&amp;lt; endl; }};// 工厂接口（抽象）class Factory {public: virtual Car* ProduceCar() = 0;};// 具体的生产产品类1工厂（实现）class MBFactory : public Factory {public: virtual Car* ProduceCar() { return new MB; }};class BMWFactory : public Factory {public: virtual Car* ProduceCar() { return new BMW; }};int main() { // 客户端 Factory* car1 = new MBFactory; car1-&amp;gt;ProduceCar()-&amp;gt;Show(); Factory* car2 = new BMWFactory(); car2-&amp;gt;ProduceCar()-&amp;gt;Show(); // 释放内存 delete car1; delete car2; return 0;}抽象工厂模式给客户端提供一个接口，可以创建多个产品种类的产品对象。优缺点优点：可以创建多个产品族的产品对象，实现多等级产品的管理。缺点：产品族增加新产品时，需要修改相应的类。应用场景比如不同的汽车品牌具有多个种类的汽车产品。#include&amp;lt;iostream&amp;gt;#include&amp;lt;string&amp;gt;using namespace std;// 汽车产品类（抽象）class Car {public: virtual void Show() = 0;};// 卡车产品类（抽象）class Trunk {public: virtual void Show() = 0;};// 具体的奔驰汽车类（实现）class MBCar : public Car {public: virtual void Show() { cout &amp;lt;&amp;lt; &quot;MB Car&quot; &amp;lt;&amp;lt; endl; }};// 具体的奔驰卡车类（实现）class MBTrunk : public Trunk {public: virtual void Show() { cout &amp;lt;&amp;lt; &quot;MB Trunk&quot; &amp;lt;&amp;lt; endl; }};// 具体的宝马汽车类（实现）class BMWCar : public Car {public: virtual void Show() { cout &amp;lt;&amp;lt; &quot;BMW Car&quot; &amp;lt;&amp;lt; endl; }};// 具体的宝马卡车类（实现）class BMWTrunk : public Trunk {public: virtual void Show() { cout &amp;lt;&amp;lt; &quot;BMW Trunk&quot; &amp;lt;&amp;lt; endl; }};// 工厂接口（抽象）class Factory {public: virtual Car* ProduceCar() = 0; virtual Trunk* ProduceTrunk() = 0;};// 奔驰工厂类：生产所有的奔驰类产品而非单一的产品（实现）class MBFactory : public Factory {public: virtual Car* ProduceCar() { return new MBCar; } virtual Trunk* ProduceTrunk() { return new MBTrunk; }};// 宝马工厂类：生产所有的宝马类产品而非单一的产品（实现）class BMWFactory : public Factory {public: virtual Car* ProduceCar() { return new BMWCar; } virtual Trunk* ProduceTrunk() { return new BMWTrunk; }};int main() { // 客户端 Factory* car1 = new MBFactory(); car1-&amp;gt;ProduceCar()-&amp;gt;Show(); car1-&amp;gt;ProduceTrunk()-&amp;gt;Show(); Factory* car2 = new BMWFactory(); car2-&amp;gt;ProduceCar()-&amp;gt;Show(); car2-&amp;gt;ProduceTrunk()-&amp;gt;Show(); // 释放内存 delete car1; delete car2; return 0;}// 运行结果MB CarMB TrunkBMW CarBMW Trunk" }, { "title": "设计模式之单例模式", "url": "/posts/Singleton/", "categories": "笔记, 设计模式", "tags": "总结, 设计模式, 八股, Singleton", "date": "2022-07-22 22:09:55 +0800", "snippet": "什么是单例模式单例模式就是一个类只能产生一个实例。单例模式的特点 单例类只有一个实例对象 该单例对象必须由单例类自行创建； 单例类对外提供一个访问该单例的全局访问点单例模式的优缺点：优点： 可以设置全局访问点，优化和共享资源访问 可以避免对资源的多重占用 由于系统内存中只存在一个对象，所以可以节约系统资源，提高性能缺点： 单例模式一般没有接口，扩展困难。 单例模式不利与代码测试。在调试过程中，如果单例中的代码没有执行完，不能模拟生成一个新的对象。 与单一职责原则有冲突。原因：一个类应该只实现一个逻辑，而不关心它是否是单例，是不是要单例取决于环境；单例模式把“要单例”和业务逻辑融合在一个类。单例模式的使用场景 系统只需要一个实例对象，比如，配置信息类，如系统要求提供一个唯一的序列号生成器或资源管理器，或者需要考虑资源消耗太大而只允许创建一个对象。 调用类的单个实例只允许使用一个公共访问点，除了该公共访问点，不能通过其他途径访问该实例比如Windows任务管理器只能启动一个，这就是单例模式的使用。单例模式实现懒汉式单例（线程不安全）懒汉式单例就是需要使用这个单例对象的时候才去创建这个单例对象。#include&amp;lt;iostream&amp;gt;#include&amp;lt;thread&amp;gt;#include&amp;lt;mutex&amp;gt;#include&amp;lt;windows.h&amp;gt;using namespace std;class Singleton {private: // 私有化构造函数 Singleton() {} // 构造函数 ~Singleton() {} // 析构函数 Singleton(const Singleton&amp;amp; s) {} // 拷贝构造函数 Singleton&amp;amp; operator=(const Singleton&amp;amp; s) {} // 拷贝赋值构造函数 // 静态成员变量 static Singleton* singleton;public: // 静态成员函数 static Singleton* GetInstance() { if (Singleton::singleton == nullptr) { Sleep(1000); // 模拟创建实例的时间 singleton = new Singleton(); } return singleton; }};// 静态成员变量必须类外初始化Singleton* Singleton::singleton = nullptr;// 定义一个互斥锁mutex m;void PrintAddress() { // 获取实例 Singleton* singleton1 = Singleton::GetInstance(); // 打印singleton1地址 加锁保证只有一个线程在打印地址 m.lock(); cout &amp;lt;&amp;lt; singleton1 &amp;lt;&amp;lt; endl; m.unlock(); }int main() { thread threads[10]; // 创建10个线程 for (auto&amp;amp; t : threads) { t = thread(PrintAddress); } // 对每个线程调用join 主线程等待子线程完成运行 for (auto&amp;amp; t : threads) { t.join(); } return 0;}// 运行结果000001B8BD907270000001B8BD906DF0000001B8BD906EB0000001B8BD906EF0000001B8BD906F30000001B8BD906FF0000001B8BD906F70000001B8BD907070000001B8BD907130000001B8BD91FA40可以看出打印出来的地址并不是完全一样，这种单例模式不是线程安全的。原因是，当几个线程同时执行到语句if (Singleton::singleton == nullptr)时，singleton都还没创建，所以就重复创建了几个实例。注意：C++中没有自带与平台无关的sleep()函数，因此在Linux和Windows平台下，使用sleep()将进程挂起的方式是不同的。 在Linux下包含头文件#include，然后使用sleep()函数，参数为秒，s是小写。 在Windows下包含头文件#include ，然后使用Sleep()函数，参数为毫秒，S是大写。懒汉式单例（线程安全）==直接加锁GetInstance函数==我们可以通过加锁来解决上面的问题，保证同时只有一个线程访问GetInstance函数。mutex m; // 创建锁class Singleton {private: // 私有化构造函数 Singleton() {} // 构造函数 ~Singleton() {} // 析构函数 Singleton(const Singleton&amp;amp; s) {} // 拷贝构造函数 Singleton&amp;amp; operator=(const Singleton&amp;amp; s) {} // 拷贝赋值构造函数 // 静态成员变量 static Singleton* singleton;public: // 静态成员函数 static Singleton* GetInstance() { m.lock(); // if (Singleton::singleton == nullptr) { Sleep(1000); // 模拟创建实例的时间 singleton = new Singleton(); } m.unlock(); return singleton; }};// 运行结果000001DCA3F76B30000001DCA3F76B30000001DCA3F76B30000001DCA3F76B30000001DCA3F76B30000001DCA3F76B30000001DCA3F76B30000001DCA3F76B30000001DCA3F76B30000001DCA3F76B30可以发现，所有线程获取到的实例的地址都相同。整个程序中只有一个Singleton实例。原因是进入GetInstance函数之后，立马锁住创建实例的语句，保证只有一个线程在访问创建实例的代码。当一个线程创建之后，后续线程再访问时，Singleton::singleton就不为空了，这是一个静态成员变量，所以只存在这一个实例，后续的线程时共享这个实例。==仅仅加锁创建实例的语句==如果仅仅是对创建实例的语句进行加锁，线程时不安全的，因为当线程同时执行到语句if (Singleton::singleton == nullptr)时，singleton都还没有被创建，故会条件为真，多个线程都会创建实例，尽管不是同时创建。// 其它部分代码相同//m.lock();if (Singleton::singleton == nullptr) { Sleep(1000); // 模拟创建实例的时间 m.lock(); singleton = new Singleton(); m.unlock();}//m.unlock();// 运行结果0000016176586E700000016176586E700000016176586E7000000161765871F00000016176586EB0000001617658723000000161765872F000000161765866B000000161765866B0000001617659D7A0为了解决这个问题，需要在加锁后再次判断实例是否为空，如果为空就创建实例。称之为双检锁，使用双检锁的好处就是只有实例为空时才加锁，而不是每次调用创建实例的函数都加锁。这样可以较少加锁的开销。// 其它部分代码相同//m.lock();if (Singleton::singleton == nullptr) { Sleep(1000); // 模拟创建实例的时间 m.lock(); if (Singleton::singleton == nullptr) { singleton = new Singleton(); } m.unlock();}//m.unlock();// 运行结果000001D4601A6630000001D4601A6630000001D4601A6630000001D4601A6630000001D4601A6630000001D4601A6630000001D4601A6630000001D4601A6630000001D4601A6630000001D4601A6630懒汉式单例（内存安全）上述new对象之后如果忘记释放内存的话会出现内存泄漏的问题。最直观的想法就是在类内定义一个释放实例的静态成员函数，在使用完实例之后，手动调用释放即可。#include&amp;lt;iostream&amp;gt;#include&amp;lt;thread&amp;gt;#include&amp;lt;mutex&amp;gt;#include&amp;lt;windows.h&amp;gt;using namespace std;mutex m;class Singleton {private: // 私有化构造函数 Singleton() { cout &amp;lt;&amp;lt; &quot;构造函数&quot; &amp;lt;&amp;lt; endl; } // 构造函数 ~Singleton() { cout &amp;lt;&amp;lt; &quot;析构函数&quot; &amp;lt;&amp;lt; endl; } // 析构函数 Singleton(const Singleton&amp;amp; s) {} // 拷贝构造函数 Singleton&amp;amp; operator=(const Singleton&amp;amp; s) {} // 拷贝赋值构造函数 // 静态成员变量 static Singleton* singleton;public: ------------------------------------------------ // 释放内存资源 static void delInstance() { if (singleton != nullptr) { delete singleton; singleton = nullptr; } } ------------------------------------------------ // 静态成员函数 static Singleton* GetInstance() { if (Singleton::singleton == nullptr) { Sleep(1000); // 模拟创建实例的时间 m.lock(); if (Singleton::singleton == nullptr) { singleton = new Singleton(); } m.unlock(); } return singleton; }};// 静态成员变量必须类外初始化Singleton* Singleton::singleton = nullptr;// 定义一个互斥锁mutex m1;void PrintAddress() { // 获取实例 Singleton* singleton1 = Singleton::GetInstance(); // 打印singleton1地址 加锁保证只有一个线程在打印地址 m1.lock(); cout &amp;lt;&amp;lt; singleton1 &amp;lt;&amp;lt; endl; m1.unlock();}int main() { thread threads[10]; // 创建10个线程 for (auto&amp;amp; t : threads) { t = thread(PrintAddress); } // 对每个线程调用join 主线程等待子线程完成运行 for (auto&amp;amp; t : threads) { t.join(); } ------------------------------------- Singleton::delInstance(); // 手动释放 ------------------------------------- return 0;}// 运行结果构造函数000002C242B47370000002C242B47370000002C242B47370000002C242B47370000002C242B47370000002C242B47370000002C242B47370000002C242B47370000002C242B47370000002C242B47370析构函数也可以使用智能指针管理动态内存，但是智能指针无法调用私有的析构函数，shared_ptr在定义的时候可以指定删除器（deleter），所以我们在使用的时候自己指定一个删除器就好了。给shared_ptr添加自定义删除器的几种方式// 注意代码的变化#include&amp;lt;iostream&amp;gt;#include&amp;lt;thread&amp;gt;#include&amp;lt;mutex&amp;gt;#include&amp;lt;windows.h&amp;gt;#include&amp;lt;memory&amp;gt;using namespace std;mutex m;class Singleton {private: // 私有化构造函数 Singleton() { cout &amp;lt;&amp;lt; &quot;调用构造函数&quot; &amp;lt;&amp;lt; endl; } // 构造函数 ~Singleton() { cout &amp;lt;&amp;lt; &quot;调用析构函数&quot; &amp;lt;&amp;lt; endl; } // 析构函数 Singleton(const Singleton&amp;amp; s) = delete; // 拷贝构造函数 Singleton&amp;amp; operator=(const Singleton&amp;amp; s) = delete; // 拷贝赋值构造函数 static void Destory(Singleton* obj) { // 自定义删除器 delete obj; } // 静态成员变量 static shared_ptr&amp;lt;Singleton&amp;gt; singleton;public: // 静态成员函数 static shared_ptr&amp;lt;Singleton&amp;gt; GetInstance() { //m.lock(); if (Singleton::singleton == nullptr) { Sleep(1000); // 模拟创建实例的时间 m.lock(); if (Singleton::singleton == nullptr) { // new创建对象 //singleton = new Singleton(); // 析构函数保持私有化 自己写删除器 //shared_ptr&amp;lt;Singleton&amp;gt; singleton(new Singleton(), Singleton::Destory); } m.unlock(); } //m.unlock(); return singleton; }};// 静态成员变量必须类外初始化shared_ptr&amp;lt;Singleton&amp;gt; Singleton::singleton = nullptr;// 定义一个互斥锁mutex m1;void PrintAddress() { // 获取实例 shared_ptr&amp;lt;Singleton&amp;gt; singleton1 = Singleton::GetInstance(); // 打印singleton1地址 加锁保证只有一个线程在打印地址 m1.lock(); cout &amp;lt;&amp;lt; singleton1 &amp;lt;&amp;lt; endl; m1.unlock(); }int main() { thread threads[10]; // 创建10个线程 for (auto&amp;amp; t : threads) { t = thread(PrintAddress); } // 对每个线程调用join 主线程等待子线程完成运行 for (auto&amp;amp; t : threads) { t.join(); } return 0;}饿汉式单例（线程安全）先实例化该单例类，而不是像之前一样初始化为空指针，饿汉式单例本身就是线程安全的。// 其它代码不变class Singleton {private: // 私有化构造函数 Singleton() { cout &amp;lt;&amp;lt; &quot;调用构造函数&quot; &amp;lt;&amp;lt; endl; } // 构造函数 ~Singleton() { cout &amp;lt;&amp;lt; &quot;调用析构函数&quot; &amp;lt;&amp;lt; endl; } // 析构函数 Singleton(const Singleton&amp;amp; s) = delete; // 拷贝构造函数 Singleton&amp;amp; operator=(const Singleton&amp;amp; s) = delete; // 拷贝赋值构造函数 // 静态成员变量 static Singleton* singleton;public: // 静态成员函数 static Singleton* GetInstance() { return singleton; }};// 静态成员变量必须类外初始化Singleton* Singleton::singleton = new Singleton();饿汉式单例模式的内存安全可以使用上述同样的方法。" }, { "title": "OS相关知识整理", "url": "/posts/OS-knowledge/", "categories": "笔记, OS", "tags": "总结, 操作系统, 八股, OS", "date": "2022-07-22 11:48:55 +0800", "snippet": "硬件结构图灵机的基本组成、工作方式图灵机的基本组成？ 有一条「纸带」，纸带由一个个连续的格子组成，每个格子可以写入字符，纸带就好比内存，而纸带上的格子的字符就好比内存中的数据或程序； 有一个「读写头」，读写头可以读取纸带上任意格子的字符，也可以把字符写入到纸带的格子； 读写头上有一些部件，比如存储单元、控制单元以及运算单元： 1、存储单元用于存放数据； 2、控制单元用于识别字符是数据还是指令，以及控制程序的流程等； 3、运算单元用于执行运算指令；图灵机的工作方式、工作原理、执行过程？ 首先，读写头将数据先写入到纸带上的格子中； 然后，读取格子中的内容到存储设备中，这个存储设备称为图灵机的状态，控制单元用来识别字符是数据还是指令，如果是数据就存入状态中，碰到运算指令就会通知运算单元工作； 接着，运算单元读入数据，然后执行运算指令，并将结果存放到状态中； 最后，运算单元将结果返回给控制单元，控制单元将结果传输给读写头，读写头继续移动把结果 3写入到纸带的格子中。冯诺依曼模型冯诺依曼定义计算机基本结构为5个部分，其基本结构是？ 运算器，在CPU中； 控制器，在CPU中； 存储器，即内存； 输入设备，键盘、鼠标等； 输出设备，显示器等。内存？程序和数据存储在内存中，存储的区域是线性的。计算机最小的存储单位是字节byte，1 byte=8 bit,每一个字节都对应一个内存地址。内存的地址是从 0 开始编号的，然后自增排列，最后一个地址为内存总字节数 - 1，所以内存读写任何一个数据的速度都是一样的。中央处理器CPU？32位、64 位 CPU 最主要区别在于一次能计算多少字节数据，之所以这样设计，是为了能计算更大的数值： 32 位 CPU 一次可以计算 4 个字节。 64 位 CPU 一次可以计算 8 个字节。CPU 内部常见组件： 寄存器，不同种类寄存器的功能不尽相同。 控制单元，负责控制 CPU 工作。 逻辑运算单元，负责计算。常见的寄存器种类： 通用寄存器，用来存放需要进行运算的数据，比如需要进行加和运算的两个数据。 程序计数器，用来存储 CPU 要执行下一条指令「所在的内存地址」，注意不是存储了下一条要执行的指令，此时指令还在内存中，程序计数器只是存储了下一条指令的地址。 指令寄存器，用来存放程序计数器指向的指令，也就是指令本身，指令被执行完成之前都存储在这里。总线？总线的作用： 用于 CPU 和内存以及其他设备之间的通信。总线分类： 地址总线，用于指定 CPU 将要操作的内存地址； 数据总线，用于读写内存的数据； 控制总线，用于发送和接收信号，比如中断、设备复位等信号，CPU 收到信号后自然进行响应，这时也需要控制总线；CPU使用总线读写内存数据的流程： 首先要通过「地址总线」来指定内存的地址； 然后通过「控制总线」控制是读或写命令； 最后通过「数据总线」来传输数据；线路位宽与 CPU 位宽线路位宽： 就是线路的条数，数据通过电压高低来表示二进制数据，一条线路每次只能传送1位数据，即0或1，称为串行通信，想要一次传送一些数据，就需要多条线路并行通信。比如 CPU想要操作4 G大的内存，那么就需要 32 条地址总线，因为 2 ^ 32 = 4G。CPU位宽： 就是一次能够处理的数据位数。程序执行的基本过程CPU 执行程序的过程？ 第一步，CPU 读取「程序计数器」的值，这个值是指令的内存地址，然后 CPU 的「控制单元」操作「地址总线」指定需要访问的内存地址，接着通知内存设备准备数据，数据准备好后通过「数据总线」将指令数据传给 CPU，CPU 收到内存传来的数据后，将这个指令数据存入到「指令寄存器」。 第二步，CPU 分析「指令寄存器」中的指令，确定指令的类型和参数，如果是计算类型的指令，就把指令交给「逻辑运算单元」运算；如果是存储类型的指令，则交由「控制单元」执行； 第三步，CPU 执行完指令后，「程序计数器」的值自增，表示指向下一条指令。这个自增的大小，由 CPU 的位宽决定，比如 32 位的 CPU，指令是 4 个字节，需要 4 个内存地址存放，因此「程序计数器」的值会自增 4；CPU 的指令周期？ CPU 从程序计数器读取指令、到执行、再到下一条指令，这个不断循环的过程即为指令周期。 CPU 通过程序计数器读取对应内存地址的指令，这个部分称为 Fetch（取得指令）； CPU 对指令进行解码，这个部分称为 Decode（指令译码）； CPU 执行指令，这个部分称为 Execution（执行指令）； CPU 将计算结果存回寄存器或者将寄存器的值存入内存，这个部分称为 Store（数据回写）；事实上，不同的阶段是由计算机中的不同组件完成： 取指令的阶段，我们的指令是存放在存储器里的，实际上，通过程序计数器和指令寄存器取出指令的过程，是由控制器操作的； 指令的译码过程，也是由控制器进行的； 指令执行的过程，无论是进行算术操作、逻辑操作，还是进行数据传输、条件分支操作，都是由算术逻辑单元操作的，也就是由运算器处理的。但是如果是一个简单的无条件地址跳转，则是直接在控制器里面完成的，不需要用到运算器。指令的类型？指令从功能角度划分，可以分为 5 大类： 数据传输类型的指令，比如 store/load 是寄存器与内存间数据传输的指令，mov 是将一个内存地址的数据移动到另一个内存地址的指令； 运算类型的指令，比如加减乘除、位运算、比较大小等等，它们最多只能处理两个寄存器中的数据； 跳转类型的指令，通过修改程序计数器的值来达到跳转执行指令的过程，比如编程中常见的 if-else、swtich-case、函数调用等。 信号类型的指令，比如发生中断的指令 trap； 闲置类型的指令，比如指令 nop，执行后 CPU 会空转一个周期；如何让程序跑的更快？程序的CPU执行时间=CPU时钟周期数*时钟周期时间。CPU是时钟周期数=指令数*每条指令的平均时钟周期数（Cycles Per Instruction，简称 CPI）。所以，需要优化一下三方面： 指令数，表示执行程序所需要多少条指令，以及哪些指令。这个层面是基本靠编译器来优化，毕竟同样的代码，在不同的编译器，编译出来的计算机指令会有各种不同的表示方式。 每条指令的平均时钟周期数 CPI，表示一条指令需要多少个时钟周期数，现代大多数 CPU 通过流水线技术（Pipeline），让一条指令需要的 CPU 时钟周期数尽可能的少； 时钟周期时间，表示计算机主频，取决于计算机硬件。有的 CPU 支持超频技术，打开了超频意味着把 CPU 内部的时钟给调快了，于是 CPU 工作速度就变快了，但是也是有代价的，CPU 跑的越快，散热的压力就会越大，CPU 会很容易奔溃。64 位相比 32 位 CPU 的优势在哪吗？64 位 CPU 的计算性能一定比 32 位 CPU 高很多吗？64 位相比 32 位 CPU 的优势主要体现在两个方面： 64 位 CPU 可以一次计算超过 32 位的数字，而 32 位 CPU 如果要计算超过 32 位的数字，要分多步骤进行计算，效率就没那么高，但是大部分应用程序很少会计算那么大的数字，所以只有运算大数字的时候，64 位 CPU 的优势才能体现出来，否则和 32 位 CPU 的计算性能相差不大。 64 位 CPU 可以寻址更大的内存空间，32 位 CPU 最大的寻址地址是 4 G，即使你加了 8 G 大小的内存，也还是只能寻址到 4 G，而 64 位 CPU 最大寻址地址是 2^64，远超于 32 位 CPU 最大寻址地址的 2^32。你知道软件的 32 位和 64 位之间的区别吗？再来 32 位的操作系统可以运行在 64 位的电脑上吗？64 位的操作系统可以运行在 32 位的电脑上吗？如果不行，原因是什么？64 位和、32 位软件，代表指令是 64 位还是 32 位的： 如果 32 位指令在 64 位机器上执行，需要一套兼容机制，就可以做到兼容运行了。但是如果 64 位指令在 32 位机器上执行，就比较困难了，因为 32 位的寄存器存不下 64 位的指令； 操作系统其实也是一种程序，我们也会看到操作系统会分成 32 位操作系统、64 位操作系统，其代表意义就是操作系统中程序的指令是多少位，比如 64 位操作系统，指令也就是 64 位，因此不能装在 32 位机器上。存储器的层次结构速度快的存储器的容量都比较小？ 对于存储器，它的速度越快，能耗会越高，而且材料的成本也是越贵的。存储器的层次结构？ 寄存器，CPU中； 缓存（cache），L1、L2、L3，CPU中； 内存； 固态硬盘（SSD）、机械硬盘（HDD）。寄存器？寄存器是最靠近 CPU 的控制单元和逻辑计算单元的存储器，使用材料速度是最快的，因此价格也是最贵的。寄存器的数量通常在几十到几百之间，每个寄存器可以用来存储一定的字节的数据，比如： 32 位 CPU 中大多数寄存器可以存储 4 个字节； 64 位 CPU 中大多数寄存器可以存储 8 个字节寄存器的访问速度非常快，一般要求在半个 CPU 时钟周期内完成读写。CPU 时钟周期跟 CPU 主频息息相关。CPU缓存？CPU Cache 用的是一种叫 SRAM（Static Random-Access Memory，静态随机存储器） 的芯片。SRAM 之所以叫「静态」存储器，是因为只要有电，数据就可以保持存在，而一旦断电，数据就会丢失了。在SRAM 里面，一个 bit 的数据，通常需要 6 个晶体管。CPU 的高速缓存，通常可以分为 L1、L2、L3 这样的三层高速缓存，也称为一级缓存、二次缓存、三次缓存。L1 高速缓存？L1 高速缓存的访问速度几乎和寄存器一样快，通常只需要 2~4 个时钟周期，而大小在几十 KB 到几百 KB 不等。每个 CPU 核心都有一块属于自己的 L1 高速缓存，指令和数据在 L1 是分开存放的，所以 L1 高速缓存通常分成指令缓存和数据缓存。L2高速缓存？L2 高速缓存同样每个 CPU 核心都有，但是 L2 高速缓存位置比 L1 高速缓存距离 CPU 核心 更远，它大小比 L1 高速缓存更大，CPU 型号不同大小也就不同，通常大小在几百 KB 到几 MB 不等，访问速度则更慢，速度在 10~20 个时钟周期。L3高速缓存？L3 高速缓存通常是多个 CPU 核心共用的，位置比 L2 高速缓存距离 CPU 核心 更远，大小也会更大些，通常大小在几 MB 到几十 MB 不等，具体值根据 CPU 型号而定。访问速度相对也比较慢一些，访问速度在 20~60个时钟周期。内存？内存用的芯片和 CPU Cache 有所不同，它使用的是一种叫作 DRAM （Dynamic Random Access Memory，动态随机存取存储器） 的芯片。相比 SRAM，DRAM 的密度更高，功耗更低，有更大的容量，而且造价比 SRAM 芯片便宜很多。DRAM 存储一个 bit 数据，只需要一个晶体管和一个电容就能存储，但是因为数据会被存储在电容里，电容会不断漏电，所以需要「定时刷新」电容，才能保证数据不会被丢失，这就是 DRAM 之所以被称为「动态」存储器的原因，只有不断刷新，数据才能被存储起来。断电后仍然会丢失数据。DRAM 的数据访问电路和刷新电路都比 SRAM 更复杂，所以访问的速度会更慢，内存速度大概在 200~300 个 时钟周期之间。SSD/HDD 硬盘？固体硬盘，结构和内存类似，但是它相比内存的优点是断电后数据还是存在的，而内存、寄存器、高速缓存断电后数据都会丢失，但是读写速度比内存慢。械硬盘HDD，它是通过物理读写的方式来访问数据，因此它访问速度是非常慢的。存储器的层次关系：存储器层次结构是分级的，每个存储器只和相邻的一层存储器设备打交道，并且存储设备为了追求更快的速度，所需的材料成本必然也是更高，也正因为成本太高，所以 CPU 内部的寄存器、L1\\L2\\L3 Cache 只好用较小的容量，相反内存、硬盘则可用更大的容量，另外，当 CPU 需要访问内存中某个数据的时候，如果寄存器有这个数据，CPU 就直接从寄存器取数据即可，如果寄存器没有这个数据，CPU 就会查询 L1 高速缓存，如果 L1 没有，则查询 L2 高速缓存，L2 还是没有的话就查询 L3 高速缓存，L3 依然没有的话，才去内存中取数据。CPU Cache 的数据结构和读取过程是什么样的？缓存块（cache line）？ CPU缓存的数据是从内存中读取过来的，它是按块读取数据的，而不是按照单个元素来读取数据，因此称之为缓存块。内存块（block）? CPU访问内存数据时，也是按块读取，称之为内存块，读取的时候我们要拿到数据所在内存块的地址。CPU如何找到 Cache 对应的数据呢？直接映射：通过取模运算，将内存块的地址始终映射在一个CPU缓存块地址。CPU缓存数据结构？ 组标记：记录缓存块中存储的数据对应的内存块，我们可以用这个组标记来区分不同的内存块。 索引：通过内存地址索引，找出对应的缓存地址。 有效位：它是用来标记对应的缓存中的数据是否是有效的，如果有效位是 0，无论 缓存中是否有数据，CPU 都会直接访问内存，重新加载数据。 数据块：从内存加载过来的实际存放数据。 偏移量：CPU 在从 CPU Cache 读取数据的时候，并不是读取 CPU Line 中的整个数据块，而是读取 CPU 所需要的一个数据片段，这样的数据统称为一个字。那通过偏移量在对应的缓存数据块中找到所需的字。CPU访问缓存步骤？ 根据内存地址中索引信息，计算在 CPU Cahe 中的索引，也就是找出对应的 CPU line 的地址； 找到对应 CPU Line 后，判断 CPU Line 中的有效位，确认 CPU Line 中数据是否是有效的，如果是无效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执行； 对比内存地址中组标记和 CPU Line 中的组标记，确认 CPU Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执行； 根据内存地址中偏移量信息，从 CPU Line 的数据块中，读取对应的字。如何写出让 CPU 跑得更快的代码？访问的数据在 CPU Cache 中的话，意味着缓存命中，缓存命中率越高的话，代码的性能就会越好，CPU 跑的越快。 对于数据缓存，我们在遍历数据的时候，应该按照内存布局的顺序操作，这是因为 CPU Cache 是根据 CPU Cache Line 批量操作数据的，所以顺序地操作连续内存数据时，性能能得到有效的提升； 对于指令缓存，有规律的条件分支语句能够让 CPU 的分支预测器发挥作用，进一步提高执行的效率如何提升多核 CPU 的缓存命中率？现代CPU 都是多核心的，线程可能在不同 CPU 核心来回切换执行，这对 CPU Cache 不是有利的，虽然 L3 Cache 是多核心之间共享的，但是 L1 和 L2 Cache 都是每个核心独有的，如果一个线程在不同核心来回切换，各个核心的缓存命中率就会受到影响，相反如果线程都在同一个核心上执行，那么其数据的 L1 和 L2 Cache 的缓存命中率可以得到有效提高，缓存命中率高就意味着 CPU 可以减少访问 内存的频率。当有多个同时执行「计算密集型」的线程，为了防止因为切换到不同的核心，而导致缓存命中率下降的问题，我们可以把线程绑定在某一个 CPU 核心上，这样性能可以得到非常可观的提升。CPU 缓存一致性CPU Cache 的数据写入CPU Cache 通常分为三级缓存：L1 Cache、L2 Cache、L3 Cache，级别越低的离 CPU 核心越近，访问速度也快，但是存储容量相对就会越小。其中，在多核心的 CPU 里，每个核心都有各自的 L1/L2 Cache，而 L3 Cache 是所有核心共享使用的。CPU读取数据的时候，我们希望高命中率。写数据之后，cache和内存数据就不一致了，这时候就需要将cache中的数据同步到内存里。下面是两种数据写入方式： 写直达（Write Through） 写回（Write Back）==写直达==保持内存与 Cache 一致性最简单的方式是，把数据同时写入内存和 Cache 中，这种方法称为写直达。在这个方法里，写入前会先判断数据是否已经在 CPU Cache 里面了： 如果数据已经在 Cache 里面，先将数据更新到 Cache 里面，再写入到内存里面； 如果数据没有在 Cache 里面，就直接把数据更新到内存里面。写直达很简单，但是每次写操作都要写回到内存，会影响性能。==写回==在写回机制中，当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中，减少了数据写回内存的频率，这样便可以提高系统的性能。在把数据写入到 Cache 的时候，只有在缓存不命中，同时数据对应的 Cache 中的 Cache Block 为脏标记的情况下，才会将数据写到内存中，而在缓存命中的情况下，则在写入后 Cache 后，只需把该数据对应的 Cache Block 标记为脏即可，而不用写到内存里。缓存一致性问题现在 CPU 都是多核的，由于 L1/L2 Cache 是多个核心各自独有的，那么会带来多核心的缓存一致性问题，具体就是某个核心修改了数据，但是还没有写入到内存，而另一个核心就读取了数据，导致缓存数据不一致。要解决这一问题，就需要一种机制，来同步两个不同核心里面的缓存数据： 第一点，某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为写传播 第二点，某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为事务的串形化总线嗅探写传播的原则就是当某个 CPU 核心更新了 Cache 中的数据，要把该事件广播通知到其他核心。最常见实现的方式是总线嗅探。总线嗅探就是总线将事务广播给其它所有核心，每个核心监听总线上的广播时间，然后根据接收到的时间进行数据操作。很简单，缺点是CPU需要时刻监听总线上的一切活动，只要有数据操作，总线都要发出广播时间，会加重CPU和总线的负担。而且总线嗅探不能保证事务的串行化。MESI 协议基于总线嗅探机制实现了事务串形化，也用状态机机制降低了总线带宽压力，可以做到 CPU 缓存一致性。MESI 协议MESI 协议其实是 4 个状态单词的开头字母缩写，分别是： Modified，已修改 Exclusive，独占 Shared，共享 Invalidated，已失效这四个状态来标记 Cache Line 四个不同的状态。「已修改」状态就是脏标记，代表该 Cache Block 上的数据已经被更新过，但是还没有写到内存里。而「已失效」状态，表示的是这个 Cache Block 里的数据已经失效了，不可以读取该状态的数据。「独占」和「共享」状态都代表 Cache Block 里的数据是干净的，也就是说，这个时候 Cache Block 里的数据和内存里面的数据是一致性的。「独占」和「共享」的差别在于，独占状态的时候，数据只存储在一个 CPU 核心的 Cache 里，而其他 CPU 核心的 Cache 没有该数据。这个时候，如果要向独占的 Cache 写数据，就可以直接自由地写入，而不需要通知其他 CPU 核心，因为只有独占的cache有这个数据，就不存在缓存一致性的问题了，所以可以随便操作该数据。在「独占」状态下的数据，如果有其他核心从内存读取了相同的数据到各自的 Cache ，那么这个时候，独占状态下的数据就会变成共享状态。「共享」状态代表着相同的数据在多个 CPU 核心的 Cache 里都有，所以当我们要更新 Cache 里面的数据的时候，不能直接修改，而是要先向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后再更新当前 Cache 里面的数据。整个 MSI 状态的变更，则是根据来自本地 CPU 核心的请求，或者来自其他 CPU 核心通过总线传输过来的请求，从而构成一个流动的状态机。另外，对于在「已修改」或者「独占」状态的 Cache Line，修改更新其数据不需要发送广播给其他 CPU 核心，可以在一定程度上减少总线带宽压力。什么是软中断？==中断是什么？==中断是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。==什么是软中断？==中断请求的处理程序应该要短且快，这样才能减少对正常进程运行调度的影响，而且中断处理程序可能会暂时关闭中断，所以如果中断处理程序执行时间过长，可能在还未执行完就丢失当前其他设备的中断请求。Linux 系统为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」： 上半部用来快速处理中断，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或时间敏感的事情。 下半部用来延迟处理上半部未完成的工作，一般以「内核线程」的方式运行。所以，中断处理程序的上部分和下半部可以理解为： 上半部直接处理硬件请求，也就是硬中断，主要是负责耗时短的工作，特点是快速执行； 下半部是由内核触发，也就说软中断，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行。还有一个区别，硬中断（上半部）是会打断 CPU 正在执行的任务，然后立即执行中断处理程序，而软中断（下半部）是以内核线程的方式执行，并且每一个 CPU 都对应一个软中断内核线程==怎么查看软中断？==在 Linux 系统里，我们可以通过查看 cat /proc/softirqs 的 内容来知晓「软中断」的运行情况，软中断是以内核线程的方式执行的，也可以用 ps 命令查看到，以及 cat /proc/interrupts 的 内容来知晓「硬中断」的运行情况。为什么 0.1 + 0.2 不等于 0.3 ？==为什么负数要用补码表示？==十进制转换为二进制是除二取余法，二进制在计算机中最高位为符号位（正数为0，负数为1），剩下的则是表示数据位。负数在计算机中以补码形式表示，补码就是把整数的二进制全部取反再加1。因为用了补码的表示方式，对于负数的加减法操作，就和正数加减法操作一样了，运算过程简单。==十进制小数与二进制的转换==乘 2 取整法：将十进制中的小数部分乘以 2 作为二进制的一位，然后继续取小数部分乘以 2 作为下一位，直到不存在小数为止。但是并不是所有的小数都可以用二进制表示，比如0.1转换为二进制是无限循环的，由于计算机的资源是有限的，所以没有办法用二进制精确表示0.1，只能用近似的方法，所以会造成精度确实的情况。二进制小数转十进制时，需要注意小数点后面的指数幂是负数。==计算机是怎么存小数的？==计算机存储小数时用浮点数，并且使用科学计数法。比如float（单精度浮点数，32位浮点数）的有效数字时7-8位，double（双精度浮点数，64位浮点数）有效数字是15-16位。==0.1 + 0.2 == 0.3 ?==由于计算机的资源是有限的，所以并不是所有的小数都可以用完整的二进制来表示，计算机智能采用近似数的方式来保存，那两个近似数相加，得到的也是一个近似数，所以0.1+0.2不等于0.3。操作系统结构Linux 内核 vs Windows 内核==什么是内核呢？==计算机是由各种外部硬件设备组成的，如果每个应用都要和这些硬件设备对接通信协议那太麻烦了，所以让内核作为应用连接硬件设备的桥梁，应用程序只需关心与内核交互，不用关心硬件的细节。==内核有哪些能力呢？==现代操作系统，内核一般会提供 4 个基本能力： 管理进程、线程，决定哪个进程、线程使用 CPU，也就是进程调度的能力； 管理内存，决定内存的分配和回收，也就是内存管理的能力； 管理硬件设备，为进程与硬件设备之间提供通信能力，也就是硬件通信能力； 提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与操作系统之间的接口。==内核是怎么工作的？==大多数操作系统，把内存分成了两个区域： 内核空间，这个内存空间只有内核程序可以访问； 用户空间，这个内存空间专门给应用程序使用；用户空间的代码只能访问一个局部的内存空间，而内核空间的代码可以访问所有内存空间。因此，当程序使用用户空间时，就是在用户态执行，而当程序使内核空间时，就是在内核态执行。应用程序如果需要进入内核空间，就需要系统调用，当应用程序使用系统调用时，会产生一个中断。发生中断后， CPU 会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作。==常见内核架构== 宏内核，包含多个模块，整个内核像一个完整的程序； 微内核，有一个最小版本的内核，一些模块和服务则由用户态管理； 混合内核，是宏内核和微内核的结合体，内核中抽象出了微内核的概念，也就是内核中会有一个小型的内核，其他模块就在这个基础上搭建，整个内核是个完整的程序；==Linux和Windows内核的区别==Linux 内核设计的理念主要有这几个点： MultiTask，多任务。多任务意味着可以有多个任务同时执行，可以是并发或并行： 对于单核 CPU 时，可以让每个任务执行一小段时间，时间到就切换另外一个任务，从宏观角度看，一段时间内执行了多个任务，这被称为并发。 对于多核 CPU 时，多个任务可以同时被不同核心的 CPU 同时执行，这被称为并行。 SMP，对称多处理。代表着每个 CPU 的地位是相等的，对资源的使用权限也是相同的，多个 CPU 共享同一个内存，每个 CPU 都可以访问完整的内存和硬件资源。这个特点决定了 Linux 操作系统不会有某个 CPU 单独服务应用程序或内核程序，而是每个程序都可以被分配到任意一个 CPU 上被执行。 ELF，可执行文件链接格式。 Monolithic Kernel，宏内核Windows 和 Linux 一样，同样支持 MultiTask 和 SMP，但Window 是混合型内核，它的可执行文件格式为PE（可移植执行文件）。内存管理为什么要有虚拟内存？虚拟内存如果CPU直接操作内存的物理地址（单片机就是这样），那想在内存中同时运行两个程序是行不通的。因为如果程序在某个位置写入了一个新的值，将会擦掉另一个程序放在相同位置上的所有内容，程序会立即崩溃。解决方法：操作系统为每个进程分配独立的虚拟地址，然后将不同进程的虚拟地址和不同内存的物理地址建立映射关系。如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样就保证不同的进程运行时写入的是不同的物理地址，也就不会冲突了。因此有以下两种地址概念： 程序所使用的内存地址叫做虚拟内存地址（Virtual Memory Address） 实际存在硬件里面的空间地址叫物理内存地址（Physical Memory Address）。虚拟地址是通过 CPU 芯片中的内存管理单元（MMU）的映射关系来转换变成物理地址的。操作系统管理虚拟地址和物理地址之间的估值关系主要有两种方式：内存分段和内存分页。内存分段程序是由若干个逻辑分段组成的，比如由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用分段的形式把这些段分离出来。==分段机制下，虚拟地址和物理地址是如何映射的？==分段机制下的虚拟地址由两部分组成，段选择因子和段内偏移量。 段选择因子就保存在段寄存器里面。段选择因子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。 虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。虚拟地址是通过段表与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段都有一个段号，分别对应段表中的一个项，在相应的项中找到段的基地址，再加上偏移量，就能找到物理内存中的地址。分段的方法能够产生连续的内存空间，但它也有一些缺点： 第一个就是内存碎片的问题。 第二个就是内存交换的效率低的问题。==分段为什么会产生内存碎片的问题？==内存碎片问题有两种： 外部内存碎片，也就是产生了多个不连续的小物理内存，导致新的程序无法被装载； 内部内存碎片，程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使用，这也会导致内存的浪费；解决内存碎片问题的方法就是内存交换。内存交换就是把原有程序占用的内存先写到硬盘上，然后再从硬盘上读回来到内存里，这样就能空缺处连续的内存空间，然后让新程序装载进去。比如Linux系统里面的swap空间，就是从硬盘划分出来的，用于内存和硬盘的空间交换。==分段为什么会导致内存交换效率低的问题？==对于多进程的系统来说，用分段的方式，内存碎片是很容易产生的，产生了内存碎片，那不得不重新 Swap 内存区域，这个过程会产生性能瓶颈。因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上然后再写回内存，这个操作效率很低。内存分页为了解决内存分段的内存碎片和内存交换效率低的问题，出现了内存分页。分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，就是页（Page），在 Linux 下，每一页的大小为 4KB。虚拟地址与物理地址之间通过页表来映射，页表是存储在内存里的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的工作。当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，然后就会进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。==分页是怎么解决分段的内存碎片、内存交换效率低的问题？==采用分页之后，内存空间都是预先划分好的，释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存。这样就可以很好的避免分段的内存碎片问题。如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。一旦需要的时候，再加载进来，称为换入（Swap In）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。更进一步地，分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存页之间的映射之后，不直接把页加载到物理内存中，而是只有在程序运行中需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存中去。==分页机制下，虚拟地址和物理地址是如何映射的？==在分页机制下，虚拟地址分为两部分，页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址：也就是说，内存地址转换包括三个步骤： 把虚拟内存地址，切分成页号和偏移量； 根据页号，从页表里面，查询对应的物理页号； 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。==简单的分页有什么缺陷吗？==如果只是简单的分页，因为操作系统同时运行非常多的进程，会导致页表占用的内存非常大。比如在32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 4MB 的内存来存储页表。4MB 的页表并不是很大，但是每个进程都是有自己的虚拟地址空间，都有自己的页表，如果是100个进程的话，就需要400MB的内存来存储页表，这样页表占用的内存就太大了。为了解决这个问题，才用了多级页表的方法。多级页表对页表进行分级，比如一级页表的页表项中存放的是一级页表号和对应的二级页表地址，而二级页表中存放的是二级页表号和对应的物理页号。多级页表是利用了局部性原理，如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即只在需要时才创建二级页表，这样就可以节约很多内存。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= 0.804MB，这对比单级页表的 4MB 来说是一个巨大的节约！TLB多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然降低了地址转换的速度，带来的时间开销更大。程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。我们可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，CPU中有一个专门存放程序最常访问页表项的cache，即TLB，也称为页表缓存、转址旁路缓存、快表等。在 CPU 芯片里面，封装了内存管理单元（MMU）芯片，它用来完成地址转换和 TLB 的访问与交互。有了 TLB 后，CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。段页式内存管理内存分段可以和内存分页组合使用，即段页式内存管理。实现方式如下： 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制； 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；这样，地址结构就由段号、段内页号和页内位移三部分组成。用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：段页式地址变换中要得到物理地址须经过三次内存访问： 第一次访问段表，得到页表起始地址； 第二次访问页表，得到物理页号； 第三次将物理页号与页内位移组合，得到物理地址。可用软、硬件相结合的方法实现段页式内存管理，虽然增加了硬件成本和系统开销，但提高了内存的利用率。Linux 内存管理Linux 内存主要采用的是页式内存管理，但同时也不可避免地涉及了段机制。因为 Intel X86 CPU 一律对程序中使用的地址先进行段式映射，然后才能进行页式映射。既然 CPU 的硬件结构是这样，Linux 内核也只好服从 Intel 的选择。但是Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护。malloc 是如何分配内存的？Linux 进程的内存分布长什么样？在 Linux 操作系统中，虚拟地址空间的内部又被分为内核空间和用户空间两部分，不同位数的系统，地址空间的范围也不同： 32 位系统的内核空间占用 1G，位于最高处，剩下的 3G 是用户空间； 64 位系统的内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。内核空间与用户区间的区别在于： 进程在用户态时，只能访问用户空间内存； 只有进入内核态后，才可以访问内核空间的内存；用户空间分布情况（32位系统为例）： 程序文件段，包括二进制可执行代码； 已初始化数据段，包括静态常量； 未初始化数据段，包括未初始化的静态变量； 堆段，包括动态分配的内存，从低地址开始向上增长； 文件映射段，包括动态库、共享内存等； 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小；在这 6 个内存段中，堆和文件映射段的内存是动态分配的。可以使用C 标准库的 malloc()进行动态分配。malloc 是如何分配内存的？malloc() 并不是系统调用，而是 C 库函数，malloc 申请内存的时候，会有两种方式向操作系统申请堆内存： 方式一：通过 brk() 系统调用从堆分配内存 方式二：通过 mmap() 系统调用在文件映射区域分配内存；方式一实现的方式很简单，就是通过 brk() 函数将「堆顶」指针向高地址移动，获得新的内存空间。方式二通过 mmap() 系统调用将一个文件或者其它对象映射进内存。==什么场景下 malloc() 会通过 brk() 分配内存？又是什么场景下通过 mmap() 分配内存？==malloc() 源码里默认定义了一个阈值： 如果用户分配的内存小于 128 KB，则通过 brk() 申请内存； 如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存；malloc() 分配的是物理内存吗？不是的，malloc() 分配的是虚拟内存。如果分配后的虚拟内存没有被访问的话，是不会将虚拟内存映射到物理内存，这样就不会占用物理内存了。只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，然后操作系统会建立虚拟内存和物理内存之间的映射关系。malloc(1) 会分配多大的虚拟内存？malloc() 在分配内存的时候，并不是按用户预期申请的字节数来分配内存空间大小，而是会预分配更大的空间作为内存池。free 释放内存，会归还给操作系统吗？free 内存后堆内存还存在，是针对 malloc 通过 brk() 方式申请的内存的情况，将释放的内存先缓存着放进malloc的内存池中，当进程再次申请内存时就可以直接复用，这样速度更快。如果 malloc 通过 mmap 方式申请的内存，free 释放内存后就会归还给操作系统。为什么不全部使用 mmap 来分配内存因为 mmap 分配的内存每次释放的时候，都会归还给操作系统，于是每次 mmap 分配的虚拟地址都是缺页状态的，然后在第一次访问该虚拟地址的时候，就会触发缺页中断。所以频繁通过 mmap 分配内存的话，不仅每次都要执行系统调用，而系统调用会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大。为了改进这两个问题，malloc 通过 brk() 系统调用申请堆空间内存的时候，会直接预分配更大的内存来作为内存池，当内存释放的时候，就先缓存在内存池中。等下次在申请内存的时候，就直接从内存池取出对应的内存块就行了，而且可能这个内存块的虚拟地址与物理地址的映射关系还存在，这样不仅减少了系统调用的次数，也减少了缺页中断的次数，这将大大降低 CPU 的消耗。既然 brk 那么牛逼，为什么不全部使用 brk 来分配？因为随着系统频繁地 malloc 和 free ，堆内将产生越来越多不可用的小块内存碎片，会导致内存泄露问题。所以，malloc 充分考虑了sbrk和mmap的优缺点，默认分配大块内存 (128KB) 才使用 mmap 分配内存空间。free() 函数只传入一个内存地址，为什么能知道要释放多大的内存？因为malloc中有一部分空间保存了分配的内存块的描述信息，比如内存块的大小。这样执行free()函数时，free会对传入进来的内存地址偏移一定大小，然后从描述信息中分析出当前内存块的大小，自然就知道要释放多少内存了。内存满了，会发生什么？内存分配的过程是怎样的？应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。当应用程序读写了这块虚拟内存，CPU 就会去访问这个虚拟内存， 这时会发现这个虚拟内存没有映射到物理内存， CPU 就会产生缺页中断，进程会从用户态切换到内核态，并将缺页中断交给内核的 Page Fault Handler （缺页中断函数）处理。缺页中断处理函数会看是否有空闲的物理内存，如果有，就直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系。如果没有空闲的物理内存，那么内核就会开始进行回收内存的工作，回收的方式主要是两种：直接内存回收和后台内存回收。 后台内存回收（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行。 直接内存回收（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行。如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——触发 OOM （Out of Memory）机制。OOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。哪些内存可以被回收？主要有两类内存可以被回收，而且它们的回收方式也不同： 文件页（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存。 匿名页（Anonymous Page）：这部分内存没有实际载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们回收的方式是通过 Linux 的 Swap 机制，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表，其中： active_list 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页； inactive_list 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页；越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统优先回收不活跃的内存。回收内存带来的性能影响回收内存的操作基本都会发生磁盘 I/O ，如果回收内存的操作很频繁，磁盘 I/O的 次数也会很频繁，这个过程势必会影响系统的性能。可以使用以下方式优化： ==调整文件页和匿名页的回收倾向==从文件页和匿名页的回收操作来看，文件页的回收操作对系统的影响相比匿名页的回收操作会少一点，因为文件页对于干净页回收是不会发生磁盘 I/O 的，而匿名页的 Swap 换入换出这两个操作都会发生磁盘 I/O。Linux 提供了一个 /proc/sys/vm/swappiness 选项，用来调整文件页和匿名页的回收倾向。swappiness 的范围是 0-100，数值越大，越积极使用 Swap，也就是更倾向于回收匿名页；数值越小，越消极使用 Swap，也就是更倾向于回收文件页。一般建议 swappiness 设置为 0（默认值是 60），这样在回收内存的时候，会更倾向于文件页的回收，但是并不代表不会回收匿名页。 ==尽早触发 kswapd 内核线程异步回收内存==因为后台内存回收是异步的，不会阻塞进程，所以应该尽早触发后台内存回收来避免应用进行直接内存回收。在 4GB 物理内存的机器上，申请 8G 内存会怎么样？在 32 位操作系统中，进程最多只能申请 3 GB 大小的虚拟内存空间，所以进程申请 8GB 内存的话，在申请虚拟内存阶段就会失败。在 64 位操作系统中，进程可以使用 128 TB 大小的虚拟内存空间，所以进程申请 8GB 内存是没问题的，因为进程申请内存是申请虚拟内存，只要不读写这个虚拟内存，操作系统就不会分配物理内存。如果申请物理内存大小超过了空闲物理内存大小，就要看操作系统有没有开启 Swap 机制： 如果没有开启 Swap 机制，程序就会直接 OOM（被内存溢出机制杀掉）； 如果有开启 Swap 机制，程序可以正常运行。==什么是 Swap 机制？==Swap 就是把一块磁盘空间或者本地文件，当成内存来使用，它包含换出和换入两个过程： 换出（Swap Out） ，是把进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存； 换入（Swap In），是在进程再次访问这些内存的时候，把它们从磁盘读到内存中来；使用 Swap 机制优点是，应用程序实际可以使用的内存空间将远远超过系统的物理内存。当然，频繁地读写硬盘，会显著降低操作系统的运行速率，这也是 Swap 的弊端。Linux 中的 Swap 机制会在内存不足和内存闲置的场景下触发： 内存不足：当系统需要的内存超过了可用的物理内存时，内核会将内存中不常使用的内存页交换到磁盘上为当前进程让出内存，保证正在执行的进程的可用性，这个内存回收的过程是强制的直接内存回收（Direct Page Reclaim）。直接内存回收是同步的过程，会阻塞当前申请内存的进程。 内存闲置：应用程序在启动阶段使用的大量内存在启动后往往都不会使用，通过后台运行的守护进程（kSwapd），我们可以将这部分只使用一次的内存交换到磁盘上为其他内存的申请预留空间。kSwapd 是 Linux 负责页面置换（Page replacement）的守护进程，它也是负责交换闲置内存的主要进程，它会在空闲内存低于一定水位时，回收内存页中的空闲内存保证系统中的其他进程可以尽快获得申请的内存。kSwapd 是后台进程，所以回收内存的过程是异步的，不会阻塞当前申请内存的进程。进程管理进程、线程基础知识进程运行中的程序，就是进程。==并发和并行有什么区别？==并发就是在某个CPU核心上多个进程交替执行，它实际上仍然是串行，但是从整体上看就好像多个进程都被执行了一样，所以就是并发。而并行就是用不同的CPU核心去同时执行不同的任务。==进程与程序的关系==程序执行起来就是进程，CPU可以从一个进程切换到另外一个进程，但是在切换前必须要记录当前进程中运行的状态信息，方便下次切换回来的时候可以恢复执行。进程的状态完整的进程状态图：进程各个状态的意义： 创建状态（new）：进程正在被创建时的状态； 就绪状态（Ready）：可运行，由于其他进程处于运行状态而暂时停止运行； 运行状态（Running）：该时刻进程占用 CPU； 阻塞状态（Blocked）：该进程正在等待某一事件发生（如等待I/O操作的完成）而暂时停止运行，此时即使给它CPU控制权，它也无法运行； 结束状态（Exit）：进程正在从系统中消失时的状态； 进程的状态变迁： NULL -&amp;gt; 创建状态：一个新进程被创建时的第一个状态； 创建状态 -&amp;gt; 就绪状态：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的； 就绪状态 -&amp;gt; 运行状态：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程； 运行状态 -&amp;gt; 结束状态：当进程已经运行完成或出错时，会被操作系统作结束状态处理； 运行状态 -&amp;gt; 就绪状态：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行； 运行状态 -&amp;gt; 阻塞状态：当进程请求某个事件且必须等待时，例如请求 I/O 事件； 阻塞状态 -&amp;gt; 就绪状态：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；此外还有挂起状态，挂起状态是由于系统和用户的需要将进程挂起，意味着该进程处于静止状态。如果进程正在执行，它将暂停执行，如果原本处于就绪状态，则该进程暂时不接受调度。比如： OS为了提高内存利用率，将暂时不能运行的程序调出磁盘 通过sleep让进程间歇性挂起，其工作原理是设置一个定时器，到期后唤醒进程 用户希望挂起一个程序的执行，比如Linux中用 Ctrl+Z 挂起进程，或者调试程序。进程的控制结构在操作系统中，是用进程控制块（process control block，PCB）数据结构来描述进程的，PCB 是进程存在的唯一标识，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。==PCB 具体包含什么信息呢？==进程描述信息： 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符； 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；进程控制和管理信息： 进程当前状态，如 new、ready、running、waiting 或 blocked 等； 进程优先级：进程抢占 CPU 时的优先级；资源分配清单： 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。CPU 相关信息： CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。==每个 PCB 是如何组织的呢？==通常是通过链表的方式进行组织，把具有相同状态的进程链在一起，组成各种队列。比如： 将所有处于就绪状态的进程链在一起，称为就绪队列； 把所有因等待某事件而处于等待状态的进程链在一起就组成各种阻塞队列；进程的控制进程的创建、终止、阻塞、唤醒过程。==创建进程==操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源，当子进程被终止时，其在父进程处继承的资源应当还给父进程。同时，终止父进程时同时也会终止其所有的子进程。注意：Linux 操作系统对于终止有子进程的父进程，会把子进程交给 1 号进程接管。创建进程的过程如下： 申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等； 为该进程分配运行时所必需的资源，比如内存资源； 将 PCB 插入到就绪队列，等待被调度运行；==终止进程==进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 kill 掉）。终止进程的过程如下： 查找需要终止的进程的 PCB； 如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程； 如果其还有子进程，则应将其所有子进程终止； 将该进程所拥有的全部资源都归还给父进程或操作系统； 将其从 PCB 所在队列中删除；==阻塞进程==当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。阻塞进程的过程如下： 找到将要被阻塞进程标识号对应的 PCB； 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行； 将该 PCB 插入到阻塞队列中去；==唤醒进程==进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。唤醒进程的过程如下： 在该事件的阻塞队列中找到相应进程的 PCB； 将其从阻塞队列中移出，并置其状态为就绪状态； 把该 PCB 插入到就绪队列中，等待调度程序调度；进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。进程的上下文切换各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，一个进程切换到另一个进程运行，称为进程的上下文切换。==CPU 上下文切换==CPU在运行每个任务之前，它需要知道任务是从哪里加载，又从哪里开始运行的。CPU寄存器保存了相关数据，程序计数器则是用来存储CPU 正在执行的指令位置、或者即将执行的下一条指令位置。所以说，CPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 CPU 上下文。CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。任务主要包含进程、线程和中断。所以，根据任务的不同，CPU 上下文切换可以分成：进程上下文切换、线程上下文切换和中断上下文切换。==进程的上下文切换到底是切换什么呢？==进程是由内核管理和调度的，所以进程的切换只能发生在内核态。所以，进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行。==发生进程上下文切换有哪些场景？== 时间轮转片用完。为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行； 进程在系统资源不足时，等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行； 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行； 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序； 当进程将自己主动挂起时，自然也会重新调度。比如sleep睡眠函数，ctrl+z命令挂起。线程==什么是线程？==线程是进程当中的一条执行流程。同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。==线程的优缺点？==线程的优点： 一个进程中可以同时存在多个线程； 各个线程之间可以并发执行； 各个线程之间可以共享地址空间和文件等资源；线程的缺点： 当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃线程与进程的比较 进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位； 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈； 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系； 线程能减少并发执行的时间和空间开销；对于，线程相比进程能减少开销，体现在： 线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们； 线程的终止时间比进程快，因为线程释放的资源相比进程少很多； 同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的； 由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；所以，不管是时间效率，还是空间效率线程比进程都要高。线程的上下文切换线程与进程最大的区别在于：线程是调度的基本单位，而进程则是资源拥有的基本单位。所以，所谓操作系统的任务调度，实际上的调度对象是线程，进程只是给线程提供了资源。线程的上下文切换需要看是否属于同一个进程： 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样； 当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据；线程的实现主要有三种线程的实现方式： 用户线程（User Thread）：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理； 内核线程（Kernel Thread）：在内核中实现的线程，是由内核管理的线程； 轻量级进程（LightWeight Process）：在内核中来支持用户线程；用户线程和内核线程有多对一、一对一、一对多的对应关系。==用户线程如何理解？存在什么优势和缺陷？==用户线程是基于用户态的线程管理库来实现的，那么线程控制块（*Thread Control Block, TCB*） 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。所以，用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。用户级线程的模型，是多对一的关系，多个用户线程对应同一个内核线程。用户线程的优点： 每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统； 用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快；用户线程的缺点： 由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。 当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。 由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢；==那内核线程如何理解？存在什么优势和缺陷？==内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。内核线程的模型是一对一的关系，一个用户线程对应一个内核线程。内核线程的优点： 在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行； 分配给线程，多线程的进程获得更多的 CPU 运行时间；内核线程的缺点： 在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB； 线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大；==轻量级进程如何理解？==轻量级进程（Light-weight process，LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持。调度调度时机在进程的生命周期中，当进程从一个运行状态到另外一状态变化的时候，就会触发一次调度。 从就绪态 -&amp;gt; 运行态：当进程被创建时，会进入到就绪队列，操作系统会从就绪队列选择一个进程运行； 从运行态 -&amp;gt; 阻塞态：当进程发生 I/O 事件而阻塞时，操作系统必须选择另外一个进程运行； 从运行态 -&amp;gt; 结束态：当进程退出结束后，操作系统得从就绪队列选择另外一个进程运行；调度原则 CPU 利用率：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率； 系统吞吐量：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量； 周转时间：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好； 等待时间：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意； 响应时间：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。调度算法单核 CPU 系统中常见的调度算法：==先来先服务调度算法==最简单的一个调度算法，就是非抢占式的先来先服务（First Come First Serve, FCFS）算法，每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择下一个进程运行。特点：对长作业有理，适用于CPU繁忙型作业的系统，不利于短作业，不适用月I/O繁忙型作业的系统。==最短作业优先调度算法==最短作业优先（Shortest Job First, SJF）调度算法会优先选择运行时间最短的进程来运行。特点：有助于提高系统的吞吐量，但是对长作业不利。==高响应比优先调度算法==高响应比优先 （Highest Response Ratio Next, HRRN）调度算法主要是权衡了短作业和长作业。每次进行调度时，先计算「响应比优先级」，然后调用「响应比优先级」最高的进程，「响应比优先级」的计算公式：优先权=（等待时间+要求服务的时间）/要求服务的时间，从公式可以发现： 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行； 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；==时间片轮转调度算法==最简单、最公平且使用最广的算法就是时间片轮转（Round Robin, RR）调度算法。每个进程被分配一个时间段，称为时间片（*Quantum*），即允许该进程在该时间段中运行。 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程； 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；另外，时间片的长度就是一个很关键的点： 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率； 如果设得太长又可能引起对短作业进程的响应时间变长。将==最高优先级调度算法==从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法。进程的优先级可以分为，静态优先级和动态优先级： 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化； 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级该算法针对优先级高的进程有两种处理方法，非抢占式和抢占式： 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。缺点就是：可能导致优先级低的进程永远不会运行。==多级反馈队列调度算法==多级反馈队列（Multilevel Feedback Queue）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。具体为： 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也变更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。进程间有哪些通信方式每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。管道管道是两个进程间的一条通道，一端负责投递，另一端负责输出。管道传输数据是单向的，如果想相互通信，我们需要创建两个管道才行。$ ps auxf | grep mysql # 查看是否有mysql相关的进程在运行上面命令行里的「|」竖线就是一个管道，它的功能是将前一个命令（ps auxf）的输出，作为后一个命令（grep mysql）的输入。通过管道这种方式，ps和grep这两个命令对应的进程进行了一次合作。管道通常有两类： 匿名管道。通过pipe的系统调用创建，即「|」，没有名字，用完了就销毁。 命名管道。使用mkfifo命令创建的，并且指定管道名字。管道的特点就是简单，但是这种通信方式效率低，不适合进程间频繁地交换数据。==管道如何创建的，背后原理是什么？==匿名管道的创建，需要调用pipe系统调用，这个调用返回两个文件描述符，一个是管道的读取端描述符 fd[0]，另一个是管道的写入端描述符 fd[1]。需要注意，匿名管道是特殊的文件，只存在于内存，不存在于文件系统中。但是，这两个描述符都在一个进程里面，是怎么起到进程间通信的？我们可以使用fork创建子进程，创建的子进程会复制父进程的文件描述符，这样就做到了两个进程各有两个「 fd[0] 与 fd[1]」，两个进程就可以通过各自的 fd 写入和读取同一个管道文件实现跨进程通信了。管道只能一端写入，另一端读出，所以上面这种模式容易造成混乱，因为父进程和子进程都可以同时写入，也都可以读出。那么，为了避免这种情况，通常的做法是： 父进程关闭读取的 fd[0]，只保留写入的 fd[1]； 子进程关闭写入的 fd[1]，只保留读取的 fd[0]；所以说如果需要双向通信，则应该创建两个管道。 需要注意的是，在shell里面执行A B命令的时候，两个进程都是shell创建出来的子进程。所以说，在 shell 里通过「|」匿名管道将多个命令连接在一起，实际上也就是创建了多个子进程。 总结一下：对于匿名管道，它的通信范围是存在父子关系的进程。因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符，来达到通信的目的。对于命名管道，它可以在不相关的进程间也能相互通信。因为命令管道，提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则。消息队列消息队列比较灵活，它支持同时存在多个发送者和多个接收者，可以用于进程间频繁的交换数据。消息队列是链表设计实现的队列。当创建新的消息队列时，内核从系统内存分配一个队列数据结构，其中有消息头部指针和权限，队列的消息由头部指针引出，每个消息都会指向下一个消息的指针。在消息的结构体中，除了指向下一个消息的指针之外，就是消息的内容。消息内容包含类型和数据两部分，数据是一段内存数据，类型是用户程序为每个消息指定的。内核不需要知道具体是什么类型，仅仅只是保存，以及基于类型进行简单的查找。消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而前面提到的匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁。消息队列的缺点： 通信不及时，存在队列中，可能出现消息延迟 不适合比较大数据的传输，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。 消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。共享内存消息队列的读取和写入的过程，需要发生用户态和内核态之间的消息拷贝过程，共享内存不需要。共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，不需要拷贝来拷贝去，大大提高了进程间通信的速度。信号量共享内存会有一个问题，就是多个进程同时修改同一个内存，可能会出现数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问，信号量就实现了这一保护机制。信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步。信号量表示资源的数量，控制信号量的方式有两种原子操作： 一个是 P 操作，这个操作会把信号量减去 1，相减后如果信号量 &amp;lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 &amp;gt;= 0，则表明还有资源可使用，进程可正常继续执行。 另一个是 V 操作，这个操作会把信号量加上 1，相加后如果信号量 &amp;lt;= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &amp;gt; 0，则表明当前没有阻塞中的进程；P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。 进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。 若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占用，因此进程 B 被阻塞。 直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始值 1。可以发现，信号初始化为 1，就代表着是互斥信号量，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存。在多个进程里，每个进程并不一定是顺序执行的，如果我们希望多个进程能够合作，比如一个进程负责生产数据，另一个进程负责读取数据。这个时候可以通过信号量来实现多进程同步，初始化信号量为0。 如果进程 B 比进程 A 先执行了，那么执行到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进程 A 还没生产数据，于是进程 B 就阻塞等待； 接着，当进程 A 生产完数据后，执行了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B； 最后，进程 B 被唤醒后，意味着进程 A 已经生产了数据，于是进程 B 就可以正常读取数据了。可以发现，信号初始化为 0，就代表着是同步信号量，它可以保证进程 A 应在进程 B 之前执行。信号上面说的进程间通信，都是常规状态下的工作模式。对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。信号是进程间通信机制中唯一的异步通信机制，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。 执行默认操作。Linux 对每种信号都规定了默认操作，收到信号就执行其对应的操作。 捕捉信号。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。 3.忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SEGSTOP，它们用于在任何时候中断或结束某一进程 信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）： Ctrl+C 产生 SIGINT 信号，表示终止该进程； Ctrl+Z 产生 SIGTSTP 信号，表示停止该进程，但还未结束； kill -9 1050 ，表示给 PID 为 1050 的进程发送 SIGKILL 信号，用来立即结束该进程；Socket前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。当然，也可以在通主机上进程间通信。创建 socket 的系统调用：int socket(int domain, int type, int protocal) domain 参数用来指定协议族，比如 AF_INET 用于 IPV4、AF_INET6 用于 IPV6、AF_LOCAL/AF_UNIX 用于本机； type 参数用来指定通信特性，比如 SOCK_STREAM 表示的是字节流，对应 TCP；SOCK_DGRAM 表示的是数据报，对应 UDP；SOCK_RAW 表示的是原始套接字； protocal 参数原本是用来指定通信协议的，但现在基本废弃。因为协议已经通过前面两个参数指定完成，protocol 目前一般写成 0 即可；根据创建 socket 类型的不同，通信的方式也就不同： 实现 TCP 字节流通信： socket 类型是 AF_INET 和 SOCK_STREAM； 实现 UDP 数据报通信：socket 类型是 AF_INET 和 SOCK_DGRAM； 实现本地进程间通信： 「本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM，「本地数据报 socket 」类型是 AF_LOCAL 和 SOCK_DGRAM。另外，AF_UNIX 和 AF_LOCAL 是等价的。==针对 TCP 协议通信的 socket 编程模型== 服务端和客户端初始化 socket，得到文件描述符； 服务端调用 bind，将绑定在 IP 地址和端口; 服务端调用 listen，进行监听； 服务端调用 accept，等待客户端连接； 客户端调用 connect，向服务器端的地址和端口发起连接请求； 服务端 accept 返回用于传输的 socket 的文件描述符； 客户端调用 write 写入数据；服务端调用 read 读取数据； 客户端断开连接时，会调用 close，那么服务端 read 读取数据的时候，就会读取到了 EOF，待处理完数据后，服务端调用 close，表示连接关闭。这里需要注意的是，服务端调用 accept 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作监听 socket，一个叫作已完成连接 socket。==针对 UDP 协议通信的 socket 编程模型==UDP 是没有连接的，所以不需要三次握手，也就不需要像 TCP 调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind。对于 UDP 来说，不需要要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念，只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind。另外，每次通信时，调用 sendto 和 recvfrom，都要传入目标主机的 IP 地址和端口。==针对本地进程间通信的 socket 编程模型==本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是绑定一个本地文件，这也就是它们之间的最大区别。多线程冲入了怎么办？互斥的概念当多线程相互竞争操作共享变量时，如果在执行过程中发生了上下文切换会得到错误的结果，事实上，每次运行都可能得到不同的结果，因此输出的结果存在不确定性。由于多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为临界区（critical section），它是访问共享资源的代码片段，一定不能给多线程同时执行。互斥：保证一个线程在临界区执行时，其它线程应该被阻止进入临界区。同步的概念同步，就是并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步。同步与互斥是两种不同的概念： 同步就好比：「操作 A 应在操作 B 之前执行」，「操作 C 必须在操作 A 和操作 B 都完成之后才能执行」等； 互斥就好比：「操作 A 和操作 B 不能在同一时刻执行」；为了实现进程/线程间正确的协作，操作系统必须提供实现进程协作的措施，主要的方法有两种： 锁：加锁、解锁操作； 信号量：P、V 操作；这两个都可以方便地实现进程/线程互斥，信号量比锁的功能更强，它还可以实现进程/线程同步。锁使用加锁操作和解锁操作可以解决并发线程/进程的互斥问题。任何想进入临界区的线程，必须先执行加锁操作。若加锁操作顺利通过，则线程可进入临界区；在完成对临界资源的访问后再执行解锁操作，以释放该临界资源。根据锁的实现不同，可以分为「忙等待锁」和「无忙等待锁」：==忙等待锁」的实现==当获取不到锁时，线程就会一直 while 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为自旋锁。这是最简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。在单处理器上，需要抢占式的调度器。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。==「无等待锁」的实现==无等待锁顾明思议就是获取不到锁的时候，不用自旋，既然不想自旋，那当没获取到锁的时候，就把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行。信号量信号量不仅可以实现临界区的互斥访问控制，还可以线程间的事件同步。信号量初始值设置为1，可以实现互斥访问，互斥信号量的值仅取 1、0 和 -1 三个值，分别表示： 如果互斥信号量为 1，表示没有线程进入临界区； 如果互斥信号量为 0，表示有一个线程进入临界区； 如果互斥信号量为 -1，表示一个线程进入临界区，另一个线程等待进入。信号量初始值设置为0，可以实现事件同步。生产者-消费者问题生产者-消费者问题描述： 生产者在生成数据后，放在一个缓冲区中； 消费者从缓冲区取出数据处理； 任何时刻，只能有一个生产者或消费者可以访问缓冲区；我们对问题分析可以得出： 任何时刻只能有一个线程操作缓冲区，说明操作缓冲区是临界代码，需要互斥； 缓冲区空时，消费者必须等待生产者生成数据；缓冲区满时，生产者必须等待消费者取出数据。说明生产者和消费者需要同步。那么我们需要三个信号量，分别是： 互斥信号量 mutex：用于互斥访问缓冲区，初始化值为 1； 资源信号量 fullBuffers：用于消费者询问缓冲区是否有数据，有数据则读取数据，初始化值为 0（表明缓冲区一开始为空）； 资源信号量 emptyBuffers：用于生产者询问缓冲区是否有空位，有空位则生成数据，初始化值为 n （缓冲区大小）；哲学家就餐问题先来看看哲学家就餐的问题描述： 5 个老大哥哲学家，闲着没事做，围绕着一张圆桌吃面； 巧就巧在，这个桌子只有 5 支叉子，每两个哲学家之间放一支叉子； 哲学家围在一起先思考，思考中途饿了就会想进餐； 奇葩的是，这些哲学家要两支叉子才愿意吃面，也就是需要拿到左右两边的叉子才进餐； 吃完后，会把两支叉子放回原处，继续思考；那么问题来了，如何保证哲 学家们的动作有序进行，而不会出现有人永远拿不到叉子呢？==方案一==用信号量的方式，拿起叉子用P操作，代表有叉子直接用，没有叉子时就等待其它哲学家。不过，这种解法存在一个极端的问题：假设五位哲学家同时拿起左边的叉子，桌面上就没有叉子了， 这样就没有人能够拿到他们右边的叉子，也就说每一位哲学家都会等待右边的叉子，很明显这发生了死锁的现象。==方案二==我们在拿叉子前，加入互斥信号，只要有一个哲学家进入了「临界区」，也就是准备要拿叉子时，其他哲学家都不能动，只有这位哲学家用完叉子了，才能轮到下一个哲学家进餐。方案二虽然能让哲学家们按顺序吃饭，但是每次进餐只能有一位哲学家，而桌面上是有 5 把叉子，按道理是能可以有两个哲学家同时进餐的，所以从效率角度上，这不是最好的解决方案。==方案三==让偶数编号的哲学家「先拿左边的叉子后拿右边的叉子」，奇数编号的哲学家「先拿右边的叉子后拿左边的叉子」。既不会出现死锁，也可以两人同时进餐。怎么避免死锁？死锁的概念当两个线程为了保护两个不同的共享资源而使用了两个互斥锁，如果这两个互斥锁应用不当，可能会造成两个线程都在等待对方释放锁的情况，在没有外力的作用下，线程会一直相互等待，就没办法继续运行，这种情况就是发生了死锁。死锁只有同时满足以下四个条件才会发生： 互斥条件； 持有并等待条件； 不可剥夺条件； 环路等待条件；==互斥条件==互斥条件是指多个线程不能同时使用同一个资源。比如线程 A 已经持有的资源，不能再同时被线程 B 持有，如果线程 B 请求获取线程 A 已经占用的资源，那线程 B 只能等待，直到线程 A 释放了资源。==持有并等待条件==简单点说，就是线程持有一个资源并且在等待另一个资源，比如当线程 A 已经持有了资源 1，又想申请资源 2，而资源 2 已经被线程 C 持有了，所以线程 A 就会处于等待状态，但是线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1。==不可剥夺条件==不可剥夺条件是指，当线程已经持有了资源 ，在自己使用完之前不能被其他线程获取，比如线程 B 如果也想使用此资源，则只能在线程 A 使用完并释放后才能获取。==环路等待条件==环路等待条件指的是，在死锁发生的时候，两个线程获取资源的顺序构成了环形链。比如线程 A 已经持有资源 2，而想请求资源 1， 线程 B 已经持有资源 1，而想请求资源 2，这就形成资源请求等待的环形图。代码实现// 线程A B分别运行代码片段 并且两个线程共享两把全局的互斥锁A和B// 线程A 函数void proc_A(void) { lock(A); // 获取锁A lock(B); // 获取锁B unlock(B); unlock(A);}// 线程B 函数void proc_B(void) { lock(B); lock(A); unlock(A); unlock(B);}避免死锁问题的发生那么避免死锁问题就只需要破环其中一个条件就可以，最常见的并且可行的就是使用资源有序分配法，来破环环路等待条件。那什么是资源有序分配法呢？线程 A 和 线程 B 获取资源的顺序要一样，当线程 A 是先尝试获取资源 A，然后尝试获取资源 B 的时候，线程 B 同样也是先尝试获取资源 A，然后尝试获取资源 B。也就是说，线程 A 和 线程 B 总是以相同的顺序申请自己想要的资源。什么是悲观锁、乐观锁？互斥锁与自旋锁当已经有一个线程加锁后，其他线程加锁会失败，互斥锁和自旋锁对加锁失败后的处理方式不一样： 互斥锁加锁失败后，线程会释放 CPU ，给其他线程； 自旋锁加锁失败后，线程会忙等待，直到它拿到锁；互斥锁是一种「独占锁」，比如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞。对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的。当加锁失败时，内核会将线程从运行状态置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。因为线程运行状态改变，需要内核切换线程，所以会有两次线程上下文切花你的成本。自旋锁是通过 CPU 提供的 CAS 函数（Compare And Swap），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。一般加锁的过程： 第一步，查看锁的状态，如果锁是空闲的，则执行第二步； 第二步，将锁设置为当前线程持有；使用自旋锁的时候，当发生多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。这里的「忙等待」可以用 while 循环等待实现。需要注意，在单核 CPU 上，需要抢占式的调度器。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。它俩是锁的最基本处理方式，更高级的锁都会选择其中一个来实现，比如读写锁既可以选择互斥锁实现，也可以基于自旋锁实现。读写锁读写锁适用于能明确区分读操作和写操作的场景。读写锁的工作原理是： 当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。 但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。所以说，写锁是独占锁，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而读锁是共享锁，因为读锁可以被多个线程同时持有。读优先锁对于读线程并发性更好，但也不是没有问题。我们试想一下，如果一直有读线程获取读锁，那么写线程将永远获取不到写锁，这就造成了写线程「饥饿」的现象。写优先锁可以保证写线程不会饿死，但是如果一直有写线程获取写锁，读线程也会被「饿死」。公平读写锁比较简单的一种方式是：用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，这样读线程仍然可以并发，也不会出现「饥饿」的现象。乐观锁与悲观锁悲观锁做事比较悲观，它认为多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁。前面提到的互斥锁、自旋锁、读写锁，都是属于悲观锁。乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。乐观锁放弃后重试的成本可能很高，但是冲突的概率比较低的话，还是可以接受的。比如在线编辑就使用了乐观锁：允许多人同时编辑，而不是一个用户在编辑文档，另一个用户就无法打开相同的文档。具体原理是：由于发生冲突的概率比较低，所以先让用户编辑文档，但是浏览器在下载文档时会记录下服务端返回的文档版本号；当用户提交修改时，发给服务端的请求会带上原始文档版本号，服务器收到后将它与当前版本号进行比较，如果版本号一致则修改成功，否则提交失败。此外，Git也用了乐观锁的思想，先让用户编辑代码，然后提交的会后，通过版本号来判断是否产生了冲突，发生冲突的地方，需要我们修改后再重新提交。乐观锁、悲观锁使用场景：乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。一个进程最多可以创建多少个线程？这个问题跟两个东西有关系： 进程的虚拟内存空间上限，因为创建一个线程，操作系统需要为其分配一个栈空间，如果线程数量越多，所需的栈空间就要越大，那么虚拟内存就会占用的越多。 系统参数限制，虽然 Linux 并没有内核参数来控制单个进程创建的最大线程个数，但是有系统级别的参数来控制整个系统的最大线程个数。那么在进程里创建一个线程需要消耗多少虚拟内存大小？我们可以执行 ulimit -a 这条命令，查看进程创建线程时默认分配的栈空间大小，假如默认分配给线程的栈空间大小为 8M。在32位系统中有3G虚拟内存可以使用，差不多可以创建300个线程。如果想要创建更多的线程，可以调整创建线程时分配的栈空间大小。如果是64位系统，用户空间的虚拟内存最大值是128T，算起来可以创建很多进程，但是除了虚拟内存的限制，还会受系统的参数或者性能限制： proc/sys/kernel/threads-max，表示系统支持的最大线程数，默认值是 14553； /proc/sys/kernel/pid_max，表示系统全局的 PID 号数值的限制，每一个进程或线程都有 ID，ID 的值超过这个数，进程或线程就会创建失败，默认值是 32768； /proc/sys/vm/max_map_count，表示限制一个进程可以拥有的VMA(虚拟内存区域)的数量，具体什么意思我也没搞清楚，反正如果它的值很小，也会导致创建线程失败，默认值是 65530。当然这些参数可以手动调整，如果一直调大的话，具体创建多少个就要受到CPU核心的性能影响了。线程崩溃了，进程也会崩溃吗？线程崩溃，进程一定会崩溃吗一般来说如果线程是因为非法访问内存引起的崩溃，那么进程肯定会崩溃，为什么系统要让进程崩溃呢，这主要是因为在进程中，各个线程的地址空间是共享的，既然是共享，那么某个线程对地址的非法访问就会导致内存的不确定性，进而可能会影响到其他线程，这种操作是危险的，操作系统会认为这很可能导致一系列严重的后果，于是干脆让整个进程崩溃。线程共享代码段，数据段，地址空间，文件非法访问内存常见的有以下几种情况： 针对只读内存写入数据，崩溃 访问了进程没有权限访问的地址空间，崩溃 访问了不存在的内存，崩溃以上错误都是访问内存时的错误，统一会报 Segment Fault 错误（即段错误），这些都会导致进程崩溃。进程是如何崩溃的-信号机制简介通过给进程发送信号来终止进程的执行，发个信号进程怎么就崩溃了呢，这背后的原理到底是怎样的？ CPU 执行正常的进程指令 调用 kill 系统调用向进程发送信号 进程收到操作系统发的信号，CPU 暂停当前程序运行，并将控制权转交给操作系统 调用 kill 系统调用向进程发送信号（假设为 11，即 SIGSEGV，一般非法访问内存报的都是这个错误） 操作系统根据情况执行相应的信号处理程序（函数），一般执行完信号处理程序逻辑后会让进程退出如果进程没有注册自己的信号处理函数，操作系统会执行默认的信号处理程序，如果注册了，则会执行自己的信号处理函数，可以在退出进程前执行相关的逻辑或者直接忽略信号。kill -9 命令例外，不管进程是否定义了信号处理函数，都会马上被干掉。为什么线程崩溃不会导致 JVM 进程崩溃因为 JVM 自定义了自己的信号处理函数，拦截了进程终止信号，针对这两者不让它们崩溃。调度算法进程调度算法内存页面置换算法当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断（出发缺页异常），请求操作系统将所缺页调入到物理内存。那它与一般中断的主要区别在于： 缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。 缺页中断返回该指令的开始重新执行「该指令」，而一般中断返回到该指令的「下一个指令」执行。缺页中断的处理流程： 如果。程序需要访问内存，CPU会去找对应的页表项。 如果该页表项的状态位是「有效的」，那 CPU 就可以直接去访问物理内存了，如果状态位是「无效的」，则 CPU 则会发送缺页中断请求。 操作系统收到了缺页中断，则会执行缺页中断处理函数，先会查找该页面在磁盘中的页面的位置。 找到磁盘中对应的页面后，需要把该页面换入到物理内存中，但是在换入前，需要在物理内存中找空闲页，如果找到空闲页，就把页面换入到物理内存中。 页面从磁盘换入到物理内存完成后，则把页表项中的状态位修改为「有效的」。 最后，CPU 重新执行导致缺页异常的指令。如果能够在物理内存中找到空闲页，就是上面的流程，如果找不到，说明内存已经满了，这时候就需要页面置换算法选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。页表项通常包括以下字段： 状态位：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。 访问字段：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。 修改位：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。 硬盘地址：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。当出现缺页异常，需调入新页面而内存已满时，就需要页面置换算法选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页。那其算法目标则是，尽可能减少页面的换入换出的次数，常见的页面置换算法有如下几种： 最佳页面置换算法（OPT） 先进先出置换算法（FIFO） 最近最久未使用的置换算法（LRU） 时钟页面置换算法（Lock） 最不常用置换算法（LFU）==最佳页面置换算法==最佳页面置换算法基本思路是，置换「未来」最长时间不访问的页面。所以，该算法实现需要计算内存中每个逻辑页面的「下一次」访问时间，然后比较，选择未来最长时间不访问的页面。但是这再实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。所以该算法的作用是作为一种标准，来衡量其它页面置换算法的效率。==先进先出置换算法==选择在内存驻留时间很长的页面进行中置换，这个就是「先进先出置换」算法的思想。性能较差。==最近最久未使用的置换算法==最近最久未使用（LRU）的置换算法的基本思路是，发生缺页时，选择最长时间没有被访问的页面进行置换，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。虽然 LRU 在理论上是可以实现的，但是开销太大。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。==时钟页面置换算法==时钟页面置换算法跟 LRU 近似，又是对 FIFO 的一种改进。所以能够兼顾优化置换的次数和方便实现。该算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。当发生缺页中断时，算法首先检查表针指向的页面： 如果它的访问位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置； 如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；==最不常用算法==最不常用（LFU）算法当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰。它的实现方式是，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。在发生缺页中断时，淘汰计数器值最小的那个页面。增加计数器的硬件成本比较高，而且如果链表长度很大，查找访问最少的页面效率不高。磁盘调度算法常见的机械磁盘是上图左边的样子，中间圆的部分是磁盘的盘片，一般会有多个盘片，每个盘面都有自己的磁头。右边的图就是一个盘片的结构，盘片中的每一层分为多个磁道，每个磁道分多个扇区，每个扇区是 512 字节。那么，多个具有相同编号的磁道形成一个圆柱，称之为磁盘的柱面，如上图里中间的样子。磁盘调度算法的目的很简单，就是为了提高磁盘的访问性能，一般是通过优化磁盘访问请求顺序来做到。常见的磁盘调度算法有： 先来先服务算法 最短寻道时间优先算法 扫描算法算法 循环扫描算法 LOOK 与 C-LOOK 算法==先来先服务==先到的先服务（FCFS），比较简单，但是如果磁道很分散，性能就会很差。==最短寻道时间优先==最短寻道时间优先（Shortest Seek First，SSF）是优先选择从当前磁头位置所需寻道时间最短的请求，比FCFS性能好，但是可能存在某些请求的饥饿，产生饥饿的原因是磁头只在某一小块区域来回移动。==扫描算法==为了防止请求饥饿的问题，可以让磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向，这就是扫描（Scan）算法。扫描调度算法性能较好，不会产生饥饿现象，但是存在这样的问题：中间部分的磁道会比较占便宜，中间部分相比其他部分响应的频率会比较多，也就是说每个磁道的响应频率存在差异。==循环扫描算法==扫描算法使得每个磁道响应的频率存在差异，那么要优化这个问题的话，可以总是按相同的方向进行扫描，使得每个磁道的响应频率基本一致。循环扫描（Circular Scan, CSCAN）规定：只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且返回中途不处理任何请求，该算法的特点，就是磁道只响应一个方向上的请求。循环扫描算法相比于扫描算法，对于各个位置磁道响应频率相对比较平均。==LOOK 与 C-LOOK算法==我们前面说到的扫描算法和循环扫描算法，都是磁头移动到磁盘「最始端或最末端」才开始调换方向。这其实是可以优化的，优化的思路就是磁头在移动到「最远的请求」位置，然后立即反向移动。针对 SCAN 算法的优化则叫 LOOK 算法，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中会响应请求。针对 C-SCAN 算法的优化则叫 C-LOOK，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中不会响应请求。文件系统文件系统全家桶文件系统的基本组成在Linux上，一切皆文件，不仅普通的文件和目录，就连设备、管道、socket等也都是交给文件系统管理。Linux 文件系统会为每个文件分配两个数据结构：索引节点（index node）和目录项（directory entry），它们主要用来记录文件的元信息和目录层次结构。 索引节点，也就是 inode，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、数据在磁盘的位置等等。索引节点是文件的唯一标识，它们之间一一对应，也同样都会被存储在硬盘中，所以索引节点同样占用磁盘空间。 目录项，也就是 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的层级关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存。注意，目录也是文件，也是用索引节点唯一标识，和普通文件不同的是，普通文件在磁盘里面保存的是文件数据，而目录文件在磁盘里面保存子目录或文件。==目录项和目录是一个东西吗？==它们不是一个东西，目录是个文件，持久化存储在磁盘，而目录项是内核一个数据结构，缓存在内存。如果查询目录频繁从磁盘读，效率会很低，所以内核会把已经读过的目录用目录项这个数据结构缓存在内存，下次再次读到相同的目录时，只需从内存读就可以，大大提高了文件系统的效率。==那文件数据是如何存储在磁盘的呢？==磁盘读写的最小单位是扇区，扇区的大小只有 512B 大小，很明显，如果每次读写都以这么小为单位，那这读写的效率会非常低。所以，文件系统把多个扇区组成了一个逻辑块，每次读写的最小单位就是逻辑块（数据块），Linux 中大小为 4KB，也就是一次性读写 8 个扇区，这将大大提高了磁盘的读写的效率。目录项、索引结点、文件数据的关系图：磁盘进行格式化的时候，会被分成三个存储区域，分别是超级块、索引节点区和数据块区： 超级块，用来存储文件系统的详细信息，比如块个数、块大小、空闲块等等。 索引节点区，用来存储索引节点； 数据块区，用来存储文件或目录数据；虚拟文件系统文件系统的种类众多，而操作系统希望对用户提供一个统一的接口，于是在用户层与文件系统层引入了中间层，这个中间层就称为虚拟文件系统（Virtual File System，VFS）。VFS 定义了一组所有文件系统都支持的数据结构和标准接口，这样程序员不需要了解文件系统的工作原理，只需要了解 VFS 提供的统一接口即可。文件系统首先要先挂载到某个目录才可以正常使用， Linux 系统在启动时，会把文件系统挂载到根目录。文件的使用操作系统会跟踪进程打开的所有文件，为每个进程维护一个打开文件表，文件表里的每一项代表「文件描述符」，所以说文件描述符是打开文件的标识。操作系统在打开文件表中维护着打开文件的状态和信息： 文件指针：系统跟踪上次读写位置作为当前文件位置指针，这种指针对打开文件的某个进程来说是唯一的； 文件打开计数器：因为多个进程可能打开同一个文件，所以系统在删除打开文件条目之前，必须等待最后一个进程关闭文件，文件打开计数器跟踪打开和关闭的数量，当计数为 0 时，系统关闭文件，删除该条目； 文件磁盘位置：绝大多数文件操作都要求系统修改文件数据，该信息保存在内存中，以免每个操作都从磁盘中读取； 访问权限：每个进程打开文件都需要有一个访问模式（创建、只读、读写、添加等），该信息保存在进程的打开文件表中，以便操作系统能允许或拒绝之后的 I/O 请求；文件系统的基本操作单位是数据块，读文件和写文件的过程为： 当用户进程从文件读取 1 个字节大小的数据时，文件系统则需要获取字节所在的数据块，再返回数据块对应的用户进程所需的数据部分。 当用户进程把 1 个字节大小的数据写进文件时，文件系统则找到需要写入数据的数据块的位置，然后修改数据块中对应的部分，最后再把数据块写回磁盘。文件的存储数据在磁盘上的存放方式，就像程序在内存中存放的方式那样，有以下两种： 连续空间存放方式 非连续空间存放方式其中，非连续空间存放方式又可以分为「链表方式」和「索引方式」。==连续空间存放方式==连续空间存放方式顾名思义，文件存放在磁盘「连续的」物理空间中。这种模式下，文件的数据都是紧密相连，读写效率很高，因为一次磁盘寻道就可以读出整个文件。但使用连续存放的方式有一个条件，必须先知道文件的大小，这样文件系统才会根据文件的大小在磁盘上找到一块连续的空间分配给文件。缺点：磁盘空间碎片，文件长度不易扩展（扩展需要挪动到新空间，效率很低）。==非连续空间存放方式==链式方式：链表的方式存放是离散的，不用连续的，于是就可以消除磁盘碎片，可大大提高磁盘空间的利用率，同时文件的长度可以动态扩展。根据实现的方式的不同，链表可分为「隐式链表」和「显式链接」两种形式。文件要以「隐式链表」的方式存放的话，实现的方式是文件头要包含「第一块」和「最后一块」的位置，并且每个数据块里面留出一个指针空间，用来存放下一个数据块的位置，这样一个数据块连着一个数据块，从链头开始就可以顺着指针找到所有的数据块，所以存放的方式可以是不连续的。隐式链表的存放方式缺点： 无法直接访问数据块，只能通过指针顺序访问文件 数据块指针会消耗一定的内存空间 稳定性较差，如果链表中的某个指针丢失或损坏，会导致文件数据的丢失。显式链接可以解决上述问题，把用于链接文件各数据块的指针，显式地存放在内存的一张链接表中，该表在整个磁盘仅设置一张，每个表项中存放链接指针，指向下一个数据块号。由于查找记录的过程是在内存中进行的，因而不仅显著地提高了检索速度，而且大大减少了访问磁盘的次数。但也正是整个表都存放在内存中的关系，它的主要的缺点是不适用于大磁盘。索引方式：索引的实现是为每个文件创建一个「索引数据块」，里面存放的是指向文件数据块的指针列表。另外，文件头需要包含指向「索引数据块」的指针，这样就可以通过文件头知道索引数据块的位置，再通过索引数据块里的索引信息找到对应的数据块。索引的方式优点在于： 文件的创建、增大、缩小很方便； 不会有碎片的问题； 支持顺序读写和随机读写；缺点就是存储索引带来的开销。如果文件很大，大到一个索引数据块放不下索引信息，我们可以通过组合的方式，来处理大文件的存储。先来看看链表 + 索引的组合，这种组合称为「链式索引块」，它的实现方式是在索引数据块留出一个存放下一个索引数据块的指针，于是当一个索引数据块的索引信息用完了，就可以通过指针的方式，找到下一个索引数据块的信息。那这种方式也会出现前面提到的链表方式的问题，万一某个指针损坏了，后面的数据也就会无法读取了。还有另外一种组合方式是索引 + 索引的方式，这种组合称为「多级索引块」，实现方式是通过一个索引块来存放多个索引数据块，一层套一层索引。空闲空间管理针对磁盘的空闲空间也是要引入管理的机制，接下来介绍几种常见的方法： 空闲表法 空闲链表法 位图法==空闲表法==空闲表法就是为所有空闲空间建立一张表，表内容包括空闲区的第一个块号和该空闲区的块个数，注意，这个方式是连续分配的当请求分配磁盘空间时，系统依次扫描空闲表里的内容，直到找到一个合适的空闲区域为止。当用户撤销一个文件时，系统回收文件空间。这时，也需顺序扫描空闲表，寻找一个空闲表条目并将释放空间的第一个物理块号及它占用的块数填到这个条目中。这种方法仅当有少量的空闲区时才有较好的效果。因为，如果存储空间中有着大量的小的空闲区，则空闲表变得很大，这样查询效率会很低。==空闲链表法==我们也可以使用「链表」的方式来管理空闲空间，每一个空闲块里有一个指针指向下一个空闲块，这样也能很方便的找到空闲块并管理起来。当创建文件需要一块或几块时，就从链头上依次取下一块或几块。反之，当回收空间时，把这些空闲块依次接到链头上。特点是简单，但不能随机访问，工作效率低，因为每当在链上增加或移动空闲块时需要做很多 I/O 操作，同时数据块的指针消耗了一定的存储空间。==位图法==位图是利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上所有的盘块都有一个二进制位与之对应。当值为 0 时，表示对应的盘块空闲，值为 1 时，表示对应的盘块已分配。在 Linux 文件系统就采用了位图的方式来管理空闲空间，不仅用于数据空闲块的管理，还用于 inode 空闲块的管理，因为 inode 也是存储在磁盘的，自然也要有对其管理。文件系统的结构Linux文件系统使用块组结构，有 N 多的块组，就能够表示 N 大的文件。最前面的第一个块是引导块，在系统启动时用于启用引导，接着后面就是一个一个连续的块组了，块组的内容如下： 超级块，包含的是文件系统的重要信息，比如 inode 总个数、块总个数、每个块组的 inode 个数、每个块组的块个数等等。 块组描述符，包含文件系统中各个块组的状态，比如块组中空闲块和 inode 的数目等，每个块组都包含了文件系统中「所有块组的组描述符信息」。 数据位图和 inode 位图， 用于表示对应的数据块或 inode 是空闲的，还是被使用中。 inode 列表，包含了块组中所有的 inode，inode 用于保存文件系统中与各个文件和目录相关的所有元数据。 数据块，包含文件的有用数据。每个块组里有很多重复的信息，比如超级块和块组描述符表，这两个都是全局信息，而且非常的重要，这么做是有两个原因： 如果系统崩溃破坏了超级块或块组描述符，有关文件系统结构和内容的所有信息都会丢失。如果有冗余的副本，该信息是可能恢复的。 通过使文件和管理数据尽可能接近，减少了磁头寻道和旋转，这可以提高文件系统的性能。目录的存储和普通文件不同的是，普通文件的块里面保存的是文件数据，而目录文件的块里面保存的是目录里面一项一项的文件信息。在目录文件的块中，最简单的保存格式就是列表，就是一项一项地将目录下的文件信息（如文件名、文件 inode、文件类型等）列在表里。通常，第一项是「.」，表示当前目录，第二项是「..」，表示上一级目录，接下来就是一项一项的文件名和 inode。如果一个目录有超级多的文件，我们要想在这个目录下找文件，按照列表一项一项的找，效率就不高了。于是，保存目录的格式改成哈希表，对文件名进行哈希计算，把哈希值保存起来，如果我们要查找一个目录下面的文件名，可以通过名称取哈希。如果哈希能够匹配上，就说明这个文件的信息在相应的块里面。目录查询是通过在磁盘上反复搜索完成，需要不断地进行 I/O 操作，开销较大。所以，为了减少 I/O 操作，把当前使用的文件目录缓存在内存，以后要使用该文件时只要在内存中操作，从而降低了磁盘操作次数，提高了文件系统的访问速度。软链接和硬链接有时候我们希望给某个文件取个别名，那么在 Linux 中可以通过硬链接（Hard Link） 和软链接（Symbolic Link） 的方式来实现，它们都是比较特殊的文件，实现方式也是不相同的。硬链接是多个目录项中的「索引节点」指向一个文件，也就是指向同一个 inode，但是 inode 是不可能跨越文件系统的，每个文件系统都有各自的 inode 数据结构和列表，所以硬链接是不可用于跨文件系统的。由于多个目录项都是指向一个 inode，那么只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。软链接相当于重新创建一个文件，这个文件有独立的 inode，但是这个文件的内容是另外一个文件的路径，所以访问软链接的时候，实际上相当于访问到了另外一个文件，所以软链接是可以跨文件系统的，甚至目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。文件 I/O缓冲与非缓冲 I/O文件操作的标准库是可以实现数据的缓存，那么根据「是否利用标准库缓冲」，可以把文件 I/O 分为缓冲 I/O 和非缓冲 I/O： 缓冲 I/O，利用的是标准库的缓存实现文件的加速访问，而标准库再通过系统调用访问文件。 非缓冲 I/O，直接通过系统调用访问文件，不经过标准库缓存。这里所说的「缓冲」特指标准库内部实现的缓冲。比方说，很多程序遇到换行时才真正输出，而换行前的内容，其实就是被标准库暂时缓存了起来，这样做的目的是，减少系统调用的次数，毕竟系统调用是有 CPU 上下文切换的开销的。直接与非直接 I/O根据是「否利用操作系统的缓存」，可以把文件 I/O 分为直接 I/O 与非直接 I/O： 直接 I/O，不会发生内核缓存和用户程序之间数据复制，而是直接经过文件系统访问磁盘。 非直接 I/O，读操作时，数据从内核缓存中拷贝给用户程序，写操作时，数据从用户程序拷贝给内核缓存，再由内核决定什么时候写入数据到磁盘。==如果用了非直接 I/O 进行写数据操作，内核什么情况下才会把缓存数据写入到磁盘？==以下几种场景会触发内核缓存的数据写入磁盘： 在调用 write 的最后，当发现内核缓存的数据太多的时候，内核会把数据写到磁盘上； 用户主动调用 sync，内核缓存会刷到磁盘上； 当内存十分紧张，无法再分配页面时，也会把内核缓存的数据刷到磁盘上； 内核缓存的数据的缓存时间超过某个时间时，也会把数据刷到磁盘上；阻塞与非阻塞 I/O VS 同步与异步 I/O阻塞I/O：当用户程序执行 read ，线程会被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序的缓冲区中，当拷贝过程完成，read 才会返回。阻塞等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程。非阻塞I/O：非阻塞的 read 请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区，read 调用才可以获取到结果。这里最后一次 read 调用，获取数据的过程，是一个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。应用程序每次轮询内核的 I/O 是否准备好，感觉有点傻乎乎，因为轮询的过程中，应用程序啥也做不了，只是在循环。为了解决这个问题， I/O 多路复用技术就出来了，如 select、poll、epoll，它是通过 I/O 事件分发，当内核数据准备好时，再以事件通知应用程序进行操作。下图是使用 select I/O 多路复用过程。注意，read 获取数据的过程（数据从内核态拷贝到用户态的过程），也是一个同步的过程，需要等待：实际上，无论是阻塞 I/O、非阻塞 I/O，还是基于非阻塞 I/O 的多路复用都是同步调用。因为它们在 read 调用时，内核将数据从内核空间拷贝到应用程序空间，过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。真正的异步 I/O是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待。当我们发起 aio_read 之后，就立即返回，内核自动将数据从内核空间拷贝到应用程序空间，这个拷贝过程同样是异步的，内核自动完成的，和前面的同步操作不一样，应用程序并不需要主动发起拷贝动作。下面这张图，总结了以上几种 I/O 模型：在前面我们知道了，I/O 是分为两个过程的： 数据准备的过程 数据从内核空间拷贝到用户进程缓冲区的过程阻塞 I/O 会阻塞在「过程 1 」和「过程 2」，而非阻塞 I/O 和基于非阻塞 I/O 的多路复用只会阻塞在「过程 2」，所以这三个都可以认为是同步 I/O。异步 I/O 则不同，「过程 1 」和「过程 2 」都不会阻塞。==用故事去理解这几种 I/O 模型==举个你去饭堂吃饭的例子，你好比用户程序，饭堂好比操作系统。阻塞 I/O 好比，你去饭堂吃饭，但是饭堂的菜还没做好，然后你就一直在那里等啊等，等了好长一段时间终于等到饭堂阿姨把菜端了出来（数据准备的过程），但是你还得继续等阿姨把菜（内核空间）打到你的饭盒里（用户空间），经历完这两个过程，你才可以离开。非阻塞 I/O 好比，你去了饭堂，问阿姨菜做好了没有，阿姨告诉你没，你就离开了，过几十分钟，你又来饭堂问阿姨，阿姨说做好了，于是阿姨帮你把菜打到你的饭盒里，这个过程你是得等待的。基于非阻塞的 I/O 多路复用好比，你去饭堂吃饭，发现有一排窗口，饭堂阿姨告诉你这些窗口都还没做好菜，等做好了再通知你，于是等啊等（select 调用中），过了一会阿姨通知你菜做好了，但是不知道哪个窗口的菜做好了，你自己看吧。于是你只能一个一个窗口去确认，后面发现 5 号窗口菜做好了，于是你让 5 号窗口的阿姨帮你打菜到饭盒里，这个打菜的过程你是要等待的，虽然时间不长。打完菜后，你自然就可以离开了。异步 I/O 好比，你让饭堂阿姨将菜做好并把菜打到饭盒里后，把饭盒送到你面前，整个过程你都不需要任何等待。进程写文件时，进程发生了崩溃，已写入的数据会丢失吗？不会的。因为进程在执行 write （使用缓冲 IO）系统调用的时候，实际上是将文件数据写到了内核的 page cache，它是文件系统中用于缓存文件数据的缓冲，所以即使进程崩溃了，文件数据还是保留在内核的 page cache，我们读数据的时候，也是从内核的 page cache 读取，因此还是依然读的进程崩溃前写入的数据。内核会找个合适的时机，将 page cache 中的数据持久化到磁盘。但是如果 page cache 里的文件数据，在持久化到磁盘化到磁盘之前，系统发生了崩溃，那这部分数据就会丢失了。当然， 我们也可以在程序里调用 fsync 函数，在写文文件的时候，立刻将文件数据持久化到磁盘，这样就可以解决系统崩溃导致的文件数据丢失的问题。==Page Cache 是什么？==Page Cache 的本质是由 Linux 内核管理的内存区域，page 是内存管理分配的基本单位， Page Cache 由多个 page 构成。page 在操作系统中通常为 4KB 大小，而 Page Cache 的大小则为 4KB 的整数倍。Page Cache 的优点： 加快数据访问。如果数据能够在内存中进行缓存，那么下一次访问就不需要通过磁盘 I/O 了，直接命中内存缓存即可，而内存访问比磁盘访问快很多。 减少磁盘I/O次数。得益于 Page Cache 的缓存以及预读能力，而程序又往往符合局部性原理，因此通过一次 I/O 将多个 page 装入 Page Cache 能够减少磁盘 I/O 次数， 进而提高系统磁盘 I/O 吞吐量。Page Cache 的缺点： 占用额外的物理内存空间，物理内存比较紧缺的时候可能会导致频繁的swap操作。 由于在内核层，所以很难在用户空间进行优化。设备管理键盘敲入 A 字母时，操作系统期间发生了什么？设备控制器为了屏蔽设备之间的差异，对各种输入输出设备做统一管理，每个设备都有一个叫设备控制器（Device Control） 的组件，比如硬盘有硬盘控制器、显示器有视频控制器等。因为这些控制器都很清楚的知道对应设备的用法和功能，所以 CPU 是通过设备控制器来和设备打交道的。设备控制器里有芯片，它可执行自己的逻辑，也有自己的寄存器，用来与 CPU 进行通信，比如： 通过写入这些寄存器，操作系统可以命令设备发送数据、接收数据、开启或关闭，或执行其他操作。 通过读取这些寄存器，操作系统可以了解设备的状态，是否准备好接收一个新的命令等。实际上，控制器有三类寄存器，分别是状态寄存器（Status Register）、 命令寄存器（Command Register）以及数据寄存器（Data Register），作用如下： 数据寄存器，CPU 向 I/O 设备写入需要传输的数据，比如要打印的内容是「Hello」，CPU 就要先发送一个 H 字符给到对应的 I/O 设备。 命令寄存器，CPU 发送一个命令，告诉 I/O 设备，要进行输入/输出操作，于是就会交给 I/O 设备去工作，任务完成后，会把状态寄存器里面的状态标记为完成。 状态寄存器，目的是告诉 CPU ，现在已经在工作或工作已经完成，如果已经在工作状态，CPU 再发送数据或者命令过来，都是没有用的，直到前面的工作已经完成，状态寄存标记成已完成，CPU 才能发送下一个字符和命令。如果传输的数据量比较大，控制器会设立一个可读写的数据缓冲区： CPU 写入数据到控制器的缓冲区时，当缓冲区的数据囤够了一部分，才会发给设备。 CPU 从控制器的缓冲区读取数据时，也需要缓冲区囤够了一部分，才拷贝到内存。这样做是为了，减少对设备的频繁操作，CPU有两种方法与控制寄存器和数据缓冲区进行通信： 端口 I/O，每个控制寄存器被分配一个 I/O 端口，可以通过特殊的汇编指令操作这些寄存器，比如 in/out 类似的指令。 内存映射 I/O，将所有控制寄存器映射到内存空间中，这样就可以像读写内存一样读写数据缓冲区。 I/O 控制方式设备读写操作完成之后，如何通知CPU呢？一种是轮询，会占用大量占用CPU的时间，另一种就是中断，中断会打断CPU，对于频繁读取数据的操作并不友好，也会占用很多的时间。对于这一类设备的解决方法就是使用DMA（Direct Memory Access）功能，它可以使设备在CPU不参与的情况下， 自行地把设备读取的数据放入到内存，需要有DMA控制器硬件的支持。工作方式如下： CPU 对 DMA 控制器下发指令，告诉它想读取多少数据，读完的数据放在内存的某个地方就可以了； 接下来，DMA 控制器会向磁盘控制器发出指令，通知它从磁盘读数据到其内部的缓冲区中，接着磁盘控制器将缓冲区的数据传输到内存； 当磁盘控制器把数据传输到内存的操作完成后，磁盘控制器在总线上发出一个确认成功的信号到 DMA 控制器； DMA 控制器收到信号后，DMA 控制器发中断通知 CPU 指令完成，CPU 就可以直接用内存里面现成的数据了；设备驱动程序虽然设备控制器屏蔽了设备的众多细节，但每种设备的控制器的寄存器、缓冲区等使用模式都是不同的，所以为了屏蔽「设备控制器」的差异，引入了设备驱动程序。设备控制器不属于操作系统范畴，它是属于硬件，而设备驱动程序属于操作系统的一部分，操作系统的内核代码可以像本地调用代码一样使用设备驱动程序的接口，而设备驱动程序是面向设备控制器的代码，它发出操控设备控制器的指令后，才可以操作设备控制器。不同的设备控制器虽然功能不同，但是设备驱动程序会提供统一的接口给操作系统，这样不同的设备驱动程序，就可以以相同的方式接入操作系统。通用块层输入输出设备可以分为块设备和字符设备。对于块设备，为了减少不同块设备的差异带来的影响，Linux 通过一个统一的通用块层，来管理不同的块设备。通用块层是处于文件系统和磁盘驱动中间的一个块设备抽象层，它主要有两个功能： 第一个功能，向上为文件系统和应用程序，提供访问块设备的标准接口，向下把各种不同的磁盘设备抽象为统一的块设备，并在内核层面，提供一个框架来管理这些设备的驱动程序； 第二功能，通用层还会给文件系统和应用程序发来的 I/O 请求排队，接着会对队列重新排序、请求合并等方式，也就是 I/O 调度，主要目的是为了提高磁盘读写的效率。Linux 内存支持 5 种 I/O 调度算法，分别是： 没有调度算法 先入先出调度算法 完全公平调度算法 优先级调度 最终期限调度算法第一种，没有调度算法，是的，你没听错，它不对文件系统和应用程序的 I/O 做任何处理，这种算法常用在虚拟机 I/O 中，此时磁盘 I/O 调度算法交由物理机系统负责。第二种，先入先出调度算法，这是最简单的 I/O 调度算法，先进入 I/O 调度队列的 I/O 请求先发生。第三种，完全公平调度算法，大部分系统都把这个算法作为默认的 I/O 调度器，它为每个进程维护了一个 I/O 调度队列，并按照时间片来均匀分布每个进程的 I/O 请求。第四种，优先级调度算法，顾名思义，优先级高的 I/O 请求先发生， 它适用于运行大量进程的系统，像是桌面环境、多媒体应用等。第五种，最终期限调度算法，分别为读、写请求创建了不同的 I/O 队列，这样可以提高机械磁盘的吞吐量，并确保达到最终期限的请求被优先处理，适用于在 I/O 压力比较大的场景，比如数据库等。存储系统 I/O 软件分层可以把 Linux 存储系统的 I/O 由上到下可以分为三个层次，分别是文件系统层、通用块层、设备层。这三个层次的作用是： 文件系统层，包括虚拟文件系统和其他文件系统的具体实现，它向上为应用程序统一提供了标准的文件访问接口，向下会通过通用块层来存储和管理磁盘数据。 通用块层，包括块设备的 I/O 队列和 I/O 调度器，它会对文件系统的 I/O 请求进行排队，再通过 I/O 调度器，选择一个 I/O 发给下一层的设备层。 设备层，包括硬件设备、设备控制器和驱动程序，负责最终物理设备的 I/O 操作。有了文件系统接口之后，不但可以通过文件系统的命令行操作设备，也可以通过应用程序，调用 read、write 函数，就像读写文件一样操作设备，所以说设备在 Linux 下，也只是一个特殊的文件。键盘敲入字母时，期间发生了什么？那当用户输入了键盘字符，键盘控制器就会产生扫描码数据，并将其缓冲在键盘控制器的寄存器中，紧接着键盘控制器通过总线给 CPU 发送中断请求。CPU 收到中断请求后，操作系统会保存被中断进程的 CPU 上下文，然后调用键盘的中断处理程序。键盘的中断处理程序是在键盘驱动程序初始化时注册的，那键盘中断处理函数的功能就是从键盘控制器的寄存器的缓冲区读取扫描码，再根据扫描码找到用户在键盘输入的字符，如果输入的字符是显示字符，那就会把扫描码翻译成对应显示字符的 ASCII 码，比如用户在键盘输入的是字母 A，是显示字符，于是就会把扫描码翻译成 A 字符的 ASCII 码。得到了显示字符的 ASCII 码后，就会把 ASCII 码放到「读缓冲区队列」，接下来就是要把显示字符显示屏幕了，显示设备的驱动程序会定时从「读缓冲区队列」读取数据放到「写缓冲区队列」，最后把「写缓冲区队列」的数据一个一个写入到显示设备的控制器的寄存器中的数据缓冲区，最后将这些数据显示在屏幕里。显示出结果后，恢复被中断进程的上下文网络系统什么是零拷贝？为什么要有 DMA 技术?在没有 DMA 技术前，I/O 的过程是这样的： CPU 发出对应的指令给磁盘控制器，然后返回； 磁盘控制器收到指令后，于是就开始准备数据，会把数据放入到磁盘控制器的内部缓冲区中，然后产生一个中断； CPU 收到中断信号后，停下手头的工作，接着把磁盘控制器的缓冲区的数据一次一个字节地读进自己的寄存器，然后再把寄存器里的数据写入到内存，而在数据传输的期间 CPU 是无法执行其他任务的。整个数据的传输，都需要CPU参与，如果传输大量数据的时候，会占用大量的CPU时间。于是就有了DMA（直接内存访问），在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。使用DMA控制器进行数据传输的过程： 用户进程调用 read 方法，向操作系统发出 I/O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态； 操作系统收到请求后，进一步将 I/O 请求发送 DMA，然后让 CPU 执行其他任务； DMA 进一步将 I/O 请求发送给磁盘； 磁盘收到 DMA 的 I/O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满； DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务； 当 DMA 读取了足够多的数据，就会发送中断信号给 CPU； CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回；CPU只需要告诉DMA读取数据的请求以及读取到的数据放哪里就行了。传统的文件传输有多糟糕？如果服务端要提供文件传输的功能，我们能想到的最简单的方式是：将磁盘上的文件读取出来，然后通过网络协议发送给客户端。也就是一个read和一个write系统调用就可以了，但是过程很复杂：首先，期间共发生了 4 次用户态与内核态的上下文切换，因为发生了两次系统调用，一次是 read() ，一次是 write()，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。上下文切换到成本并不小，一次切换需要耗时几十纳秒到几微秒，虽然时间看上去很短，但是在高并发的场景下，这类时间容易被累积和放大，从而影响系统的性能。其次，还发生了 4 次数据拷贝，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的，下面说一下这个过程： 第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。 第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。 第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。 第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。我们只是搬运一份数据，结果却搬运了 4 次，过多的数据拷贝无疑会消耗 CPU 资源，大大降低系统性能。所以，要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数。如何优化文件传输的性能？==先来看看，如何减少「用户态与内核态的上下文切换」的次数呢？==读取磁盘数据的时候，之所以要发生上下文切换，这是因为用户空间没有权限操作磁盘或网卡，内核的权限最高，这些操作设备的过程都需要交由操作系统内核来完成，所以一般要通过内核去完成某些任务的时候，就需要使用操作系统提供的系统调用函数。而一次系统调用必然会发生 2 次上下文切换：首先从用户态切换到内核态，当内核执行完任务后，再切换回用户态交由进程代码执行。所以，要想减少上下文切换到次数，就要减少系统调用的次数。==再来看看，如何减少「数据拷贝」的次数？==在前面我们知道了，传统的文件传输方式会历经 4 次数据拷贝，而且这里面，「从内核的读缓冲区拷贝到用户的缓冲区里，再从用户的缓冲区里拷贝到 socket 的缓冲区里」，这个过程是没有必要的。因为文件传输的应用场景中，在用户空间我们并不会对数据「再加工」，所以数据实际上可以不用搬运到用户空间，因此用户的缓冲区是没有必要存在的。如何实现零拷贝？零拷贝技术实现的方式通常有 2 种： mmap + write sendfile==mmap + write==在前面我们知道，read() 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，于是为了减少这一步开销，我们可以用 mmap() 替换 read() 系统调用函数。mmap() 系统调用函数会直接把内核缓冲区里的数据「映射」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。 应用进程调用了 mmap() 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区； 应用进程再调用 write()，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据； 最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。我们可以得知，通过使用 mmap() 来代替 read()， 可以减少一次数据拷贝的过程。==sendfile==统调用函数 sendfile()专门用来发送文件。#include &amp;lt;sys/socket.h&amp;gt;ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。首先，它可以替代前面的 read() 和 write() 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。如下图：但是这还不是真正的零拷贝技术，如果网卡支持 SG-DMA（The Scatter-Gather Direct Memory Access）技术（和普通的 DMA 有所不同），sendfile() 系统调用的过程发生了点变化，具体过程如下： 第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里； 第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；所以，这个过程之中，只进行了 2 次数据拷贝，如下图：这就是所谓的零拷贝（Zero-copy）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。所以，总体来看，零拷贝技术可以把文件传输的性能提高至少一倍以上PageCache 有什么作用？把磁盘文件数据拷贝「内核缓冲区」里，这个「内核缓冲区」实际上是磁盘高速缓存（PageCache）。ageCache 的优点主要是两个： 缓存最近被访问的数据； 预读功能；（读取数据页的时候，根据局部性原理，会预读邻近的数据页）这两个做法，将大大提高读写磁盘的性能。但是，在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用这是因为在传输大文件时，每当用户访问这些大文件的时候，内核就会把它们载入 PageCache 中，于是 PageCache 空间很快被这些大文件占满，这样会带来两个问题： PageCache 由于长时间被大文件占据，其他「热点」的小文件可能就无法充分使用到 PageCache，于是这样磁盘读写的性能就会下降了，在高并发的环境下可能会带来严重的性能问题。 PageCache 中的大文件数据，可能某些部分的文件数据被再次访问的概率比较低，也就相当于没有享受到缓存带来的好处，但这样却耗费 DMA 多拷贝到 PageCache 一次；所以，针对大文件的传输，不应该使用 PageCache，也就是说不应该使用零拷贝技术。大文件传输用什么方式实现？大文件传输不应该使用PageCache，异步I/O可以解决I/O请求的阻塞问题，同时不涉及PageCache。使用 PageCache 的 I/O 则叫缓存 I/O，而绕开 PageCache 的 I/O 叫直接 I/O。通常，对于磁盘，异步 I/O 只支持直接 I/O。所以，在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术，这样就可以无阻塞地读取文件了。直接 I/O 应用场景常见的两种： 应用程序已经实现了磁盘数据的缓存，那么可以不需要 PageCache 再次缓存，减少额外的性能损耗。 传输大文件的时候，由于大文件难以命中 PageCache 缓存，而且会占满 PageCache 导致「热点」文件无法充分利用缓存，从而增大了性能开销，因此，这时应该使用直接 I/O。所以，传输文件的时候，我们要根据文件的大小来使用不同的方式： 传输大文件的时候，使用「异步 I/O + 直接 I/O」； 传输小文件的时候，则使用「零拷贝技术」；I/O 多路复用：select/poll/epoll最基本的 Socket 模型服务端首先调用 socket() 函数，创建网络协议为 IPv4，以及传输协议为 TCP 的 Socket ，接着调用 bind() 函数，给这个 Socket 绑定一个 IP 地址和端口，绑定这两个的目的是什么？ 绑定端口的目的：当内核收到 TCP 报文，通过 TCP 头里面的端口号，来找到我们的应用程序，然后把数据传递给我们。 绑定 IP 地址的目的：一台机器是可以有多个网卡的，每个网卡都有对应的 IP 地址，当绑定一个网卡时，内核在收到该网卡上的包，才会发给我们；绑定完 IP 地址和端口后，就可以调用 listen() 函数进行监听，此时对应 TCP 状态图中的 listen，如果要判定服务器中一个网络程序有没有启动，可以通过 netstat 命令查看对应的端口号是否有被监听。服务端进入了监听状态后，通过调用 accept() 函数，来从内核获取客户端的连接，如果没有客户端连接，则会阻塞等待客户端连接的到来。那客户端是怎么发起连接的呢？客户端在创建好 Socket 后，调用 connect() 函数发起连接，该函数的参数要指明服务端的 IP 地址和端口号，然后万众期待的 TCP 三次握手就开始了。在 TCP 连接的过程中，服务器的内核实际上为每个 Socket 维护了两个队列： 一个是还没完全建立连接的队列，称为 TCP 半连接队列，这个队列都是没有完成三次握手的连接，此时服务端处于 syn_rcvd 的状态； 一个是已经建立连接的队列，称为 TCP 全连接队列，这个队列都是完成了三次握手的连接，此时服务端处于 established 状态；当 TCP 全连接队列不为空后，服务端的 accept() 函数，就会从内核中的 TCP 全连接队列里拿出一个已经完成连接的 Socket 返回应用程序，后续数据传输都用这个 Socket。注意，监听的 Socket 和真正用来传数据的 Socket 是两个： 一个叫作监听 Socket； 一个叫作已连接 Socket；连接建立后，客户端和服务端就开始相互传输数据了，双方都可以通过 read() 和 write() 函数来读写数据。至此， TCP 协议的 Socket 程序的调用过程就结束了，整个过程如下图：如何服务更多的用户？前面提到的 TCP Socket 调用流程是最简单、最基本的，它基本只能一对一通信，因为使用的是同步阻塞的方式，当服务端在还没处理完一个客户端的网络 I/O 时，或者 读写操作发生阻塞时，其他客户端是无法与服务端连接的。务器单机理论最大能连接多少个客户端？TCP 连接是由四元组唯一确认的，这个四元组就是：本机IP, 本机端口, 对端IP, 对端端口。服务器作为服务方，通常会在本地固定监听一个端口，等待客户端的连接。因此服务器的本地 IP 和端口是固定的，于是对于服务端 TCP 连接的四元组只有对端 IP 和端口是会变化的，所以最大 TCP 连接数 = 客户端 IP 数×客户端端口数。对于 IPv4，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是服务端单机最大 TCP 连接数约为 2 的 48 次方。但是服务器肯定承载不了那么大的连接数，主要会受两个方面的限制： 文件描述符，Socket 实际上是一个文件，也就会对应一个文件描述符。在 Linux 下，单个进程打开的文件描述符数是有限制的，没有经过修改的值一般都是 1024，不过我们可以通过 ulimit 增大文件描述符的数目； 系统内存，每个 TCP 连接在内核中都有对应的数据结构，意味着每个连接都是会占用一定内存的；从硬件资源角度看，对于 2GB 内存千兆网卡的服务器，如果每个请求处理占用不到 200KB 的内存和 100Kbit 的网络带宽就可以满足并发 1 万个请求。当然，这与服务器的网络I/O模型也有很大关系。多进程模型如果服务器要支持多个客户端，其中比较传统的方式，就是使用多进程模型，也就是为每个客户端分配一个进程来处理请求。服务器的主进程负责监听客户的连接，一旦与客户端连接完成，accept() 函数就会返回一个「已连接 Socket」，这时就通过 fork() 函数创建一个子进程，实际上就把父进程所有相关的东西都复制一份，包括文件描述符、内存地址空间、程序计数器、执行的代码等。这两个进程刚复制完的时候，几乎一摸一样。不过，会根据返回值来区分是父进程还是子进程，如果返回值是 0，则是子进程；如果返回值是其他的整数，就是父进程。正因为子进程会复制父进程的文件描述符，于是就可以直接使用「已连接 Socket 」和客户端通信了。可以发现，子进程不需要关心「监听 Socket」，只需要关心「已连接 Socket」；父进程则相反，将客户服务交给子进程来处理，因此父进程不需要关心「已连接 Socket」，只需要关心「监听 Socket」。另外，当「子进程」退出时，实际上内核里还会保留该进程的一些信息，也是会占用内存的，如果不做好“回收”工作，就会变成僵尸进程，随着僵尸进程越多，会慢慢耗尽我们的系统资源。因此，父进程要“善后”好自己的孩子，怎么善后呢？那么有两种方式可以在子进程退出后回收资源，分别是调用 wait() 和 waitpid() 函数。这种用多个进程来应付多个客户端的方式，在应对 100 个客户端还是可行的，但是当客户端数量高达一万时，肯定扛不住的，因为每产生一个进程，必会占据一定的系统资源，而且进程间上下文切换的“包袱”是很重的，性能会大打折扣。多线程模型当服务器与客户端 TCP 完成连接后，通过 pthread_create() 函数创建线程，然后将「已连接 Socket」的文件描述符传递给线程函数，接着在线程里和客户端进行通信，从而达到并发处理的目的。如果每来一个连接就创建一个线程，线程运行完后，还得操作系统还得销毁线程，虽说线程切换的上写文开销不大，但是如果频繁创建和销毁线程，系统开销也是不小的。那么，我们可以使用线程池的方式来避免线程的频繁创建和销毁，所谓的线程池，就是提前创建若干个线程，这样当由新连接建立时，将这个已连接的 Socket 放入到一个队列里，然后线程池里的线程负责从队列中取出已连接 Socket 进程处理。需要注意的是，这个队列是全局的，每个线程都会操作，为了避免多线程竞争，线程在操作这个队列前要加锁。上面基于进程或者线程模型的，其实还是有问题的。新到来一个 TCP 连接，就需要分配一个进程或者线程，那么如果要达到 C10K，意味着要一台机器维护 1 万个连接，相当于要维护 1 万个进程/线程，操作系统就算死扛也是扛不住的。I/O 多路复用既然为每个请求分配一个进程/线程的方式不合适，那有没有可能只使用一个进程来维护多个 Socket 呢？答案是有的，那就是 I/O 多路复用技术。一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程，这就是多路复用，这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用。我们熟悉的 select/poll/epoll 内核提供给用户态的多路复用系统调用，进程可以通过一个系统调用函数从内核中获取多个事件。select/poll/epoll 是如何获取网络事件的呢？在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可。select/pollselect 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。但是 poll 和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。epoll先复习下 epoll 的用法。如下的代码中，先用e poll_create 创建一个 epol l对象 epfd，再通过 epoll_ctl 将需要监视的 socket 添加到epfd中，最后调用 epoll_wait 等待数据。第一点，epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)。而 select/poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select/poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。第二点， epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。epoll 的方式即使监听的 Socket 数量越多的时候，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了，上限就为系统定义的进程打开的最大文件描述符个数。因而，epoll 被称为解决 C10K 问题的利器。边缘触发和水平触发epoll 支持两种事件触发模式，分别是边缘触发（edge-triggered，ET）和水平触发（level-triggered，LT）。它们的区别： 使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完； 使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取；一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。select/poll 只有水平触发模式，epoll 默认的触发模式是水平触发，但是可以根据应用场景设置为边缘触发模式。另外，使用 I/O 多路复用时，最好搭配非阻塞 I/O 一起使用（因为多路复用 API 返回的事件并不一定可读写的，如果使用阻塞 I/O， 那么在调用 read/write 时则会发生程序阻塞）。高性能网络模式：Reactor 和 ProactorReactor基于面向对象的思想，对I/O多路复用作了一层封装，让使用者用考虑底层网络 API 的细节，只需要关注应用代码的编写，即Reactor模式。==单 Reactor 单进程 / 线程==可以看到进程里有 Reactor、Acceptor、Handler 这三个对象： Reactor 对象的作用是监听和分发事件； Acceptor 对象的作用是获取连接； Handler 对象的作用是处理业务；「单 Reactor 单进程」方案流程： Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型； 如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件； 如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应； Handler 对象通过 read -&amp;gt; 业务处理 -&amp;gt; send 的流程来完成完整的业务流程。全部工作在单进程中完成，实现起来比较简单，但是，这种方案存在 2 个缺点： 第一个缺点，因为只有一个进程，无法充分利用 多核 CPU 的性能； 第二个缺点，Handler 对象在业务处理时，整个进程是无法处理其他连接的事件的，如果业务处理耗时比较长，那么就造成响应的延迟；所以，单 Reactor 单进程的方案不适用计算机密集型的场景，只适用于业务处理非常快速的场景。==单 Reactor 多线程 / 多进程== Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型； 如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件； 如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应； Handler 对象不再负责业务处理，只负责数据的接收和发送，Handler 对象通过 read 读取到数据后，会将数据发给子线程里的 Processor 对象进行业务处理； 子线程里的 Processor 对象就进行业务处理，处理完后，将结果发给主线程中的 Handler 对象，接着由 Handler 通过 send 方法将响应结果发送给 client；单 Reator 多线程的方案优势在于能够充分利用多核 CPU 的能，那既然引入多线程，那么自然就带来了多线程竞争资源的问题。要避免多线程由于竞争共享资源而导致数据错乱的问题，就需要在操作共享资源前加上互斥锁，以保证任意时间里只有一个线程在操作共享资源，待该线程操作完释放互斥锁后，其他线程才有机会操作共享数据。因为一个 Reactor 对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方。==多 Reactor 多进程 / 线程== 主线程中的 MainReactor 对象通过 select 监控连接建立事件，收到事件后通过 Acceptor 对象中的 accept 获取连接，将新的连接分配给某个子线程； 子线程中的 SubReactor 对象将 MainReactor 对象分配的连接加入 select 继续进行监听，并创建一个 Handler 用于处理连接的响应事件。 如果有新的事件发生时，SubReactor 对象会调用当前连接对应的 Handler 对象来进行响应。 Handler 对象通过 read -&amp;gt; 业务处理 -&amp;gt; send 的流程来完成完整的业务流程。多 Reactor 多线程的方案虽然看起来复杂的，但是实际实现时比单 Reactor 多线程的方案要简单的多，原因如下： 主线程和子线程分工明确，主线程只负责接收新连接，子线程负责完成后续的业务处理。 主线程和子线程的交互很简单，主线程只需要把新连接传给子线程，子线程无须返回数据，直接就可以在子线程将处理结果发送给客户端。ProactorProactor 采用了异步 I/O 技术，所以被称为异步网络模型。当我们发起 aio_read （异步 I/O） 之后，就立即返回，内核准备数据并且自动将数据从内核空间拷贝到用户空间，整个过程都是异步的，内核自动完成的，和前面的同步操作不一样，应用程序并不需要主动发起拷贝动作。Reactor 和 Proactor 的区别： Reactor 是非阻塞同步网络模式，感知的是就绪可读写事件。在每次感知到有事件发生（比如可读就绪事件）后，就需要应用进程主动调用 read 方法来完成数据的读取，也就是要应用进程主动将 socket 接收缓存中的数据读到应用进程内存中，这个过程是同步的，读取完数据后应用进程才能处理数据。 Proactor 是异步网络模式， 感知的是已完成的读写事件。在发起异步读写请求时，需要传入数据缓冲区的地址（用来存放结果数据）等信息，这样系统内核才可以自动帮我们把数据的读写工作完成，这里的读写工作全程由操作系统来做，并不需要像 Reactor 那样还需要应用进程主动发起 read/write 来读写数据，操作系统完成读写工作后，就会通知应用进程直接处理数据。因此，Reactor 可以理解为「来了事件操作系统通知应用进程，让应用进程来处理」，而 Proactor 可以理解为「来了事件操作系统来处理，处理完再通知应用进程」。这里的「事件」就是有新连接、有数据可读、有数据可写的这些 I/O 事件这里的「处理」包含从驱动读取到内核以及从内核读取到用户空间。Proactor 模式的工作流程： Proactor Initiator 负责创建 Proactor 和 Handler 对象，并将 Proactor 和 Handler 都通过 Asynchronous Operation Processor 注册到内核； Asynchronous Operation Processor 负责处理注册请求，并处理 I/O 操作； Asynchronous Operation Processor 完成 I/O 操作后通知 Proactor； Proactor 根据不同的事件类型回调不同的 Handler 进行业务处理； Handler 完成业务处理；在 Linux 下的异步 I/O 是不完善的， aio 系列函数是由 POSIX 定义的异步操作接口，不是真正的操作系统级别支持的，而是在用户空间模拟出来的异步，并且仅仅支持基于本地文件的 aio 异步操作，网络编程中的 socket 是不支持的，这也使得基于 Linux 的高性能网络程序都是使用 Reactor 方案什么是一致性哈希？如何分配请求？服务器集群是如何分配客户端的请求的？这个问题就是负载均衡问题。最简单的方式就是引入一个中间的负载均衡层，让它将外界的请求轮流的转发给内部的集群，达到分配请求的目的。考虑到每个服务器的配置不同，可以引入权重值，做加权轮训。轮询的使用场景是每个服务器存储的数据都是相同的，所以访问任意一个数据库都能得到结果。但是在分布式系统中，每个节点存储的数据是不同的，比如一个分布式 KV（key-valu） 缓存系统，某个 key 应该到哪个或者哪些节点上获得，应该是确定的，不是说任意访问一个节点都可以得到缓存结果的。就需要使用别的负载均衡算法。使用哈希算法有什么问题？哈希算法最简单的做法就是进行取模运算，比如分布式系统中有 3 个节点，基于 hash(key) % 3 公式对数据进行了映射。但是有一个很致命的问题，如果节点数量发生了变化，也就是在对系统做扩容或者缩容时，必须迁移改变了映射关系的数据，否则会出现查询不到数据的问题。使用一致性哈希算法有什么问题？一致性哈希算法就很好地解决了分布式系统在扩容或者缩容时，发生过多的数据迁移的问题。一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而一致哈希算法是对 2^32 进行取模运算，是一个固定的值。我们可以把一致哈希算法是对 2^32 进行取模运算的结果值组织成一个圆环，即哈希环。一致性哈希要进行两步哈希： 第一步：对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希； 第二步：当对数据进行存储或访问时，对数据进行哈希映射；所以，一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上。问题来了，对「数据」进行哈希映射得到一个结果要怎么找到存储该数据的节点呢？答案是，映射的结果值往顺时针的方向的找到第一个节点，就是存储该数据的节点。所以，当需要对指定 key 的值进行读写的时候，要通过下面 2 步进行寻址： 首先，对 key 进行哈希计算，确定此 key 在环上的位置； 然后，从这个位置沿着顺时针方向走，遇到的第一节点就是存储 key 的节点。在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。但是一致性哈希算法并不保证节点能够在哈希环上分布均匀，这样就会带来一个问题，会有大量的请求集中在一个节点上。所以，一致性哈希算法虽然减少了数据迁移量，但是存在节点分布不均匀的问题。如何通过虚拟节点提高均衡度？要想解决节点能在哈希环上分配不均匀的问题，就是要有大量的节点，节点数越多，哈希环上的节点分布的就越均匀。但问题是，实际中我们没有那么多节点。所以这个时候我们就加入虚拟节点，也就是对一个真实节点做多个副本。具体做法是，不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。另外，虚拟节点除了会提高节点的均衡度，还会提高系统的稳定性。当节点变化时，会有不同的节点共同分担系统的变化，因此稳定性更高。比如，当某个节点被移除时，对应该节点的多个虚拟节点均会移除，而这些虚拟节点按顺时针方向的下一个虚拟节点，可能会对应不同的真实节点，即这些不同的真实节点共同分担了节点变化导致的压力。带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景。" }, { "title": "计网相关知识整理", "url": "/posts/NetWork-knowledge/", "categories": "笔记, 计网", "tags": "总结, 计算机网络, 八股, HTTP, TCP, IP", "date": "2022-07-19 20:06:20 +0800", "snippet": "基础TCP/IP 网络模型有哪几层？首先，需要明确，为什么要有TCP/IP网络模型？因为如果要对同一台设备上的进程间进行通信，有很多种方式，比如管道、消息队列、共享内存、信号等，但是对不同设备上的进程间通信，就需要网络通信，而设备是多种多样的，所以就要兼容这些设备，就协商出了一套通用的网络协议。网络协议是分层的，每一层都有各自的作用和职责。应用层向用户提供应用服务并规定应用程序间通信的相关细节。比如HTTP、FTP、Telnet、DNS、SMTP等。应用层是工作在操作系统中的用户态，传输层及以下则工作在内核态。传输层应用层的数据包会传给传输层，传输层是为应用层提供网络支持的。在传输层会有两个传输协议，分别是 TCP 和 UDP。TCP 是可靠传输。TCP 相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等。UDP 是不可靠传输，只负责发送数据包，不保证数据包是否能抵达对方，但它实时性更好，传输效率也高。TCP段：应用需要传输的数据可能会非常大，如果直接传输就不好控制，因此当传输层的数据包大小超过 MSS（TCP 最大报文段长度） ，就要将数据包分块，这样即使中途有一个分块丢失或损坏了，只需要重新发送这一个分块，而不用重新发送整个数据包。在 TCP 协议中，每个分块称之为一个 TCP 段。端口：当设备作为接收方时，传输层则要负责把数据包传给应用，但是一台设备上可能会有很多应用在接收或者传输数据，因此需要用一个编号将应用区分开来，这个编号就是端口。网络层传输层值负责应用之间的通信，而网络层负责将数据从一各设备传输到另一个设备。网络层最常使用的是 IP 协议，IP 协议会将传输层的报文加上 IP 头部组装成 IP 报文，如果 IP 报文大小超过 MTU（最大传输单元）就会再次进行分片。IP协议主要有两个功能： 寻址。通过IP地址确定数据包传输的目的地址。 路由。数据包到达一各节点后通过路由算法决定下一步的路径。网络接口层网络接口层在 IP 报文的前面加上 MAC 头部，并封装成数据帧（Data frame）发送到网络上。每一层的数据封装格式网络接口层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message），可以统称为数据包。键入网址到网页显示，期间发生了什么？1、浏览器做的第一步工作是解析 URL，生成HTTP请求消息2、生成HTTP消息后，通过DNS查询服务器域名对应的IP地址3、获取到 IP 后，就可以把 HTTP 的传输工作通过调用socket库交给操作系统中的协议栈4、TCP通过三次挥手建立连接，将数据封装成TCP数据包交给IP，IP封装成IP数据包交个网卡驱动5、网卡驱动接受IP包，将其装交给网卡，网卡将包转换为电信号，通过网线发送出去6、数据包通过交换机到达路由器，通过多个路由器的转发到达服务器7、服务器逐层拆解数据包，根据请求响应资源，然后再发给客户端，客户端接受数据并在浏览器显示。8、请求操作完成，客户端向服务器发起四次挥手断开连接。HTTPHTTP 常见面试题HTTP 基本概念==HTTP 是什么？==HTTP 是超文本传输协议，也就是HyperText Transfer Protocol。超文本：互联网早期的文本只是简单的字符文字，而超文本是文字、图片、音频、视频、超链接等混合体。传输：就是在两点之间传送数据。协议：计算机之间通信约定的规范。==HTTP 常见的状态码有哪些？==1xx 类状态码属于提示信息，是协议处理中的一种中间状态，实际用到的比较少。2xx 类状态码表示服务器成功处理了客户端的请求。 「200 OK」是最常见的成功状态码，表示一切正常。如果是非 HEAD 请求，服务器返回的响应头都会有 body 数据。 「204 No Content」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。 「206 Partial Content」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。3xx 类状态码表示客户端请求的资源发生了变动，需要客户端用新的URL重新请求资源，即重定向。 「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。 「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。 「304 Not Modified」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。4xx 类状态码表示客户端发送的报文有误，服务器无法处理。 「400 Bad Request」表示客户端请求的报文有错误，但只是个笼统的错误。 「403 Forbidden」表示服务器禁止访问资源，并不是客户端的请求出错。 「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。5xx 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。 「500 Internal Server Error」，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。 「501 Not Implemented」表示客户端请求的功能还不支持。 「502 Bad Gateway」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。 「503 Service Unavailable」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。==HTTP 常见字段有哪些？==Host字段：客户端发送请求时，用来指定服务器的域名。Content-Length字段：表明服务器返回时，本次回应的数据长度。Connection 字段：用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。Content-Type 字段：用于服务器回应时，告诉客户端，本次数据是什么格式Content-Encoding 字段：表示服务器返回的数据使用了什么压缩格式Get 与 Post==GET 和 POST 有什么区别？==GET 是从服务器获取指定的资源，比如文本、图片、视频等。POST 是根据请求负荷（报文body）对指定的资源做出处理，具体的处理方式视资源类型而不同==GET 和 POST 方法都是安全和幂等的吗？==安全和幂等的概念： 在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。GET 方法就是安全且幂等的，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。因此，浏览器可以缓存get请求，也可以把get请求保存为书签。POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签。==GET 请求可以带 body 吗？==理论上，任何请求都可以带 body 的，但是get的规范定义是请求资源，所以不需要用到body。HTTP 缓存技术==HTTP 缓存有哪些实现方式？==对于一些具有重复性的 HTTP 请求，我们可以把「请求-响应」的数据都缓存在本地，那么下次就直接读取本地的数据，这样可以提高HTTP的性能。HTTP 缓存有两种实现方式，分别是强制缓存和协商缓存。==什么是强制缓存？==强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。 Cache-Control， 是一个相对时间； Expires，是一个绝对时间；如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，Cache-Control的优先级高于 Expires 。Cache-control 选项更多一些，设置更加精细，所以建议使用 Cache-Control 来实现强缓存。具体如下： 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 响应头部加上 Cache-Control，Cache-Control 中设置了过期时间大小； 浏览器再次请求访问服务器中的该资源时，会先通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期，如果没有，则使用该缓存，否则重新请求服务器； 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。==什么是协商缓存？==通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。协商缓存可以基于两种头部来实现。第一种：请求头部中的 If-Modified-Since 字段与响应头部中的 Last-Modified 字段实现，这两个字段的意思是： 响应头部中的 Last-Modified：标示这个响应资源的最后修改时间； 请求头部中的 If-Modified-Since：当资源过期了，发现响应头中具有 Last-Modified 声明，则再次发起请求的时候带上If-Modified-Since的时间，服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。第二种：请求头部中的 If-None-Match 字段与响应头部中的 ETag 字段，这两个字段的意思是： 响应头部中 Etag：唯一标识响应资源； 请求头部中的 If-None-Match：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。第一种实现方式是基于时间实现的，第二种实现方式是基于一个唯一标识实现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。注意：协商缓存这两个字段都需要配合强制缓存中 Cache-control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求。HTTP 特性==HTTP（1.1） 的优点有哪些？==HTTP 最凸出的优点是「简单、灵活和易于扩展、应用广泛和跨平台」。简单：HTTP 基本的报文格式就是 header + body，头部信息也是 key-value 简单文本的形式，易于理解，降低了学习和使用的门槛。灵活和易于扩展：HTTP协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员自定义和扩充。应用广泛和跨平台：可以用在不同操作系统以及手机上的各种应用中。==HTTP（1.1） 的缺点有哪些？==有无状态、明文传输的双刃剑，同时还有一大缺点「不安全」。无状态：无状态的好处，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担。无状态的坏处，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦，没操作一次都要验证信息。比较简单的解决方式是cookie技术。Cookie 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。具体过程是：客户端第一次请求后，服务器在响应中添加cookie后返回，然后客户端如果保存了cookie，在第二次请求时就会带上cookie，服务器通过检查cookie来辨认客户端。明文传输：明文意味着在传输过程中的信息，是可方便阅读的，也方便调试。但是这样会引发信息安全问题。不安全：比较严重的缺点，可以用HTTPS的方式解决。 通信使用明文（不加密），存在窃听风险。比如，账号信息容易泄漏导致被盗号。 不验证通信方的身份，存在冒充风险。比如，访问假的淘宝、拼多多导致被骗钱。 无法证明报文的完整性，存在篡改风险。比如，网页上植入垃圾广告影响使用体验==HTTP/1.1 的性能如何？==长连接：HTTP/1.1 提出了长连接的通信方式，好处是减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。管道连接：因为使用了长连接的方式，所以管道网络传输成为了可能，也就是在发送请求的时候，不必等到请求相应就可以发送另一个请求，从而减少整体的响应时间。但是没有默认开启，浏览器也很少有支持的。队头阻塞：「请求 - 应答」的模式加剧了 HTTP 的性能问题，容易引发队头阻塞问题。即顺序发送的请求序列中一个请求被阻塞后，后面的所有请求也一同被阻塞了，导致客户端一直请求不到数据。总之 HTTP/1.1 的性能一般般，后续的 HTTP/2 和 HTTP/3 就是在优化 HTTP 的性能。HTTPS 与 HTTP==HTTP 与 HTTPS 有哪些区别？== HTTP 是明文传输，存在安全问题，HTTPS 针对此问题在 TCP 和 HTTP 之间加入了 SSL/TLS 安全协议。 HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。 HTTP 的端口号是 80，HTTPS 的端口号是 443。 HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。==HTTPS 是如何解决HTTP的安全问题的？==安全问题主要有三个：明文传输导致的窃听风险，不验证通信方身份导致的冒充风险，无法证明报文的完整性导致的被攥改风险。解决方法分别如下： 信息加密：使用混合加密的方式对传输的信息进行加密 身份证书：使用数字证书验证通信方身份 校验机制：使用摘要算法来保证校验数据的完整性混合加密：HTTPS 采用的是对称加密和非对称加密结合的「混合加密」方式： 在通信建立前采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密。 在通信过程中全部使用对称加密的「会话秘钥」的方式加密明文数据。采用「混合加密」的方式的原因： 对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。 非对称加密使用两个密钥：公钥和私钥，公钥可任意分发而私钥保密，解决了密钥交换问题但速度慢。非对称加密常用算法有RSA和ECDHE（椭圆曲线加密）。摘要算法：用摘要算法（哈希函数）来计算出内容的哈希值，这个哈希值是唯一的，且无法通过哈希值推导出内容。客户端将内容和哈希值一同发送出去，服务端收到后对内容也计算出一个哈希值，计较两个哈希值是否相同就可以判断内容是否被篡改。但哈希算法并不能保证内容+哈希值不会被其他人替换。可以使用非对称加密算法来解决这个问题： 公钥加密，私钥解密。这个目的是为了保证内容传输的安全，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容； 私钥加密，公钥解密。这个目的是为了保证消息不会被冒充，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。一般我们不会用非对称加密来加密实际的传输内容，因为非对称加密的计算比较耗费性能的。数字签名算法就是通过「私钥加密，公钥解密」的非对称加密方式，来确认消息的身份。不过私钥加密内容不是内容本身，而是对内容的哈希值加密。私钥是由服务端保管，然后服务端会向客户端颁发对应的公钥。如果客户端收到的信息，能被公钥解密，就说明该消息是由服务器发送的。数字证书：使用加密算法可以对信息进行加密，对信息完整性进行校验，但是还有一个问题，就是身份验证问题，也就是要确保公钥的身份正确，因为公钥也可能会被伪造。通过CA（数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。==HTTPS 是如何建立连接的？其间交互了什么？==SSL/TLS 协议基本流程： 客户端向服务器索要并验证服务器的公钥。 双方协商生产「会话秘钥」。 双方采用「会话秘钥」进行加密通信。前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段。SSL/TLS 协议建立的详细流程（基于RSA的HTTPS）：1. ClientHello首先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。在这一步，客户端主要向服务器发送以下信息：（1）客户端支持的 SSL/TLS 协议版本，如 TLS 1.2 版本。（2）客户端生产的随机数（Client Random），后面用于生成「会话秘钥」条件之一。（3）客户端支持的密码套件列表，如 RSA 加密算法。2. SeverHello服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello。服务器回应的内容有如下内容：（1）确认 SSL/ TLS 协议版本，如果浏览器不支持，则关闭加密通信。（2）服务器生产的随机数（Server Random），也是后面用于生产「会话秘钥」条件之一。（3）确认的密码套件列表，如 RSA 加密算法。（4）服务器的数字证书。3.客户端回应客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：（1）一个随机数（pre-master key）。该随机数会被服务器公钥加密。（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。4. 服务器的最后回应服务器收到客户端的第三个随机数（pre-master key）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。然后，向客户端发送最后的信息：（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。至此，整个 SSL/TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。==客户端校验数字证书的流程是怎样的？==CA 签发证书的过程： 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值； 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名； 最后将 Certificate Signature 添加在文件证书上，形成数字证书；客户端校验服务端的数字证书的过程： 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1； 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ； 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。HTTP/1.1、HTTP/2、HTTP/3 演变==HTTP/1.1 相比 HTTP/1.0 提高了什么性能？==HTTP/1.1 相比 HTTP/1.0 性能上的改进： 使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。但 HTTP/1.1 还是有性能瓶颈： 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。 服务器是按请求的顺序响应的，如果服务器响应慢，会导致客户端一直请求不到数据，出现队头阻塞； 请求只能从客户端开始，服务器只能被动响应。 没有请求优先级控制==HTTP/2 做了什么优化？==HTTP/2 相比 HTTP/1.1 性能上的改进：1. 头部压缩HTTP/2 会压缩头部（Header），如果你同时发出多个请求，他们的头部是一样的或是相似的，那么，协议会帮你消除重复的部分。这就是所谓的 HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。2. 二进制格式HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式，头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧（Headers Frame）和数据帧（Data Frame）。这样收到报文之后可以直接进行解析，增加了数据传输的效率。3. 数据流在 HTTP/2 中每个请求或响应的所有数据包，称为一个数据流（Stream）。每个数据流都标记着一个独一无二的编号（Stream ID），不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ），因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息客户端和服务器双方都可以建立 Stream， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。客户端还可以指定数据流的优先级。优先级高的请求，服务器就先响应该请求。4. 多路复用HTTP/2 是可以在一个连接中并发多个请求或回应，而不用按照顺序一一对应。移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，降低了延迟，大幅度提高了连接的利用率。5. 服务器推送HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以主动向客户端发送消息。==HTTP/2 有什么缺陷？==HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。==HTTP/3 做了哪些优化？==HTTP/2 队头阻塞的问题是因为 TCP，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！因为UDP是不可靠传输，所以使用QUIC协议来实现类似TCP的可靠性传输。QUIC 有以下 3 个特点：1、无队头阻塞QUIC 有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。2、更快的连接建立对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS/1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商注意：SSL/TLS 1.2 需要 4 握手，需要 2 个 RTT 的时延，SSL/TLS 1.3 优化了过程，只需要 1 个 RTT 往返时延，也就是只需要 3 次握手。3、连接迁移基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接，那么当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过连接 ID来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了连接迁移的功能。HTTP/1.1如何优化？第一个思路是，通过缓存技术来避免发送 HTTP 请求。客户端收到第一个请求的响应后，可以将其缓存在本地磁盘，下次请求的时候，如果缓存没过期，就直接读取本地缓存的响应数据。如果缓存过期，客户端发送请求的时候带上响应数据的摘要，服务器比对后发现资源没有变化，就发出不带包体的 304 响应，告诉客户端缓存的响应仍然有效。第二个思路是，减少 HTTP 请求的次数，有以下的方法： 将原本由客户端处理的重定向请求，交给代理服务器处理，这样可以减少重定向请求的次数； 将多个小资源合并成一个大资源再传输，能够减少 HTTP 请求次数以及 头部的重复传输，再来减少 TCP 连接数量，进而省去 TCP 握手和慢启动的网络消耗； 按需访问资源，只访问当前用户看得到/用得到的资源，当客户往下滑动，再访问接下来的资源，以此达到延迟请求，也就减少了同一时间的 HTTP 请求次数。第三思路是，通过压缩响应资源，降低传输资源的大小，从而提高传输效率，压缩方式可分为有损压缩（比如webP格式图片）和无损压缩（比如gzip）。TCPTCP 三次握手与四次挥手TCP基本认识==TCP 头格式==序列号：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。用来解决网络包乱序问题。确认应答号：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。用来解决丢包的问题。控制位： ACK：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 SYN 包之外该位必须设置为 1 。 RST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。 SYN：该位为 1 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。 FIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。==为什么需要 TCP 协议 ？==IP 层是「不可靠」的，它不保证网络包的交付、不保证网络包的顺序、也不保证网络包中的数据的完整性。如果需要保障网络数据包的可靠性，那么就需要由传输层的 TCP 协议来负责。因为 TCP 是一个工作在传输层的可靠数据传输的服务，它能确保接收端接收的网络包是无损坏、无间隔、非冗余和按序的。==什么是 TCP ？==TCP 是面向连接的、可靠的、基于字节流的传输层通信协议。 面向连接：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的； 可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端； 字节流：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方程序不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。==如何唯一确定一个 TCP 连接呢？==TCP 四元组可以唯一的确定一个连接，四元组包括如下：源地址、源端口、目的地址、目的端口源地址和目的地址的字段（32位）是在 IP 头部中，作用是通过 IP 协议发送报文给对方主机。源端口和目的端口的字段（16位）是在 TCP 头部中，作用是告诉 TCP 协议应该把报文发给哪个进程。==UDP 和 TCP 有什么区别呢？分别的应用场景是？==UDP 是面向无连接的、不可靠的传输层控制协议。UDP 协议非常简单，头部只有 8 个字节： 目标和源端口：主要是告诉 UDP 协议应该把报文发给哪个进程。 包长度：该字段保存了 UDP 首部的长度跟数据的长度之和。 校验和：校验和是为了提供可靠的 UDP 首部和数据而设计，防止收到在网络传输中受损的 UDP包。TCP 和 UDP 区别：1. 连接 TCP 是面向连接的传输层协议，传输数据前先要建立连接。 UDP 是不需要连接，即刻传输数据。2. 服务对象 TCP 是一对一的两点服务，即一条连接只有两个端点。 UDP 支持一对一、一对多、多对多的交互通信3. 可靠性 TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。 UDP 是尽最大努力交付，不保证可靠交付数据。4. 拥塞控制、流量控制 TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。 UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。5. 首部开销 TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。 UDP 首部只有 8 个字节，并且是固定不变的，开销较小。6. 传输方式 TCP 是流式传输，没有边界，但保证顺序和可靠。 UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。7. 分片不同 TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要重传丢失的这个分片。 UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。TCP 和 UDP 应用场景：由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于： FTP 文件传输； HTTP / HTTPS；由于 UDP 面向无连接，尽最大努力交付，再加上UDP简单高效，因此经常用于： 包总量较少的通信，如 DNS ； 视频、音频等多媒体通信； 广播通信；==为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？==因为TCP 有可变长的「选项」字段，因此其头部长度也是可变的；而UDP 头部长度则是固定的，无需多一个字段去记录 UDP 的首部长度。==为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？==TCP计算负载数据的长度：TCP数据长度=IP总长度-IP首部长度-TCP首部长度，其中 IP 总长度 和 IP 首部长度，在 IP 首部格式已知。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度。UDP也可以算出来，可能是为了内存对齐（4字节的整数倍）吧，所以才补充了包长度字段。TCP连接建立==TCP 三次握手过程和状态变迁==TCP通过三次握手来建立连接，过程如下： 一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态 客户端会随机初始化序列号（client_isn），将此序列号置于 TCP 首部的「序列号」字段中，同时把 SYN 标志位置为 1 ，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态。 服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序列号（server_isn），将此序列号填入 TCP 首部的「序列号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带应用数据，之后客户端处于 ESTABLISHED 状态。 服务器收到客户端的应答报文后，也进入 ESTABLISHED 状态。一旦完成三次握手，双方都处于 ESTABLISHED 状态，此时连接就已建立完成，客户端和服务端就可以相互发送数据了。第三次握手是可以携带数据的，前两次握手是不可以携带数据的==如何在 Linux 系统中查看 TCP 状态？==TCP 的连接状态查看，在 Linux 可以通过 netstat -napt 命令查看。==为什么是三次握手？不是两次、四次？==原因一：避免历史连接什么情况下可能会出现历史连接问题？客户端连续发送多次 SYN 建立连接的报文，在网络拥堵情况下一个「」比「最新的 SYN 」 报文早到达了服务端，这个时候可能会与旧SYN报文建立连接，这就是历史连接问题。三次握手怎么避免历史连接？如果使用的是三次握手，当服务器接收到旧 SYN 报文之后，会回一个SYN + ACK 报文给客户端，客户端收到后可以根据自身的上下文，判断这是一个历史连接（序列号过期或超时），那么客户端就会发送 RST 报文给服务端，表示中止这一次连接，然后再与最新SYN报文建立连接。两次握手为什么无法阻止历史连接？因为如果是两次握手的话，服务器在收到SYN报文后，就进入 ESTABLISHED 状态，这意味着可以给客户端发送数据，但是此时客户端还没有进入ESTABLISHED 状态。如果这次是历史连接，客户端判断此次连接为历史连接后回复 RST 报文来断开连接，但是服务端在第一次握手的时候就进入 ESTABLISHED 状态，所以它是可以发送数据的，因为它并不知道这个是历史连接，它只有在收到 RST 报文后，才会断开连接。也就是说在两次握手的情况下，「被动发起方」没有中间状态给「主动发起方」来阻止历史连接，导致「被动发起方」可能建立一个历史连接，造成资源浪费。原因二：同步双方初始序列号TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，作用是： 接收方可以去除重复的数据； 接收方可以根据数据包的序列号按序接收； 可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；四次握手其实也能够可靠的同步双方的初始化序号，但由于第二步和第三步可以优化成一步，所以就成了「三次握手」。而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。（需要一个应答来回，才能确保双方的初始化序列号都能被可靠同步）原因三：避免资源浪费在两次握手中，如果客户端的 SYN 阻塞了，就会重复发送多次 SYN 报文，那么服务器在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。总结：TCP 建立连接时，通过三次握手能防止简历历史连接，能减少不必要的资源开销，能帮助双方同步初始化序列号。不使用「两次握手」和「四次握手」的原因： 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号； 「四次握手」：三次握手就已经可以建立可靠连接，所以不需要使用更多的通信次数。==为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？==主要原因有两个方面： 为了防止历史报文被下一个相同四元组的连接接收（主要方面）； 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；具体来说，如果在建立连接过程中出现了网络阻塞，就会出现历史SYN报文，此时如果服务端的进程重启，会发送RST报文来断开连接。然后，客户端与服务端重新建立连接，因为客户端和服务端的初始化序列号一样，所以会建立和上一个相同的连接。等到连接建立完成后，被阻塞的数据包到达服务端周后，会被当做数据正常接收，就会造成数据错乱。如果每次建立连接客户端和服务端的初始化序列号都「不一样」，就有大概率因为历史报文的序列号「不在」对方接收窗口，从而很大程度上避免了接受历史报文。注意并不是完全避免==初始序列号 ISN 是如何随机产生的？==随机数是会基于时钟计时器递增的，所以基本不可能会随机成一样的初始化序列号。==既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？==首先要区分一下MTU和MSS： MTU：一个网络包的最大长度，以太网中一般为 1500 字节； MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；IP层没有超时重传机制，如果在IP层分片，那丢失某片后，需要依靠TCP的超时重传整个TCP报文，效率低。因此，为了达到最佳的传输效率，TCP 协议在建立连接的时候通常要协商双方的 MSS 值，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。经过 TCP 层分片后，如果一个 TCP 分片丢失后，进行重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传的效率。==第一次握手丢失了，会发生什么？==当客户端想和服务端建立 TCP 连接的时候，首先第一个发的就是 SYN 报文，然后进入到 SYN_SENT 状态。在这之后，如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发「超时重传」机制，重传 SYN 报文。在 Linux 里，户端的 SYN 报文最大重传次数默认值一般是5（由 tcp_syn_retries内核参数控制），每次超时等待的时间是上一次的2倍，重传五次后仍然无回应会断开TCP连接。所以，总耗时是 1+2+4+8+16+32=63 秒，大约 1 分钟左右。==第二次握手丢失了，会发生什么？==当服务端收到客户端的第一次握手后，就会回 SYN-ACK 报文给客户端，这个就是第二次握手，此时服务端会进入 SYN_RCVD 状态。第二次握手的 SYN-ACK 报文其实有两个目的 ： 第二次握手里的 ACK， 是对第一次握手的确认报文； 第二次握手里的 SYN，是服务端发起建立 TCP 连接的报文；所以，第二次握手丢失，客户端没有收到服务端的确认报文，会认为自己的SYN报文丢失了，然后触发超时重传机制；而服务端的请求报文丢失，就得不到客户端的确认报文，也会触发超时重传机制。在 Linux 下，SYN-ACK 报文的最大重传次数由 tcp_synack_retries内核参数决定，默认值是 5。==第三次握手丢失了，会发生什么？==客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 ESTABLISH 状态。因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。注意：ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的请求报文。==什么是 SYN 攻击？如何避免 SYN 攻击？==SYN 攻击：TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到一个 SYN 报文，就进入SYN_RCVD 状态，但服务端发送出去的 ACK+SYN 报文，无法得到未知 IP 主机的 ACK 应答，久而久之就会占满服务端的半连接队列，使得服务器不能为正常用户服务。避免 SYN 攻击方式一其中一种解决方式是通过修改 Linux 内核参数，控制半连接队列大小和当队列满时做相应的处理，比如队列满后超出处理能力时，对新的SYN直接回报RST，丢弃连接。避免 SYN 攻击方式二开启tcp_syncookies功能Linux 内核的 SYN 队列（半连接队列）与 Accpet 队列（全连接队列）是如何工作的？ 当服务端接收到客户端的 SYN 报文时，会将其加入到内核的「 SYN 队列」； 接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文； 服务端接收到 ACK 报文后，从「 SYN 队列」移除放入到「 Accept 队列」； 应用通过调用 accpet() socket 接口，从「 Accept 队列」取出连接。当半连接队列占满后，服务器后续收到SYN包后计算出一个 cookie 值，放在 SYN + ACK 中发出，服务端接收到客户端的应答报文时，取出改制验证，检查这个 ACK 包的合法性。如果合法，直接放入到「 Accept 队列」。避免 SYN 攻击方式三减少SYN+ACK重传次数当服务端受到 SYN 攻击时，就会有大量处于 SYN_REVC 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。可以减少SYN+ACK的重传次数，使TCP连接更快的断开。TCP连接断开==TCP 四次挥手过程和状态变迁==双方都可以主动断开连接，断开连接后主机中的「资源」将被释放，四次挥手的过程如下： 客户端打算关闭连接，此时会发送一个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。 服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSED_WAIT 状态。 客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。 等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。 客户端收到服务端的 FIN 报文后，回一个 ACK 应答报文，之后进入 TIME_WAIT 状态 服务器收到了 ACK 应答报文后，就进入了 CLOSED 状态，至此服务端已经完成连接的关闭。 客户端在经过 2MSL 一段时间后，自动进入 CLOSED 状态，至此客户端也完成连接的关闭每个方向都需要一个FIN和一个ACK，所以是四次挥手，主动关闭连接的，才有TIME_WAIT状态。==为什么挥手需要四次？==服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，从而比三次握手导致多了一次。 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。 服务器收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。==第一次挥手丢失了，会发生什么？==当客户端（主动关闭方）调用 close 函数后，就会向服务端发送 FIN 报文，试图与服务端断开连接，此时客户端的连接进入到 FIN_WAIT_1 状态。正常情况下，如果能及时收到服务端（被动关闭方）的 ACK，则会很快变为 FIN_WAIT2状态。如果第一次挥手丢失了，那么客户端迟迟收不到被动方的 ACK 的话，也就会触发超时重传机制，重传 FIN 报文，重发次数由 tcp_orphan_retries 参数控制。当客户端重传 FIN 报文的次数超过 tcp_orphan_retries 后，就不再发送 FIN 报文，直接进入到 close 状态。==第二次挥手丢失了，会发生什么？==当服务端收到客户端的第一次挥手后，就会先回一个 ACK 确认报文，此时服务端的连接进入到 CLOSE_WAIT 状态。在前面我们也提了，ACK 报文是不会重传的，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。==第三次挥手丢失了，会发生什么？==当服务端（被动关闭方）收到客户端（主动关闭方）的 FIN 报文后，内核会自动回复 ACK，同时连接处于 CLOSE_WAIT 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。此时，内核是没有权利替代进程关闭连接，必须由进程主动调用 close 函数来触发服务端发送 FIN 报文。服务端处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文，同时连接进入 LAST_ACK 状态，等待客户端返回 ACK 来确认连接关闭。如果迟迟收不到这个 ACK，服务端就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。==第四次挥手丢失了，会发生什么？==当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 TIME_WAIT 状态。在 Linux 系统，TIME_WAIT 状态会持续 2MSL 后才会进入关闭状态。如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由前面介绍过的 tcp_orphan_retries 参数控制。==为什么 TIME_WAIT 等待的时间是 2MSL？==MSL 是 Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被自然消亡。TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了。TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间。2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 2MSL 时间将重新计时。==为什么需要 TIME_WAIT 状态？==主动发起关闭连接的一方，才会有 TIME-WAIT 状态。需要 TIME-WAIT 状态，主要是两个原因： 防止历史连接中的数据，被后面相同四元组的连接错误的接收； 保证「被动关闭连接」的一方，能被正确的关闭；原因一：序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据。假设 TIME-WAIT 没有等待时间或时间过短，被延迟的数据包抵达后会发生什么呢？在关闭之前发送的报文被延迟后，服务端断开之后又以相同的四元组重新打开了新连接，被延迟的数据包到达了客户端，而且该数据报文的序列号刚好在客户端接收窗口内，因此客户端会正常接受这个报文，但是这个报文是历史数据，这样就会残生数据错乱的问题。而设置2MSL时长的TIME_WAIT，足以让两个方向上的数据包都被丢弃，是的原来连接的数据包在网络中都自然消失，再出现的数据包一定是建立连接所产生的。原因二：IME-WAIT 作用是等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。如果客户端（主动关闭方）最后一次 ACK 报文（第四次挥手）在网络中丢失了，那么按照 TCP 可靠性原则，服务端（被动关闭方）会重发 FIN 报文。假设客户端没有 TIME_WAIT 状态，而是在发完最后一次回 ACK 报文就直接进入 CLOSED 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会回 RST 报文。服务端收到这个 RST 并将其解释为一个错误（Connection reset by peer），这对于一个可靠的协议来说不是一个优雅的终止方式。为了防止这种情况出现，客户端必须等待足够长的时间确保对端收到 ACK，如果对端没有收到 ACK，那么就会触发 TCP 重传机制，服务端会重新发送一个 FIN，这样一去一来刚好两个 MSL 的时间。==TIME_WAIT 过多有什么危害？== 第一是内存资源占用； 第二是对端口资源的占用，一个 TCP 连接至少消耗「发起连接方」的一个本地端口；客户端（发起连接方）受端口资源限制：客户端TIME_WAIT过多，就会导致端口资源被占用，因为端口就 65536 个，被占满就会导致无法创建新的连接。服务端（被动连接方）受系统资源限制：由于一个四元组表示 TCP 连接，理论上服务端可以建立很多连接，因为服务端只监听一个端口，不会因为 TCP 连接过多而导致端口资源受限。但是 TCP 连接过多，会占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等。==如果已经建立了连接，但是客户端突然出现故障了怎么办？==TCP 有一个机制是保活机制。这个机制的原理是这样的：定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。如果开启了 TCP 保活，需要考虑以下几种情况： 第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 TCP 保活时间会被重置，等待下一个 TCP 保活时间的到来。 第二种，对端程序崩溃并且已经重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，会产生一个 RST 报文，这样很快就会发现 TCP 连接已经被重置。 第三种，是对端程序由于崩溃或其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，没有响应，连续几次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。==如果已经建立了连接，但是服务端的进程崩溃会发生什么？==使用 kill -9 来模拟进程崩溃的情况，发现在 kill 掉进程后，服务端会发送 FIN 报文与客户端进行四次挥手。Socket编程==针对 TCP 应该如何 Socket 编程？== 服务端和客户端初始化 socket，得到文件描述符； 服务端调用 bind，将绑定在 IP 地址和端口; 服务端调用 listen，进行监听； 服务端调用 accept，等待客户端连接； 客户端调用 connect，向服务器端的地址和端口发起连接请求； 服务端 accept 返回用于传输的 socket 的文件描述符； 客户端调用 write 写入数据；服务端调用 read 读取数据； 客户端断开连接时，会调用 close，那么服务端 read 读取数据的时候，就会读取到了 EOF，待处理完数据后，服务端调用 close，表示连接关闭。这里需要注意的是，服务端调用 accept 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作监听 socket，一个叫作已完成连接 socket。成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。==listen 时候参数 backlog 的意义？==Linux内核中会维护两个队列： 半连接队列（SYN 队列）：接收到一个 SYN 建立连接请求，处于 SYN_RCVD 状态； 全连接队列（Accpet 队列）：已完成 TCP 三次握手过程，处于 ESTABLISHED 状态；backlog 是已完成连接建立的队列长度，通常认为 backlog 是 accept 队列。但是上限值是内核参数 somaxconn 的大小，也就说 accpet 队列长度 = min(backlog, somaxconn)。==accept 发生在三次握手的哪一步？== 客户端的协议栈向服务器端发送了 SYN 包，并告诉服务器端当前发送序列号 client_isn，客户端进入 SYN_SENT 状态； 服务器端的协议栈收到这个包之后，和客户端进行 ACK 应答，应答的值为 client_isn+1，表示对 SYN 包 client_isn 的确认，同时服务器也发送一个 SYN 包，告诉客户端当前我的发送序列号为 server_isn，服务器端进入 SYN_RCVD 状态； 客户端协议栈收到 ACK 之后，使得应用程序从 connect 调用返回，表示客户端到服务器端的单向连接建立成功，客户端的状态为 ESTABLISHED，同时客户端协议栈也会对服务器端的 SYN 包进行应答，应答数据为 server_isn+1； ACK 应答包到达服务器端后，服务器端的 TCP 连接进入 ESTABLISHED 状态，同时服务器端协议栈使得 accept 阻塞调用返回，这个时候服务器端到客户端的单向连接也建立成功。至此，客户端与服务端两个方向的连接都建立成功。客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。==客户端调用 close 了，连接时断开的流程是什么？== 客户端调用 close，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报文，进入 FIN_WAIT_1 状态； 服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 EOF 到接收缓冲区中，应用程序可以通过 read 调用来感知这个 FIN 包。这个 EOF 会被放在已排队等候的其他已接收的数据之后，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，服务端进入 CLOSE_WAIT 状态； 接着，当处理完数据后，自然就会读到 EOF，于是也调用 close 关闭它的套接字，这会使得服务端发出一个 FIN 包，之后处于 LAST_ACK 状态； 客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态； 服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态； 客户端经过 2MSL 时间之后，也进入 CLOSE 状态；TCP 重传、滑动窗口、流量控制、拥塞控制重传机制常见的重传机制： 超时重传 快速重传 SACK D-SACK超时重传重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 ACK 确认应答报文，就会重发该数据，也就是我们常说的超时重传。TCP在数据包丢失和确认应答丢失时都会触发超时重传机制。==超时时间应该设置为多少呢？==RTT （往返时延）指的是数据发送时刻到接收到确认的时刻的差值，也就是包的往返时间。超时重传时间是以 RTO （Retransmission Timeout 超时重传时间）表示。 当超时时间 RTO 较大时，重发就慢，丢了老半天才重发，效率低，性能差； 当超时时间 RTO 较小时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。因此，超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。实际上「报文往返 RTT 的值」是经常变化的，因为我们的网络也是时常变化的。也就因为「报文往返 RTT 的值」 是经常波动变化的，所以「超时重传时间 RTO 的值」应该是一个动态变化的值。Linux超时重传次数一般默认五次，每次都是上次的两倍时间。问题是：超时重发等待的时间可能较长，这个时候可以使用快速重传。快速重传快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。快速重传机制只解决了超时时间的问题，但是它并不知道该重传哪些TCP报文，因此就有SACK方法。SACK 方法SACK（选择性确认）需要在 TCP 头部「选项」字段里加一个 SACK 的东西，它将缓存的地图发送给发送方，这样发送方就知道哪些数据收到了，哪些数据没收到，然后只重传丢失的数据。D- SACK主要使用 SACK 来告诉「发送方」有哪些数据被重复接收了。接收方发给发送方的ACK丢失并且发送发超时后，发送方会重传数据包，接收方收到发送方重传的数据包，发现数据是重复收到的，于是恢复一个表示重复数据的SACK和当前ACK，告诉发送放当前ACK之前的所有数据都搜到了，刚才发的是重复数据。因此发送发就知道了，数据没有丢，是接受方的ACK确认报文丢了。滑动窗口==为什么引入窗口的概念？==TCP发送数据得到确认应答后才能继续发送下一个数据，这样的传输方式效率很低。所以引入了窗口，窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值。窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。ACK即使丢失了，也不会进行数据重发，因为可以通过下一个确认应答进行确认， 只要发送发收到了后面的确认应答，就意味着在此之前的所有数据接收方都收到了，这个模式叫累计确认或累计应答。==窗口大小由哪一方决定？==TCP 头部有一个字段叫 Window，也就是窗口大小。这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。所以，窗口的大小通常是由接收方的窗口大小来决定的。==发送方的滑动窗口==发送方将窗口内的未发送数据全部发送出去之后，可用窗口的大小就变成0了，这表示可用窗口在没收到ACK确认之前无法继续发送数据。在收到ACK确认之后，如果发送窗口的大小没有变化， 则窗口向右滑动，滑动记录等于接收到的ACK数量，滑动窗口内的未发送数据又变成了可用窗口。==接收方的滑动窗口==接收窗口将其大小通告给发送方，然后接受相应的数据。==接收窗口和发送窗口的大小是相等的吗？==并不是完全相等，接收窗口的大小是约等于发送窗口的大小的。因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据速度非常快的话，接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。流量控制发送方不能无脑的发数据给接收方，要考虑接收方处理能力。如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。为了解决这种现象发生，TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。简单来说就是保持接收方发送数据窗口大小不变，然后发送数据后等待确认应答，确认多少应答，就恢复多少的发送能力，如果达到发送窗口大小但还没有收到确认应答，就暂时停止发送数据。这样一来，发送数据量就能一直控制在一个阈值内，即实现了流量控制。==操作系统缓冲区与滑动窗口的关系==实际上，发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，会被操作系统调整。如果系统资源非常紧张的时候，操作系统可能会直接减少缓冲区的大小，这可能会引起丢包现象（接收方比较忙，暂时接受不了，会存在缓存中，但是操作系统又缩小了缓存，导致缓存保存不了，所以直接丢弃）。为了防止这种情况发生，TCP规定不允许同时减少缓存又收缩窗口，而是采用先收缩窗口，过段时间再减少缓存的策略。==窗口关闭==发送方的窗口大小由接收方来指定，如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。窗口关闭潜在的危险：当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，如果这个通告窗口的 ACK 报文在网络中丢失了，会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象。==TCP 是如何解决窗口关闭时，潜在的死锁现象呢？==为了解决这个问题，TCP 为每个连接设有一个持续定时器，只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。如果持续计时器超时，就会发送窗口探测 ( Window probe ) 报文，而对方在确认这个探测报文时，给出自己现在的接收窗口大小： 如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器； 如果接收窗口不是 0，那么死锁的局面就可以被打破了。窗口探测的次数一般为 3 次，如果 3 次过后接收窗口还是 0 的话，TCP就会发 RST 报文来中断连接。==糊涂窗口综合症==如果接收方来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。到最后，如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症。TCP + IP 头有 40 个字节，为了传输那几个字节的数据，要搭上这么大的开销，有点糊涂。糊涂窗口综合症的现象可以发生在发送方和接收方： 接收方可以通告一个小的窗口 而发送方可以发送小数据于是，要解决糊涂窗口综合症，就解决上面两个问题就可以了 让接收方不通告小窗口给发送方 让发送方避免发送小数据怎么让接收方不通告小窗口呢？当「窗口大小」小于 min( MSS，缓存空间/2 ) ，也就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通告窗口为 0，阻止发送方再发数据过来。等到接收方处理了一些数据后，窗口大小 &amp;gt;= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来。怎么让发送方避免发送小数据呢？发送方通常的策略:使用 Nagle 算法，该算法的思路是延时处理，满足两个条件中的一个才可以发送数据： 要等到窗口大小 &amp;gt;= MSS 或是 数据大小 &amp;gt;= MSS 收到之前发送数据的 ack 回包只要没满足上面条件中的一条，发送方一直在囤积数据，直到满足上面的发送条件。拥塞控制==为什么要有拥塞控制，不是有流量控制了吗？==流量控制是避免发送方的数据填满接收方的缓存而重发浪费流量，拥塞控制是为了避免网络拥堵。在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，然后陷入恶性循环。于是，就有了拥塞控制，控制的目的就是避免「发送方」的数据填满整个网络。==什么是拥塞窗口？和发送窗口有什么关系呢？==拥塞窗口 cwnd是发送方维护的一个的状态变量，它会根据网络的拥塞程度动态变化的。由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。拥塞窗口 cwnd 变化的规则： 只要网络中没有出现拥塞，cwnd 就会增大； 一旦网络中出现了拥塞，cwnd 就减少；==那么怎么知道当前网络是否出现了拥塞呢？==只要「发送方」没有在规定时间内接收到 ACK 应答报文，即发生超时重传，就认为网络出现了拥塞。==拥塞控制有哪些控制算法？==塞控制主要是四个算法： 慢启动 拥塞避免 拥塞发生 快速恢复慢启动TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量。慢启动的算法规则是：当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。慢启动算法发包的个数是指数性的增长。==慢启动会一直涨吗，涨到什么时候会停止？==有一个叫慢启动门限 ssthresh （slow start threshold）状态变量。 当 cwnd &amp;lt; ssthresh 时，使用慢启动算法。 当 cwnd &amp;gt;= ssthresh 时，就会使用「拥塞避免算法」。一般来说 ssthresh 的大小是 65535 字节。拥塞避免进入拥塞避免算法后，它的规则是：每当收到一个 ACK 时，cwnd 增加 1/cwnd。比如慢启动门限为8（此时可以一次发送8个数据），当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 MSS 大小的数据，变成了线性增长。所以，拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。一直增长会导致网络慢慢进入阻塞的状态，于是就会出现丢包现象，就触发了重传机制，一旦触发重传机制，就进入了拥塞发生算法。拥塞发生当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种： 超时重传 快速重传这两种使用的拥塞发生算法是不同的。==发生超时重传的拥塞发生算法==这个时候，ssthresh 和 cwnd 的值会发生变化： ssthresh 设为 cwnd/2， cwnd 恢复为 cwnd 初始化值接着，就重新开始慢启动，慢启动是会突然减少数据流的。这个反映太强烈，会造成网络卡顿。==发生快速重传的拥塞发生算法==TCP 认为发生快速重传时丢包现象不严重，则 ssthresh 和 cwnd 变化如下： cwnd = cwnd/2 ，也就是设置为原来的一半; ssthresh = cwnd; 进入快速恢复算法快速恢复快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像超时重传那么强烈。快速恢复算法如下： 拥塞窗口 cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）； 重传丢失的数据包； 如果再收到重复的 ACK，那么 cwnd 增加 1； 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh（出发快速重传时的cwnd的一半）的值，原因是该 ACK 确认了新的数据，说明从 D-ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；也就是没有像「超时重传」那么强烈，而是还在比较高的值，后续呈线性增长。如何优化TCP优化三次握手 客户端优化：当客户端发起 SYN 包时，可以通过 tcp_syn_retries 控制其重传的次数。 服务端优化：调整SYN办理按揭队列长度，调整SYN+ACK报文的重传次数，调整全连接队列长度 绕过三次握手：TCP Fast Open功能可以绕过三次握手，减少HTTP请求时间，通过tcp_fastopen开启。优化四次挥手 主动方优化：调整FIN报文重传次数，调整FIN_WAIT2状态的时间（close函数关闭会产生孤儿连接，shutdown函数则是直接关闭），调整孤儿连接的上限个数、调整time_wait状态的上限个数，复用time_wait状态的连接。 被动方优化：调整CLOSE_WAIT状态的个数，在LAST_ACK状态下控制FIN报文重传的次数。TCP 传输数据的性能提升 扩大滑动窗口大小 调整发送缓冲、接收缓冲区范围 打开接受缓冲区动态调节 调整内存范围如何理解是 TCP 面向字节流协议？TCP 是面向字节流的协议，UDP 是面向报文的协议？这里的「面向字节流」和「面向报文」该如何理解。如何理解字节流？==先来说说为什么 UDP 是面向报文的协议？==当用户消息通过 UDP 协议传输时，操作系统不会对消息进行拆分，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是每个 UDP 报文就是一个用户消息的边界，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。那收到了两个UDP报文，操作系统怎么区分开呢？操作系统在收到 UDP 报文后，会将其插入到队列里，队列里的每一个元素就是一个 UDP 报文，这样当用户调用 recvfrom() 系统调用读数据的时候，就会从队列里取出一个数据，然后从内核里拷贝给用户缓冲区。==再来说说为什么 TCP 是面向字节流的协议？==当用户消息通过 TCP 协议传输时，消息可能会被操作系统分组成多个的 TCP 报文，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。因此，我们不能认为一个用户消息对应一个 TCP 报文，正因为这样，所以 TCP 是面向字节流的协议。如果在发送的时候两个消息的某个部分被分到同一个 TCP 报文时，就出现了TCP 粘包问题，这时接收方不知道消息的边界的话，是无法读出有效的消息的。如何解决粘包？粘包的问题在于不知道用户消息的边界，如果知道了边界，就可以通过边界划分出有效的用户消息： 固定长度的消息 特殊字符作为边界 自定义消息结构==固定长度的消息==这种是最简单方法，即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。但是这种方式灵活性不高，实际中很少用。==特殊字符作为边界==我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。比如HTTP通过设置回车符、换行符作为HTTP报文协议的边界需要注意的是：如果消息内容里有特殊字符，需要对整个字符进行转移，避免被误当做消息边界。==自定义消息结构==我们可以自定义一个消息结构，由包头和数据组成，其中包头是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。当接收方接受到爆头之后就可以知道数据大小，然后读满数据组装成用户消息。SYN 报文什么时候情况下会被丢弃？ 开启 tcp_tw_recycle 参数，并且在 NAT 环境下，造成 SYN 报文被丢弃 TCP 两个队列满了（半连接队列和全连接队列），造成 SYN 报文被丢弃==tcp_tw_recycle==在四次挥手中，如果主动断开连接放的TIME_WAIT状态过多，占满了所有端口资源，会导致无法创建新连接。Linux提供了两个系统参数来快速挥手处于TIME_WAIT状态的连接，这两个参数都是默认关闭： tcp_tw_reuse，如果开启该选项的话，连接发起方在调用 connect() 函数时，内核会随机找一个 TIME_WAIT状态超过 1 秒的连接给新的连接复用，所以该选项只适用于连接发起方。 tcp_tw_recycle，如果开启该选项的话，允许处于 TIME_WAIT 状态的连接被快速回收。要使得这两个选项生效，有一个前提条件，就是要打开 TCP 时间戳，即tcp_timestamps=1（默认为1）。tcp_tw_recycle 在使用了 NAT（网络地址转换） 的网络下是不安全的！对于服务器来说，如果同时开启recycle 和 timestamps 选项，则会开启「 per-host 的 PAWS 机制」。什么是PAWS机制？tcp_timestamps 选项开启之后， PAWS 机制会自动开启，它的作用是防止 TCP 包中的序列号发生绕回。每个TCP包都会有自己唯一的序列号，序列号是有限的（32位），溢出之后会从0再次开始递增。某个数据包因网络或重发而延迟时，当它再次到达，可能会与当前数据包的序列号发生冲突，导致连接数据传输错误。PAWS 就是为了避免这个问题而产生的，在开启 tcp_timestamps 选项情况下，一台机器发的所有 TCP 包都会带上发送时间戳，PAWS 要求连接双方维护最近一次收到的数据包的时间戳（Recent TSval），每收到一个新数据包都会读取数据包中的时间戳值跟 最近一次疏导的数据包的时间戳做比较，如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包。什么是 per-host 的 PAWS 机制呢？per-host 是对「对端 IP 做 PAWS 检查」，但是如果客户端网络环境是用了 NAT 网关，那么客户端环境的每一台机器通过 NAT 网关后，都会是相同的 IP 地址，服务端无法区分。当客户端 A 通过 NAT 网关和服务器建立 TCP 连接，然后服务器主动关闭并且快速回收 TIME-WAIT 状态的连接后，客户端 B 也通过 NAT 网关和服务器建立 TCP 连接，注意客户端 A 和 客户端 B 因为经过相同的 NAT 网关，所以是用相同的 IP 地址与服务端建立 TCP 连接，如果客户端 B 的 timestamp 比 客户端 A 的 timestamp 小，那么由于服务端的 per-host 的 PAWS 机制的作用，服务端就会丢弃客户端主机 B 发来的 SYN 包。因此，tcp_tw_recycle 在使用了 NAT 的网络下可能会丢弃SYN报文，在Linux4.12后取消了这个参数。==TCP 两个队列满了==服务端收到客户端发起的 SYN 请求后，内核会把该连接存储到半连接队列，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到全连接队列，等待进程调用 accept函数时把连接取出来。当服务器造成syn攻击，就有可能导致 TCP 半连接队列满了，这时后面来的 syn 包都会被丢弃。但是，如果开启了syncookies 功能，即使半连接队列满了，也不会丢弃syn 包。防御 SYN 攻击的方法： 增大半连接队列； 开启 tcp_syncookies 功能 减少 SYN+ACK 重传次数在服务端并发处理大量请求时，如果 TCP accpet 队列过小，或者应用程序调用 accept() 不及时，就会造成 accpet 队列满了 ，这时后续的连接就会被丢弃，这样就会出现服务端请求数量上不去的现象。解决方法： 调大 accpet 队列的最大长度，调大的方式是通过调大 backlog 以及 somaxconn 参数。 检查系统或者代码为什么调用 accept() 不及时；已建立连接的TCP，收到SYN会发生什么？一个已经建立的 TCP 连接，客户端中途宕机了，而服务端此时也没有数据要发送，一直处于 establish 状态，客户端恢复后，向服务端建立连接，此时服务端会怎么处理？TCP 连接是由「四元组」唯一确认的，在这个场景下，只有源端口可能会不一样。1. 客户端的 SYN 报文里的端口号与历史连接不相同如果客户端恢复后发送的 SYN 报文中的源端口号跟上一次连接的源端口号不一样，此时服务端会认为是新的连接要建立，于是就会通过三次握手来建立新的连接。此时旧连接处于establish状态的服务端，如果发送了数据包给客户端，由于客户端的连接已经被关闭，此时客户端会回RST报文，服务端收到后就会释放连接。如果服务端一直没有发送数据包给客户端，在超过一段时间后， TCP 保活机制就会启动，检测到客户端没有存活后，接着服务端就会释放掉该连接。2. 客户端的 SYN 报文里的端口号与历史连接相同处于 establish 状态的服务端如果收到了客户端的 SYN 报文（注意此时的 SYN 报文是乱序的，因为 SYN 报文的初始化序列号是一个随机数），会回复一个携带了正确序列号和确认号的 ACK 报文，接着，客户端收到这个ACK，发现序列号并不是自己期望收到的，于是就会回 RST 报文，服务端收到后，就会释放掉该连接。四次挥手中收到乱序的 FIN 包会如何处理？如果 FIN 报文比数据包先抵达客户端，此时 FIN 报文其实是一个乱序的报文，此时客户端的 TCP 连接并不会从 FIN_WAIT_2 状态转换到 TIME_WAIT 状态。在 FIN_WAIT_2 状态时，如果收到乱序的 FIN 报文，那么就被会加入到「乱序队列」，并不会进入到 TIME_WAIT 状态。等再次收到前面被网络延迟的数据包时，会判断乱序队列有没有数据，然后会检测乱序队列中是否有可用的数据，如果能在乱序队列中找到与当前报文的序列号保持顺序的报文，就会看该报文是否有 FIN 标志，如果发现有 FIN 标志，这时才会进入 TIME_WAIT 状态。在 TIME_WAIT 状态的 TCP 连接，收到 SYN 后会发生什么？这个问题场景是服务器发送FIN断开连接，然后处于TIME_WAIT状态时收到客户端的SYN请求，因为在HTTP1.1中，服务器无法主动发送请求，只能由客户端主动发送请求。如果开启了时间戳机制的话，关键是要看 SYN 的「序列号和时间戳」是否合法，因为处于 TIME_WAIT 状态的连接收到 SYN 后，会根据其是否合法做出不同的处理。 合法 SYN：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要大，并且 SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要大。 非法 SYN：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要小，或者 SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要小。==收到合法 SYN==如果处于 TIME_WAIT 状态的连接收到「合法的 SYN 」后，就会重用此四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程。==收到非法的 SYN==如果处于 TIME_WAIT 状态的连接收到「非法的 SYN 」后，就会再回复一个第四次挥手的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号（ack num），就回 RST 报文给服务端。==处于 TIME_WAIT 状态的连接，收到 RST 会断开连接吗？==会不会断开，关键看 tcp_rfc1337 这个内核参数（默认情况是为 0）： 如果这个参数设置为 0， 收到 RST 报文会提前结束 TIME_WAIT 状态，释放连接。 如果这个参数设置为 1， 就会丢掉 RST 报文。提前结束可能会存在潜在问题，所以设置成1比较安全。TCP 连接，一端断电和进程崩溃有什么区别？==有keepalive 但是双方一直没有数据交互==TCP keepalive就是TCP的保活机制。两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。 如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 TCP 保活时间会被重置，等待下一个 TCP 保活时间的到来。 如果对端主机崩溃并且已经重启，请求端会收到一个对其保活探测报文的RST响应报文，然后断开连接。 如果对端主机崩溃，或对端由于其他原因导致报文不可达（比如断电）。当 TCP 保活的探测报文发送给对端后，没有响应，连续几次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活。那进程崩溃的情况呢？在进程崩溃后，服务端会发送 FIN 报文，与客户端进行四次挥手。==没有开启 TCP keepalive，且双方一直没有数据交互的情况下，如果客户端的「主机崩溃」了，会发生什么。==客户端主机崩溃了，服务端是无法感知到的，在加上服务端没有开启 TCP keepalive，又没有数据交互的情况下，服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态，直到服务端重启进程。==有数据交互场景下的一些异常情况==客户端主机宕机，又迅速重启，会发生什么？在客户端主机宕机后，服务端向客户端发送的报文会得不到任何的响应，在一定时长后，服务端就会触发超时重传机制，重传未得到响应的报文。客户端主机重启完成后，收到之前TCP连接的报文，由于之前的TCP连接数据结构已经丢失，所以会回复RST报文，断开连接。客户端主机宕机，一直没有重启，会发生什么？这种情况，服务端超时重传报文的次数达到一定阈值后，会停止重传，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了。拔掉网线后， 原本的 TCP 连接还存在吗？TCP 连接的状态等信息在 Linux 内核中的一个名为 struct socket 的结构体。拔掉网线，操作系统并不会更新该结构体中的内容，所以TCP连接的状态也不会发生改变。但是拔掉网线后会断网，此时需要看TCP连接中有没有数据传输。==拔掉网线后，有数据传输==在客户端拔掉网线后，客户端无法向服务端发送任何数据，服务端向客户端发送的数据报文就会得不到任何响应，在等待一定时长后，服务端会触发超时重传机制，重传未得到响应的数据报文。如果在服务端重传报文的过程中，客户端刚好把网线插回去了，由于拔掉网线并不会改变客户端的 TCP 连接状态，并且还是处于 ESTABLISHED 状态，所以这时客户端可以正常接收服务端发来的数据报文，然后客户端就会回 ACK 响应报文。此时，客户端和服务端的 TCP 连接依然存在的，就感觉什么事情都没有发生。但是，如果如果在服务端重传报文的过程中，客户端一直没有将网线插回去，服务端超时重传报文的次数达到一定阈值（达到一定时间或者一定次数）后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。而等客户端插回网线后，如果客户端向服务端发送了数据，由于服务端已经没有与客户端相同四元祖的 TCP 连接了，因此服务端内核就会回复 RST 报文，客户端收到后就会释放该 TCP 连接。此时，客户端和服务端的 TCP 连接都已经断开了。==拔掉网线后，没有数据传输==针对拔掉网线后，没有数据传输的场景，还得看是否开启了 TCP keepalive 机制。如果没有开启 TCP keepalive 机制，在客户端拔掉网线后，并且双方都没有进行数据传输，那么客户端和服务端的 TCP 连接将会一直保持存在。而如果开启了 TCP keepalive 机制，在客户端拔掉网线后，即使双方都没有进行数据传输，在持续一段时间后，TCP就会启动保活机制，发送探测报文，有三种情况（上面有）。==TCP keepalive 机制具体是怎么样的？==定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：net.ipv4.tcp_keepalive_time=7200 保活时间net.ipv4.tcp_keepalive_intvl=75 每次检测间隔net.ipv4.tcp_keepalive_probes=9 最大的检测次数也就是说在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接。==TCP keepalive 机制探测的时间也太长了吧？==TCP keepalive 是 TCP 层（内核态） 实现的，它是给所有基于 TCP 传输协议的程序一个兜底的方案。实际上，我们应用层可以自己实现一套探测机制，可以在较短的时间内，探测到对方是否存活。比如类似HTTP中长连接的超时时间一样，设置一个定时器，如果一个请求之后规定的时间内没有发起新的请求，定时器的时间到了，然后触发回调函数来释放该连接。TCP Keepalive 和 HTTP Keep-Alive 是一个东西吗？这两个完全是两样不同东西，实现的层面也不同： HTTP 的 Keep-Alive，是由应用层（用户态） 实现的，称为 HTTP 长连接； TCP 的 Keepalive，是由 TCP 层（内核态） 实现的，称为 TCP 保活机制；==HTTP 的 Keep-Alive==由于 HTTP 是基于 TCP 传输协议实现的，客户端与服务端要进行 HTTP 通信前，需要先建立 TCP 连接，然后客户端发送 HTTP 请求，服务端收到后就返回响应，至此「请求-应答」的模式就完成了，随后就会释放 TCP 连接，这种短连接每次请求应答都要建立、释放连接，效率太低。于是HTTP 的 Keep-Alive 实现了长连接，可以使用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，避免了连接建立和释放的开销。HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。如何使用HTTP的 Keep-Alive 功能？HTTP 1.0 中默认是关闭的，如果浏览器要开启 Keep-Alive，它必须在HTTP请求包头部中添加connection: Keep-Alive字段。从 HTTP 1.1 开始， 默认开启Keep-Alive，如果要关闭，需要在HTTP请求包头部添加connection: close字段。==TCP 的 Keepalive==CP 的 Keepalive 就是 TCP 的保活机制，如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。三种情况，前面有。如何使用TCP的Keepalive？应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 SO_KEEPALIVE 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。TCP 协议有什么缺陷？主要有四个方面： 升级 TCP 的工作很困难； TCP 建立连接的延迟； TCP 存在队头阻塞问题； 网络迁移需要重新建立 TCP 连接；==升级 TCP 的工作很困难==TCP 协议是在内核中实现的，应用程序只能使用不能修改，如果要想升级 TCP 协议，那么只能升级内核。这样TCP更新推广的速度就很慢。==TCP 建立连接的延迟==基于 TCP 实现的应用协议，都是需要先建立三次握手才能进行数据传输，比如 HTTP 1.0/1.1、HTTP/2、HTTPS。现在大多数网站都是使用 HTTPS 的，这意味着在 TCP 三次握手之后，还需要经过 TLS 四次握手后，才能进行 HTTP 数据的传输，这在一定程序上增加了数据传输的延迟。==TCP 存在队头阻塞问题==TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且有序的，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据，只有丢失的重传之后，应用层才可以从内核读取到数据。==网络迁移需要重新建立 TCP 连接==基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。那么当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。如何基于 UDP 协议实现可靠传输？QUIC 协议就是基于UDP协议实现的可靠传输方案，已经应用在了HTTP/3。QUIC 是如何实现可靠传输的？要基于 UDP 实现可靠传输协议，就要在应用层下功夫，也就是要设计好协议的头部字段HTTP/3 的 UDP 报文头部与 HTTP 消息之间，共有 3 层头部：Packet HeaderPacket Header 首次建立时和日常传输数据时使用的Header是不同的，因此分为两种： Long Packet Header 用于首次建立连接。 Short Packet Header 用于日常传输数据。QUIC 也是需要三次握手来建立连接的，主要目的是为了协商连接 ID。协商出连接 ID 后，后续传输时，双方只需要固定住连接 ID，从而实现连接迁移功能。所以，你可以看到日常传输数据的 Short Packet Header 不需要在传输 Source Connection ID 字段了，只需要传输 Destination Connection ID。Short Packet Header 中的 Packet Number 是每个报文独一无二的编号，它是严格递增的，也就是说就算 Packet N 丢失了，重传的 Packet N 的 Packet Number 已经不是 N，而是一个比 N 大的值。Packet Number 单调递增有两个好处： 可以更加精确计算 RTT，没有 TCP 重传的歧义性问题（TCP重传的序列号和丢失的相同，这样恢复的ACK也相同，无法判断出事原始报文的响应还是重传报文的相应，计算RTT不准确）； 可以支持乱序确认，当数据包丢失后，只要有新的已接收数据包确认，就可以滑动窗口；而 TCP 必须是顺序确认的，丢包时会导致窗口不滑动；QUIC Frame Header一个 Packet 报文中可以存放多个 QUIC Frame。每一个 Frame 都有明确的类型，针对类型的不同，功能也不同，格式也不同。Packet Number 是严格递增，即使重传报文的 Packet Number 也是递增的，既然重传数据包的 Packet N+M 与丢失数据包的 Packet N 编号并不一致，我们怎么确定这两个数据包的内容一样呢？所以引入 Frame Header 这一层，通过 Stream ID + Offset 字段信息实现数据的有序性，通过比较两个数据包的 Stream ID 与 Stream Offset ，如果都是一致，就说明这两个数据包的内容一致。QUIC 是如何解决 TCP 队头阻塞问题的？==什么是 TCP 队头阻塞问题？==TCP 队头阻塞的问题要从两个角度看，一个是发送窗口的队头阻塞，另外一个是接收窗口的队头阻塞。发送窗口的队头阻塞：TCP 发送出去的数据，都是需要按序确认的，只有在数据都被按顺序确认完后，发送窗口才会往前滑动。如果某个数据包的ACK报文丢失了，发送方就要超时重传这个数据包，知道收到这个数据包的ACK，发送窗口才能往后移动，这样即使后面的数据包收到了ACK，也不无法移动，即队头阻塞。接收窗口的队头阻塞：接收方收到的数据范围必须在接收窗口范围内，如果收到超过接收窗口范围的数据，就会丢弃该数据，当接收窗口收到有序数据时，接收窗口才能往前滑动，然后那些已经接收并且被确认的「有序」数据就可以被应用层读取。但是，当接收窗口收到的数据不是有序的，缺失了某个数据包，发送窗口就无法向前滑动，只有出重传了这个数据包并且被接收方收到后，接收窗口才会向前滑动，然后应用层读取数据。==HTTP/2 的队头阻塞==HTTP/2 通过抽象出 Stream 的概念，实现了 HTTP 并发传输，一个 Stream 就代表 HTTP/1.1 里的请求和响应。HTTP/2连接中不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ），因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息，而同一 Stream 内部的帧必须是严格有序的。但是 HTTP/2 多个 Stream 请求都是在一条 TCP 连接上传输， 共用同一个 TCP 滑动窗口，当发生数据丢失，滑动窗口也是无法往前移动的，此时就会阻塞住所有的 HTTP 请求，也会出现队头阻塞问题。==没有队头阻塞的 QUIC==QUIC 也借鉴 HTTP/2 里的 Stream 的概念，在一条 QUIC 连接上可以并发发送多个 HTTP 请求，但是 QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口。QUIC 是如何做流量控制的？TCP 流量控制是通过让「接收方」告诉「发送方」，它（接收方）的接收窗口有多大，从而让「发送方」根据「接收方」的实际接收能力控制发送的数据量。QUIC 实现流量控制的方式： 通过 window_update 帧告诉对端自己可以接收的字节数，这样发送方就不会发送超过这个数量的数据。 通过 BlockFrame 告诉对端由于流量控制被阻塞了，无法发送数据。QUIC 实现了两种级别的流量控制，分别为 Stream 和 Connection 两种级别： Stream 级别的流量控制：Stream 可以认为就是一条 HTTP 请求，每个 Stream 都有独立的滑动窗口，所以每个 Stream 都可以做流量控制，防止单个 Stream 消耗连接（Connection）的全部接收缓冲。 Connection 流量控制：限制连接中所有 Stream 相加起来的总字节数，防止发送方超过连接的缓冲容量。==Stream 级别的流量控制==每个Stream都有一个滑动窗口进行流量控制，当单个stream中已接收并且已被上层读取的数据超出最大接受窗口的一半时，最大接受窗口向右移动对应的字节数，同时给对端发动窗口更新帧，发送方接受后，发送窗口的窗口也向右滑动。==Connection 流量控制==对于 Connection 级别的流量窗口，其接收窗口大小就是各个 Stream 接收窗口大小之和。比如，所有stream的最大窗口数是某个值，那么整个connection的可用窗口就是所有stream的可用窗口之和。而每个stream的可用窗口取决于最大窗口数和最大接受偏移量的差值。QUIC 对拥塞控制改进QUIC 协议当前默认使用了 TCP 的拥塞控制算法，但QUIC 是处于应用层的，应用层面就能实现不同的拥塞控制算法，这样不同于在内核和操作系统中不实现，部署相对简单，升级迭代快，灵活性得到了提高。QUIC 更快的连接建立对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手（1RTT），再 TLS 握手（2RTT）。HTTP/3 在传输数据前虽然需要 QUIC 协议握手，但这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」。 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。因此QUIC建立连接的速度更快。QUIC 是如何迁移连接的？基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。那么当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。QUIC 协议没有用四元组的方式来绑定连接，而是通过连接 ID来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了连接迁移的功能。IPIP 基础知识全家桶IP 基本认识源IP地址和目标IP地址在传输过程中是不会变化的，只有源 MAC 地址和目标 MAC 一直在变化。这就是IP层和数据链路层的区别，IP层负责将数据包发送到最终的目的地址，数据链路层负责各个区间的通信传输。IP 地址的基础知识每个设备只有配置了正确的IP地址，才能实现正常的通信，IP 地址（IPv4 地址）由 32 位正整数来表示，在计算机中以二进制的方式处理，使用点分十进制法来标记。IP 地址的分类IP 地址分类成了 5 种类型，分别是 A 类、B 类、C 类、D 类、E 类。==什么是 A、B、C 类地址？==A、B、C 类地址有分类号、网络号和主机号三个部分， A类，分类号以0开头，主机号24位 B类，分类号以10开头，主机号16位 C类，分类号以110开头，主机号8位==A、B、C 分类地址最大主机个数是如何计算的呢？==最大主机个数，需要看主机号的位数，然后减去2。为什么减去2呢，因为在IP地址中，有两个IP地址是特殊的，分别是主机号全为1和全为0的地址。 主机号全为 1 指定某个网络下的所有主机，用于广播 主机号全为 0 指定某个网络广播地址用于在同一个链路中相互连接的主机之间发送数据包。分为本地广播（本网络内的广播）和直接广播（不同网络之间的广播）。==什么是 D、E 类地址？==D 类和 E 类地址没有主机号，所以不可用于主机 IP，D 类常被用于多播，E 类是预留的分类，暂未使用。==多播地址用于什么？==多播用于将包发送给特定组内的所有主机。==IP 分类的优点与缺点==优点：简单明了，可以很快的找出网络地址和主机地址。缺点：同一网络下没有地址层次，缺少灵活性；还有就是不能很好的与现实网络匹配，C类地址包含的最大主机数太少，而B类地址包含的最大主机数又太多。无分类地址 CIDR为了解决IP分类地址的缺点，提出了无分类地址，这种方式不再有分类地址的概念，32 比特的 IP 地址被划分为两部分，前面是网络号，后面是主机号。==怎么划分网络号和主机号的呢？==表示形式 a.b.c.d/x，其中 /x 表示前 x 位属于网络号， x 的范围是 0 ~ 32，这就使得 IP 地址更加具有灵活性。比如 10.100.122.2/24，表示前24位为网络号，剩余的8位是主机号。子网掩码也可以划分网络号与主机号，掩码的意思就是掩盖掉主机号，剩余的就是网络号。将子网掩码和 IP 地址按位计算 AND，就可得到网络号。比如上述地址的子网掩码是255.255.255.0。==为什么要分离网络号和主机号？==因为两台计算机要通讯，首先要判断是否处于同一个广播域内，即网络地址是否相同。如果网络地址相同，表明接受方在本网络上，那么可以把数据包直接发送到目标主机。路由器寻址工作中，也就是通过这样的方式来找到对应的网络号的，进而把数据包转发给对应的网络内。==怎么进行子网划分？==子网掩码除了可以划分出网络号和主机号，还可以划分子网。子网划分实际上是将主机地址分为两个部分：子网网络地址和子网主机地址。 未做子网划分的 ip 地址：网络地址＋主机地址 做子网划分后的 ip 地址：网络地址＋（子网网络地址＋子网主机地址）IP 地址与路由控制P地址的网络地址这一部分是用于进行路由控制。路由控制表中记录着网络地址与下一步应该发送至路由器的地址。在主机和路由器上都会有各自的路由器控制表。工作原理是：在发送 IP 包时，首先要确定 IP 包首部中的目标地址，再从路由控制表中找到与该地址具有相同网络地址的记录，根据该记录将 IP 包转发给相应的下一个路由器。如果路由控制表中存在多条相同网络地址的记录，就选择相同位数最多的网络地址，也就是最长匹配。==环回地址是不会流向网络==环回地址是在同一台计算机上的程序之间进行网络通信时所使用的一个默认地址。计算机使用一个特殊的 IP 地址 127.0.0.1 作为环回地址。与该地址具有相同意义的是一个叫做 localhost 的主机名。使用这个 IP 或主机名时，数据包不会流向网络。IP 分片与重组每种数据链路的 MTU 之所以不同，是因为每个不同类型的数据链路的使用目的不同。使用目的不同，可承载的 MTU 也就不同。其中，我们最常见数据链路是以太网，它的 MTU 是 1500 字节。当 IP 数据包大小大于 MTU 时， IP 数据包就会被分片，经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行，路由器是不会进行重组的。IPv6 基本认识IPv6 的地址是 128 位的，IPv6 除了有更多的地址之外，还有更好的安全性和扩展性。==IPv6 的亮点== 更多的可分配地址 IPv6 可自动配置，即使没有 DHCP 服务器也可以实现自动分配IP地址 IPv6 数据包头部长度采用固定的值 40 字节，去掉了包头校验和，简化了首部结构，减轻了路由器负荷，大大提高了传输的性能。 IPv6 有应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能，大大提升了安全性。==IPv6 地址的标识方法==IPv4 地址长度共 32 位，是以每 8 位作为一组，并用点分十进制的表示方式。IPv6 地址长度是 128 位，是以每 16 位作为一组，使用十六进制数表示，每组用冒号 「:」 隔开。IP 协议相关技术DNS 域名解析为了方便记忆，我们访问网址的时候，使用的是域名，而不是IP地址，这背后需要DNS域名解析技术支撑，DNS可以将域名网址自动转换为具体的IP地址。DNS中的域名是按照句点来分隔的，域名之间是层级关系，越靠右其层级越高。==域名解析的工作流程== 客户端首先会发送一个DNS请求，问当前域名的IP地址是什么，并发给本地DNS服务器 本地DNS服务器收到DNS请求后，如果在缓存里能够找到对应的域名，则直接返回IP地址。如果找不到，就循环他的根域名服务器。 根域名服务器收到本地DNS的请求后，给出顶级域名服务器地址，然后本地DNS去访问 顶级域名服务器收到本地DNS的请求后，给出全为DNS服务器的地址，然后本地DNS去访问 权威DNS服务器收到本地DNS请求后，经过查询给出域名的IP地址，然后告诉本地DNS 本地DNS将IP地址返回客户端访问的特点是：每层只负责给出下一层的地址，本地DNS逐次访问每层域名服务器，直到找到对应IP地址。ARP 与 RARP 协议在传输一个 IP 数据报的时候，确定了源 IP 地址和目标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下一跳。主机的路由表中可以找到下一跳的 IP 地址，然后通过 ARP 协议，求得下一跳的 MAC 地址。==那么 ARP 又是如何知道对方 MAC 地址的呢？==ARP 是借助 ARP 请求与 ARP 响应两种类型的包确定 MAC 地址的。 主机会通过广播发送 ARP 请求，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。 当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包里的内容，如果 ARP 请求包中的目标 IP 地址与自己的 IP 地址一致，那么这个设备就将自己的 MAC 地址塞入 ARP 响应包返回给主机。==RARP 协议你知道是什么吗？==ARP 协议是已知 IP 地址求 MAC 地址，那 RARP 协议正好相反，它是已知 MAC 地址求 IP 地址。通常需要架设一台 RARP 服务器，在这个服务器上注册设备的 MAC 地址及其 IP 地址。然后再将这个设备接入到网络，接着： 该设备会发送一条「我的 MAC 地址是XXXX，请告诉我，我的IP地址应该是什么」的请求信息。 RARP 服务器接到这个消息后返回「MAC地址为 XXXX 的设备，IP地址为 XXXX」的信息给这个设备。 最后，设备就根据从 RARP 服务器所收到的应答信息设置自己的 IP 地址。DHCP 动态获取 IP 地址DHCP自动获取IP地址的流程： 客户端首先发起 DHCP 发现报文（DHCP DISCOVER） 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 UDP 广播通信，其使用的广播目的地址是 255.255.255.255（端口 67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。 DHCP 服务器收到 DHCP 发现报文时，用 DHCP 提供报文（DHCP OFFER） 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 IP 地址租用期。 客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 DHCP 请求报文（DHCP REQUEST进行响应，回显配置的参数。 最后，服务端用 DHCP ACK 报文对 DHCP 请求报文进行响应，应答所要求的参数。客户端收到 DHCP ACK 后，交互便完成了，客户端就能够在租用期内使用 DHCP 服务器分配的 IP 地址。如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报文： 服务器如果同意继续租用，则用 DHCP ACK 报文进行应答，客户端就会延长租期。 服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要停止使用租约的 IP 地址。==如果 DHCP 服务器和客户端不是在同一个局域网（链路）内，路由器又不会转发广播包怎么办？==为了解决这一问题，出现了 DHCP 中继代理。有了 DHCP 中继代理以后，对不同网段的 IP 地址分配也可以由一个 DHCP 服务器统一进行管理。 客户端会向 DHCP 中继代理发送 DHCP 请求包，而 DHCP 中继代理在收到这个广播包以后，再以单播的形给 DHCP 服务器。 服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包广播给 客户端 。NAT 网络地址转换NAT是为了缓解IPv4地址紧缺的问题，它是将私有IP地址转换为共有IP地址。为了区分不同的私有IP地址，需要将IP地址+端口号一起进行装换，具体实现就是将不同的私有IP地址转换成一个公有IP地址，但是它们的端口号不同，以此作为区分。NAT路由器会自动生成转换表。==NAT的缺点？==由于 NAT/NAPT 都依赖于自己的转换表，因此会有以下的问题： 外部无法主动与 NAT 内部服务器建立连接，因为 NAPT 转换表没有转换记录。 转换表的生成与转换操作都会产生性能开销。 通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。==如何解决 NAT 潜在的问题呢？==解决的方法主要有两种方法。第一种就是改用 IPv6IPv6 可用范围非常大，以至于每台设备都可以配置一个公有 IP 地址，但是IPv6还未普及。第二种 NAT 穿透技术NAT 穿透技术拥有这样的功能，它能够让网络应用程序主动发现自己位于 NAT 设备之后，并且会主动获得 NAT 设备的公有 IP，并为自己建立端口映射条目，注意这些都是 NAT设备后的应用程序自动完成的。就是客户端主动从 NAT 设备获取公有 IP 地址，然后自己建立端口映射条目，然后用这个条目对外通信，就不需要 NAT 设备来进行转换了。ICMP 互联网控制报文协议ICMP报文是封装在IP包里面，它工作在网络层，是IP协议的助手。ICMP 主要的功能包括：确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。ICMP 包头的类型字段大致可以分为两大类： 一类是用于诊断的查询消息，也就是「查询报文类型」 另一类是通知出错原因的错误消息，也就是「差错报文类型」==查询报文类型==回送消息用于进行通信的主机或路由器之间，判断所发送的数据包是否已经成功到达对端的一种消息，ping 命令就是利用这个消息实现的。可以向对端主机发送回送请求的消息（ICMP Echo Request Message，类型 8），也可以接收对端主机发回来的回送应答消息（ICMP Echo Reply Message，类型 0）==差错报文类型==目标不可达消息（Destination Unreachable Message） —— 类型为 3IP 路由器无法将 IP 数据包发送给目标地址时，会给发送端主机返回一个目标不可达的 ICMP 消息，并在这个消息中显示不可达的具体原因，原因记录在 ICMP 包头的代码字段。原点抑制消息（ICMP Source Quench Message） —— 类型 4当路由器向低速线路发送数据时，其发送队列的缓存变为零而无法发送出去时，可以向 IP 包的源地址发送一个 ICMP 原点抑制消息。收到这个消息的主机借此了解在整个线路的某一处发生了拥堵的情况，从而增大 IP 包的传输间隔，减少网络拥堵的情况。重定向消息（ICMP Redirect Message） —— 类型 5如果路由器发现发送端主机使用了「不是最优」的路径发送数据，那么它会返回一个 ICMP 重定向消息给这个主机。在这个消息中包含了最合适的路由信息和源数据。这主要发生在路由器持有更好的路由信息的情况下。路由器会通过这样的 ICMP 消息告知发送端，让它下次发给另外一个路由器。超时消息（ICMP Time Exceeded Message） —— 类型 11IP 包中有一个字段叫做 TTL （Time To Live，生存周期），它的值随着每经过一次路由器就会减 1，直到减到 0 时该 IP 包会被丢弃。此时，路由器将会发送一个 ICMP 超时消息给发送端主机，并通知该包已被丢弃。IGMP 因特网组管理协议IGMP工作在主机（组播成员）和最后一跳路由之间 IGMP 报文向路由器申请加入和退出组播组，默认情况下路由器是不会转发组播包到连接中的主机，除非主机通过 IGMP 加入到组播组，主机申请加入到组播组时，路由器就会记录 IGMP 路由器表，路由器后续就会转发组播包到对应的主机了。 IGMP 报文采用 IP 封装，IP 头部的协议号为 2，而且 TTL 字段值通常为 1，因为 IGMP 是工作在主机与连接的路由器之间。ping 的工作原理ping命令使用了ICMP协议的查询报文类型，ping的发送和接收过程如下：ping 命令执行的时候，源主机首先会构建一个 ICMP 回送请求消息数据包。ICMP 数据包内包含多个字段，最重要的是两个： 第一个是类型，对于回送请求消息而言该字段为 8； 另外一个是序号，主要用于区分连续 ping 的时候发出的多个数据包，每发出一个请求数据包，序号自动加1。此外，还会在报文的数据部分插入发送时间，这是为了计算往返时间RTT。然后，由 ICMP 协议将这个数据包连同目标主机的地址一起交给 IP 层。IP 层将以目标主机IP地址作为目的地址，本机 IP 地址作为源地址，协议字段设置为 1 表示是 ICMP 协议，再加上一些其他控制信息，构建一个 IP 数据包。接下来，需要加入 MAC 头部。如果在本地 ARP 映射表中查找目标主机IP地址所对应的 MAC 地址，则可以直接使用；如果没有，则需要发送 ARP 协议查询 MAC 地址，获得 MAC 地址后，由数据链路层构建一个数据帧，目的地址是 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址；还要附加上一些控制信息，然后将它们传送出去。目标主机收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃。目标主机会构建一个 ICMP 回送响应消息数据包，回送响应数据包的类型字段为 0，序号为接收到的请求数据包中的序号，然后再发送出去给源主机。在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 回送响应消息，则说明目标主机可达。此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。上面说的是同一个局域网里面的情况。如果跨网段的话，还会涉及网关的转发、路由器的转发等等。但是对于 ICMP 的头来讲，是没什么影响的。会影响的是根据目标 IP 地址，选择路由的下一跳，还有每经过一个路由器到达一个新的局域网，需要换 MAC 头里面的 MAC 地址。总结：ping是使用了ICMP协议里面的回应请求查询报文（类型为8）和回应响应查询报文（类型为0）。==traceroute —— 差错报文类型的使用==一款充分利用 ICMP 差错报文类型的应用叫做 traceroute（在UNIX、MacOS中是这个命令，而在Windows中对等的命令叫做 tracert ）。traceroute 的第一个作用就是故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器。traceroute 的参数指向某个目的 IP 地址：traceroute 192.168.1.100它的原理就是利用 IP 包的生存期限 从 1 开始按照顺序递增的同时发送 UDP 包，强制接收 ICMP 超时消息的一种方法。比如，将 TTL 设置 为 1，则遇到第一个路由器，就牺牲了，接着返回 ICMP 差错报文网络包，类型是时间超时。接下来将 TTL 设置为 2，第一个路由器过了，遇到第二个路由器也牺牲了，也同时返回了 ICMP 差错报文数据包，如此往复，直到到达目的主机。不断重复这样的过程，traceroute 就可以拿到了所有的路由器 IP。那发送方如何知道发出的 UDP 包是否到达了目的主机呢？raceroute 在发送 UDP 包时，会填入一个不可能的端口号值作为 UDP 目标端口号（大于 3000 ）。当目的主机，收到 UDP 包后，会返回 ICMP 差错报文消息，但这个差错报文消息的类型是「端口不可达」。所以，当差错报文类型是端口不可达时，说明发送方发出的 UDP 包到达了目的主机。traceroute 还有一个作用是故意设置不分片，从而确定路径的 MTU。因为有的时候我们并不知道路由器的 MTU 大小，以太网的数据链路上的 MTU 通常是 1500 字节，但是非以外网的 MTU 值就不一样了，所以我们要知道 MTU 的大小，从而控制发送的包大小。首先在发送端主机发送 IP 数据报时，将 IP 包首部的分片禁止标志位设置为 1。根据这个标志位，途中的路由器不会对大数据包进行分片，而是将包丢弃。随后，通过一个 ICMP 的不可达消息将数据链路上 MTU*的值一起给发送主机，不可达消息的类型为「需要进行分片但设置了不分片位」。发送主机端每次收到 ICMP 差错报文时就减少包的大小，以此来定位一个合适的 MTU 值，以便能到达目标主机。" }, { "title": "Redis相关知识整理", "url": "/posts/Redis-knowledge/", "categories": "笔记, Redis", "tags": "总结, Redis, 八股, 数据库", "date": "2022-07-16 22:35:05 +0800", "snippet": "认识Redis什么是RedisRedis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此读写速度非常快，常用于缓存，消息队列、分布式锁等场景。Redis 提供了多种数据类型来支持不同的业务场景并且对数据类型的操作都是原子性的，因为执行命令由单线程负责的，不存在并发竞争的问题。除此之外，Redis 还支持事务 、持久化、Lua 脚本、多种集群方案（主从复制模式、哨兵模式、切片集群模式）、发布/订阅模式，内存淘汰机制、过期删除机制等等。Redis和Memcached有什么区别很多人都说用 Redis 作为缓存，但是 Memcached 也是基于内存的数据库，为什么不选择它作为缓存呢？要解答这个问题，我们就要弄清楚 Redis 和 Memcached 的区别。Redis 与 Memcached 共同点： 都是基于内存的数据库，一般都用来当做缓存使用。 都有过期策略。 两者的性能都非常高。Redis 与 Memcached 区别： Redis 支持的数据类型更丰富（String、Hash、List、Set、ZSet），而 Memcached 只支持最简单的 key-value 数据类型； Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 没有持久化功能，数据全部存在内存之中，Memcached 重启或者挂掉后，数据就没了； Redis 原生支持集群模式，Memcached 没有原生的集群模式，需要依靠客户端来实现集群。 Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持；为什么用Redis作为MySQL的缓存主要是因为 Redis 具备「高性能」和「高并发」两种特性。1、Redis 具备高性能Redis是基于内存的数据库，读写操作非常快，而MySQL如果对磁盘进行I/O操作会非常慢。2、 Redis 具备高并发单台设备的 Redis 的 QPS（Query Per Second，每秒钟处理完请求的次数） 是 MySQL 的 10 倍，Redis 单机的 QPS 能轻松破 10w，而 MySQL 单机的 QPS 很难破 1w。所以，直接访问 Redis 能够承受的请求是远远大于直接访问 MySQL 的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。Redis数据类型与数据结构Redis常用数据类型及应用场景？stringString 是最基本的 key-value 结构，key 是唯一标识，value 是具体的值，value其实不仅是字符串， 也可以是数字（整数或浮点数）。内部实现String 类型的底层的数据结构实现主要是 int 和 SDS（简单动态字符串）。string对象的内部编码方式：有三种，分别为int、raw和embstr： 如果一个字符串对象保存的是整数值，并且这个整数值可以用long类型来表示，那么字符串对象会将整数值保存在字符串对象结构的ptr属性里面，并将字符串对象的编码设置为int。 如果字符串对象保存的是一个字符串，并且这个字符申的长度小于等于 32 字节，字符串对象将使用一个SDS来保存这个字符串，并将对象的编码设置为embstr， embstr编码是专门用于保存短字符串的一种优化编码方式。 如果字符串对象保存的是一个字符串，并且这个字符串的长度大于 32 字节，那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串，并将对象的编码设置为raw。注意：embstr 编码和 raw 编码的边界在 redis 不同版本中是不一样的。embstr和raw编码都会使用SDS来保存值，但不同之处在于embstr会通过一次内存分配函数来分配一块连续的内存空间来保存redisObject和SDS，而raw编码会通过调用两次内存分配函数来分别分配两块空间来保存redisObject和SDS。Redis这样做会有很多好处： embstr编码将创建字符串对象所需的内存分配次数从 raw 编码的两次降低为一次； 释放 embstr编码的字符串对象同样只需要调用一次内存释放函数； 因为embstr编码的字符串对象的所有数据都保存在一块连续的内存里面可以更好的利用 CPU 缓存提升性能。但是 embstr 也有缺点的： 如果字符串的长度增加需要重新分配内存时，整个redisObject和sds都需要重新分配空间，所以embstr编码的字符串对象实际上是只读的，redis没有为embstr编码的字符串对象编写任何相应的修改程序。当我们对embstr编码的字符串对象执行任何修改命令（例如append）时，程序会先将对象的编码从embstr转换成raw，然后再执行修改命令。应用场景 缓存对象：比如直接缓存对象的JSON 常规计数：因为 Redis 处理命令是单线程，所以执行命令的过程是原子的。因此 String 数据类型适合计数场景，比如计算访问次数、点赞、转发、库存数量等等。 分布式锁：使用SET命令和Lua脚本在Redis单节点上完成分布式锁的加锁和解锁。 共享Session信息：使用Redis统一存储和管理不同服务器的Sesson信息。ListList 列表是简单的字符串列表，按照插入顺序排序，可以从头部或尾部向 List 列表添加元素。内部实现List 类型的底层数据结构是由双向链表或压缩列表实现的： 如果列表的元素个数小于 512 个（默认值，可由 list-max-ziplist-entries 配置），列表每个元素的值都小于 64 字节（默认值，可由 list-max-ziplist-value 配置），Redis 会使用压缩列表作为 List 类型的底层数据结构； 如果列表的元素不满足上面的条件，Redis 会使用双向链表作为 List 类型的底层数据结构；但是在 Redis 3.2 版本之后，List 就只由 quicklist 实现了，替代了双向链表和压缩列表。应用场景 消息队列：满足消息队列的存取消息时的三个需求（消息保序、处理重复的消息和保证消息可靠性），但是List不支持多个消费者消费同一条消息。HashHash 是一个键值对（key - value）集合，特别适合用于存储对象。内部实现Hash 类型的底层数据结构是由压缩列表或哈希表实现的： 如果哈希类型元素个数小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），所有值小于 64 字节（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用压缩列表作为 Hash 类型的底层数据结构； 如果哈希类型元素不满足上面条件，Redis 会使用哈希表作为 Hash 类型的 底层数据结构。在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。应用场景 缓存对象：hash类型的结构（key、field、value）与对象的结构（对象id、属性、值）相似，也可以用来存储对象。 购物车：以用户id为key，商品id为field，商品数量为value，可以用于实现购物车。SetSet 类型是一个无序并唯一的键值集合，它的存储顺序不会按照插入的先后顺序进行存储。Set 类型除了支持集合内的增删改查，同时还支持多个集合取交集、并集、差集。Set 类型和 List 类型的区别如下： List 可以存储重复元素，Set 只能存储非重复元素； List 是按照元素的先后顺序存储元素的，而 Set 则是无序方式存储元素的。内部实现Set 类型的底层数据结构是由哈希表或整数集合实现的： 如果集合中的元素都是整数且元素个数小于 512 （默认值，set-maxintset-entries配置）个，Redis 会使用整数集合作为 Set 类型的底层数据结构； 如果集合中的元素不满足上面条件，则 Redis 使用哈希表作为 Set 类型的底层数据结构。应用场景 数据去重、统计数据等：主要是由于不可重复、支持并交差集等特性，比如点赞（一个人只能点一个赞），共同关注（交集）。ZsetZset 类型（有序集合类型）相比于 Set 类型多了一个排序属性 score（分值），对于有序集合 ZSet 来说，每个存储元素相当于有两个值组成的，一个是有序结合的元素值，一个是排序值。有序集合类型成员不能仍然不能重复，但是分值可以重复。内部实现Zset 类型的底层数据结构是由压缩列表或跳表实现的： 如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用压缩列表作为 Zset 类型的底层数据结构； 如果有序集合的元素不满足上面的条件，Redis 会使用跳表作为 Zset 类型的底层数据结构；在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。应用场景 排行榜：根据某个权值进行排名。BitMapBitmap，即位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。BitMap通过最小的单位bit来进行0|1的设置，表示某个元素的值或者状态，时间复杂度为O(1)。内部实现Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态，你可以把 Bitmap 看作是一个 bit 数组。应用场景由于 bit 是计算机中最小的单位，使用它进行储存海量数据使将非常节省空间，特别适合二值统计的场景。 签到统计：签到为1，未签到为0 判断用户登录状态：在线设置为1，下线设置为0HyperLogLogRedis HyperLogLog 是一种用于「统计基数」的数据集合类型，基数统计就是指统计一个集合中不重复的元素个数。但要注意，HyperLogLog 是统计规则是基于概率完成的，不是非常准确，存在误差。HyperLogLog 的优点是：在输入元素的数量或者体积非常非常大时，计算基数所需的内存空间总是固定的、并且是很小的。在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。内部实现。。。应用场景 百万级网页UV计数：优势在于只需要花费12KB内存，就可以计算接近2^64 个元素的基数，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。但是要注意存在误差。GEO主要用于存储地理位置信息，并对存储的信息进行操作。内部实现GEO 本身并没有设计新的底层数据结构，而是直接使用了 Sorted Set 集合类型。应用场景 滴滴叫车：Redis根据输入用户的经纬度信息，查找以这个经纬度为中心一定范围内的车辆信息（车辆id和车辆经纬度位置），并且返回应用。StreamStream是Redis 专门为消息队列设计的数据类型。相较于list，可以实现持久化和重复消费。Redis数据结构键值对数据库是怎么实现的？Redis 的键值对中的 key 就是字符串对象，而 value 可以是字符串对象，也可以是集合数据类型的对象，比如 List 对象、Hash 对象、Set 对象和 Zset 对象。Redis键值对数据库结构全景图： redisDb 结构，表示 Redis 数据库的结构，结构体里存放了指向了 dict 结构的指针； dict 结构，结构体里存放了 2 个哈希表，正常情况下都是用「哈希表1」，「哈希表2」只有在 rehash 的时候才用； ditctht 结构，表示哈希表的结构，结构里存放了哈希表数组，数组中的每个元素都是指向一个哈希表节点结构（dictEntry）的指针； dictEntry 结构，表示哈希表节点的结构，结构里存放了 void * key 和 void * value 指针， *key 指向的是 String 对象，而 *value 则可以指向 String 对象，也可以指向集合类型的对象，比如 List 对象、Hash 对象、Set 对象和 Zset 对象。void * key 和 void * value 指针指向的是 Redis 对象，Redis 中的每个对象都由 redisObject 结构表示 type，标识该对象是什么类型的对象（String 对象、 List 对象、Hash 对象、Set 对象和 Zset 对象）； encoding，标识该对象使用了哪种底层的数据结构； ptr，指向底层数据结构的指针。SDSRedis 是用 C 语言实现的，但是它没有直接使用 C 字符数组来实现字符串，而是自己封装了一个简单动态字符串（simple dynamic string，SDS） 的数据结构来表示字符串。C 语言的字符串的缺陷 获取字符串长度的时间复杂度为 O（N）； 字符串的结尾是以 “\\0” 字符标识，字符串里面不能包含有 “\\0” 字符，因此不能保存二进制数据； 字符串操作函数不高效且不安全，比如有缓冲区溢出的风险，有可能会造成程序运行终止；SDS 结构设计SDS的数据结构（Redis5.0 和Redis设计与实现中的不同，那个版本比较低）由以下几个成员变量组成： len，记录了字符串长度。 alloc，分配给字符数组的空间长度。 flags，用来表示不同类型的 SDS。 buf[]，字符数组，用来保存实际数据**。SDS相较于C字符串的优点： O（1）复杂度获取字符串长度：SDS 结构因为加入了 len 成员变量，那么获取字符串长度的时候，直接返回这个成员变量的值就行，所以复杂度只有 O（1）。 二进制安全： SDS 不需要用 “\\0” 字符来标识字符串结尾了，而是有个专门的 len 成员变量来记录长度，所以可存储包含 “\\0” 的数据。但是为了兼容部分 C 语言标准库的函数， SDS 字符串结尾还是会加上 “\\0” 字符。SDS的API都是二进制安全的，所有SDS API都会以处理二进制的方式来处理SDS存在于buf[]里的数据，程序不会对其中的数据做任何限制。因此 Redis 不仅可以保存文本数据，也可以保存任意格式的二进制数据。 不会发生缓冲区溢出：C字符串操作函数不会判断缓冲区大小是否够用，容易引发缓冲区溢出。但是Redis的SDS 结构里引入了 alloc 和 len 成员变量，这样 SDS API 通过 alloc - len 可以算出剩余可用的空间大小。SDS的空间分配策略是：当对字符串做修改操作时，首先会检查SDS的空间是否满足修改所需的要求，当判断出缓冲区大小不够用时，Redis 会自动扩大 SDS 的空间大小以满足修改所需的大小。这样使用SDS即不需要手动修改空间大小，也不会引发缓存区溢出的问题。 减少内存分配次数：在扩展 SDS 空间之前，SDS API 会优先检查未使用空间是否足够，如果不够的话，API 不仅会为 SDS 分配修改所必须要的空间，还会给 SDS 分配额外的「未使用空间」。分配策略是：小于 1MB 翻倍扩容，大于等于 1MB 按 1MB 扩容。这样的好处是，下次在操作 SDS 时，如果 SDS 空间够的话，API 就会直接使用未使用空间，而无须执行内存分配，因此可减少内存分配次数。 节省内存空间：SDS 结构中的flags 成员变量表示的是 SDS 类型。Redis 一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64。这 5 种类型的主要区别就在于，它们数据结构中的 len 和 alloc 成员变量的数据类型不同。之所以 设计不同类型的结构体，是为了能灵活保存不同大小的字符串，从而有效节省内存空间。链表C 语言本身没有链表，所以 Redis 自己实现了一个链表数据结构。list 结构为链表提供了链表头指针 head、链表尾节点 tail、链表节点数量 len、以及可以自定义实现的 dup（节点值赋值函数）、free（节点值释放函数）、match（节点值匹配函数） 。Redis链表结构的特性： 链表节点带有 prev 和 next 指针，是双向链表，所以获取某个节点的前置节点或后置节点的时间复杂度只需O(1)，而且这两个指针都可以指向 NULL，所以也是无环链表； 带表头和表尾指针：获取链表的表头结点和表尾节点时间复杂度为O(1)； 带节点长度len：获取链表中的节点数量的时间复杂度只需O(1)； 链表节点使用 void* 指针保存节点值，并且可以通过 list 结构的 dup、free、match 函数指针为节点设置该节点类型特定的函数，因此链表节点可以保存各种不同类型的值；链表的缺陷也是有的： 链表每个节点之间的内存都是不连续的，意味着无法很好利用 CPU 缓存。 保存一个链表节点的值需要一个链表节点结构头的分配，内存开销较大。 压缩列表压缩列表结构设计压缩列表是 Redis 为了节约内存而开发的，它是由连续内存块组成的顺序型数据结构，有点类似于数组。压缩列表结构有四个个字段： zlbytes，记录整个压缩列表占用对内存字节数； zltail，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量； zllen，记录压缩列表包含的节点数量； zlend，标记压缩列表的结束点，固定值 0xFF（十进制255）。在压缩列表中，查找定位第一个元素和最后一个元素复杂度是 O(1)。而查找其他元素时，只能逐个查找，复杂度为O(N) ，因此压缩列表不适合保存过多的元素。压缩列表节点包含三部分内容： prevlen，记录了「前一个节点」的长度； encoding，记录了当前节点实际数据的类型以及长度； data，记录了当前节点的实际数据；当我们往压缩列表中插入数据时，压缩列表就会根据数据是字符串还是整数，以及数据的大小，会使用不同空间大小的 prevlen 和 encoding 这两个元素里保存的信息，这种根据数据大小和类型进行不同的空间大小分配的设计思想，正是 Redis 为了节省内存而采用的。prevlen 属性都记录了「前一个节点的长度」，而且 prevlen 属性的空间大小跟前一个节点长度值有关，比如： 如果前一个节点的长度小于 254 字节，那么 prevlen 属性需要用 1 字节的空间来保存这个长度值； 如果前一个节点的长度大于等于 254 字节，那么prevlen 属性需要用 5 字节的空间来保存这个长度值；encoding 属性的空间大小跟数据是字符串还是整数，以及字符串的长度有关： 如果当前节点的数据是整数，则 encoding 会使用 1 字节的空间进行编码。 如果当前节点的数据是字符串，根据字符串的长度大小，encoding 会使用 1 字节/2字节/5字节的空间进行编码。连锁更新压缩列表新增某个元素或修改某个元素时，如果空间不不够，压缩列表占用的内存空间就需要重新分配。而当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降。压缩列表的优点和缺陷优点： 占用一块连续的内存空间，可以有效利用 CPU 缓存 针对不同长度的数据进行相应编码，内存紧凑，可以有效地节省内存开销。缺点： 只适用于保存的节点数量不多的场景，节点数量多查询效率低。 存在连锁更新问题，连锁更新会导致压缩列表占用的内存空间多次重新分配，这样会直接影响到压缩列表的访问性能。哈希表哈希表是一种保存键值对（key-value）的数据结构。哈希表中的每一个 key 都是独一无二的，程序可以根据 key 对与之关联的 value进行操作。哈希表优点在于，它能以 O(1) 的复杂度快速查询数据。哈希表缺点在于，在哈希表大小固定的情况下，随着数据不断增多，那么哈希冲突的可能性也会越高。哈希表结构设计哈希表是一个数组（dictEntry table），数组的每个元素是一个指向「哈希表节点（dictEntry）」的指针。dictEntry 结构里不仅包含指向键和值的指针，还包含了指向下一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对链接起来，以此来解决哈希冲突的问题，这就是链式哈希。哈希冲突哈希表实际上是一个数组，数组里多每一个元素就是一个哈希桶。当一个键值对的键经过 Hash 函数计算后得到哈希值，再将(哈希值 % 哈希表大小)取模计算，得到的结果值就是该 key-value 对应的数组元素位置，也就是第几个哈希桶。当有两个以上数量的 key 被分配到了哈希表中同一个哈希桶上时，即发生了冲突。链式哈希Redis 采用了「链式哈希」的方法来解决哈希冲突。实现的方式就是每个哈希表节点都有一个 next 指针，用于指向下一个哈希表节点，因此多个哈希表节点可以用 next 指针构成一个单项链表，被分配到同一个哈希桶上的多个节点可以用这个单项链表连接起来，这样就解决了哈希冲突。但是，链式哈希的局限性也很明显，随着链表长度的增加，在查询这一位置上的数据的耗时就会增加，毕竟链表的查询时间复杂度为O（n）。要想解决这个问题，就需要进行rehash，也就是对哈希表的大小进行扩展。rehashRedis 定义一个 dict 结构体，这个结构体里定义了两个哈希表，正常情况下使用哈希表1，rehash的时候使用哈希表2。rehash操作过程如下： 给「哈希表 2」 分配空间，一般会比「哈希表 1」 大 2 倍； 将「哈希表 1 」的数据迁移到「哈希表 2」 中； 迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备。重点在于第二步，如果「哈希表 1 」的数据量非常大，那么在迁移至「哈希表 2 」的时候，因为会涉及大量的数据拷贝，此时可能会对 Redis 造成阻塞，无法服务其他请求。渐进式rehash为了避免 rehash 在数据迁移过程中，因拷贝数据的耗时而影响 Redis 性能的情况，所以 Redis 采用了渐进式 rehash，也就是数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。渐进式rehash步骤： 给「哈希表 2」 分配空间； 在 rehash 进行期间，每次哈希表元素进行增删改查操作时，Redis 除了会执行对应的操作之外，还会顺便将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上； 随着处理客户端发起的哈希表操作请求数量越多，最终在某个时间点会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作。在进行渐进式 rehash 的过程中，会有两个哈希表，所以在渐进式 rehash 进行期间，哈希表元素的增删改查操作都会在这两个哈希表进行。比如，查找一个 key 的值的话，先会在「哈希表 1」 里面进行查找，如果没找到，就会继续到哈希表 2 里面进行找到。另外，在渐进式 rehash 进行期间，新增一个键值对时，会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作，这样保证了「哈希表 1 」的 键值对数量只会减少，随着 rehash 操作的完成，最终「哈希表 1 」就会变成空表。rehash 触发条件什么情况下会触发 rehash 操作呢？rehash 的触发条件跟负载因子（load factor）有关系，负载因子=哈希表已保存结点数量/哈希表大小。触发 rehash 操作的条件主要有两个： 当负载因子大于等于 1 ，并且 Redis 没有在执行 bgsave 命令或者 bgrewriteaof 命令，也就是没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作。 当负载因子大于等于 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作。整数集合整数集合结构设计整数集合本质上是一块连续内存空间，它的结构定义如下：typedef struct intset { //编码方式 uint32_t encoding; //集合包含的元素数量 uint32_t length; //保存元素的数组 int8_t contents[];} intset;contents 数组中元素的类型取决于结构体中的 encoding 属性的值。比如： 如果 encoding 属性值为 INTSET_ENC_INT16，那么 contents 就是一个 int16_t 类型的数组，数组中每一个元素的类型都是 int16_t； 如果 encoding 属性值为 INTSET_ENC_INT32，那么 contents 就是一个 int32_t 类型的数组，数组中每一个元素的类型都是 int32_t； 如果 encoding 属性值为 INTSET_ENC_INT64，那么 contents 就是一个 int64_t 类型的数组，数组中每一个元素的类型都是 int64_t；整数集合的升级操作整数集合会有一个升级规则，就是当我们将一个新元素加入到整数集合里面，如果新元素的类型（int32_t）比整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进行升级，也就是按新元素的类型（int32_t）扩展 contents 数组的空间大小，然后才能将新元素加入到整数集合里，升级的过程中同时也要维持整数集合的有序性。整数集合升级有什么好处呢？如果要让一个数组同时保存 int16_t、int32_t、int64_t 类型的元素，最简单做法就是直接使用 int64_t 类型的数组。不过这样的话，当如果元素都是 int16_t 类型的，就会造成内存浪费的情况。因此，整数集合升级的好处是节省内存资源。还有就是：不支持降级操作，一旦对数组进行了升级，就会一直保持升级后的状态。跳表Zset 对象是唯一一个同时使用了两个数据结构来实现的 Redis 对象，这两个数据结构一个是跳表，一个是哈希表。这样的好处是既能进行高效的范围查询，也能进行高效单点查询。跳表结构设计链表在查找元素的时候，因为需要逐一查找，所以查询效率非常低，时间复杂度是O(N)，于是就出现了跳表。跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表，这样的好处是能快读定位数据。当数据量很大时，跳表的查找复杂度就是 O(logN)。跳表结点的数据结构：typedef struct zskiplistNode { //Zset 对象的元素值 sds ele; //元素权重值 double score; //后向指针 指向前一个结点 方便从跳表的尾结点开始访问结点 倒序查找方便 struct zskiplistNode *backward; //节点的level数组，保存每层上的前向指针和跨度 struct zskiplistLevel { struct zskiplistNode *forward; unsigned long span; } level[];} zskiplistNode;跨度span实际上是为了计算这个节点在跳表中的排位：因为跳表中的节点都是按序排列的，那么计算某个节点排位的时候，从头节点到该结点的查询路径上，将沿途访问过的所有层的跨度累加起来，得到的结果就是目标节点在跳表中的排位。谁定义哪个跳表节点是头节点呢？是「跳表」结构体：typedef struct zskiplist { struct zskiplistNode *header, *tail; unsigned long length; int level;} zskiplist;跳表结构里包含了： 跳表的头尾节点，便于在O(1)时间复杂度内访问跳表的头节点和尾节点； 跳表的长度，便于在O(1)时间复杂度获取跳表节点的数量； 跳表的最大层数，便于在O(1)时间复杂度获取跳表中层高最大的那个节点的层数量；跳表节点查询过程查找一个跳表节点的过程时，跳表会从头节点的最高层开始，逐一遍历每一层。在遍历某一层的跳表节点时，会用跳表节点中的 元素值和元素的权重来进行判断，共有两个判断条件： 如果当前节点的权重「小于」要查找的权重时，跳表就会访问该层上的下一个节点。 如果当前节点的权重「等于」要查找的权重时，并且当前节点的 元素值「小于」要查找的数据时，跳表就会访问该层上的下一个节点。 如果上面两个条件都不满足，或者下一个节点为空时，跳表就会使用目前遍历节点数组里的下一层指针，然后沿着下一层指针继续查找，这就相当于跳到了下一层接着查找。跳表节点层数设置跳表的相邻两层的节点数量的比例会影响跳表的查询性能。跳表的相邻两层的节点数量最理想的比例是 2:1，查找复杂度可以降低到 O(logN)。那怎样才能维持相邻两层的节点数量的比例为 2 : 1 呢？如果采用新增节点或者删除节点时，来调整跳表节点以维持比例的方法的话，会带来额外的开销。Redis 则采用一种巧妙的方法是，跳表在创建节点的时候，随机生成每个节点的层数，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况。具体的做法为：跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64。quicklist在 Redis 3.0 之前，List 对象的底层数据结构是双向链表或者压缩列表。然后在 Redis 3.2 的时候，List 对象的底层改由 quicklist 数据结构实现。其实 quicklist 就是「双向链表 + 压缩列表」组合，因为一个 quicklist 就是一个链表，而链表中的每个元素又是一个压缩列表。quicklist 通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能，但并没有完全解决此问题。listpackRedis 在 5.0 新设计一个数据结构叫 listpack，目的是替代压缩列表，它最大特点是 listpack 中每个节点不再包含前一个节点的长度了，压缩列表正因为每个结点保存前一个节点的长度，才会有连锁更新的隐患。listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，向 listpack 加入一个新元素的时候，不会影响其他节点长度字段的变化，从而避免了压缩列表的连锁更新问题。结构上是少了zltail字段，然后每个结点的prelen字段变成了len字段，len是encoding+data的总长度，即节点长度。Redis线程模型Redis 是单线程吗？Redis 单线程指的是「接收客户端请求-&amp;gt;解析请求 -&amp;gt;进行数据读写等操作-&amp;gt;发生数据给客户端」这个过程是由一个主线程来完成的，这也是我们常说 Redis 是单线程的原因。但是，Redis 程序并不是单线程的，Redis 在启动的时候，是会启动后台线程的，比如关闭文件、AOF刷盘、释放内存线程。之所以为这些任务创建单独的线程来处理，是因为这些任务的操作很费时，如果都放在主线程中处理，主线程容易发生阻塞而影响性能。后台线程相当于一个消费者，主线程相当于生产者，生产者把耗时任务丢到任务队列中，消费者不停轮询这个队列，拿出任务就去对应的线程处理即可。关闭文件、AOF 刷盘、释放内存都有各自的任务队列： BIO_CLOSE_FILE，关闭文件任务队列：当队列有任务后，后台线程会调用 close(fd) ，将文件关闭； BIO_AOF_FSYNC，AOF刷盘任务队列：当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到队列中。当发现队列有任务后，后台线程会调用 fsync(fd)，将 AOF 文件刷盘， BIO_LAZY_FREE，lazy free 任务队列：当队列有任务后，后台线程会 free(obj) 释放对象 / free(dict) 删除数据库所有对象 / free(skiplist) 释放跳表对象；Redis 采用单线程为什么还这么快？之所以 Redis 采用单线程（网络 I/O 和执行命令）那么快，有如下几个原因： Redis 的大部分操作都在内存中完成，并且采用了高效的数据结构，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了； Redis 采用单线程模型可以避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。 Redis 采用了 I/O 多路复用机制处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。Redis 6.0 之前为什么使用单线程？ CPU 并不是制约 Redis 性能表现的瓶颈所在，更多情况下是受到内存大小和网络I/O的限制，所以 Redis 核心网络模型使用单线程并没有什么问题，如果你想要使用服务的多核CPU，可以在一台服务器上启动多个节点或者采用集群的方式。 使用了单线程后，可维护性高，多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗。Redis 6.0 之后为什么引入了多线程？在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求，这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上。所以为了提高网络请求处理的并行度，Redis 6.0 对于网络请求采用多线程来处理。但是对于读写命令，Redis 仍然使用单线程来处理Redis持久化Redis 如何实现数据不丢失？Redis 的读写操作都是在内存中，所以 Redis 性能才会高，但是当 Redis 重启后，内存中的数据就会丢失，那为了保证内存中的数据不会丢失，Redis 实现了数据持久化的机制，这个机制会把数据存储到磁盘，这样在 Redis 重启就能够从磁盘中恢复原有的数据。Redis 共有三种数据持久化的方式： AOF 日志：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里； RDB 快照：将某一时刻的内存数据，以二进制的方式写入磁盘； 混合持久化方式：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点；AOF 日志是如何实现的？Redis 在执行完一条写操作命令后，就会把该命令以追加的方式写入到一个文件里，然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。为什么先执行命令，再把数据写入日志呢？这样做的好处： 避免额外的检查开销：因为如果先将写操作命令记录到 AOF 日志里，再执行该命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到 AOF 日志里后，Redis 在使用日志恢复数据时，就可能会出错。 不会阻塞当前写操作命令的执行：因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。这样做的风险： 数据可能会丢失： 执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有丢失的风险。AOF 写回策略有几种？Redis 提供了 3 种写回硬盘的策略，在 Redis.conf 配置文件中的 appendfsync 配置项有 3 种参数可填： Always，它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；优点是可靠性高、最大程度的保证数据不丢失，缺点是每个写命令都要写回硬盘，性能开销大。 Everysec，它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；性能适中，如果宕机会丢失1s内的数据。 No，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时写回硬盘。性能好，但是宕机时丢失的数据可能会更多。AOF 日志过大，会触发什么机制？AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。 如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。所以，Redis 为了避免 AOF 文件越写越大，提供了 AOF 重写机制，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。AOF 重写机制：在重写时读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。这就相当于压缩了AOF文件，使AOF的文件体积变小了。重写 AOF 日志的过程是怎样的？Redis 的重写 AOF 过程是由后台子进程 来完成的，这么做可以达到两个好处： 子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程； 子进程带有主进程的数据副本，这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程就不用加锁来保证数据安全。重写过程：触发重写机制后，主进程就会创建重写 AOF 的子进程bgrewriteaof，此时父子进程共享物理内存，重写子进程只会对这个内存进行只读，重写 AOF 子进程会读取数据库里的所有数据，并逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志（新的 AOF 文件）。问题来了：重写过程中，主线程依然可以正常处理命令，如果重写AOF日志过程中，主线程修改了已经存在的key-value，那么会发生写时复制，此时这个key-value数据在子进程和主进程中的数据就不一致了！解决方法：Redis 设置了一个 AOF 重写缓冲区，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作： 执行客户端发来的命令； 将执行后的写命令追加到 「AOF 缓冲区」； 将执行后的写命令追加到 「AOF 重写缓冲区」；当子进程完成 AOF 重写工作后，会向主进程发送一条信号。主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作： 将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致； 新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。信号函数执行完后，主线程和子线程的数据就保持一致了，主进程就可以继续像往常一样处理命令了。RDB快照是如何实现的？AOF日志的弊端：因为 AOF 日志记录的是操作命令，不是实际的数据，所以用 AOF 方法做故障恢复时，需要全量把日志都执行一遍，一旦 AOF 日志非常多，势必会造成 Redis 的恢复操作缓慢。处理方法：Redis 增加了 RDB 快照，记录某一个瞬间的内存数据，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。RDB 做快照时会阻塞线程吗？Redis 提供两个命令来生成 RDB 文件，分别是 save 和 bgsave，区别就在于是否在「主线程」里执行： 执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，会阻塞主线程； 执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以避免主线程的阻塞；Redis 还可以通过配置文件的选项来实现每隔一段时间自动执行一次 bgsave 命令，默认会提供以下配置：需要注意的是，虽然配置名是save，但是实际执行的bgsave命令。save 900 1 // 900 秒之内，对数据库进行了至少 1 次修改；save 300 10 // 300 秒之内，对数据库进行了至少 10 次修改；save 60 10000 // 60 秒之内，对数据库进行了至少 10000 次修改Redis 的快照是全量快照，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。所以如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多。RDB 在执行快照的时候，数据能修改吗？可以的，执行 bgsave 过程中，Redis 依然可以继续处理操作命令的，也就是数据是能被修改的，关键的技术就在于写时复制技术（Copy-On-Write, COW）。执行 bgsave 命令的时候，会通过 fork() 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个，此时如果主线程执行读操作，则主线程和 bgsave 子进程互相不影响。如果主线程执行写操作，则被修改的数据会复制一份副本，然后 bgsave 子进程会把该副本数据写入 RDB 文件，在这个过程中，主线程仍然可以直接修改原来的数据。为什么会有混合持久化？RDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。AOF 优点是丢失数据少，但是数据恢复不快。为了集成了两者的优点， Redis 4.0 提出了混合使用 AOF 日志和内存快照，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。混合持久化AOF 日志重写过程：当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。混合持久化优点： 混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险。混合持久化缺点： AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差； 兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。Redis集群Redis 如何实现服务高可用？要想设计一个高可用的 Redis 服务，一定要从 Redis 的多服务节点来考虑，比如 Redis 的主从复制、哨兵模式、切片集群。主从复制主从复制是 Redis 高可用服务的最基础的保证，实现方案就是将主Redis 服务器的数据同同步到多台从 Redis 服务器上，即一主多从的模式，且主从服务器之间采用的是「读写分离」的方式。第一次同步我们可以使用 replicaof（Redis 5.0 之前使用 slaveof）命令形成主服务器和从服务器的关系。主从服务器间的第一次同步的过程可分为三个阶段： 第一阶段是建立链接、协商同步； 第二阶段是主服务器同步数据给从服务器； 第三阶段是主服务器发送新写操作命令给从服务器。第一阶段：建立链接、协商同步执行了 replicaof 命令后，从服务器就会给主服务器发送 psync 命令，表示要进行数据同步。psync 命令包含两个参数，分别是主服务器的 runID 和复制进度 offset。 runID，每个 Redis 服务器在启动时都会自动生产一个随机的 ID 来唯一标识自己。当从服务器和主服务器第一次同步时，因为不知道主服务器的 run ID，所以将其设置为 “?”。 offset，表示复制的进度，第一次同步时，其值为 -1。主服务器收到 psync 命令后，会用 FULLRESYNC 作为响应命令返回给对方。并且这个响应命令会带上两个参数：主服务器的 runID 和主服务器目前的复制进度 offset。从服务器收到响应后，会记录这两个值。FULLRESYNC 响应命令的意图是采用全量复制的方式，也就是主服务器会把所有的数据都同步给从服务器。第二阶段：主服务器同步数据给从服务器接着，主服务器会执行 bgsave 命令来生成 RDB 文件，然后把文件发送给从服务器。从服务器收到 RDB 文件后，会先清空当前的数据，然后载入 RDB 文件。需要注意的是，主服务器生成 RDB 这个过程是不会阻塞主线程的，因为 bgsave 命令是产生了一个子进程来做生成 RDB 文件的工作，是异步工作的，这样 Redis 依然可以正常处理命令。但是，这期间主线程的写操作命令并没有记录到刚刚生成的 RDB 文件中，这时主从服务器间的数据就不一致了。那么为了保证主从服务器的数据一致性，主服务器在下面这三个时间阶段中将收到的写操作命令，写入到 replication buffer 缓冲区里。第三阶段：主服务器发送新写操作命令给从服务器在主服务器生成的 RDB 文件发送完，从服务器加载完 RDB 文件后，然后将 replication buffer 缓冲区里所记录的写操作命令发送给从服务器，然后「从服务器」重新执行这些操作，至此主从服务器的数据就一致了。命令传播主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接。后续主服务器可以通过这个连接继续将写操作命令传播给从服务器，然后从服务器执行该命令，使得与主服务器的数据库状态相同。而且这个连接是长连接的，目的是避免频繁的 TCP 连接和断开带来的性能开销。Redis 也是一样的，从服务器可以有自己的从服务器，因此我们可以让已经同步的从服务器来执行上述工作分担主服务器的压力。分摊主服务器的压力主从服务器在第一次数据同步的过程中，主服务器会做两件耗时的操作：生成 RDB 文件和传输 RDB 文件。主服务器是可以有多个从服务器的，如果从服务器数量非常多，而且都与主服务器进行全量同步的话，就会影响主服务器的性能。Redis 也是一样的，从服务器可以有自己的从服务器，因此我们可以让已经同步的从服务器来执行上述工作减轻主服务器的负担。我们可以在「从服务器」上执行下面这条命令，使其作为目标服务器的从服务器：replicaof &amp;lt;目标服务器的IP&amp;gt; 6379。增量复制主从服务器在完成第一次同步后，就会基于长连接进行命令传播。如果主从服务器间的网络连接断开了，那么就无法进行命令传播了，这时从服务器的数据就没办法和主服务器保持一致了，客户端就可能从「从服务器」读到旧的数据。断开网络又恢复后，怎么继续保证主从服务器的数据一致性？主从服务器采用增量复制继续同步：也就是只会把网络断开期间主服务器接收到的写操作命令，同步给从服务器。具体如下：网络断开后，当从服务器重新连上主服务器时，从服务器会通过 psync 命令将自己的复制偏移量 slave_repl_offset 发送给主服务器，主服务器根据自己的 master_repl_offset 和 slave_repl_offset 之间的差距，然后来决定对从服务器执行哪种同步操作： 如果判断出从服务器要读取的数据还在 repl_backlog_buffer 缓冲区里，那么主服务器将采用增量同步的方式； 相反，如果判断出从服务器要读取的数据已经不存在 repl_backlog_buffer 缓冲区里，那么主服务器将采用全量同步的方式。在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里，因此 这个缓冲区里会保存着最近传播的写命令。怎么判断 redis 某个节点是否正常工作？redis 判断接点是否正常工作，基本都是通过互相的 ping-pong 心跳检测机制，如果有一半以上的节点去 ping 一个节点的时候没有 pong 回应，集群就会认为这个节点挂掉了，会断开与这个节点的连接。redis 主从节点发送的心态间隔是不一样的，而且作用也有一点区别： redis 主节点默认每隔 10 秒对从节点发送 ping 命令，判断从节点的存活性和连接状态。 redis 从节点每隔 1 秒发送 replconf ack{offset} 命令，给主节点上报自身当前的复制偏移量，目的是为了： 实时检测主从节点网络状态； 上报自身复制偏移量， 检查复制数据是否丢失， 如果从节点数据丢失， 再从主节点的复制缓冲区中拉取丢失数据。 redis 是同步复制还是异步复制？redis 主节点每次收到写命令之后，先写到内部的缓冲区，然后异步发送给从节点。主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？ replication buffer 是在全量复制阶段会出现，主库会给每个新连接的从库，分配一个 replication buffer；repl backlog buffer 是在增量复制阶段出现，一个主库只分配一个repl backlog buffer； 这两个 Buffer 都有大小限制的，当缓冲区满了之后。repl backlog buffer，因为是环形结构，会直接覆盖起始位置数据，replication buffer则会导致连接断开，删除缓存，从库重新连接，重新开始全量复制。redis 主从切换如何减少数据丢失？异步复制同步数据丢失：主从复制是异步的，所以可能有部分数据还没复制到从服务器，主服务器就宕机了，此时这些部分数据就丢失了解决方案： 第一种：客户端将数据暂时写入本地缓存和磁盘中，在一段时间后将本地缓存或者磁盘的数据发送给主节点，来保证数据不丢失； 第二种：客户端将数据写入到消息队列中，发送一个延时消费消息，比如10分钟后再消费消息队列中的数据，然后再写到主节点。集群脑裂导致数据丢失：脑裂：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。解决方案：在 Redis 的配置文件中有两个参数我们可以设置： min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，小于这个数，主节点会禁止写数据。 min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据（1）减少异步复制的数据丢失有了min-slaves-max-lag这个配置，就可以确保，一旦slave复制数据和ack延时太长，就认为可能主服务器宕机后损失的数据太多了，那么就拒绝写请求。（2）减少脑裂的数据丢失可以把 min-slaves-to-write 和 min-slaves-max-lag 这两个配置项搭配起来使用，分别给它们设置一定的阈值，表示如果不能继续给指定数量的slave发送数据，而且slave超过10秒没有给自己ack消息，那么就直接拒绝客户端的写请求。这样脑裂后的旧主服务器就不会接受client的新数据。上述解决方案将数据丢失控制在了min-slaves-max-lag范围内。哨兵模式如果主节点（master）挂了，那么将没有主节点来服务客户端的写操作请求，也没有主节点给从节点（slave）进行数据同步了，这个时候需要人工介入来恢复服务。Redis提供了哨兵机制，它的作用是实现主从节点的故障转移。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。哨兵机制是如何工作的？哨兵其实是一个运行在特殊模式下的 Redis 进程，所以它也是一个节点。哨兵节点主要负责三件事情：监控、选主、通知。如何判断主节点真的故障了？哨兵会每隔 1 秒给所有主从节点发送 PING 命令，如果主从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「主观下线」。这个「规定的时间」是配置项 down-after-milliseconds 参数设定的，单位是毫秒。此外还有客观下线，客观下线只适用于主节点。之所以针对「主节点」设计「主观下线」和「客观下线」两个状态，是因为有可能「主节点」其实并没有故障，而是因为主节点的系统压力比较大或者网络发送了拥塞，导致主节点没有在规定时间内响应哨兵的 PING 命令。所以，哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成哨兵集群（最少需要三台机器来部署哨兵集群），由多个哨兵共同决策就可以降低误判率。具体是怎么判定主节点为「客观下线」的呢？当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。当这个哨兵的赞同票数达到一定数量时（哨兵配置文件中的 quorum 值），主节点就会被该哨兵标记为「客观下线」。哨兵判断完主节点客观下线后，哨兵就要开始在多个「从节点」中，选出一个从节点来做新主节点。由哪个哨兵进行主从故障转移？通过投票从候选者中选举，候选者就是那些判断主节点为客观下线的哨兵结点。主从故障转移的过程是怎样的？主从故障转移操作包含以下四个步骤： 第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。 第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」； 第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端； 第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；哨兵集群是如何组成的？通过 Redis 的发布/订阅机制，哨兵之间可以相互感知，然后组成集群，同时，哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。切片集群模式当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 Redis 切片集群（Redis Cluster ）方案，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。在 Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中，具体执行过程分为两大步： 根据键值对的 key，按照 CRC16 算法 (opens new window)计算一个 16 bit 的值。 再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。接下来的问题就是，这些哈希槽怎么被映射到具体的 Redis 节点上的呢？有两种方案： 平均分配： 在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384/9 个。 手动分配： 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。Redis过期删除与内存淘汰Redis 使用的过期删除策略是什么？Redis 是可以对 key 设置过期时间的，同时也需要有相应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。常用的过期删除策略： 定时删除 惰性删除 定期删除如何设置过期时间？设置key过期时间的命令： expire &amp;lt;key&amp;gt; &amp;lt;n&amp;gt;：设置 key 在 n 秒后过期，比如 expire pexpire &amp;lt;key&amp;gt; &amp;lt;n&amp;gt;：设置 key 在 n 毫秒后过期，比如 expireat &amp;lt;key&amp;gt; &amp;lt;n&amp;gt;：设置 key 在某个时间戳（精确到秒）之后过期 pexpireat &amp;lt;key&amp;gt; &amp;lt;n&amp;gt;：设置 key 在某个时间戳（精确到毫秒）之后过期。查看某个key剩余的存活时间： TTL &amp;lt;key&amp;gt;取消key的过期时间： PERSIST &amp;lt;key&amp;gt;如何判断key是否过期？过期字典保存了数据库中所有key的过期时间，当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中： 如果不在，则正常读取键值； 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。什么是定时删除策略？定时删除策略的做法是，在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。定时删除策略的优点： 可以保证过期 key 会被尽快删除，也就是内存可以被尽快地释放。因此，定时删除对内存是最友好的。定时删除策略的缺点： 在过期 key 比较多的情况下，删除过期 key 可能会占用相当一部分 CPU 时间，在内存不紧张但 CPU 时间紧张的情况下，将 CPU 时间用于删除和当前任务无关的过期键上，无疑会对服务器的响应时间和吞吐量造成影响。所以，定时删除策略对 CPU 不友好。什么是惰性删除策略？惰性删除策略的做法是，不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。惰性删除策略的做法是，不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。惰性删除策略的优点： 因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对 CPU 时间最友好。惰性删除策略的缺点： 如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。所以，惰性删除策略对内存不友好。什么是定期删除策略？定期删除策略的做法是，每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。Redis 的定期删除的流程： 从过期字典中随机抽取 20 个 key； 检查这 20 个 key 是否过期，并删除已过期的 key； 如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。可以看到，定期删除是一个循环的流程。那 Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms。定期删除策略的优点： 通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。定期删除策略的缺点： 难以确定删除操作执行的时长和频率。如果执行的太频繁，就会对 CPU 不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。Redis 持久化时，对过期键会如何处理的？Redis 持久化文件有两种格式：RDB（Redis Database）和 AOF（Append Only File），下面我们分别来看过期键在这两种格式中的呈现状态。RDB 文件分为两个阶段，RDB 文件生成阶段和加载阶段。 RDB 文件生成阶段：从内存状态持久化成 RDB（文件）的时候，会对 key 进行过期检查，过期的键「不会」被保存到新的 RDB 文件中，因此 Redis 中的过期键不会对生成新 RDB 文件产生任何影响。 RDB 加载阶段：RDB 加载阶段时，要看服务器是主服务器还是从服务器，分别对应以下两种情况： 如果 Redis 是「主服务器」运行模式的话，在载入 RDB 文件时，程序会对文件中保存的键进行检查，过期键「不会」被载入到数据库中。所以过期键不会对载入 RDB 文件的主服务器造成影响； 如果 Redis 是「从服务器」运行模式的话，在载入 RDB 文件时，不论键是否过期都会被载入到数据库中。但由于主从服务器在进行数据同步时，从服务器的数据会被清空。所以一般来说，过期键对载入 RDB 文件的从服务器也不会造成影响。 AOF 文件分为两个阶段，AOF 文件写入阶段和 AOF 重写阶段。 AOF 文件写入阶段：当 Redis 以 AOF 模式持久化时，如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值。 AOF 重写阶段：执行 AOF 重写时，会对 Redis 中的键值对进行检查，已过期的键不会被保存到重写后的 AOF 文件中，因此不会对 AOF 重写造成任何影响。Redis 主从模式中，对过期键会如何处理？当 Redis 运行在主从模式下时，从库不会进行过期扫描，从库对过期的处理是被动的。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。从库的过期键处理依靠主服务器控制，主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库，从库通过执行这条 del 指令来删除过期的 key。Redis 内存满了，会发生什么？在 Redis 的运行内存达到了某个阀值，就会触发内存淘汰机制。这个阀值就是我们设置的最大运行内存，在配置文件redis.conf中，可以通过参数maxmemory &amp;lt;bytes&amp;gt; 来设定最大运行内存.不同位数的操作系统，maxmemory 的默认值是不同的： 在 64 位操作系统中，maxmemory 的默认值是 0，表示没有内存大小限制，那么不管用户存放多少数据到 Redis 中，Redis 也不会对可用内存进行检查，直到 Redis 实例因内存不足而崩溃也无作为。 在 32 位操作系统中，maxmemory 的默认值是 3G，因为 32 位的机器最大只支持 4GB 的内存，而系统本身就需要一定的内存资源来支持运行，所以 32 位操作系统限制最大 3 GB 的可用内存是非常合理的，这样可以避免因为内存不足而导致 Redis 实例崩溃。Redis 内存淘汰策略有哪些？Redis 内存淘汰策略共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。1、不进行数据淘汰的策略noeviction（Redis3.0之后，默认的内存淘汰策略） ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，而是不再提供服务，直接返回错误。2、进行数据淘汰的策略针对「进行数据淘汰」这一类策略，又可以细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。在设置了过期时间的数据中进行淘汰： volatile-random：随机淘汰设置了过期时间的任意键值； volatile-ttl：优先淘汰更早过期的键值。 volatile-lru（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值； volatile-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；在所有数据范围内进行淘汰： allkeys-random：随机淘汰任意键值; allkeys-lru：淘汰整个键值中最久未使用的键值； allkeys-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。LRU 算法和 LFU 算法有什么区别？什么是 LRU 算法？LRU 全称是 Least Recently Used 翻译为最近最少使用，会选择淘汰最近最少使用的数据。传统 LRU 算法的实现是基于「链表」结构，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要内存淘汰时，只需要删除链表尾部的元素即可，因为链表尾部的元素就代表最久未被使用的元素。Redis 并没有使用这样的方式实现 LRU 算法，因为传统的 LRU 算法存在两个问题： 需要用链表管理所有的缓存数据，这会带来额外的空间开销； 当有数据被访问时，需要在链表上把该数据移动到头端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。Redis 是如何实现 LRU 算法的？Redis 实现的是一种近似 LRU 算法，目的是为了更好的节约内存，它的实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间。当 Redis 进行内存淘汰时，会使用随机采样的方式来淘汰数据，它是随机取 5 个值（此值可配置），然后淘汰最久没有使用的那个。Redis 实现的 LRU 算法的优点： 不用为所有的数据维护一个大链表，节省了空间占用； 不用在每次数据访问时都移动链表项，提升了缓存的性能；但是 LRU 算法有一个问题，无法解决缓存污染问题，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染。因此，在 Redis 4.0 之后引入了 LFU 算法来解决这个问题。什么是 LFU 算法？LFU 全称是 Least Frequently Used 翻译为最近最不常用的，LFU 算法是根据数据访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。（局部性原理）所以， LFU 算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。这样就解决了缓存污染问题。Redis 是如何实现 LFU 算法的？LFU 算法相比于 LRU 算法的实现，多记录了「数据的访问频次」的信息。Redis 对象结构中的 lru 字段，在 LRU 算法下和 LFU 算法下使用方式并不相同。在 LRU 算法中，Redis 对象结构的 24 bits 的 lru 字段是用来记录 key 的访问时间戳。在 LFU 算法中，Redis对象结构的 24 bits 的 lru 字段被分成两段来存储，高 16bit 用来记录 key 的访问时间戳；低 8bit用来记录 key 的访问频次。Redis缓存设计如何避免缓存雪崩、缓存击穿、缓存穿透？如何避免缓存雪崩？缓存雪崩：当大量缓存数据在同一时间过期时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃。解决方案： 将缓存失效时间随机打散： 我们可以在原有的失效时间基础上增加一个随机值，这样每个缓存的过期时间都不重复了，也就降低了缓存集体失效的概率。 设置缓存不过期： 我们可以通过后台服务来更新缓存数据，从而避免因为缓存失效造成的缓存雪崩。如何避免缓存击穿？缓存击穿：如果缓存中的某个热点数据过期了，此时大量的请求访问了该热点数据，我们无法从缓存中读取，就只能直接访问数据库，数据库很容易就被高并发的请求冲垮。解决方案： 互斥锁方案，保证同一时间只有一个业务线程请求缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。 不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；如何避免缓存穿透？缓存穿透：当用户访问的数据，既不在缓存中，也不在数据库中，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力会骤增。解决方案： 非法请求的限制：当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理、是否含有非法值、以及是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。 设置空值或者默认值：当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。 使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在：我们可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在，即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。如何设计一个缓存策略，可以动态缓存热点数据呢？热点数据动态缓存的策略总体思路：通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据。以电商平台场景中的例子，现在要求只缓存用户经常访问的 Top 1000 的商品。具体细节如下： 先通过缓存系统做一个排序队列（比如存放 1000 个商品），系统会根据商品的访问时间，更新队列信息，越是最近访问的商品排名越靠前； 同时系统会定期过滤掉队列中排名最后的 200 个商品，然后再从数据库中随机读取出 200 个商品加入队列中； 这样当请求每次到达的时候，会先从队列中获取商品 ID，如果命中，就根据 ID 再从另一个缓存数据结构中读取实际的商品信息，并返回。说说常见的缓存更新策略？常见的缓存更新策略共有3种： Cache Aside（旁路缓存）策略； Read/Write Through（读穿 / 写穿）策略； Write Back（写回）策略；Cache Aside（旁路缓存）策略Cache Aside（旁路缓存）策略是最常用的，应用程序直接与「数据库、缓存」交互，并负责对缓存的维护，该策略又可以细分为「读策略」和「写策略」。写策略的步骤： 先更新数据库中的数据，再删除缓存中的数据。读策略的步骤： 如果读取的数据命中了缓存，则直接返回数据； 如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。注意：写策略的步骤的顺序顺序不能倒过来，即不能先删除缓存再更新数据库，原因是在「读+写」并发的时候，会出现缓存和数据库的数据不一致性的问题。比如写请求删除缓存之后，另一个读请求发现缓存中没有此数据，就从数据库中读取并将其写入缓存，而写请求删除缓存之后去更新数据库，此时缓存与数据库数据不一致了。Cache Aside 策略适合读多写少的场景，不适合写多的场景，因为当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。Read/Write Through（读穿 / 写穿）策略Read/Write Through（读穿 / 写穿）策略原则是应用程序只和缓存交互，不再和数据库交互，而是由缓存和数据库交互，相当于更新数据库的操作由缓存自己代理了。Read Through 策略先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库查询数据，并将结果写入到缓存组件，最后缓存组件将数据返回给应用。Write Through 策略当有数据更新的时候，先查询要写入的数据在缓存中是否已经存在： 如果缓存中数据已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，然后缓存组件告知应用程序更新完成。 如果缓存中数据不存在，直接更新数据库，然后返回；在我们开发过程中相比 Cache Aside 策略要少见一些，原因是我们经常使用的分布式缓存组件，无论是 Memcached 还是 Redis 都不提供写入数据库和自动加载数据库中的数据的功能。而我们在使用本地缓存的时候可以考虑使用这种策略。Write Back（写回）策略Write Back（写回）策略在更新数据的时候，只更新缓存，同时将缓存数据设置为脏的，然后立马返回，并不会更新数据库。对于数据库的更新，会通过批量异步更新的方式进行。Write Back 策略特别适合写多的场景，因为发生写操作的时候， 只需要更新缓存，就立马返回了。比如，写文件的时候，实际上是写入到文件系统的缓存就返回了，并不会写磁盘。但是带来的问题是，数据不是强一致性的，而且会有数据丢失的风险。如何保证缓存和数据库数据的一致性？Redis实战Redis 如何实现延迟队列？延迟队列是指把当前要做的事情，往后推迟一段时间再做。在 Redis 可以使用有序集合（ZSet）的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。Redis的大 key 如何处理？什么是大key？大 key 并不是指 key 的值很大，而是 key 对应的 value 很大。一般而言，下面这两种情况被称为大 key： String 类型的值大于 10 KB； Hash、List、Set、ZSet 元素的个数超过 5000个；如何删除大 key？删除操作的本质是要释放键值对占用的内存空间。不要小瞧内存的释放过程。释放内存只是第一步，为了更加高效地管理内存空间，在应用程序释放内存时，操作系统需要把释放掉的内存块插入一个空闲内存块的链表，以便后续进行管理和再分配。这个过程本身需要一定时间，而且会阻塞当前释放内存的应用程序。所以，如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成 Redis 主线程的阻塞，如果主线程发生了阻塞，其他所有请求可能都会超时，超时越来越多，会造成 Redis 连接耗尽，产生各种异常。我们可以采用分批次删除的方式： 对于 Hash，使用 hscan 扫描法； 对于 Set，采用 srandmember 每次随机取数据进程删除； 对于 ZSet，可以使用 zremrangebyrank 命令直接删除； 对于 List，直接 pop 即可了；另外，也可以采用异步删除法，用 unlink 命令代替 del 来删除，这样 Redis 会讲这个 key 放入到一个异步线程中进行删除，这样不会阻塞主线程。Redis 管道有什么用？管道技术（Pipeline）是客户端提供的一种批处理技术，用于一次处理多个 Redis 命令，从而提高整个交互的性能。使用管道技术可以解决多个命令执行时的网络等待，它是把多个命令整合到一起发送给服务器端处理之后统一返回给客户端，这样就免去了每条命令执行后都要等待的情况，从而有效地提高了程序的执行效率。要注意的是，管道技术本质上是客户端提供的功能，而非 Redis 服务器端的功能。Redis 事务支持回滚吗？Redis 中并没有提供回滚机制，虽然 Redis 提供了 DISCARD 命令，但是这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。为什么Redis 不支持事务回滚？ Redis作者认为Redis 事务的执行时，错误通常都是编程错误造成的，这种错误通常只会出现在开发环境中，而很少会在实际的生产环境中出现，所以他认为没有必要为 Redis 开发事务回滚功能； 不支持事务回滚是因为这种复杂的功能和 Redis 追求的简单高效的设计主旨不符合。" }, { "title": "MySQL相关知识整理", "url": "/posts/MySQL-knowledge/", "categories": "笔记, SQL", "tags": "总结, MySQL, 八股, 数据库, SQL", "date": "2022-07-15 22:41:27 +0800", "snippet": "基础执行一条select语句，期间发生了什么？首先需要了解MySQL的内部架构，共分为两层：Server层和存储引擎层 Server层负责建立连接、分析和执行SQL，主要包络连接器、查询缓存、解析器、预处理器、优化器、执行器等核心功能模块。 存储引擎层负责数据的存储和提取。MySQL支持MyISAM、InnoDB、Memory等多个存储引擎，不同的存储引擎公用一个Server层，现在最常用的是InnoDB，MySQL从5.5版本之后使用其为默认存储引擎。第一步：连接器首先要连接到MySQL服务，然后才能执行SQL语句，连接器主要做以下几个工作： 与客户端进行TCP三次握手建立连接； 建立连接后会校验客户端的用户名和密码，如果用户名和密码不对，则会报错； 如果用户名和密码都对了，接下来会读取用户的权限，后面的权限逻辑判断都基于此时读取到的权限。相关问题：1、如何查看MySQL服务被多少个客户端连接了？可以使用show processlist命令进行查看。2、空闲连接的客户端会一直占用着吗？当然不是，MySQL定义了空闲连接的最大空闲时长，由wait_timeout参数控制，默认值为8小时，如果空闲连接超过了这个时间，连接器就会自动将它断开。我们也可以手动断开空闲的链接，使用kill connection + id命令。3、MySQL的连接数有限制吗？MySQL服务支持的最大连接数由max_connections参数控制，超过这个值，系统会拒绝接下来的连接请求，并报错提示too many connections。4、MySQL短连接和长连接的区别？短连接就是每执行一次操作，就进行一次连接过程；长连接是建立连接后一直保持连接。很明显，长连接的好处就是可以减少建立连接和断开连接的过程，所以一般推荐长连接。但是，因为连接对象的资源只有在连接断开时才会释放，所以长连接会占用很大的内存。如果长连接累计很多，可能会因为MySQL占用内存太大而被系统强制杀掉，进而引起MySQL服务异常重启的现象。5、怎么解决长连接占用内存大的问题？有两种解决方式： 第一种是定期断开长连接。定期断开释放占用的内存资源，就可以避免内存占用过多这个问题。 第二种是客户端主动重置连接。可以调用mysql_reset_connection()函数来重置连接，达到释放内存的效果，这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。第二步：查询缓存连接器完成工作之后，客户端就可以向MySQL服务发送SQL语句了，MySQL接收到SQL语句之后会解析语句的第一个字段，看看是什么类型的语句。如果SQL是查询语句（即select语句）,MySQL会先去查询缓存里查找数据，看看之前有没有执行过这一条语句。查询缓存是以key-value形式保存在内存中的，key是SQL查询语句，value为SQL语句查询的结果。如果查询的语句命中查询缓存，就会直接返回value给客户端。如果没有命中，那么继续往下执行，等执行完后，查询的结果会被放入查询缓存中。相关问题：1、为什么不建议使用查询缓存？因为对于更新比较频繁的表，查询缓存的命中率很低。因为只要一个表有更新操作，那么这个表的查询缓存就会被清空。如果缓存了一个查询结果很大的数据，还没被使用的时候，刚好这个表有更新操作，查询缓存就被清空了，那缓存也就没有意义了。所以，MySQL8.0版本直接将查询缓存删除掉了。第三步：解析SQL语句正式执行SQL语句之前，需要先对其进行解析，这个工作由解析器完成。解析器会做两件事情： 词法解析。根据输入的字符串识别出关键字，然后构建SQL语法树。 语法解析。根据词法解析的结果，语法解析器会根据语法规则，判断输入的语句是否满足MySQL语法。第四步：执行SQL语句解析完成之后就是执行语句了，每个select查询语句流程主要可以分为三个阶段： 预处理阶段 优化阶段 执行阶段预处理器预处理阶段主要做以下事情： 检查SQL查询语句中的表或字段是否存在 将select * 中的*符号，扩展为表上所有列优化器优化器主要负责将SQL查询语句的执行方案确定下来，比如在表里有多个索引的时候，优化器会基于查询成本的考虑，来决定选择使用哪个索引。执行器确定好执行方案后，MySQL就真正开始执行语句了，这个工作由执行器完成，在执行的过程中，执行器会和存储引擎交互，读取记录，然后返回客户端。索引索引常见面试题什么是索引？索引是帮助存储引擎快速获取数据的一种数据结构。简单的说就是索引是数据的目录，通过建立目录来达到快速查找相关数据的目的，所以索引时空间换时间的思想。索引分类？按数据结构分类从数据结构的角度看，MySQL常见索引有B+Tree索引、Hash索引、Full-Text索引。按物理存储分类聚簇索引和二级索引。按字段特性分类从字段特性的角度来看，索引分为主键索引、唯一索引、普通索引、前缀索引。 主键索引：是建立在主键字段上的索引，通常在创建表的时候一起创建，一张表最多只有一个主键索引，索引列的值不允许有空值。 唯一索引建立在 UNIQUE 字段上的索引，一张表可以有多个唯一索引，索引列的值必须唯一，但是允许有空值。 普通索引就是建立在普通字段上的索引，既不要求字段为主键，也不要求字段为 UNIQUE。 前缀索引是指对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，使用前缀索引的目的是为了减少索引占用的存储空间，提升查询效率。按字段个数分类从字段个数的角度来看，索引分为单列索引、联合索引。 建立在单列上的索引为单列索引，比如主键索引； 建立在多列上的索引为联合索引。什么时候需要、不需要索引？首先需要明确索引的优点与缺点。优点是： 大幅提高数据的查询速度；缺点是： 需要占用物理空间，数量越大，占用空间越大； 建索引和维护索引要耗费时间，这种时间随着数据量的增加而增大； 会降低表的增删改效率，因为每次增删改，B+ 树为了维护索引有序性，都需要进行动态维护。因此，索引不是万能钥匙，需要根据场景来使用。什么时候需要索引？ 字段有唯一性限制的，比如商品编码；可以建立唯一性索引保证数据的唯一性。 经常用于 WHERE 查询条件的字段，这样能够提高整个表的查询速度。 经常用于 GROUP BY 和 ORDER BY 的字段，这样在查询的时候就不需要再去做一次排序了，因为建立索引之后在 B+Tree 中的记录都是排序好的。什么时候不需要创建索引？ WHERE 条件，GROUP BY，ORDER BY 里用不到的字段，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。 字段中存在大量重复数据，不需要创建索引。因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。 表数据太少的时候，不需要创建索引，全表扫描也很快，建立索引会额外增加负担。 经常更新的字段不用创建索引。因为索引字段频繁修改，由于要维护B+树的有序性，那么久需要频繁的重建索引，这个过程会影响数据库的性能。有什么优化索引的方法？几种常用的索引优化方法： 前缀索引优化 覆盖索引优化 主键索引最好是自增的 索引最好设置为 NOT NULL 防止索引失效前缀索引优化使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。在一些大字符串的字段作为索引时，使用前缀索引可以帮助我们减小索引项的大小。覆盖索引优化覆盖索引是指 SQL 中请求的所有字段，从二级索引中可以直接查询得到记录，而不需要再通过主键索引查询获得，可以避免回表的操作。所以，使用覆盖索引的好处就是，不需要查询出包含整行记录的所有信息，也就减少了大量的 I/O 操作。主键索引最好是自增的我们在建表的时候，都会默认将主键索引设置为自增的，具体为什么要这样做呢？又什么好处？InnoDB 创建主键索引默认为聚簇索引，数据被存放在了 B+Tree 的叶子节点上。也就是说，同一个叶子节点内的各个数据是按主键顺序存放的，因此，每当有一条新的数据插入时，数据库会根据主键将其插入到对应的叶子节点中。如果我们使用自增主键，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为每次插入一条新记录，都是追加操作，不需要重新移动数据，因此这种插入数据的方法效率非常高。如果我们使用非自增主键，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为页分裂。页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率。索引最好设置为 NOT NULL为了更好的利用索引，索引列要设置为 NOT NULL 约束。有两个原因： 第一原因：索引列存在 NULL 就会导致优化器在做索引选择的时候更复杂，更难以优化，因为可为 NULL 的列会使索引、索引统计和值比较都更复杂，比如进行索引统计时，count 会省略值为NULL 的行。 第二个原因：NULL 值是一个没意义的值，但是它会占用物理空间，所以会造成更多的存储空间占用，因为 InnoDB 默认行存储格式COMPACT，会用 1 字节空间存储 NULL 值列表防止索引失效用上了索引并不意味着查询的时候会使用到索引，所以我们心里要清楚有哪些情况会导致索引失效，从而避免写出索引失效的查询语句，否则这样的查询效率是很低的。几种常见的发生索引失效的情况： 当我们使用左或者左右模糊匹配的时候，也就是 like %xx 或者 like %xx%使可能会造成索引失效； 当我们在查询条件中对索引列做了计算等操作，也会造成索引失效； 联合索引的正确使用需要遵循最左匹配原则，按照最左优先的方式进行索引匹配，否则会导致索引失效。 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，索引会失效。我们可以使用explain 语句来查看语句的执行情况，其中type字段描述了找到所需数据时使用的扫描方式，常见扫描类型的执行效率从低到高顺序为： All（全表扫描）； index（全索引扫描）； range（索引范围扫描）； ref（非唯一索引扫描）； eq_ref（唯一索引扫描）； const（结果只有一条的主键或唯一索引扫描）。All 是最坏的情况，因为采用了全表扫描的方式。index 和 All 差不多，只不过 index 对索引表进行全扫描，这样做的好处是不再需要对数据进行排序，但是开销依然很大。所以，要尽量避免全表扫描和全索引扫描。range 表示采用了索引范围扫描，只检索给定范围的行，属于范围查找。从这一级别开始，索引的作用会越来越明显，因此我们需要尽量让 SQL 查询可以使用到 range 这一级别及以上的扫描方式。从数据页的角度看B+树InnoDB是如何存储数据的？数据记录是按照行来存储的，但是数据库的读取并不以「行」为单位，否则一次读取（也就是一次 I/O 操作）只能处理一行数据，效率会非常低。因此，InnoDB 的数据是按「数据页」为单位来读写的，也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。数据库的 I/O 操作的最小单位是数据页，InnoDB 数据页的默认大小是 16KB，意味着数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16K 的内容到内存中，一次最少把内存中的 16K 内容刷新到磁盘。数据页包括七个部分，每个部分的作用如下： 文件头：表示页的信息 页头：表示页的状态信息 最小和最大记录：两个虚拟的伪记录，分别表示页中的最小记录和最大记录 用户记录：存储行记录内容 空闲空间：页中还没被使用的空间 页目录：存储用户记录的相对位置，对记录起到索引作用 文件尾：校验页是否完整在文件头中有两个指针，分别指向上一个数据页和下一个数据页，连接起来的页相当于一个双向的链表。采用链表的结构是让数据页之间不需要是物理上的连续的，而是逻辑上的连续。数据页中的记录按照「主键」顺序组成单向链表，单向链表的特点就是插入、删除非常方便，但是检索效率不高，最差的情况下需要遍历链表上的所有节点才能完成检索。因此，数据页中有一个页目录，起到记录的索引作用，通过页目录可以快速的找到记录。页目录创建的过程如下： 将所有的记录划分成几个组，这些记录包括最小记录和最大记录； 每个记录组的最后一条记录就是组内最大记录，最后一条记录的头信息中会存储该组一共有多少条记录 页目录用来存储每组最后一条记录的地址偏移量，这些地址偏移量会按照先后顺序存储起来，每组的地址偏移量也被称之为槽（slot），每个槽相当于指针指向了不同组的最后一个记录。因此，页目录是由多个槽组成的，槽相当于分组记录的索引。然后，因为记录是按照主键值从小到大排序的，所以我们可以使用二分法快速定位到查询的记录在哪个槽，然后再遍历槽内的所有记录，找到对应的记录。而无须从最小记录开始遍历整个页中的记录链表。B+树是如何进行查询的？页目录可以在数据页内快速检索记录，但是当我们需要存储大量的记录时，就需要多个数据页，这时我们就需要考虑如何建立合适的索引，才能方便定位记录所在的页。为了解决这个问题，InnoDB 采用了 B+ 树作为索引。InnoDB 里的 B+ 树中的每个节点都是一个数据页，B+ 树的特点： 只有叶子节点（最底层的节点）才存放了数据，非叶子节点仅用来存放目录项作为索引。 非叶子节点分为不同层次，通过分层来降低每一层的搜索量； 所有节点按照索引键大小排序，构成一个双向链表，便于范围查询；在定位记录所在哪一个页时，也是通过二分法快速定位到包含该记录的页。定位到该页后，又会在该页内进行二分法快速定位记录所在的分组（槽号），最后在分组内进行遍历查找聚簇索引和二级索引另外，索引又可以分成聚簇索引和非聚簇索引（二级索引），它们区别就在于叶子节点存放的是什么数据： 聚簇索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚簇索引的叶子节点； 非聚簇索引的叶子节点存放的是主键值，而不是实际数据。因为表的数据都是存放在聚簇索引的叶子节点里，所以 InnoDB 存储引擎一定会为表创建一个聚簇索引，且由于数据在物理上只会保存一份，所以聚簇索引只能有一个。InnoDB 在创建聚簇索引时，会根据不同的场景选择不同的列作为索引： 如果有主键，默认会使用主键作为聚簇索引的索引键； 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键； 在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键；一张表只能有一个聚簇索引，那为了实现非主键字段的快速搜索，就引出了二级索引（非聚簇索引/辅助索引），它也是利用了 B+ 树的数据结构，但是二级索引的叶子节点存放的是主键值，不是实际数据。如果某个查询语句使用了二级索引，但是查询的数据不是主键值，这时在二级索引找到主键值后，需要去聚簇索引中获得数据行，这个过程就叫作「回表」，也就是说要查两个 B+ 树才能查到数据。不过，当查询的数据是主键值时，因为只在二级索引就能查询到，不用再去聚簇索引查，这个过程就叫作「索引覆盖」，也就是只需要查一个 B+ 树就能找到数据。为什么 MySQL 采用 B+ 树作为索引？由于数据库的索引是保存到磁盘上的，因此当我们通过索引查找某行数据的时候，就需要先从磁盘读取索引到内存，再通过索引从磁盘中找到某行数据，然后读入到内存，也就是说查询过程中会发生多次磁盘 I/O，而磁盘 I/O 次数越多，所消耗的时间也就越大。所以，我们希望索引的数据结构能在尽可能少的磁盘的 I/O 操作中完成查询工作，因为磁盘 I/O 操作越少，所消耗的时间也就越小。另外，MySQL 是支持范围查找的，所以索引的数据结构不仅要能高效地查询某一个记录，而且也要能高效地执行范围查找。然后就说 B+ 树的特点： B+树是一个N叉树，只有叶子节点（最底层的节点）才存放了数据，非叶子节点仅用来存放目录项作为索引。 非叶子节点分为不同层次，通过分层来降低每一层的搜索量； 所有节点按照索引键大小排序，构成一个双向链表，便于范围查询；B+树与相关数据结构的比较： B+树vs B树B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据，所以 B+Tree 的单个节点的数据量更小，在相同的磁盘 I/O 次数下，就能查询更多的节点。另外，B+Tree 叶子节点采用的是双链表连接，适合 MySQL 中常见的基于范围的顺序查找，而 B 树无法做到这一点。 B+树vs二叉树对于有 N 个叶子节点的 B+Tree，其搜索复杂度为O(logdN)，其中 d 表示节点允许的最大子节点个数为 d 个。在实际的应用当中， d 值是大于100的，这样就保证了，即使数据达到千万级别时，B+Tree 的高度依然维持在 3~4 层左右，也就是说一次数据查询操作只需要做 3~4 次的磁盘 I/O 操作就能查询到目标数据。而二叉树的每个父节点的儿子节点个数只能是 2 个，意味着其搜索复杂度为 O(logN)，这已经比 B+Tree 高出不少，因此二叉树检索到目标数据所经历的磁盘 I/O 次数要更多。 B+树vsHashHash 在做等值查询的时候效率很快，搜索复杂度为 O(1)。但是 Hash 表不适合做范围查询，它更适合做等值查询，这也是 B+Tree 索引要比 Hash 表索引有着更广泛的适用场景的原因。count(*) 和 count(1) 有什么区别？哪个性能最好？哪种count性能最好直接上结论，按照性能排序：count(*)=count(1)&amp;gt;count(主键字段)&amp;gt;count(字段)count()是什么？count() 是一个聚合函数，作用是统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个。count(主键字段)的执行过程是怎样的？在通过 count 函数统计有多少个记录时，MySQL 的 server 层会维护一个名叫 count 的变量。server 层会循环向 InnoDB 读取一条记录，如果 count 函数指定的参数不为 NULL，那么就会将变量 count 加 1，直到符合查询的全部记录被读完，就退出循环。最后将 count 变量的值发送给客户端。如果表里只有主键索引，没有二级索引时，那么，InnoDB 循环遍历聚簇索引，将读取到的记录返回给 server 层，然后读取记录中的 id 值，就会 id 值判断是否为 NULL，如果不为 NULL，就将 count 变量加 1。但是，如果表里有二级索引时，InnoDB 循环遍历的对象就不是聚簇索引，而是二级索引。这是因为相同数量的二级索引记录可以比聚簇索引记录占用更少的存储空间，所以二级索引树比聚簇索引树小，这样遍历二级索引的 I/O 成本比遍历聚簇索引的 I/O 成本小，因此「优化器」优先选择的是二级索引。count(1)的执行过程是怎样的？如果表里只有主键索引，没有二级索引时。那么，InnoDB 循环遍历聚簇索引（主键索引），将读取到的记录返回给 server 层，但是不会读取记录中的任何字段的值，因为 count 函数的参数是 1，不是字段，所以不需要读取记录中的字段值。参数 1 很明显并不是 NULL，因此 server 层每从 InnoDB 读取到一条记录，就将 count 变量加 1。可以看到，count(1) 相比 count(主键字段) 少一个步骤，就是不需要读取记录中的字段值，所以通常会说 count(1) 执行效率会比 count(主键字段) 高一点。但是，如果表里有二级索引时，InnoDB 循环遍历的对象就二级索引了count(*)的执行过程是怎样的？count(*) 其实等于 count(0)，也就是说，当你使用 count(*) 时，MySQL 会将 * 参数转化为参数 0 来处理。所以，count(*) 执行过程跟 count(1) 执行过程基本一样的，性能没有什么差异。只有当没有二级索引的时候，才会采用主键索引来进行统计。count(字段)的执行过程是怎样的？count(字段) 的执行效率相比前面的 count(1)、 count(*)、 count(主键字段) 执行效率是最差的。因为是采用全表扫描的方式来计数，所以它的执行效率是比较差的。总结： count(1)、 count(*)、 count(主键字段)在执行的时候，如果表里存在二级索引，优化器就会选择二级索引进行扫描。所以，执行上述语句时，尽量在数据表上建立二级索引，这样优化器会自动采用 key_len 最小的二级索引进行扫描，相比于扫描主键索引效率会高一些。 再来，就是不要使用 count(字段) 来统计记录个数，因为它的效率是最差的，会采用全表扫描的方式来统计。如果你非要统计表中该字段不为 NULL 的记录个数，建议给这个字段建立一个二级索引。 为什么要通过遍历的方式来计数因为InnoDB 存储引擎支持事务，同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”是不确定的。也就是说，对于不同会话，同时查一张表的记录总个数，显示的结果是可能不一样的。所以，在使用 InnoDB 存储引擎时，需要扫描表来统计具体的记录。如何优化count(*)如果对一张大表经常用 count(*) 来做统计，其实是很不好的，因为每次统计都要花费较多的时间。我们可以通过一些方法来进行优化： 第一种方法：近似值。如果业务对于统计个数不需要很精确，比如搜索引擎在搜索关键词的时候，给出的搜索结果条数就是一个大概值。这时，我们可以使用explain命令来对表进行估算，执行explain命令的效率很高，因为它并不会真正的去查询，而是显示记录的估算值。 第二种方法：额外表保存计数值。如果是想精确的获取表的记录总数，我们可以将这个计数值保存到单独的一张计数表中，当我们在数据表插入一条记录的同时，将计数表中的计数字段 + 1。也就是说，在新增和删除操作时，我们需要额外维护这个计数表。事务事务隔离级别是怎么实现的？事事务有哪些特性？事务是由 MySQL 的引擎来实现的，不过并不是所有的引擎都能支持事务，比如 MySQL 原生的 MyISAM 引擎就不支持事务，而 InnoDB 引擎是支持事务的，也正是这样，所以大多数 MySQL 的引擎都是用 InnoDB。事务的四个特性ACID： 原子性（Atomicity）：一个事务中的所有操作，要么全部完成，要么全部失败，不会结束在中间某个环节，若事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样。 一致性（Consistency）：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。 隔离性（Isolation）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时导致数据不一致的问题。这是因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。 持久性（Durability）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？ 持久性是通过 redo log （重做日志）来保证的； 原子性是通过 undo log（回滚日志） 来保证的； 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的； 一致性则是通过持久性+原子性+隔离性来保证；并发事务会引发什么问题？为什么事务要有隔离性？因为不隔离的话，并发事务时会引发一系列问题。MySQL在同时处理多个事务的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题。脏读如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。这是因为在一个事务没有提交之前，它随时可能发生回滚操作，如果事务发生了回滚，那么另一个事务得到的数据就是过期的数据。不可重复读在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。这是因为在一个事务处理的过程中，另一个事务对数据进行了修改并且提交了事务，那么这个事务再次读取的数据就会和前面读取的数据不一致。幻读在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。这是因为在一个事务读取记录数量的时候，另一个事务的操作对改变了记录数量，导致前后两次读到的记录数量不一样，就感觉发生了幻觉一样。三个现象的严重性如下：脏读&amp;gt;不可重复读&amp;gt;幻读事务的隔离级别有哪些？SQL 标准提出了四种隔离级别，隔离级别越高，性能效率就越低，分别如下： 读未提交（read uncommitted），指一个事务还没提交时，它做的变更就能被其他事务看到； 读提交（read committed），指一个事务提交之后，它做的变更才能被其他事务看到； 可重复读（repeatable read），指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别； 串行化（serializable ）；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；针对不同的隔离级别，并发事务时可能发生的现象也会不同： 在「读未提交」隔离级别下，可能发生脏读、不可重复读和幻读现象； 在「读提交」隔离级别下，可能发生不可重复读和幻读现象，但是不可能发生脏读现象； 在「可重复读」隔离级别下，可能发生幻读现象，但是不可能脏读和不可重复读现象； 在「串行化」隔离级别下，脏读、不可重复读和幻读现象都不可能会发生。不过，要解决幻读现象不建议将隔离级别升级到「串行化」，因为这样会导致数据库在并发事务时性能很差。InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它通过next-key lock 锁（行锁和间隙锁的组合）来锁住记录之间的“间隙”和记录本身，防止其他事务在这个记录之间插入新的记录，这样就避免了幻读现象。这四种隔离级别具体是如何实现的呢？ 对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了； 对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问； 对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 Read View 来实现的，它们的区别在于创建 Read View 的时机不同， Read View 可以理解成一个数据快照，就像相机拍照那样，将数据定格在某一个时刻。「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。Read View在MVCC里如何工作的？首先知道Read View是什么，Read View 有四个重要的字段： m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的事务 id 列表，注意是一个列表，“活跃事务”指的就是，启动了但还没提交的事务。 min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 id 最小的事务，也就是 m_ids 的最小值。 max_trx_id ：这个并不是 m_ids 的最大值，而是创建 Read View 时当前数据库中应该给下一个事务的 id 值，也就是全局事务中最大的事务 id 值 + 1； creator_trx_id ：指的是创建该 Read View 的事务的事务 id。对于使用 InnoDB 存储引擎的数据库表，它的聚簇索引记录中都包含下面两个隐藏列（undo log）： trx_id，当一个事务对某条聚簇索引记录进行改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列里； roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后这个隐藏列是个指针，指向每一个旧版本记录，于是就可以通过它找到修改前的记录。一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况： 如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。 如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。 如果记录的 trx_id 值在 Read View 的min_trx_id和max_trx_id之间，需要判断 trx_id 是否在 m_ids 列表中： 如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。 如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。 需要注意的是，对当前事务可见，并不意味着一定可以读取数据，还要看隔离级别。这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。具体的实现方式可以简略概括为：启动事务后，在执行第一个查询语句后，会创建一个 Read View，然后后续的查询语句利用这个 Read View，通过 Read View 就可以在 undo log 版本链找到事务开始时的数据，所以每次查询的数据都是一样的。可重复读是如何工作的？可重复读隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View。读提交是如何工作的？读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View。也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。幻读是怎么被解决的？需要注意的是，如果用普通查询语句（select），看不到幻读现象。因为在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。但是，MySQL 里除了普通查询是快照读，其他都是当前读，比如update、insert、delete，这些语句执行前都会查询最新版本的数据，然后再做进一步的操作。 这很好理解，假设你要 update 一个记录，另一个事务已经 delete 这条记录并且提交事务了，这样不是会产生冲突吗，所以 update 的时候肯定要知道最新的数据。因此，要讨论「可重复读」隔离级别的幻读现象，是要建立在「当前读」的情况下。所以，Innodb 引擎为了解决「可重复读」隔离级别使用「当前读」而造成的幻读问题，就引出了 next-key lock锁，就是记录锁和间隙锁的组合。 记录锁，锁的是记录本身； 间隙锁，锁的就是两个值之间的空隙，以防止其他事务在这个空隙间插入新的数据，从而避免幻读现象。需要注意的是，如果 update 语句的 where 条件没有用到索引列，那么就会全表扫描，在一行行扫描的过程中，不仅给行数据加上了行锁，还给行两边的空隙也加上了间隙锁，相当于锁住整个表，然后直到事务结束才会释放锁。所以，在线上千万不要执行没有带索引的 update 语句，不然会造成业务停滞。锁MySQL有那些锁？全局锁全局锁是怎么用的？要使用全局锁，则要执行这条命：flush tables with read lock执行后，整个数据库就处于只读状态了，这时其他线程执行以下操作，都会被阻塞： 对数据的增删改操作，比如 insert、delete、update等语句； 对表结构的更改操作，比如 alter table、drop table 等语句。如果要释放全局锁，则要执行这条命令：unlock tables当然，当会话断开了，全局锁会被自动释放。全局锁应用场景是什么？全局锁主要应用于做全库逻辑备份，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。加全局锁会带来什么问题呢？加上全局锁，意味着整个数据库都是只读状态。那么如果数据库里有很多数据，备份就会花费很多的时间，关键是备份期间，业务只能读数据，而不能更新数据，这样会造成业务停滞。备份数据库数据的时候，使用全局锁会影响业务，那有什么其他方式可以避免？有的，如果数据库的引擎支持的事务支持可重复读的隔离级别，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。因为在可重复读的隔离级别下，即使其他事务更新了表的数据，也不会影响备份数据库时的 Read View，这样备份期间备份的数据一直是在开启事务时的数据。这种方法只适用于支持「可重复读隔离级别的事务」的存储引擎。可以使用数据库备份工具 mysqldump。但是，对于 MyISAM 这种不支持事务的引擎，在备份数据库时就要使用全局锁的方法。表级锁MySQL 表级锁有哪些？具体怎么用的?MySQL 里面表级别的锁有这几种： 表锁； 元数据锁（MDL）; 意向锁； AUTO-INC 锁；表锁如果想对某张表加表锁，可以使用下面的命令：//表级别的共享锁，也就是读锁；lock tables t_student read;//表级别的独占锁，也就是写锁；lock tables t_stuent write;需要注意的是，表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作。加上锁之后无论哪个线程对锁进行读写操作，都会阻塞，直到锁被释放。要释放表锁，可以使用下面这条命令，会释放当前会话的所有表锁：unlock tables另外，当会话退出后，也会释放所有表锁。不过尽量避免在使用 InnoDB 引擎的表使用表锁，因为表锁的颗粒度太大，会影响并发性能，InnoDB 牛逼的地方在于实现了颗粒度更细的行级锁元数据锁我们不需要显式的使用 MDL，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL： 对一张表进行 CRUD 操作时，加的是 MDL 读锁； 对一张表做结构变更操作的时候，加的是 MDL 写锁；MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。MDL 不需要显示调用，那它是在什么时候释放的?MDL 是在事务提交后才会释放，这意味着事务执行期间，MDL 是一直持有的。那如果数据库有一个长事务（所谓的长事务，就是开启了事务，但是一直还没提交），在对表结构做变更操作的时候，可能会发生意想不到的事情，比如下面这个顺序的场景： 首先，线程 A 先启用了事务（但是一直不提交），然后执行一条 select 语句，此时就先对该表加上 MDL 读锁； 然后，线程 B 也执行了同样的 select 语句，此时并不会阻塞，因为「读读」并不冲突； 接着，线程 C 修改了表字段，此时由于线程 A 的事务并没有提交，也就是 MDL 读锁还在占用着，这时线程 C 就无法申请到 MDL 写锁，就会被阻塞，那么在线程 C 阻塞后，后续有对该表的 select 语句，就都会被阻塞，如果此时有大量该表的 select 语句的请求到来，就会有大量的线程被阻塞住，这时数据库的线程很快就会爆满了。为什么线程 C 因为申请不到 MDL 写锁，而导致后续的申请读锁的查询操作也会被阻塞？这是因为申请 MDL 锁的操作会形成一个队列，队列中写锁获取优先级高于读锁，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。所以为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑 kill 掉这个长事务，然后再做表结构的变更。意向锁 在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」； 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；也就是说，当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。而普通的 select 是不会加行级锁的，普通的 select 语句是利用 MVCC 实现一致性读，是无锁的，不过也可以通过下面的方式对记录加共享锁和独占锁：//先在表上加上意向共享锁，然后对读取的记录加共享锁select ... lock in share mode;//先表上加上意向独占锁，然后对读取的记录加独占锁select ... for update;意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（lock tables … read）和独占表锁（lock tables … write）发生冲突。意向锁的目的是为了快速判断表里是否有记录被加锁。如果没有「意向锁」，那么加「独占表锁」时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢。如果有了「意向锁」，由于在对记录加独占锁前，先会加上表级别的意向独占锁，那么在加「独占表锁」时，直接查该表是否有意向独占锁，如果有就意味着表里已经有记录被加了独占锁，这样就不用去遍历表里的记录。AUTO-INC锁作用：在为某个字段声明 AUTO_INCREMENT 属性时，之后可以在插入数据时不指定该字段的值，数据库会自动给该字段赋值递增的值，这主要是通过 AUTO-INC 锁实现的。原理：AUTO-INC 锁是特殊的表锁机制，它不是在一个事务提交后才释放，而是在执行完插入语句后就会立即释放。在插入数据时，会加一个表级别的 AUTO-INC 锁，然后为被 AUTO_INCREMENT 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。缺点及解决措施：但是， AUTO-INC 锁再对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞。因此，InnoDB 存储引擎提供了一种轻量级的锁来实现自增。一样也是在插入数据的时候，会为被 AUTO_INCREMENT 修饰的字段加上轻量级锁，然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁。InnoDB 存储引擎提供了个 innodb_autoinc_lock_mode 的系统变量，是用来控制选择用 AUTO-INC 锁，还是轻量级的锁。 当 innodb_autoinc_lock_mode = 0，就采用 AUTO-INC 锁； 当 innodb_autoinc_lock_mode = 2，就采用轻量级锁； 当 innodb_autoinc_lock_mode = 1，这个是默认值，两种锁混着用，如果能够确定插入记录的数量就采用轻量级锁，不确定时就采用 AUTO-INC 锁。当 innodb_autoinc_lock_mode = 2 是性能最高的方式，但是会带来一定的问题。因为并发插入的存在，在每次插入时，自增长的值可能不是连续的，这在有主从复制的场景中是不安全的行级锁行级锁的类型主要有三类： Record Lock，记录锁，也就是仅仅把一条记录锁上； Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身； Next-Key Lock：记录锁和间隙所的组合，锁定一个范围，并且锁定记录本身。MySQL是怎么加锁的？对记录加锁时，加锁的基本单位是 next-key lock，它是由记录锁和间隙锁组合而成的，记录锁是锁一条记录，间隙锁是锁定一个范围，但是不包含记录本身；间隙锁是前开后开区间，而组合了记录锁之后的next-key lock 是前开后闭区间。next-key lock 在一些场景下会退化成记录锁或间隙锁。唯一索引等值查询当我们用唯一索引进行等值查询的时候，查询的记录存不存在，加锁的规则也会不同： 当查询的记录是存在的，next-key lock 会退化成「记录锁」。 当查询的记录是不存在的，next-key lock 会退化成「间隙锁」。唯一索引范围查询首先需要明确：范围查询和等值查询的加锁规则是不同的。会话加锁变化过程如下： 最开始要找的第一行是 id = 8，因此 next-key lock(4,8]，但是由于 id 是唯一索引，且该记录是存在的，因此会退化成记录锁，也就是只会对 id = 8 这一行加锁； 由于是范围查找，就会继续往后找存在的记录，也就是会找到 id = 16 这一行停下来，然后加 next-key lock (8, 16]，但由于 id = 16 不满足 id &amp;lt; 9，所以会退化成间隙锁，加锁范围变为 (8, 16)。非唯一索引等值查询当我们用非唯一索引进行等值查询的时候，查询的记录存不存在，加锁的规则也会不同： 当查询的记录存在时，除了会加 next-key lock 外，还额外加间隙锁，也就是会加两把锁。 当查询的记录不存在时，只会加 next-key lock，然后会退化为间隙锁，也就是只会加一把锁。非唯一索引范围查询非唯一索引和主键索引的范围查询的加锁也有所不同，不同之处在于普通索引范围查询，next-key lock 不会退化为间隙锁和记录锁。需要注意的是，不同的版本加锁规则可能会有所不同。update没加索引会锁全表？为什么会出现这种现象？nnoDB 存储引擎的默认事务隔离级别是「可重复读」，但是在这个隔离级别下，在多个事务并发的时候，会出现幻读的问题，所谓的幻读是指在同一事务下，连续执行两次同样的查询语句，第二次的查询语句可能会返回之前不存在的行。因此 InnoDB 存储引擎自己实现了行锁，通过 next-key 锁（记录锁和间隙锁的组合）来锁住记录本身和记录之间的“间隙”，防止其他事务在这个记录之间插入新的记录，从而避免了幻读现象。当我们执行 update 语句时，实际上是会对记录加独占锁（X 锁）的，如果其他事务对持有独占锁的记录进行修改时是会被阻塞的。另外，这个锁并不是执行完 update 语句就会释放的，而是会等事务结束时才会释放。在 InnoDB 事务中，对记录加锁带基本单位是 next-key 锁，但是会因为一些条件会退化成间隙锁，或者记录锁。加锁的位置准确的说，锁是加在索引上的而非行上。比如，在 update 语句的 where 条件使用了唯一索引，那么 next-key 锁会退化成记录锁，也就是只会给一行记录加锁。但是，在 update 语句的 where 条件没有使用索引，就会全表扫描，于是就会对所有记录加上 next-key 锁（记录锁 + 间隙锁），相当于把整个表锁住了。因此，当在数据量非常大的数据库表执行 update 语句时，如果没有使用索引，就会给全表的加上 next-key 锁， 那么锁就会持续很长一段时间，直到事务结束，而这期间除了查询语句，其他语句都会被锁住不能执行，业务会因此停滞。那 update 语句的 where 带上索引就能避免全表记录加锁了吗？并不是。关键还得看这条语句在执行过程种，优化器最终选择的是索引扫描，还是全表扫描，如果走了全表扫描，就会对全表的记录加锁了。该如何避免这种事故的发生？我们可以将 MySQL 里的 sql_safe_updates 参数设置为 1，开启安全更新模式。当 sql_safe_updates 设置为 1 时，update 语句必须满足如下条件之一才能执行成功： 使用 where，并且 where 条件中必须有索引列； 使用 limit； 同时使用 where 和 limit，此时 where 条件中可以没有索引列；delete 语句必须满足以下条件能执行成功： 同时使用 where 和 limit，此时 where 条件中可以没有索引列；如果 where 条件带上了索引列，但是优化器最终扫描选择的是全表，而不是索引的话，我们可以使用 强制索引force index([index_name]) 可以告诉优化器使用哪个索引，以此避免有几率锁全表带来的隐患。MySQL死锁了，怎么办？死锁的发生简单的来说就是两个或以上事务相互等待对方释放锁而陷入等待状态。为什么会产生死锁？插入意向锁与间隙锁是冲突的，所以当其它事务持有该间隙的间隙锁时，需要等待其它事务释放间隙锁之后，才能获取到插入意向锁。所以当两个事务都持有相同的间隙锁之后，接下来的插入操作为了获取到插入意向锁，都在等在对方事务的间隙锁释放，于是就造成了循环等待，导致死锁。为什么间隙锁与间隙锁之间是兼容的？两个事务可以同时持有包含共同间隙的间隙锁。这里的共同间隙包括两种场景： 其一是两个间隙锁的间隙区间完全一样； 其二是一个间隙锁包含的间隙区间是另一个间隙锁包含间隙区间的子集。间隙锁本质上是用于阻止其他事务在该间隙内插入新记录，而自身事务是允许在该间隙内插入数据的。插入意向锁是什么？插入意向锁并不是意向锁，而是一种特殊的间隙锁，但不同于间隙锁的是，该锁只用于并发插入操作。如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。插入意向锁与间隙锁的另一个非常重要的差别是：尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的）。所以这也是两个事务形成死锁的原因，要想插入，只能等待另一个事务释放间隙锁。插入意向锁的生成时机：每插入一条新记录，都需要看一下待插入记录的下一条记录上是否已经被加了间隙锁，如果已加间隙锁，那 Insert 语句应该被阻塞，并生成一个插入意向锁insert语句时怎么加行级锁的？Insert 语句在正常执行时是不会生成锁结构的，它是靠聚簇索引记录自带的 trx_id 隐藏列来作为隐式锁来保护记录的。什么是隐式锁？当事务需要加锁的时，如果这个锁不可能发生冲突，InnoDB会跳过加锁环节，这种机制称为隐式锁。隐式锁是 InnoDB 实现的一种延迟加锁机制，其特点是只有在可能发生冲突时才加锁，从而减少了锁的数量，提高了系统整体性能。隐式锁就是在 Insert 过程中不加锁，在特殊情况下，才会将隐式锁转换为显式锁，这里我们列举两个场景。 如果记录之间加有间隙锁，为了避免幻读，此时是不能插入记录的； 如果 Insert 的记录和已有记录存在唯一键冲突，此时也不能插入记录；记录之间加有间隙锁每插入一条新记录，都需要看一下待插入记录的下一条记录上是否已经被加了间隙锁，如果已加间隙锁，那 Insert 语句应该被阻塞，并生成一个插入意向锁。遇到唯一键冲突如果在插入新记录时，插入了一个与「已有的记录的主键或者唯一二级索引列值相同」的记录」，此时插入就会失败，然后对于这条记录加上了 S 型的锁（共享型锁，也就是读锁，对应的是X型锁，排他锁，即写锁）。至于是行级锁的类型是记录锁，还是 next-key 锁，跟是主键冲突还是唯一二级索引冲突有关系。如果主键值重复： 当隔离级别为读已提交时，插入新记录的事务会给已存在的主键值重复的聚簇索引记录添加 S 型记录锁。 当隔离级别是可重复读（默认隔离级别），插入新记录的事务会给已存在的主键值重复的聚簇索引记录添加 S 型 next-key 锁。如果唯一二级索引列重复： 不论是哪个隔离级别，插入新记录的事务都会给已存在的二级索引列值重复的二级索引记录添加 S 型 next-key 锁。因为如果不添加间隙锁的话，会让唯一二级索引中出现多条唯一二级索引列值相同的记录，这就违背了唯一 的约束。如何避免死锁？死锁的四个必要条件：互斥、占有且等待、不可强占用、循环等待。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态： 设置事务等待锁的超时时间。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 innodb_lock_wait_timeout 是用来设置超时时间的，默认值时 50 秒。 开启主动死锁检测。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑，默认就开启。 上面这个两种策略是「当有死锁发生时」的避免方式，最好还是预防死锁。日志MySQL 日志：undo log、redo log、binlog 有什么用？执行一条 update 语句，期间发生了什么？查询语句的那一套流程，更新语句也是同样会走一遍： 客户端先通过连接器建立连接，连接器自会判断用户身份； 因为这是一条 update 语句，所以不需要经过查询缓存，但是表上有更新语句，是会把整个表的查询缓存情空的，所以说查询缓存很鸡肋，在 MySQL 8.0 就被移除这个功能了； 解析器会通过词法分析识别出关键字 update，表名等等，构建出语法树，接着还会做语法分析，判断输入的语句是否符合 MySQL 语法； 预处理器会判断表和字段是否存在； 优化器确定执行计划，因为 where 条件中的 id 是主键索引，所以决定要使用 id 这个索引； 执行器负责具体执行，找到这一行，然后更新。不过，更新语句的流程会涉及到 undo log（回滚日志）、redo log（重做日志） 、binlog （归档日志）： undo log：是 Innodb 存储引擎层生成的日志，实现了事务中的原子性，主要用于事务回滚和 MVCC。 redo log：是 Innodb 存储引擎层生成的日志，实现了事务中的持久性，主要用于掉电等故障恢复； binlog ：是 Server 层生成的日志，主要用于数据备份和主从复制；为什么需要undo log？执行一条语句是否自动提交事务，是由 autocommit 参数决定的，默认是开启。所以，执行一条 update 语句也是会使用事务的。那么，考虑一个问题。一个事务在执行过程中，在还没有提交事务之前，如果MySQL 发生了崩溃，要怎么回滚到事务之前的数据呢？如果我们每次在事务执行过程中，都记录下回滚时需要的信息到一个日志里，那么在事务执行中途发生了 MySQL 崩溃后，就不用担心无法回滚到事务之前的数据，我们可以通过这个日志回滚到事务之前的数据。实现这一机制就是 undo log（回滚日志），它保证了事务的 ACID中的原子性。undo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，在发生回滚时，就读取 undo log 里的数据，然后做原先相反操作。。每当 InnoDB 引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 undo log 里，比如： 在插入一条记录时，要把这条记录的主键值记下来，这样之后回滚时只需要把这个主键值对应的记录删掉就好了； 在删除一条记录时，要把这条记录中的内容都记下来，这样之后回滚时再把由这些内容组成的记录插入到表中就好了； 在更新一条记录时，要把被更新的列的旧值记下来，这样之后回滚时再把这些列更新为旧值就好了。一条记录的每一次更新操作产生的 undo log 格式都有一个 roll_pointer 指针和一个 trx_id 事务id： 通过 trx_id 可以知道该记录是被哪个事务修改的； 通过 roll_pointer 指针可以将这些 undo log 串成一个链表，这个链表就被称为版本链；另外，undo log 还有一个作用，通过 ReadView + undo log 实现 MVCC（多版本并发控制）。简单来说就是undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。为什么需要Buffer Pool?MySQL 的数据都是存在磁盘中的，那么我们要更新一条记录的时候，得先要从磁盘读取该记录，然后在内存中修改这条记录。每次读取和修改在磁盘上操作很费时。为此，Innodb 存储引擎设计了一个缓冲池（Buffer Pool），来提高数据库的读写性能。有了 Buffer Poo 后： 当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。 当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。Buffer Pool 缓存什么？InnoDB 会把存储的数据划分为若干个「页」，以页作为磁盘和内存交互的基本单位，一个页的默认大小为 16KB。因此，Buffer Pool 同样需要按「页」来划分。在 MySQL 启动的时候，InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的16KB的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。所以，MySQL 刚启动的时候，你会观察到使用的虚拟内存空间很大，而使用到的物理内存空间却很小，这是因为只有这些虚拟内存被访问后，操作系统才会触发缺页中断，申请物理内存，接着将虚拟地址和物理地址建立映射关系。Buffer Pool 除了「索引页」和「数据页」，还包括了 Undo 页，插入缓存、自适应哈希索引、锁信息等。Undo 页是记录什么？用来保存undo log查询一条记录，就只需要缓存一条记录吗？不是的，以页为单位。当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，将页加载到 Buffer Pool 后，再通过页里的「页目录」去定位到某条具体的记录。为什么需要redo log?Buffer Pool 是提高了读写效率没错，但是问题来了，Buffer Pool 是基于内存的，而内存总是不可靠，万一断电重启，还没来得及落盘的脏页数据就会丢失。为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log 里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 WAL （Write-Ahead Logging）技术，指的是 MySQL 的写操作并不是立刻更新到磁盘上，而是先记录在日志上，然后在合适的时间再更新到磁盘上。什么是 redo log？redo log 是物理日志，记录了某个数据页做了什么修改，每当执行一个事务就会产生这样的一条物理日志。在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。被修改的Undo 页面，需要记录对应 redo log 吗？需要的。开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。不过，在修改该 Undo 页面前需要先记录对应的 redo log，所以先记录redo log里面的undo页面修改 ，然后再真正的修改 Undo 页面。redo log 和 undo log 区别在哪？这两种日志是属于 InnoDB 存储引擎的日志，它们的区别在于： redo log 记录了此次事务「完成后」的数据状态，记录的是更新之「后」的值； undo log 记录了此次事务「开始前」的数据状态，记录的是更新之「前」的值；事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务。所以有了 redo log，再通过 WAL 技术，InnoDB 就可以保证即使数据库发生异常重启，之前已提交的记录都不会丢失，这个能力称为 crash-safe（崩溃恢复）。可以看出来， redo log 保证了事务四大特性中的持久性。redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举？写入 redo log 的方式使用了追加操作， 磁盘操作是顺序写；而写入磁盘数据需要先找到写入位置，然后才写到磁盘，磁盘操作是随机写。磁盘的「顺序写 」比「随机写」 高效的多，因此 redo log 写入磁盘的开销更小。至此， 针对为什么需要 redo log 这个问题我们有两个答案： 实现事务的持久性，让 MySQL 有 crash-safe 的能力，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失； 将写操作从「随机写」变成了「顺序写」，提升 MySQL 写入磁盘的性能。产生的 redo log 是直接写入磁盘的吗？不是的。产生的 redo log 不是直接写入磁盘的，因为这样会产生大量的 I/O 操作，而磁盘的运行速度远慢于内存。所以，redo log 也有自己的缓存—— redo log buffer，每当产生一条 redo log 时，会先写入到 redo log buffer，后续再持久化到磁盘。redo log buffer 默认大小 16 MB，可以通过 innodb_log_Buffer_size 参数动态的调整大小，增大它的大小可以让 MySQL 处理「大事务」是不必写入磁盘，进而提升写 IO 性能。redo log 什么时候刷盘？缓存在 redo log buffe 里的 redo log 还是在内存中，它什么时候刷新到磁盘？主要有下面几个时机： MySQL 正常关闭时； 当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘； InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。 每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（这个策略可由 innodb_flush_log_at_trx_commit 参数控制）。innodb_flush_log_at_trx_commit 参数控制的是什么？除了默认的事务提交刷盘外，InnoDB 还提供了另外两种策略，由参数 innodb_flush_log_at_trx_commit 参数控制，可取的值有：0、1、2，默认值为 1，这三个值分别代表的策略如下： 当设置该参数为 0 时，表示每次事务提交时 ，还是将 redo log 留在 redo log buffer 中 ，该模式下在事务提交时不会主动触发写入磁盘的操作。 当设置该参数为 1 时，表示每次事务提交时，都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘，这样可以保证 MySQL 异常重启之后数据不会丢失。 当设置该参数为 2 时，表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件那么参数为0和2的时候，什么时候才将redo log写入磁盘？InnoDB 的后台线程每隔 1 秒： 针对参数 0 ：会把缓存在 redo log buffer 中的 redo log ，通过调用 write() 写到操作系统的 Page Cache，然后调用 fsync() 持久化到磁盘。所以参数为 0 的策略，MySQL 进程的崩溃会导致上一秒钟所有事务数据的丢失; 针对参数 2 ：调用 fsync，将缓存在操作系统中 Page Cache 里的 redo log 持久化到磁盘。所以参数为 2 的策略，较取值为 0 情况下更安全，因为 MySQL 进程的崩溃并不会丢失数据，只有在操作系统崩溃或者系统断电的情况下，上一秒钟所有事务数据才可能丢失这三个参数的数据安全性和写入性能的比较如下： 数据安全性：参数 1 &amp;gt; 参数 2 &amp;gt; 参数 0 写入性能：参数 0 &amp;gt; 参数 2&amp;gt; 参数 1因此参数的选择需要在数据安全性和写入性能之间做权衡。redo log 文件写满了怎么办？默认情况下， InnoDB 存储引擎有 1 个重做日志文件组( redo log Group），「重做日志文件组」由有 2 个 redo log 文件组成，这两个 redo 日志的文件名叫 ：ib_logfile0 和 ib_logfile1 ，每个 redo log File 的大小是固定且一致的。重做日志文件组是以循环写的方式工作的，从头开始写，写到末尾就又回到开头，相当于一个环形。所以 InnoDB 存储引擎会先写 ib_logfile0 文件，当 ib_logfile0 文件被写满的时候，会切换至 ib_logfile1 文件，当 ib_logfile1 文件也被写满时，会切换回 ib_logfile0 文件。redo log 是为了防止Buffer Pool 中的脏页丢失而设计的，随着系统运行，如果Buffer Pool 的脏页刷新到了磁盘中，那redo log 对应的记录就没用了，这时候我们擦除这些旧记录，以腾出空间记录新的更新操作。redo log 是循环写的方式，相当于一个环形，InnoDB 用 write pos 表示 redo log 当前记录写到的位置，用 checkpoint 表示当前要擦除的位置： write pos 和 checkpoint 的移动都是顺时针方向； write pos ～ checkpoint 之间的部分（图中的红色部分），用来记录新的更新操作； check point ～ write pos 之间的部分（图中蓝色部分）：待落盘的脏数据页记录；如果 write pos 追上了 checkpoint，就意味着 redo log 文件满了，这时 MySQL 不能再执行新的更新操作，也就是说 MySQL 会被阻塞（因此所以针对并发量大的系统，适当设置 redo log 的文件大小非常重要），此时会停下来将 Buffer Pool 中的脏页刷新到磁盘中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动（图中顺时针），然后 MySQL 恢复正常运行，继续执行新的更新操作。为什么需要binlog?MySQL 在完成一条更新操作后，Server 层还会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件。binlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，比如 SELECT 和 SHOW 操作。为什么有了 binlog， 还要有 redo log？最开始 MySQL 里并没有 InnoDB 引擎，MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用 redo log 来实现 crash-safe 能力。redo log 和 binlog 有什么区别？这两个日志有四个区别。1、适用对象不同： binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用； redo log 是 Innodb 存储引擎实现的日志；2、文件格式不同： binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下： STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致； ROW：记录行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已； MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式； redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 某张表空间中的 某个 数据页 在多少 偏移量的地方做了什么 更新；3、写入方式不同： binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。 redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。4、用途不同： binlog 用于备份恢复、主从复制； redo log 用于掉电等故障恢复。如果不小心整个数据库的数据被删除了，能使用 redo log 文件恢复数据吗？不可以使用 redo log 文件恢复，只能使用 binlog 文件恢复。因为 redo log 文件是循环写，是会边写边擦除日志的，只记录未被刷入磁盘的数据的物理日志，已经刷入磁盘的数据都会从 redo log 文件里擦除。binlog 文件保存的是全量的日志，也就是保存了所有数据变更的情况，理论上只要记录在 binlog 上的数据，都可以恢复，所以如果不小心整个数据库的数据被删除了，得用 binlog 文件恢复数据。主从复制是怎么实现？MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上。MySQL 集群的主从复制过程梳理成 3 个阶段： 写入 Binlog：主库写 binlog 日志，提交事务，并更新本地存储数据。 同步 Binlog：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。 回放 Binlog：回放 binlog，并更新存储引擎中的数据。具体详细过程如下： MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。 从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。 从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。主从复制的一个优点就是可以读写分离：在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。从库是不是越多越好？不是的。因为从库数量增加，从库连接上来的 I/O 线程也比较多，主库也要创建同样多的 log dump 线程来处理复制的请求，对主库资源消耗比较高，同时还受限于主库的网络带宽。所以在实际使用中，一个主库一般跟 2～3 个从库（1 套数据库，1 主 2 从 1 备主），这就是一主多从的 MySQL 集群结构。MySQL 主从复制还有哪些模型？主要有三种： 同步复制：MySQL 主库提交事务的线程要等待所有从库的复制成功响应，才返回客户端结果。这种方式在实际项目中，基本上没法用，原因有两个：一是性能很差，因为要复制到所有节点才返回响应；二是可用性也很差，主库和所有从库任何一个数据库出问题，都会影响业务。 异步复制（默认模型）：MySQL 主库提交事务的线程并不会等待 binlog 同步到各从库，就返回客户端结果。这种模式一旦主库宕机，数据就会发生丢失。 半同步复制：MySQL 5.7 版本之后增加的一种复制方式，介于两者之间，事务线程不用等待所有的从库复制成功响应，只要一部分复制成功响应回来就行，比如一主二从的集群，只要数据成功复制到任意一个从库上，主库的事务线程就可以返回给客户端。这种半同步复制的方式，兼顾了异步复制和同步复制的优点，即使出现主库宕机，至少还有一个从库有最新的数据，不存在数据丢失的风险。binlog 什么时候刷盘？事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），事务提交的时候，再把 binlog cache 写到 binlog 文件中。MySQL 给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。什么时候 binlog cache 会写到 binlog 文件？在事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 文件中，并清空 binlog cache。虽然每个线程有自己 binlog cache，但是最终都写到同一个 binlog 文件：写入到 binlog 文件，并没有把数据持久化到磁盘，因为数据还缓存在文件系统的 page cache 里，write 的写入速度还是比较快的，因为不涉及磁盘 I/O。调用fsync才是将数据持久化到磁盘的操作，这里就会涉及磁盘 I/O，所以频繁的 fsync 会导致磁盘的 I/O 升高。MySQL提供一个 sync_binlog 参数来控制数据库的 binlog 刷到磁盘上的频率： sync_binlog = 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘；这是默认设置，但是风险较大，一旦主机发生异常重启，在binlog cache中的所有binlog日志都会被丢失。 sync_binlog = 1 的时候，表示每次提交事务都会 write，然后马上执行 fsync；最安全但是性能损耗最大的设置，即使发生异常重启，也最多丢失binlog cache中未完成的一个事务，对实际数据无影响，但是频繁的写入磁盘会影响性能。 sync_binlog =N(N&amp;gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。能够允许少量事务的binlog丢失的风险，同时也提高了写入的性能。为什么需要两阶段提交？事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态（一个刷入到磁盘之后，另一个还没来得及刷入磁盘就发生了宕机），这样就造成两份日志之间的逻辑不一致，引起主从数据不一致的问题。因为 redo log 影响主库的数据，binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致。解决方法就是两阶段提交：两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是分别是「准备（Prepare）阶段」和「提交（Commit）阶段」。两阶段提交的过程是怎样的？为了保证这两个日志的一致性，MySQL 使用了内部 XA 事务（XA是一个分布式事务协议）。客户端执行 commit 语句或者在自动提交的情况下，MySQL 内部开启一个 XA 事务，分两阶段来完成 XA 事务的提交： prepare 阶段：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘； commit 阶段：把 XID 写入到 binlog，然后将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件，所以 commit 状态也是会刷盘的）；异常重启会出现什么现象？在 MySQL 重启后会按顺序扫描 redo log 文件，碰到处于 prepare 状态的 redo log，就拿着 redo log 中的 XID 去 binlog 查看是否存在此 XID： 如果 binlog 中没有当前内部 XA 事务的 XID，说明 redolog 完成刷盘，但是 binlog 还没有刷盘，则回滚事务。对应时刻 A 崩溃恢复的情况。 如果 binlog 中有当前内部 XA 事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务。对应时刻 B 崩溃恢复的情况。对于处于 prepare 阶段的 redo log，既可以提交事务，也可以回滚事务，这取决于是否能在 binlog 中查找到与 redo log 相同的 XID。因此，两阶段提交是以 binlog 写成功为事务提交成功的标识，因为 binlog 写成功了，就意味着能在 binlog 中查找到与 redo log 相同的 XID。处于 prepare 阶段的 redo log 加上完整 binlog，重启就提交事务，MySQL 为什么要这么设计?binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。两阶段提交有什么问题？两阶段提交虽然保证了两个日志文件的数据一致性，但是性能很差，主要有两个方面的影响： 磁盘 I/O 次数高：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 binlog 刷盘。 锁竞争激烈：两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。为什么两阶段提交的磁盘 I/O 次数会很高？binlog 和 redo log 在内存中都对应的缓存空间，binlog 会缓存在 binlog cache，redo log 会缓存在 redo log buffer，它们持久化到磁盘的时机分别由下面这两个参数控制。一般我们为了避免日志丢失的风险，会将这两个参数设置为 1： 当 sync_binlog = 1 的时候，表示每次提交事务都会将 binlog cache 里的 binlog 直接持久到磁盘； 当 innodb_flush_log_at_trx_commit = 1 时，表示每次事务提交时，都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘；可以看到，如果 sync_binlog 和 当 innodb_flush_log_at_trx_commit 都设置为 1，那么在每个事务提交过程中， 都会至少调用 2 次刷盘操作，一次是 redo log 刷盘，一次是 binlog 落盘，所以这会成为性能瓶颈。为什么锁竞争激烈？两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性。在一个事务获取到锁时才能进入 prepare 阶段，一直到 commit 阶段结束才能释放锁，下个事务才可以继续进行 prepare 操作。通过加锁虽然完美地解决了顺序一致性的问题，但在并发量较大的时候，就会导致对锁的争用，性能不佳组提交MySQL 引入了 binlog 组提交（group commit）机制，当有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I/O 的次数。引入了组提交机制后，prepare 阶段不变，只针对 commit 阶段，将 commit 阶段拆分为三个过程： flush 阶段：多个事务按进入的顺序将 binlog 从 cache 写入文件（不刷盘）； sync 阶段：对 binlog 文件做 fsync 操作（多个事务的 binlog 合并一次刷盘）； commit 阶段：各个事务按顺序做 InnoDB commit 操作；上面的每个阶段都有一个队列，每个阶段有锁进行保护，对每个阶段引入了队列后，锁就只针对每个队列进行保护，不再锁住提交事务的整个过程，可以看的出来，锁粒度减小了，这样就使得多个阶段可以并发执行，从而提升效率。有 binlog 组提交，那有 redo log 组提交吗？在 MySQL 5.7 版本中有redo log组提交，在 prepare 阶段不再让事务各自执行 redo log 刷盘操作，而是推迟到组提交的 flush 阶段，也就是说 prepare 阶段融合在了 flush 阶段。这个优化是将 redo log 的刷盘延迟到了 flush 阶段之中，sync 阶段之前。通过延迟写 redo log 的方式，为 redo log 做了一次组写入，这样 binlog 和 redo log 都进行了优化。组提交机制每个阶段的执行过程（双1配置）：1、flush 阶段第一个事务会成为 flush 阶段的 Leader，此时后面到来的事务都是 Follower，接着，获取队列中的事务组，由事务组的 Leader 对 rodo log 做一次 write + fsync，即一次将同组事务的 redolog 刷盘，完成了 prepare 阶段后，将这一组事务执行过程中产生的 binlog 写入 binlog 文件（调用 write，不会调用 fsync，所以不会刷盘，binlog 缓存在操作系统的文件系统中）。从上面这个过程，可以知道 flush 阶段队列的作用是用于支撑 redo log 的组提交。如果这一步完成后数据库崩溃，由于 binlog 中没有该组事务的记录，所以 MySQL 重启后会回滚该组事务。2、sync 阶段一组事务的 binlog 写入到 binlog 文件后，并不会马上执行刷盘的操作，而是会等待一段时间，这个等待的时长由 Binlog_group_commit_sync_delay 参数控制，目的是为了组合更多事务的 binlog，然后再一起刷盘。不过，在等待的过程中，如果事务的数量提前达到了 Binlog_group_commit_sync_no_delay_count 参数设置的值，就不用继续等待了，就马上将 binlog 刷盘。从上面的过程，可以知道 sync 阶段队列的作用是用于支持 binlog 的组提交。如果想提升 binlog 组提交的效果，可以通过设置下面这两个参数来实现： binlog_group_commit_sync_delay= N，表示在等待 N 微妙后，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘，也就是将「 binlog 文件」持久化到磁盘。 binlog_group_commit_sync_no_delay_count = N，表示如果队列中的事务数达到 N 个，就忽视binlog_group_commit_sync_delay 的设置，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘。如果在这一步完成后数据库崩溃，由于 binlog 中已经有了事务记录，MySQL会在重启后通过 redo log 刷盘的数据继续进行事务的提交。3、commit 阶段最后进入 commit 阶段，调用引擎的提交事务接口，将 redo log 状态设置为 commit。commit 阶段队列的作用是承接 sync 阶段的事务，完成最后的引擎提交，使得 sync 可以尽早的处理下一组事务，最大化组提交的效率。MySQL磁盘I/O很高，有什么优化的方法？主要优化方法是调整binlog 和redo log控制磁盘刷入的参数，通过参数降低磁盘I/O的频率，从而提高性能。数据安全和性能不可兼得，所以需要根据业务场景来选择参数的设置。 设置组提交的两个参数： binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，延迟 binlog 刷盘的时机，从而减少 binlog 的刷盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间。 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000），表示每次提交事务都 write，但累积 N 个事务后才 fsync，相当于延迟了 binlog 刷盘的时机。但是这样做的风险是，主机掉电时会丢 N 个事务的 binlog 日志。 将 innodb_flush_log_at_trx_commit 设置为 2。表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘，因为操作系统的文件系统中有个 Page Cache，专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存，然后交由操作系统控制持久化到磁盘的时机。但是这样做的风险是，主机掉电的时候会丢数据。总结再回过头来看执行一条 update 语句，期间发生了什么？主要是记录更新过程中的详细细节。体更新一条记录 UPDATE t_user SET name = &#39;xiaolin&#39; WHERE id = 1; 的流程如下: 执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录： 如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新； 如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。 执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样： 如果一样的话就不进行后续更新流程； 如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作； 开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在修改该 Undo 页面前需要先记录对应的 redo log，所以先记录修改 Undo 页面的 redo log ，然后再真正的修改 Undo 页面。 InnoDB 层开始更新记录，根据 WAL 技术，先记录修改数据页面的 redo log ，然后再真正的修改数据页面。修改数据页面的过程是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。 至此，一条记录更新完了。 在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。 事务提交（为了方便说明，这里不说组提交的过程，只说两阶段提交）： prepare 阶段：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘； commit 阶段：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）； 至此，一条更新语句执行完成。内存为什么要有Buffer Pool?MySQL 的数据都是存在磁盘中的，那么我们要更新一条记录的时候，得先要从磁盘读取该记录，然后在内存中修改这条记录。每次读取和修改在磁盘上操作很费时。为此，Innodb 存储引擎设计了一个缓冲池（Buffer Pool），来提高数据库的读写性能。有了 Buffer Poo 后： 当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。 当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。Buffer Pool 有多大？Buffer Pool 是在 MySQL 启动的时候，向操作系统申请的一片连续的内存空间，默认配置下 Buffer Pool 只有 128MB 。可以通过调整 innodb_buffer_pool_size 参数来设置 Buffer Pool 的大小，一般建议设置成可用物理内存的 60%~80%Buffer Pool 缓存什么？InnoDB 会把存储的数据划分为若干个「页」，以页作为磁盘和内存交互的基本单位，一个页的默认大小为 16KB。因此，Buffer Pool 同样需要按「页」来划分。在 MySQL 启动的时候，InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的16KB的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。所以，MySQL 刚启动的时候，你会观察到使用的虚拟内存空间很大，而使用到的物理内存空间却很小，这是因为只有这些虚拟内存被访问后，操作系统才会触发缺页中断，申请物理内存，接着将虚拟地址和物理地址建立映射关系。Buffer Pool 除了「索引页」和「数据页」，还包括了 Undo 页，插入缓存、自适应哈希索引、锁信息等。为了更好的管理这些在 Buffer Pool 中的缓存页，InnoDB 为每一个缓存页都创建了一个控制块。控制块也是占有内存空间的，它是放在 Buffer Pool 的最前面，接着才是缓存页控制块与缓存页之间为什么会有碎片空间？每一个控制块都对应一个缓存页，那在分配足够多的控制块和缓存页后，可能剩余的那点儿空间不够一对控制块和缓存页的大小，这个用不到的那点儿内存空间就被称为碎片了。查询一条记录，就只需要缓存一条记录吗？不是的。当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，因为，通过索引只能定位到磁盘中的页，而不能定位到页中的一条记录。将页加载到 Buffer Pool 后，再通过页里的页目录去定位到某条具体的记录。如何管理Buffer Poll?如何管理空闲页？Buffer Pool 是一片连续的内存空间，当 MySQL 运行一段时间后，这片连续的内存空间中的缓存页既有空闲的，也有被使用的。为了能够快速找到空闲的缓存页，可以使用链表结构，将空闲缓存页的「控制块」作为链表的节点，这个链表称为 Free 链表（空闲链表）。Free 链表节点是一个一个的控制块，而每个控制块包含着对应缓存页的地址，所以相当于 Free 链表节点都对应一个空闲的缓存页。有了 Free 链表后，每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 Free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的控制块从 Free 链表中移除。如何管理脏页？设计 Buffer Pool 除了能提高读性能，还能提高写性能，也就是更新数据的时候，不需要每次都要写入磁盘，而是将 Buffer Pool 对应的缓存页标记为脏页，然后再由后台线程将脏页写入到磁盘。那为了能快速知道哪些缓存页是脏的，于是就设计出 Flush 链表，它跟 Free 链表类似的，链表的节点也是控制块，区别在于 Flush 链表的元素都是脏页。有了 Flush 链表后，后台线程就可以遍历 Flush 链表，将脏页写入到磁盘。如何提高缓存命中率？Buffer Pool 的大小是有限的，我们希望频繁使用的数据可以一直留在 Buffer Pool 中，而很少访问的数据可以在某些时机淘汰掉。从而既能保证缓存命中率，也可以保证Buffer Pool不会因为满了而导致无法再缓存新的数据。简单的LRU算法可以解决这个问题。链表头部的节点是最近使用的，而链表末尾的节点是最久没被使用的。实现思路为： 当访问的页在 Buffer Pool 里，就直接把该页对应的 LRU 链表节点移动到链表的头部。 当访问的页不在 Buffer Pool 里，除了要把页放入到 LRU 链表的头部，还要淘汰 LRU 链表末尾的节点。简单的 LRU 算法并没有被 MySQL 使用，因为简单的 LRU 算法无法避免下面这两个问题： 预读失效； Buffer Pool 污染；什么是预读失效？由于程序的局部性原理，MySQL 有预读机制。MySQL 在加载数据页时，会提前把它相邻的数据页一并加载进来，目的是为了减少磁盘 IO。但是可能这些被提前加载进来的数据页，并没有被访问，相当于这个预读是白做了，这个就是预读失效。如果使用简单的 LRU 算法，就会把预读页放到 LRU 链表头部，而当 Buffer Pool空间不够的时候，还需要把末尾的页淘汰掉。如果这些预读页如果一直不会被访问到，就会出现一个很奇怪的问题，不会被访问的预读页却占用了 LRU 链表前排的位置，而末尾淘汰的页，可能是频繁访问的页，这样就大大降低了缓存命中率。怎么解决预读失效而导致缓存命中率降低的问题？要避免预读失效带来影响，最好就是让预读的页停留在 Buffer Pool 里的时间要尽可能的短，让真正被访问的页移动到 LRU 链表的头部，从而保证真正被读取的页数据留在 Buffer Pool 里的时间尽可能长。MySQL 改进了 LRU 算法，将 LRU 划分了 2 个区域：old 区域 和 young 区域。young 区域在 LRU 链表的前半部分，old 区域则是在后半部分，old 区域占整个 LRU 链表长度的比例可以通过 innodb_old_blocks_pc 参数来设置。划分这两个区域后，预读的页只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部。如果预读的页一直没有被访问，就会从 old 区域移除，这样就不会影响 young 区域中的页数据。虽然通过划分 old 区域 和 young 区域避免了预读失效带来的影响，但是还有个问题无法解决，那就是 Buffer Pool 污染的问题。什么是 Buffer Pool 污染？当某一个 SQL 语句扫描了大量的数据时，在 Buffer Pool 空间比较有限的情况下，可能会将 Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 IO，MySQL 性能就会急剧下降，这个过程被称为 Buffer Pool 污染。怎么解决出现 Buffer Pool 污染而导致缓存命中率下降的问题？LRU 链表中 young 区域就是热点数据，只要我们提高进入到 young 区域的门槛，就能有效地保证 young 区域里的热点数据不会被替换掉。MySQL 是这样做的，进入到 young 区域条件增加了一个停留在 old 区域的时间判断。具体为： 如果后续的访问时间与第一次访问的时间在某个时间间隔内，那么该缓存页就不会从 old 区域移动到 young 区域的头部； 如果后续的访问时间与第一次访问的时间不在某个时间间隔内，那么该缓存页移动到 young 区域的头部；这个间隔时间是由 innodb_old_blocks_time 控制的，默认是 1000 ms。也就是说，只有同时满足「被访问」与「在 old 区域停留时间超过 1 秒」两个条件，才会被插入到 young 区域头部，这样就解决了 Buffer Pool 污染的问题 。另外，MySQL 针对 young 区域其实做了一个优化，为了防止 young 区域节点频繁移动到头部。young 区域前面 1/4 被访问不会移动到链表头部，只有后面的 3/4被访问了才会。脏页什么时候会被刷入磁盘？下面几种情况会触发脏页的刷新： 当 redo log 日志满了的情况下，会主动触发脏页刷新到磁盘； Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘； MySQL 认为空闲时，后台线程回定期将适量的脏页刷入到磁盘； MySQL 正常关闭之前，会把所有的脏页刷入到磁盘；数据库操作抖动：因为脏页在刷新到磁盘时可能会给数据库带来性能开销，导致偶尔会出现一些用时稍长的SQL语句。如果间断出现这种现象，可以通过调大Buffer Pool空间和redo log日志的大小来解决。总结：Innodb 通过三种链表来管理Buffer Pool里面的缓存页： Free List （空闲页链表），管理空闲页； Flush List （脏页链表），管理脏页； LRU List，管理脏页+干净页，将最近且经常查询的数据缓存在其中，而不常查询的数据就淘汰出去。；" }, { "title": "LeetCode200题记录", "url": "/posts/leetcode200/", "categories": "思考", "tags": "总结, LeetCode, 算法", "date": "2022-07-11 22:14:04 +0800", "snippet": "力扣200题记录：菜鸡如我，缓慢的刷着力扣，但现在代码随想录和剑指offer都过了一遍，前段时间过了200题，现在才拿来写总结，题目增长速度慢是因为在二刷代码随想录和剑指，后面也不打算刷多少新题，还是刷旧题。毕竟刷过的题都不会，刷新题也就没有什么意义了。LeetCode200总结：第二遍刷题，有个明显的进步就是第一遍看题解感觉有点困难，但是第二遍似乎感觉也就那样，但是自己写还是写不出来，实际就是自己代码能力太差。那就没办法，只能坚持刷下去，一直刷，不间断，不断总结，总会有慢慢懂的那一天。也不要给自己定什么宏伟的目标，比如刷600题、1000题诸如此类等等，那样做只会给自己压力和挫败感，现在最大的目标就是天天刷，坚持下去就行了。" }, { "title": "Linux常用命令", "url": "/posts/Linux-commands/", "categories": "笔记, Linux", "tags": "笔记, Linux", "date": "2022-07-05 16:49:57 +0800", "snippet": "说明：很难也没必要记住所有命令，常用的熟练，不常用的可以搜索使用文档或者在terminal使用一下两种方法： command –help man command cd用于切换当前目录，参数为要切换到的目录的路径（绝对路径或相对路径）。cd // 进入个人的主目录cd /Linux // 进入&quot;/Linux&quot;目录cd .. // 返回上一级目录cd ../.. // 返回上两级目录（）cd Linux // 切换到当前目录下的Linux文件touch后接文件名，如果文件不存在，则新建文件（常用来新建一个文件）。mkdir后接目录名，创建目录；rmdir删除指定的目录clear清屏pwd显示工作路径ls查看文件与目录的命令，list的意思：ls // 查看目录中的文件（非隐藏文件的文件名）ls -l // 显示文件与目录的详细资料（时间、权限、大小等）ls -a // 列出所有文件 包括隐藏文件cpcp [options] source destcp -r test/ newtest // 将当前目录test/的所有文件复制到newtestmv用于移动文件、文件夹（在不同工作目录中移动）或更名（如果文件或文件夹存在于当前工作目录），move的意思：mv oldNameFile newNameFile // 重命名文件rm用于删除文件或目录，remove的意思：findfind / -name filename.txt // 据name查找/目录下的filename.txtfind . -name &quot;*.xml&quot; // 递归查找所有的xml文件ps显示进程运行情况，process的意思：ps aux // 查看系统所有的进程数据ps ax // 查看不与terminal有关的所有进程ps -lA // 查看系统所有的进程数据killkill -9 2525 // 终止PID2525topLinux下常用的性能分析工作，能够实时显示系统中各个进程的资源占用情况，类似于windows的任务管理器susu -usename // 切换用户treetree a // 以树状图列出目录a的内容ping网络检测vi随意写文件命令，后接文件名，以编辑方式打开文件echo向屏幕输出带空格的字符串：echo hello worldcatcat 文件名：显示全部文件内容more 文件名：分页显示文件内容less 文件名：与more类似，更好地是可以往前翻页tail 文件名：仅查看尾部，还可以指定行数tail -n 文件名head 文件名：仅查看头部，还可以指定行数head -n 文件名grep在给定的文件中搜寻指定的字符串grep 1 test.txt // test.txt文件中搜索1grep -i &quot;&quot; // 忽略大小写grep -r &quot;&quot; // 在当前工作目录的文件中递归搜索指定的字符串ifconfig查看ip地址及接口信息exit结束当前的终端会话shutdown用于关闭计算机，shutdown -r用于重启计算机tar压缩文件、查看压缩文件、解压chmod改变文件的权限：r读、w写、x执行" }, { "title": "Linux GCC、GDB、Makefile基本使用", "url": "/posts/GCC-GDB-Makefile/", "categories": "笔记, Linux", "tags": "GCC, GDB, Makefile, 笔记, Linux", "date": "2022-07-05 16:47:21 +0800", "snippet": "GCC1、什么是GCCGCC（GNU Compiler Collection，GNU编译器套件）是由GNU开发的编程语言编译器。2、GCC工作流程常用命令： -v 查看gcc编译器的版本，显示gcc执行时的详细过程 -o 指定输出文件名，不能与源文件同名 -E 只预处理，不会编译、汇编、链接 -S 只编译，不会汇编，链接 -c 编译和汇编，不会链接 -g 产生符号调试工具（GNU的GDB）所必要的符号信息，想要对源代码进行调试，就必须加入这个选项1、预处理gcc -E -o gcc.i gcc.c预处理是将包含（include）的文件插入源文件中，将宏定义展开、根据文件编译命令选择要使用的代码，最后将代码输出到一个.i文件中等待进一步处理。2、编译gcc -S -o gcc.s gcc.i编译就是将代码翻译成汇编语言。3、汇编gcc -c -o gcc.o gcc.s汇编是将汇编代码翻译成符合一定格式的机器代码，生成OBJ文件。4、链接gcc -o gcc gcc.o链接是将汇编生成的OBJ文件、系统库的OBJ文件、库文件链接起来，最终生成可以在特定平台运行的可执行程序。上述过程可以一步生成：gcc -o gcc gcc.c如果不指定文件名的话，默认生成a.out。3、gcc和g++的区别1、对于.c和.cpp文件，gcc分别当做c和cpp文件编译；g++则统一当做cpp文件编译。2、使用g++编译文件时，g++会自动链接标准库STL，而gcc不会自动链接，为了能够使用STL，需要加参数-lstdc++，但这并不代表与g++等价。3、gcc在编译c文件时，可使用的预定义宏是比较少的，gcc在编译cpp文件时，需要添加一些额外的宏（比如_cplusplus），g++在编译c和cpp文件时，也会添加一些额外的宏。Makefile1、目标文件目标文件常常按照特定格式来组织，在linux下，它是ELF格式（Executable Linkable Format，可执行可链接格式）。通常目标文件有三种形式： 可执行目标文件。即可直接运行的二进制文件。 可重定位目标文件（.o object file）。包含了二进制的代码和数据，可以与其它可重定位目标文件合并，并创建一个可执行目标文件。 共享目标文件（.so shared object file）。它是一种在加载或者运行时进行链接的特殊可重定位目标文件。2、库文件库文件是计算机上的一类文件，可以简单的把库文件看成一种代码仓库，但它是一种特殊的程序，编写库的程序和编写一般的程序区别不大，只是库不能单独运行。库文件有两种，静态库（.a）和动态库（共享库.so），区别是：静态库在程序的链接结点被复制到了程序中；动态库在链接阶段没有被复制到程序汇总，而是程序在运行时有系统动态加载到内存中供程序调用。库的好处：代码保密；方便部署和分发等。3、静态库静态库是什么：之所以称为静态库，是因为在链接阶段，会将汇编生成的目标文件.o与引用到的库一起链接打包到可执行文件中，对应的链接方式称为静态链接。linux下命名规则：libxxx.a lib：前缀（固定）、xxx（库名字）、.a：后缀（固定）静态库的制作： 首先，将代码文件编译成.o 然后，通过ar（archive）工具将目标文件打包成.a静态库文件gcc -c -o StaticMath.o StaticMath.car -rcs libstaticmath.a StaticMath.or：将文件插入库中（如果同名已存在，则替换）、c：创建一个库（不管库是否存在，都将创建）、s：创建目标文件索引。以便于查找和检索。静态库的使用：Linux下使用静态库，只需要在编译的时候，指定静态库的搜索路径（-L选项）、指定静态库名（不需要lib前缀和.a后缀，-l选项）。gcc TestStaticLibrary -L../StaticLibrary -lstaticmath -L：表示要链接的库所在目录。 -l：指定链接时需要的库，编译器查找链接库时有隐含的命名规则，即在给出的名字前面加上lib，后面加上.a或.so来确定库的名字。4、动态库为什么需要动态库？静态库容易使用和理解，也达到了代码复用的目的，为什么需要动态库？主要是由于静态库的特点导致： 空间浪费是静态库的一个问题，每链接一个程序都要打包一份静态库到可执行文件中，因此静态库在内存中存在多分拷贝导致空间浪费。 另一个问题就是静态库对程序的更新、部署和发布也会带来麻烦。如果静态库更新了，那么所有使用它的应用程序都需要重新编译，重新发布给用户（对于用户来说，只是一个很小的改动，却导致整个程序重新下载，全量更新）。动态库在程序运行时才被载入。不同的应用程序如果调用相同的库，那么在内存里只需要一份该共享库的实例记了，避免了空间浪费问题。用户只需要更新动态库即可，增量更新，也解决了静态库对程序的更新、部署和发布带来的麻烦。linux下命名规则：libxxx.so动态库的制作：与创建静态库不同，动态库不需要打包工具，直接使用编译器即可创建。 首先，生成目标文件，此时要加编译器选项-fpic（pic，position independent code），创建与地址无关的编译程序，是为了能够在多个应用程序间共享。 然后， 生成动态库，此时要加编译器选项-sharedgcc -fpic -c -o DynamicMath.o DynamicMath.cgcc -shared -o libdynamicmath.so DynamicMath.o动态库的使用：gcc TestDynamicLibrary.c -L../DynamicLibrary -ldynamicmath5、静态库和动态库的区别主要区别是一个在链接时载入，一个在运行时载入，导致了下面的特点： 可执行文件大小不一样。静态库的可执行文件要比动态库的可执行文件大得多，静态库需要将用到的代码从二进制文件中拷贝一份，而动态库仅仅是复制了一些重定位和符号表信息。 空间消耗不一样。静态库可能存在多份拷贝而浪费空间，动态库只需要一份即可。 扩展性和兼容不一样。静态库更新之后需要重新编译，动态库只需要更新本身即可，因此更方便部署和发布。 依赖不一样。静态链接的可执行文件不需要依赖其它的内容即可运行，而动态链接的可执行文件必须依赖动态库的存在。因此发布程序时需要提供依赖的库。 加载速度不一样。由于静态库在链接时就和可执行文件在一起了，而动态库在加载或者运行时才链接，因此，对于同样的程序，静态连接要比动态链接加载更快。6、MakefileMakefile的介绍：Makefile是一个工程文件的编译规则，描述了整个工程的编译和链接等规则，可以使我们的项目工程的编译变得自动化，不需要每次都手动输入一堆源文件和参数。而make是一个解释Makefile文件中指令的命令工具。Makefile的规则：一个Makefile文件中可以有一个或者多个规则。目标 … ：依赖 …​ 命令（shell命令）​ … 目标：最终要生成的文件 依赖：生成目标所需要的文件和/目标 命令：通过执行命令对依赖操作生成目标（命令前必须Tab缩进）Makefile中的其它规则一般都是为第一条规则服务的。Makefile的工作原理： 首先需要检查规则中的依赖是否存在。如果不存在，则向下检查其它的规则，检查有没有一个规则是用来生成这个依赖的，如果找到，则执行规则中的命令。 检测更新，执行命令。在执行命令时会比较目标和依赖文件的时间，如果依赖的时间比目标的时间晚，则需要重新生成目标；如果依赖的时间比目标的时间早，则目标不需要更新，对应规则中的命令不需要被执行。Makefile中使用变量：避免重复修改多个文件名，可以声明一个变量，后续使用该变量即可。声明：objects = main.o xxx.o ...使用：$(objects)Makefile里有什么？ 显示规则。显示规则说明了如何生成一个或多个目标文件。要指出生成的文件、依赖关系、以及命令。 隐晦规则。make可以自动识别文件以及推导文件依赖关系后面的命令，因此我们可以简化Makefile。 变量的定义。在Makefile中要定义一系列的变量，变量一般都是字符串，类似于宏定义，当Makefile被执行时，变量会被扩展到相应的引用位置上。 文件指示。包括三部分，一个是在一个Makefile中引用另一个Makefile，就想include一样；另一个是根据某些情况指定Makefile中的有效部分，就想预编译#if一样；还有就是定义一个多行的命令。 注释。Makefile只有行注释，使用#字符。make使用：可以直接使用make命令，默认情况下make命令会在当前目录下寻找Makefile文件，找到了就解释这个文件。也可以指定Makefile：make -f Makefilemake的工作流程： 读入所有的Makefile 读入被include的其它Makefile 初始化文件中的变量 推导隐晦规则，并分析所有规则 为所有的目标文件创建依赖关系链 根据依赖关系，决定哪些目标要重新生成 执行生成命令GDB在程序编译时加上-g参数，保留调试信息。另外，-Wall在尽量不影响程序行为的情况下打开所有warning，也可以发现更多问题，避免一些不必要的BUG。常用调试命令：break(b)在源代码指定的某一行设置断点，其中xxx用于指定打断点位置break ... if cond设置条件断点，…用于指定生成断点的位置，cond是某个表达式，只有当cond成立时，才会发挥作用， 多用于循环体调试info break查看断点delete 断点编号删除断点run(r)执行被调试的程序，会自动在第一个端点处暂停执行continue(c)当程序在某一端点处执行后，用该指令可以继续执行，直至遇到新的端点或者程序结束next(n)令程序代码一行一行的执行step(s)如果有调用函数，进入调用的函数内部，否则和next功能一样until(u)单纯使用until，可以运行程序直到退出循环体，until n命令中，n为代码行号，该命令会使程序运行至第n行代码处停止print(p)打印指定变量的值，其中xxx指的是某个变量名list(l)显示源程序代码的内容，包括各行代码所在的行号finish(fi)结束当前正在执行的函数，当前函数的剩余语句将会正常运行，并在跳出函数后暂停程序的执行，return函数直接返回，不会继续执行下面的语句，也可以使用return expression命令指定函数的返回值jump(j)使程序从当前位置挑战到指定位置处继续执行后续的代码quit(q)终止调试" }, { "title": "网页资料202207", "url": "/posts/web-sources-202207/", "categories": "其它", "tags": "总结, 网页资料", "date": "2022-07-01 23:27:16 +0800", "snippet": "priority_queue基本用法" }, { "title": "WebServer项目启动", "url": "/posts/MyWebServer-start/", "categories": "项目, MyWebServer", "tags": "WebServer, 项目, Linux, MySQL, make", "date": "2022-06-08 21:58:16 +0800", "snippet": "项目启动1、配置MySQL数据库首先，需要在Linux上配置MySQL，可参考Ubuntu18.04安装MySQL。然后，进入MySQL，执行以下操作：# 建立yourdb库create database yourdb;# 创建user表USE yourdb;CREATE TABLE user( username char(50) NULL, password char(50) NULL)ENGINE=InnoDB;# 插入数据INSERT INTO user(username, password) VALUES(&#39;name&#39;,&#39;password&#39;);2、生成可执行文件make # make执行Makefile文件 编译代码生成可执行文件./bin/server # 生成的可执行文件默认目录" }, { "title": "WebServer项目介绍", "url": "/posts/MyWebServer-intro/", "categories": "项目, MyWebServer", "tags": "WebServer, 项目, Linux, MySQL, make", "date": "2022-06-08 19:18:55 +0800", "snippet": "项目介绍用C++实现的高性能WebServer，经过webbench压力测试可以实现上万的QPS。环境配置 Linux（ubuntu18） MySQL C++11目录结构.├── bin # 可执行文件├── build # Makefile├── code # 源代码│ ├── buffer│ ├── http│ ├── log│ ├── pool│ ├── server│ └── timer├── log # 日志文件├── resources # 静态资源│ ├── css│ ├── fonts│ ├── images│ ├── js│ └── video└── webbench-1.5# 压力测试项目功能 利用IO复用技术Epoll与线程池实现多线程的Reactor高并发模型； 利用正则与状态机解析HTTP请求报文，实现处理静态资源的请求； 利用标准库容器封装char，实现自动增长的缓冲区； 基于小根堆实现的定时器，关闭超时的非活动连接； 利用单例模式与阻塞队列实现异步的日志系统，记录服务器运行状态； 利用RAII机制实现了数据库连接池，减少数据库连接建立与关闭的开销，同时实现了用户注册登录功能。 " }, { "title": "MarthCup数学建模比赛总结", "url": "/posts/marthcup-conclusion/", "categories": "思考", "tags": "数学建模, MarthCup, 总结, 比赛", "date": "2022-06-07 23:33:06 +0800", "snippet": "这次比赛研究生组只能选择前两组赛题，感觉连个题都没有接触过，所以还是很难的，最终选择的A题，指纹检索算法相关的。过程很艰难： 刚开始题目都看不太懂，然后一个问题一个问题的解析，去查文献，查到了做指纹检索算法的相关文献，但是又找不到代码，所以只能自己复现。 最后的结果是复现了三种方法，然后挑了效果最好，看起来最牛逼的一种方法作为论文的主要内容，其它两种方法作为对比。 感觉成就感还是挺高的，因为以前都是找代码去改，这次完全是我们自己复现，所以期望也很高，感觉最少能拿个二等奖。结果出来了，是三等奖，有点失落，因为感觉自己做的挺好的，但是结果已经不可能改变了。所以想了一下哪里可能出了问题： 找的文献太老，导致努力的方向和题目正解方向相差太远？ 还有就是自己选的检索算法复杂度太高？ 还有个可能就是论文摘要没写好，然后整体美化没做好，但是感觉已经很用心了啊，写论文写到了晚上三点半才回寝室。 还有就是别人做的太好了，害。虽然三等奖，但是总比没有强，同时感谢两位同门大哥带我打比赛，他们都好强。" }, { "title": "网页资料202206", "url": "/posts/web-sources-202206/", "categories": "其它", "tags": "总结, 网页资料", "date": "2022-06-07 20:37:57 +0800", "snippet": "C 语言中 void* 详解及应用C++ explicit和implicit c++ 拷贝函数和赋值函数的区别C++中的reverse()函数" }, { "title": "cdn.jsdelivr.net被墙解决方案", "url": "/posts/MyBlog-cdn-fastly/", "categories": "项目, MyBlog", "tags": "bug, blog", "date": "2022-06-01 21:25:33 +0800", "snippet": "前段时间发现博客无法正常显示，主要变现为网页样式错乱，用了梯子可以正常使用，所以也就没有多管它。今天强迫症犯了，看着访问不正常心里着实膈应，势要解决这个问题。第一步：网页F12查看报错信息，发现是请求cdn.jsdelivr.net资源未响应。百度之后才发现是该网站被强了，这也正是为什么翻墙可以正常访问的原因。第二步：百度搜索解决方案，看到了一个详细的帖子。解决博客 jsDelivr 资源无法访问的问题 - 炸鸡人博客 (zhajiman.github.io)第三步：按照博客的解决方案将网站换成fastly.jsdelivr.net。 使用vscode搜索cdn.就可以全部检索出来了，然后一键修改即可，push修改上去。 这里收回之前抱怨vscode的话，厌恶的原因是自己不会用，果然无能是人生最大的不幸，哈哈哈。能百度解决的问题都是小问题，不要怕折腾，折腾的过程就是变强的过程，也是变禿的过程。哈哈，bug一直不解决真的容易心烦气躁，但是解决之后会有一种成就感，然后再回过头来看就发现，就这？果然就是那句话，会了不难，所以，方法总比困难多，积极的去解决就没有解决不了的问题。" }, { "title": "WebServer搭建Linux开发环境", "url": "/posts/MyWebServer-development/", "categories": "项目, MyWebServer", "tags": "WebServer, 项目, Linux编程, 环境", "date": "2022-05-18 21:58:16 +0800", "snippet": "Linux开发环境搭建在newcoder上下载课程资料，里面有用到的所有软件的安装包。第一步：安装VMware虚拟机，然后在虚拟机上安装Ubuntu18系统。第二步：安装xshell、xftp、vscode。 大坑：vscode，编译器配置一直失败！！！搞了一晚上，麻了，就是不知道问题出在哪里。吐槽一下，vscode虽然功能十分丰富，但使用十分不友好，配置环境能恶心死人，而且界面杂乱，强迫症看着真受不了。吐了吐了，刷题冷静下。 后续：用终端命令用虚拟机下载gcc和g++，然后更改一下编译器配置为g++暂时可以用了。需要注意的是，.c文件不能用CPP相关头文件，反之，.cpp兼容c。 累了累了，一个bug搞半天，其实在看到报错检测不到路径时，就应该想到自己链接的远程的虚拟机linux系统，应该在远程下载gcc和g++。本地配置应该也行，但是搞了好久没搞出来，就先这样用吧，后面除了问题再解决。第三步：远程连接远程虚拟机，用SSH方式，本地vscode开发，然后同步到远程Linux系统中。" }, { "title": "MyWebServer说明", "url": "/posts/MyWebServer-begin/", "categories": "项目, MyWebServer", "tags": "WebServer, 项目, Linux编程", "date": "2022-05-12 17:01:21 +0800", "snippet": "这是我的第一个C++项目相关说明。为什么选择“烂大街”的WebServe项目？ 虽说是烂大街，人手一个，但是毕竟很经典，覆盖的知识点很全面，能够很好的锻炼自己学习的知识。还有就是，添加一些自己的功能也能称为亮点，只要做好做深，自己弄明白，有收获。选择什么项目都问题不大。参考了什么资源？ 首先是牛客网的相关项目的课程：课程列表_牛客网 (nowcoder.com)。我真的很菜，又是一个C++小白，所以还是看课程轻松点。 还有就是《Linux高性能服务器编程》这本书。 也会参考一些github上别人做的WebServe服务器项目。写项目博客的目的? 主要是记录做项目的历程，包括项目整体框架、遇到的问题、解决方法还有项目的一些其它说明等等。" }, { "title": "Git基本使用", "url": "/posts/git-basicuse/", "categories": "笔记, Linux", "tags": "git, github, 笔记, Linux", "date": "2022-05-09 22:27:29 +0800", "snippet": "1、clone远程库这个直接参看上篇博文即可。需要注意的是，使用ssh连接而不是https，后面因为https连接踩了坑。2、使用SSH连接使用https连接也可以，但是反复遇到输入账号密码问题，而且密码需要使用token来登录。使用token可以正常登录，但是后面再次启动或者过一段时间再登录，提示账号信息输入错误，这样如此反复。当然，也可以通过保存token的方法来解决这个问题，但是查阅相关技术博客发小unix系统才支持，windows虽然现在也支持，但是git不会去检查账号凭证！在这里花了好多时间解决这个问题。最后还是通过SSH公钥私钥连接的方式解决了上述问题，需要参考上篇博文的SSH来设置。设置之后，就完美的解决了账号密码问题。3、与远程库建立连接参考上篇文章的连接问题即可，使用git remote -v查看建立的连接。4、初次push初次push要使用git push -u origin main，后续直接git push即可。后续就是愉快的写博文，然后常规的三连操作就行了。总结刚开始使用的github desktop软件进行操作，想着后续再学，而且基本操作已经够了。这里自己犯懒了，不想折腾使用git，虽然知道以后工作基本上都会用到，但还是想着能用就用吧，学git还要花费时间。这次通过几个小时的摸索，掌握了一些git基本命令，基本的推文可以搞定了，后续遇到其它难点的操作现学现搜。既然是搞技术的，就不要怕折腾，不要畏难，踩坑的过程就是成长的过程。" }, { "title": "Git使用踩坑", "url": "/posts/git-problems/", "categories": "笔记, Linux", "tags": "git, github, 笔记, Linux", "date": "2022-05-08 17:57:21 +0800", "snippet": "连接远程仓库连接命令（连接一次即可）：git remote add origin git@github.com:yourName/repositoryname.gitgit remote add origin https://github.com/yourName/repositoryname.git如果连接中显示失败，可以通过git remote -v 查看远程库信息。git remote rm origin删除关联的origin远程库，然后再重新使用上述命令进行连接。fatal: remote origin already exists. (远程来源已存在 解决办法)add、commit、push三连git的add、commit、push的详细介绍 OpenSSL错误Git更新报错OpenSSL SSL_read: Connection was reset, errno 10054每次都要输入密码解决每次git pull、git push都需要输入账号密码的问题Failed connect to github.com:443git错误: Failed connect to github.com:443token认证访问 使用https每次都得输入账号密码，改成使用ssh！git/github采用token进行认证访问SSH连接！git：SSH连接，无需登录账号密码" }, { "title": "网页资料202205", "url": "/posts/web-sources-202205/", "categories": "其它", "tags": "总结, 网页资料", "date": "2022-05-06 08:08:25 +0800", "snippet": "C++11 不允许使用auto的四个场景 在明知数据类型且输入不复杂时，尽量写出来类型，当输入比较复杂时，可以用auto，但注意限制。C/C++程序计时函数vector中如何查找元素的下标C++ 的not1与not2C++ bind2nd用法" }, { "title": "MySQL配置本地服务", "url": "/posts/mysql-begin/", "categories": "笔记, SQL", "tags": "数据库, MySQL, 笔记, SQL", "date": "2022-04-22 19:45:53 +0800", "snippet": "今天开始学习《MySQL》必知必会，跟着书中实例敲常用命令，需要装一下MySQL本地服务，主要参考了书还有网上的一些链接。MySQL的安装与配置 这篇写的很详细，需要注意的是用管理员权限打开cmd，不然可能会出现权限上的问题。MySQL必知必会样例表导入方法 需要导入一些书中已经写好的样例表，用来展示效果。" }, { "title": "C++Primer5 多重继承和虚继承", "url": "/posts/C++Primer18-3/", "categories": "笔记, C++", "tags": "笔记, C++Primer5, C++", "date": "2022-04-12 17:27:31 +0800", "snippet": "多重继承多重继承是指从多个直接基类中产生派生类的能力。派生类的派生列表可以包含多个基类，每个基类包含一个可选的访问说明符。class Bear : public ZooAnimal { };class Panda : public Bear, public Endangered { };多重继承的派生类从每个基类中继承状态多重继承中，派生类的对象包含有每个基类的子对象。派生类构造函数初始化所有基类构造一个派生类的对象将同时构造并初始化它的所有基类子对象，派生类的构造函数初始值列表将实参分别传递给每个直接基类，其中基类的构造顺序与派生列表中的出现顺序一致，而与派生类的构造函数初始值列表中的顺序无关。 ZooAnimal是最终直接基类，首先初始化 接下来初始化第一个直接基类Bear 然后初始化第二个直接基类Endangered 最后初始化Panda继承的构造函数与多重继承C++11新标准允许派生类从它的多个基类中继承构造函数，但是如果继承了相同的构造函数，程序将产生错误，因此派生类必须为该构造函数定义自己的版本。析构函数与多重继承和往常一样，派生类的析构函数只负责清楚派生类本身分配的资源，派生类的成员及基类都是自动销毁的，析构顺序与构造顺序相反。多重继承的派生类的拷贝和移动操作与只有一个基类的继承一样，如果派生类定义了自己拷贝控制成员，则必须在完成的对象上进行操作。只有当派生类使用的是合成的拷贝控制成员时，才会自动对基类部分执行这些操作，每个基类分别使用自己的对应成员隐式的完成拷贝控制。类型转换与多个基类在多重继承中，我们可以令某个可访问基类的指针或引用直接指向一个派生类对象。编译器不会在派生类向基类的几种转换中进行比较和选择，因为在它看来转换到任意一个基类都一样好。注意：因为认为一样好，所以要小心二义性错误。void print(const Bear&amp;amp;);void print(const Endangered&amp;amp;);Panda ying_yang(&quot;ying_yang&quot;);print(ying_yang); // 二义性错误 哪个基类？需要带前缀限定符避免二义性基于指针类型和引用类型的查找与只有一个基类的继承一样，对象、指针和引用的静态类型决定了我们能够使用哪些成员。多重继承下的类作用域对于一个派生类来说，从它的几个基类中分别继承名字相同的成员是完全合法的，但是在使用这个名字是必须明确指出它的版本，否则会产生二义性错误。 如果想避免二义性，最好的办法就是在派生类中定义一个新版本。虚继承为什么要有虚继承？因为在默认情况下，派生类含有继承链上每个类对应的子部分，如果某个类在派生过程中出现了多次，则派生类中将包含该类的多个子对象。虚继承的目的就是令某个类做出声明，承诺愿意共享它的基类，其中，共享的基类子对象称为虚基类。在这种机制下，不管虚基类在继承体系中出现了多少次，在派生类中都只包含唯一一个共享的虚基类子对象。虚继承有一个特性：必须在虚派生的真实需求出现前就已经完成虚派生的操作。 虚派生只影响从指定了的虚基类的派生类中进一步派生出的类，它不会影响派生类本身。（想象一下菱形继承关系）使用虚基类class Raccoon : public virtual ZooAnimal { };class Bear : virtual public ZooAnimal { };// Panda中只有一个ZooAnimal实例class Panda : public Bear, public Raccoon, public Endangered { }; 1、通过在派生列表中添加关键字virtual来指定虚基类，virtual说明符表明了一个愿望，即在后续的派生类当中共享虚基类的同一份实例。 与访问说明符的顺序随意。2、如果某个类指定了虚基类，则该类的派生仍按常规方式进行。支持向基类的常规类型转换无论基类是不是虚基类，派生类对象都能被可访问基类的指针或引用操作。虚基类成员的可见性因为每个共享的虚基类只有一个共享的子对象，所以该基类的成员可以被直接访问，并且不会产生二义性。但是如果成员被多于一个基类覆盖（多个多重继承），则一般情况下派生类必须为该成员自定义一个新的版本。构造函数与虚继承在虚派生中，虚基类是由最底层的派生类初始化的。但每个类都可能称为最底层的派生类，所以只要我们能创建虚基类的派生类对象，该派生类的构造函数就必须初始化它的虚基类。 如果以普通规则处理初始化任务，虚基类将会在多条继承路径上别重复初始化。// 如果Bear位于派生的最底层Bear::Bear(string name, bool oe) : ZooAnimal(name, oe, &quot;Bear&quot;) { } // 初始化虚基类// Panda最底层Panda::Panda(string name, booe oe) : ZooAnimal(name, oe, &quot;Panda&quot;), Bear(name, oe), Raccoon(name, oe), Endangered(Endangered::critical) { } //初始化虚基类虚继承的对象的构造方式含有虚基类的对象的构造顺序与一般的构造顺序稍有区别：首先使用提供给最底层派生类构造函数的初始值初始化该对象的虚基类子部分，接下来按照直接基类在派生列表中出现的顺序依次对其进行初始化。 首先使用Panda的构造函数初始值列表中提供的初始值构造虚基类ZooAnimal部分 接下来构造Bear部分 然后构造Raccoon部分 然后构造Endangered部分 最后构造Panda部分如果Panda没有显示初始化ZooAnimal基类，则其默认构造函数将被调用，如果没有默认构造函数，代码将发生错误。构造函数与析构函数的次序一个类可以有多个虚基类，此时，这些虚的子对象按照它们在派生列表中出现的顺序从左向右一次构造。class Character { };class BookCharacter : public Character { };class ToyAnimal { };class TeddyBear : public BookCharacter, public Bear, public virtual ToyAnimal { };编译器按照直接基类的声明顺序对其一次进行检查，以确定其中是否含有虚基类，如果有，则先构造虚基类，然后按照声明的顺序逐一构造其它非虚基类。ZooAnimal(); // Bear的虚基类ToyAnimal(); // 直接虚基类Character(); // 第一个间接非虚基类BookCharacter(); // 第一个直接非虚基类Bear(); // 第二个直接非虚基类TeddyBear(); // 最底层的派生类" }, { "title": "第七届蓝桥杯真题题解", "url": "/posts/lanqiao7/", "categories": "题解", "tags": "蓝桥杯, 题解, 算法", "date": "2022-04-09 16:47:33 +0800", "snippet": "方格填数 dfs。 全排列解法。寒假作业 小学生的寒假作业都不会做？ 全排列时间太长，13个数全排列，用dfs+剪枝。#include&amp;lt;iostream&amp;gt;#include&amp;lt;algorithm&amp;gt;#include&amp;lt;cmath&amp;gt;using namespace std;int a[] = { 1,2,3,4,5,6,7,8,9,10,11,12,13 };bool check(){ bool b1 = (a[0] + a[1] == a[2]); bool b2 = (a[3] - a[4] == a[5]); bool b3 = (a[6] * a[7] == a[8]); bool b4 = (fabs((a[9] * 1.0) / (a[10] * 1.0) - a[11] * 1.0) &amp;lt;= 0.00000000000001); if (b1 &amp;amp;&amp;amp; b2 &amp;amp;&amp;amp; b3 &amp;amp;&amp;amp; b4) return true; else return false;}int main(){ int res = 0; do { if (check()) { res++; } } while (next_permutation(a, a + 13)); cout &amp;lt;&amp;lt; res &amp;lt;&amp;lt; endl; return 0;}剪邮票 dfs+标记，mark一下。四平方和 直接暴力搜索，可以做一些处理减少复杂度。优化// 最直接的搜索 参考链接优化#include&amp;lt;iostream&amp;gt;#include&amp;lt;cmath&amp;gt;using namespace std;int n;int main() { cin &amp;gt;&amp;gt; n; int root = sqrt(n) + 1; for (int i = 0; i &amp;lt;= root; ++i) { for (int j = 0; j &amp;lt;= root; ++j) { for (int k = 0; k &amp;lt;= root; ++k) { for (int l = 0; l &amp;lt;= root; ++l) { if (pow(i, 2) + pow(j, 2) + pow(k, 2) + pow(l, 2) == n) { cout &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &quot; &quot; &amp;lt;&amp;lt; j &amp;lt;&amp;lt; &quot; &quot; &amp;lt;&amp;lt; k &amp;lt;&amp;lt; &quot; &quot; &amp;lt;&amp;lt; l &amp;lt;&amp;lt; endl; return 0; } } } } } return 0;}密码脱落 最长回文串，dp。#include&amp;lt;iostream&amp;gt;using namespace std;const int n = 1005;string s;int dp[n][n]; // dp[i][j]表示以i为起点 j为终点的字符串中的最大回文串int main() { cin &amp;gt;&amp;gt; s; int len = s.size(); for (int i = 0; i &amp;lt; len; ++i) { dp[i][i] = 1; // 单个字符就是长度为1的回文串 初始化为1 } for (int i = 2; i &amp;lt;= len; ++i) { // 枚举回文串的长度 从第二个到最后一个字符依次求最大回文串长度 for (int l = 0; l + i - 1 &amp;lt; len; ++l) { int r = i + l - 1; if (s[l] == s[r]) // 左边界==右边界 左边前移 右边后移 长度+2 dp[l][r] = dp[l + 1][r - 1] + 2; else // 不相等 最大长度为左边前移一位 和 右边后移一位的最大者 dp[l][r] = max(dp[l][r - 1], dp[l + 1][r]); } } cout &amp;lt;&amp;lt; len - dp[0][len - 1]; return 0;}最大比例" }, { "title": "第十三届蓝桥杯比赛总结", "url": "/posts/lanqiao-conclusion/", "categories": "思考", "tags": "蓝桥杯, 总结, 比赛", "date": "2022-04-09 14:59:27 +0800", "snippet": "从去年十二月份信心满满报名蓝桥杯，到现在四月初垂头丧气地考完。转眼间过去四个月了，时间过得真快，总感觉自己啥也没做就过去了。关于这次比赛，一是自己准备的时间太短，二是线上考试水分着实太大，已经对获奖未报希望。但还是要总结一下，总不至于稀里糊涂的考完试之后，然后让他稀里糊涂的过去!关于这次比赛的准备： 完整的准备时间应该是考试前两个周，只是刷了刷真题，第一个周还慢悠悠的，最后勉强把大部分省赛真题看了一遍，可已经是亡羊补牢，为时已晚。关于这次比赛的一些热点词： “蓝桥杯狗都不打”，这是在华为软件精英挑战赛中听到的一句话，扎心了老铁。不过仔细思考一下，还是有那么些道理的，对于那些算法大佬来说，已经不屑于参加这些比赛了。可自己毕竟是个小白，还是不要那么较真，能够从中得到点自己想要的东西就行了。 “圈钱杯”，有一说一，蓝桥杯的报名费着实贵，和同门参加数模比赛，三个人也最多才200的报名费！有点越想越亏，算了，就当扔水里听个响了。可是某同门说：响也听不到啊。确实，都获不了奖，哪来的响？哈哈哈，算了，权当买个教训了。 关于这次比赛的收获（反思）: 刷题的方式：考试的时候并不觉得题目有特别难，刷的真题还是有用的，但是自己写的程序漏洞百出，总是调试不出来，时间白白浪费。以前看题解是看着题解一行一行的敲代码，一边抄一边理解，这样虽然能够少用点时间，但是别人的代码是AC的，看不出来自己的弊端，所以以后看题解不能跟着抄了，可以看他们的思路，然后再自己写，哪里不会再回去看，这样刷题才有意义。慢慢来，比较快，欲速则不达，不要过度追求速度，要静下心来完完整整的刷完一道题！ 取舍：时间就那么多，无论做什么都会付出相应的代价，不要一味地跟风，别人干什么自己就干什么，要根据自己的目标，结合自己的实际情况，做自己最需要做的事。 做了就好好做，让耗费的时间收益最大化。 还有就是时间利用问题，一方面要抓住自己的琐碎的时间，还要尽量克服自己的惰性；另一方面就是要提高效率，学习的时候就不要想其他的，沉下心来，把无关的事都抛在脑后。 最后就是刷的真题，有些题目还是有难度的，不要完全放在那，等感觉自己算法水平有所进步了，再回来看看。最后的最后，三等奖，我真菜！害，继续努力吧，感觉自己做出来好几道题啊，不应该这样的。最后的最后的最后，后面真没有了。省奖可以退钱，哈哈哈，拿这钱买其它的不香嘛，这个还是令人欣慰。" }, { "title": "第六届蓝桥杯真题题解", "url": "/posts/lanqiao6/", "categories": "题解", "tags": "蓝桥杯, 题解, 算法", "date": "2022-04-08 22:09:04 +0800", "snippet": "奇妙的数字 字符串操作更简单一点。#include&amp;lt;iostream&amp;gt;#include&amp;lt;string&amp;gt;#include&amp;lt;algorithm&amp;gt;#include&amp;lt;cmath&amp;gt;using namespace std;char a[10], b[10];char c[] = &quot;0123456789&quot;;long long p, q; // p存储平方 q存储立方int main() { // 暴力搜索 不可能超出1000 for (int i = 10; i &amp;lt;= 100; ++i) { p = pow(i,2); // 平方 q = p * i; // 立方 sprintf_s(a, &quot;%d&quot;, p); // 写入到字符串里 sprintf_s(b, &quot;%d&quot;, q); strcat_s(a, b); // 拼接字符串 sort(a, a + 10); // 字符串排序 if (strcmp(a, c) == 0) { // 两个字符串比较 相等就输出 cout &amp;lt;&amp;lt; i &amp;lt;&amp;lt; endl; break; } } return 0;}牌型种数 dfs，简单的dfs。#include&amp;lt;iostream&amp;gt;#include&amp;lt;algorithm&amp;gt;#include&amp;lt;cmath&amp;gt;using namespace std;int sum = 0; // 种数void dfs(int pos, int cnt) { // pos表示当前当前搜索到的牌的类型 cnt表示以及取得牌的数量 if (cnt == 13) { // 已经取13张 ++sum; return; } if (pos == 13) { // 一种13种牌 越界 return; } int num = min(13 - cnt, 4); // 每种类型的牌最多四张 for (int i = 0; i &amp;lt;= num; ++i) { dfs(pos + 1, cnt + i); } return; // 搜索完 return}int main() { dfs(0, 0); cout &amp;lt;&amp;lt; sum; return 0;}手链样式 全排列。饮料换购 暴力搜索。垒骰子 dp，矩阵快速幂。灾后重建" }, { "title": "第八届蓝桥杯真题题解", "url": "/posts/lanqiao8/", "categories": "题解", "tags": "蓝桥杯, 题解, 算法", "date": "2022-04-07 23:01:37 +0800", "snippet": "迷宫 很简单的一个dfs！简单题用来学方法论，弄明白！#include&amp;lt;iostream&amp;gt;using namespace std;char arr[10][10] = { // 用一个字符数组存放 &#39;U&#39;,&#39;D&#39;,&#39;D&#39;,&#39;L&#39;,&#39;U&#39;,&#39;U&#39;,&#39;L&#39;,&#39;R&#39;,&#39;U&#39;,&#39;L&#39;, &#39;U&#39;,&#39;U&#39;,&#39;R&#39;,&#39;L&#39;,&#39;L&#39;,&#39;L&#39;,&#39;R&#39;,&#39;R&#39;,&#39;R&#39;,&#39;U&#39;, &#39;R&#39;,&#39;R&#39;,&#39;U&#39;,&#39;U&#39;,&#39;R&#39;,&#39;L&#39;,&#39;D&#39;,&#39;L&#39;,&#39;R&#39;,&#39;D&#39;, &#39;R&#39;,&#39;U&#39;,&#39;D&#39;,&#39;D&#39;,&#39;D&#39;,&#39;D&#39;,&#39;U&#39;,&#39;U&#39;,&#39;U&#39;,&#39;U&#39;, &#39;U&#39;,&#39;R&#39;,&#39;U&#39;,&#39;D&#39;,&#39;L&#39;,&#39;L&#39;,&#39;R&#39;,&#39;R&#39;,&#39;U&#39;,&#39;U&#39;, &#39;D&#39;,&#39;U&#39;,&#39;R&#39;,&#39;L&#39;,&#39;R&#39;,&#39;L&#39;,&#39;D&#39;,&#39;L&#39;,&#39;R&#39;,&#39;L&#39;, &#39;U&#39;,&#39;L&#39;,&#39;L&#39;,&#39;U&#39;,&#39;R&#39;,&#39;L&#39;,&#39;L&#39;,&#39;R&#39;,&#39;D&#39;,&#39;U&#39;, &#39;R&#39;,&#39;D&#39;,&#39;L&#39;,&#39;U&#39;,&#39;L&#39;,&#39;L&#39;,&#39;R&#39;,&#39;D&#39;,&#39;D&#39;,&#39;D&#39;, &#39;U&#39;,&#39;U&#39;,&#39;D&#39;,&#39;D&#39;,&#39;U&#39;,&#39;D&#39;,&#39;U&#39;,&#39;D&#39;,&#39;L&#39;,&#39;L&#39;, &#39;U&#39;,&#39;L&#39;,&#39;R&#39;,&#39;D&#39;,&#39;L&#39;,&#39;U&#39;,&#39;U&#39;,&#39;R&#39;,&#39;R&#39;,&#39;R&#39;};bool vis[10][10]; // 标记是否访问过int ans; // 存放结果 即走出去的人数void dfs(int i, int j) { if (i &amp;lt; 0 || i &amp;gt; 9 || j &amp;lt; 0 || j&amp;gt;9) { // 终止条件 越界表示出去了 所以ans+1 ++ans; return; } else { // 出不去的肯定是在某个地方循环 if (vis[i][j]) return; // 已经访问过的元素 再次遍历说明进入了循环 直接return vis[i][j] = 1; // 表示当前元素已经访问过 打上标记 if (arr[i][j] == &#39;L&#39;) dfs(i, j - 1); if (arr[i][j] == &#39;R&#39;) dfs(i, j + 1); if (arr[i][j] == &#39;U&#39;) dfs(i - 1, j); if (arr[i][j] == &#39;D&#39;) dfs(i + 1, j); }}int main() { for (int i = 0; i &amp;lt; 10; ++i) { for (int j = 0; j &amp;lt; 10; ++j) { memset(vis, 0, sizeof(vis)); dfs(i, j); // 依次遍历所有元素 } } cout &amp;lt;&amp;lt; ans; return 0;}跳蚱蜢 bfs，链接讲解的很清楚。魔方状态 上面的链接包含整个A组的题解。方格分割 上面讲的很清楚。// 另一种写法#include&amp;lt;iostream&amp;gt;using namespace std;int dir[4][2] = { // 表示四种状态 {-1, 0}, {1, 0}, {0, -1}, {0, 1}};int vis[7][7]; // 点：格子数+1int ans; // 方法数void dfs(int x, int y) { // 终止条件 0和6都是边 边不能裁剪 搜索到边界就返回 if (x == 0 || y == 0 || x == 6 || y == 6) { ans++; return; } vis[x][y] = 1; // 当前点 vis[6 - x][6 - y] = 1; // 对称点 // 开始遍历搜索其他点 for (int i = 0; i &amp;lt; 4; ++i) { // 这里从0-3 因为是从中心店（3,3）开始搜索的 int tx = x + dir[i][0]; // dir第一列为x int ty = y = dir[i][1]; // dir第二列为y if (tx &amp;lt; 0 || tx &amp;gt; 6 || ty &amp;lt; 0 || ty &amp;gt; 6) continue; if (vis[tx][ty] != 1) dfs(tx, ty); } // 四个方向都走完了 回溯 vis[x][y] = 0; // 当前点 vis[6 - x][6 - y] = 0; // 对称点}int main() { dfs(3, 3); cout &amp;lt;&amp;lt; ans / 4 &amp;lt;&amp;lt; endl; // 从中心搜索 对称除以4 return 0;}正则问题 dfs，上面讲的很清楚，确定当前dfs函数要做什么，不要管后续的，只用想好当前一层dfs函数的作用就行了，后续的有更深的dfs作用，这样就不会思路不清了。#include&amp;lt;iostream&amp;gt;#include&amp;lt;string&amp;gt;using namespace std;string str; // 输入的字符串int pos, len; // 每个字符的位置索引 字符串的长度// dfsint dfs() { int num = 0, ans = 0; // num是当前字符串的长度 ans是当前字符串的最大长度 while (pos &amp;lt; len) { if (str[pos] == &#39;(&#39;) { // (遍历下一个字符 递归调用函数 ++pos; num += dfs(); } else if (str[pos] == &#39;)&#39;) { // ) 结束本次调用 继续向后遍历字符 ++pos; break; } else if (str[pos] == &#39;|&#39;) { // |继续向后遍历 求|前后字符串的最大值 // 两个变量 一个是num当前字串长度 一个是ans当前字串的最大长度 // num &amp;gt; ans 更新ans 否则不变 ++pos; ans = max(num, ans); num = 0; // num重置0 } else { // 遇到一般的字符 当前长度num+1 继续向后遍历 ++num; ++pos; } } ans = max(num, ans); return ans;}int main() { // 输入 cin &amp;gt;&amp;gt; str; pos = 0; len = str.length(); cout &amp;lt;&amp;lt; dfs() &amp;lt;&amp;lt; endl; return 0;}包子凑数 dp，讲的很详细了。#include&amp;lt;iostream&amp;gt;using namespace std;int gcd(int a, int b) { return b == 0 ? a : (gcd(b, a % b));}int main() { // 输入 int n; cin &amp;gt;&amp;gt; n; bool dp[10005]; // dp[i]表示要i个包子时 能否凑出来 memset(dp, 0, sizeof(dp)); int maxgcd = 0; // 最大公约数 int ans = 0; // 凑不出来的数量 int nums[100005]; for (int i = 0; i &amp;lt; n; ++i) { cin &amp;gt;&amp;gt; nums[i]; if (i == 0) { maxgcd = nums[i]; // 第一个数的最大公约数为自己 } else { maxgcd = gcd(maxgcd, nums[i]); // 其它数与第一个数的最大公约数 } } if (maxgcd &amp;gt; 1) { // 如果不互质 有无穷个凑不出来 cout &amp;lt;&amp;lt; &quot;INF&quot; &amp;lt;&amp;lt; endl; return 0; } dp[0] = 1; for (int i = 0; i &amp;lt; n; ++i) { // 遍历背包 就是笼 for (int j = nums[i]; j &amp;lt; 10005; ++j) { // 遍历物品 就是可以凑出的包子个数 // nums[i]表示第i笼的包子数量 dp[j] = dp[j - nums[i]] | dp[j]; // bool型 要位运算 } } for (int i = 1; i &amp;lt;= 10005; ++i) { if (dp[i] == 0) ++ans; // 凑不出来 ans+1 } cout &amp;lt;&amp;lt; ans &amp;lt;&amp;lt; endl; return 0;}分巧克力 二分!#include&amp;lt;iostream&amp;gt;using namespace std;const int maxn = 100005; // 最大范围int n; // 巧克力数int k; // 小朋友数int h[maxn]; // 每块巧克力的长度int w[maxn]; // ..........宽度// 这道题要明确怎么切 才能让边长是整数 大小相同 且满足k个小朋友// 刚开始想的是贪心或dp 毕竟最优问题？但是又无从下手// 从样例中可以推出 巧克力块数 = (长 / 边) * (宽 / 边) 需要&amp;gt;=k// 在上面的公式下 可以查找满足条件的最大边长 怎么查找最快？二分// 判断是否满足条件bool Check(int side) { // 传进来的是正方形边长 返回是否能够切分成K块 int nums = 0; // 切分的块数 for (int i = 0; i &amp;lt; n; ++i) { nums += (h[i] / side) * (w[i] / side); // 这里是+= 因为多块巧克力 if (nums &amp;gt;= k) return true; } return false; // 不能放循环内 要遍历所有巧克力}int main() { // 输入 cin &amp;gt;&amp;gt; n &amp;gt;&amp;gt; k; for (int i = 0; i &amp;lt; n; ++i) { cin &amp;gt;&amp;gt; h[i] &amp;gt;&amp;gt; w[i]; } // 二分查找最大边 int l = 0, r = 1e5; while (l &amp;lt; r) { int mid = (l + r) &amp;gt;&amp;gt; 1; if (Check(mid)) l = mid; else r = mid - 1; } cout &amp;lt;&amp;lt; l; return 0;}油漆面积 思维灵活点！#include&amp;lt;iostream&amp;gt;using namespace std;int n; // 多少个矩形int sum; // 油漆面积bool arr[10005][10005]; // 标记涂过油漆的点// 这题直接计算矩形面积会有重叠的 不好区分// 不如化整为零 分成一个个1*1的小正方形 刷过油漆就打上标记// 计算所有小正方形的和就行了void paint(int x1, int y1, int x2, int y2) { for (int x = x1; x &amp;lt; x2; ++x) { for (int y = y1; y &amp;lt; y2; ++y) { arr[x][y] = 1; // 标记矩阵范围内的所有小正方形 } }}int main() { // 输入 cin &amp;gt;&amp;gt; n; for (int i = 0; i &amp;lt; n; ++i) { int x1, x2, y1, y2; cin &amp;gt;&amp;gt; x1 &amp;gt;&amp;gt; y1 &amp;gt;&amp;gt; x2 &amp;gt;&amp;gt; y2; paint(x1, y1, x2, y2); // 标记 } // 遍历所有点 for (int i = 0; i &amp;lt; 10005; ++i) { for (int j = 0; j &amp;lt; 10005; ++j) { if (arr[i][j]) ++sum; // 增加面积 } } cout &amp;lt;&amp;lt; sum; return 0;}" }, { "title": "第九届蓝桥杯真题题解", "url": "/posts/lanqiao9/", "categories": "题解", "tags": "蓝桥杯, 题解, 算法", "date": "2022-04-06 21:35:20 +0800", "snippet": "研究生组是从第十届开始设立的，所以前面的只有大学ABC组。分数#include&amp;lt;iostream&amp;gt;using namespace std;// 求最大公约数int gcd(int a, int b) { return b ? gcd(b, a % b) : a;}int main() { // 求几项和找规律 1/1 3/2 7/4 15/8 // 或者用等比数列算出来 然后约分 int a = 1, b = 1; for (int i = 1; i &amp;lt; 20; ++i) { a = 2 * a + 1; b *= 2; } int t = gcd(a, b); cout &amp;lt;&amp;lt; a / t &amp;lt;&amp;lt; &#39;/&#39; &amp;lt;&amp;lt; b / t; return 0;}星期一#include&amp;lt;iostream&amp;gt;using namespace std;int month[13] = { 0,31,28,31,30,31,30,31,31,30,31,30,31 };// 判断是不是闰年bool Check(int a) { if (a % 400 == 0 || (a % 4 == 0 &amp;amp;&amp;amp; a % 100 != 0)) return true; else return false;}int main() { // 2000.12.31为星期日 int yearday = 0; // 一年的天数 for (int i = 1; i &amp;lt; 13; ++i) { yearday += month[i]; } int count = 0; // 闰年的个数 for (int i = 1901; i &amp;lt;= 2001; ++i) { if (Check(i)) { ++count; } } int sumday = count * (yearday + 1) + (2001 - 1901 - count) * yearday; int week = sumday / 7; // 多少个周 int mod = sumday % 7; // 多几天 if (mod == 1) --week; // 如果刚好多一天 因为从2001.1.1开始 所以减去这个星期一 cout &amp;lt;&amp;lt; week; return 0;}乘积尾零 2*5产生0，分解成2和5取最小的就行了。注意技巧，不可能直接乘的！#include&amp;lt;iostream&amp;gt;using namespace std;int arr[10][10] = { 5650, 4542, 3554, 473, 946, 4114, 3871, 9073, 90, 4329, 2758, 7949, 6113, 5659, 5245, 7432, 3051, 4434, 6704, 3594, 9937, 1173, 6866, 3397, 4759, 7557, 3070, 2287, 1453, 9899, 1486, 5722, 3135, 1170, 4014, 5510, 5120, 729, 2880, 9019, 2049, 698, 4582, 4346, 4427, 646, 9742, 7340, 1230, 7683, 5693, 7015, 6887, 7381, 4172, 4341, 2909, 2027, 7355, 5649, 6701, 6645, 1671, 5978, 2704, 9926, 295, 3125, 3878, 6785, 2066, 4247, 4800, 1578, 6652, 4616, 1113, 6205, 3264, 2915, 3966, 5291, 2904, 1285, 2193, 1428, 2265, 8730, 9436, 7074, 689, 5510, 8243, 6114, 337, 4096, 8199, 7313, 3685, 211};int main() { int num2 = 0, num5 = 0; long long sum = 1; for (int i = 0; i &amp;lt; 10; ++i) { for (int j = 0; j &amp;lt; 10; ++j) { while (true) { if (arr[i][j] % 2 == 0){ ++num2; arr[i][j] /= 2; } else if (arr[i][j] % 5 == 0) { ++num5; arr[i][j] /= 5; } else { break; } } } } cout &amp;lt;&amp;lt; min(num2,num5); return 0;}第几个幸运数 参考了上面的链接，为啥直接循环不对呢，思维好像有点问题。#include&amp;lt;iostream&amp;gt;#include&amp;lt;queue&amp;gt;#include&amp;lt;unordered_set&amp;gt;using namespace std;typedef long long ll;int w[3] = { 3,5,7 };ll ans = 59084709587505;// 优先队列解法int main() { unordered_set&amp;lt;ll&amp;gt; s; priority_queue &amp;lt;ll, vector&amp;lt;ll&amp;gt;, greater&amp;lt;ll&amp;gt;&amp;gt; q; q.push(1); int cnt = 0; while (q.size()) { ++cnt; ll t = q.top(); // 取最大值 即优先队列首元素 q.pop(); if (t == ans) { cout &amp;lt;&amp;lt; cnt - 1 &amp;lt;&amp;lt; endl; break; } // 3 5 7 第二轮 3*3 3*5 3*7 按照顺序加入优先队列中 for (int i = 0; i &amp;lt; 3; ++i) { ll x = t * w[i]; if (!s.count(x)) { // 如果s中x的个数为0 q.push(x); s.insert(x); } } } return 0;}// 暴力搜索#include&amp;lt;stdio.h&amp;gt;int main(){ int c = 0; long long n, j, i, r; scanf_s(&quot;%lld&quot;, &amp;amp;n); for (i = 1; i &amp;lt;= n; i = 3 * i) { for (j = 1; i * j &amp;lt;= n; j = 5 * j) { for (r = 1; i * j * r &amp;lt;= n; r = 7 * r) ++c; } } printf(&quot;%d&quot;, c - 1); return 0;}航班时间 字符串处理！如何消除时差？#include&amp;lt;iostream&amp;gt;using namespace std;typedef long long ll;int t;// 计算飞行时间函数ll FlyTime() { // 读入两个基本时间 int h1, m1, s1, h2, m2, s2; scanf_s(&quot;%d:%d:%d %d:%d:%d&quot;, &amp;amp;h1, &amp;amp;m1, &amp;amp;s1, &amp;amp;h2, &amp;amp;m2, &amp;amp;s2); char x; // 读取后缀字符 int ans = 0; // 记录隔了几天到 while ((x = getchar()) != &#39;\\n&#39;) { if (x &amp;lt;= &#39;9&#39; &amp;amp;&amp;amp; x &amp;gt;= &#39;0&#39;) ans = x - &#39;0&#39;; } // 计算起止时间的差值 ll num1 = h1 * 3600 + m1 * 60 + s1; ll num2 = h2 * 3600 + m2 * 60 + s2 + ans * 24 * 3600; return num2 - num1;}int main() { cin &amp;gt;&amp;gt; t; while (t--) { // 计算两次的差值求平均 就可以消除时差的影响 ll res1 = FlyTime(); ll res2 = FlyTime(); ll res = (res1 + res2) &amp;gt;&amp;gt; 1; // 输出时间 printf(&quot;%02d:%02d:%02d\\n&quot;, res / 3600, res % 3600 / 60, res % 60); } return 0;}三体攻击 三维前缀和和三维查分？真就是数学杯？全球变暖 dfs，dfs，dfs！#include&amp;lt;iostream&amp;gt;using namespace std;int n; // 输入const int num = 1005;bool vis[num][num]; // 标记该点是否被检查过int ans[num] = { 0 }; // 记录每个连通块有几块陆地不被淹没 初始为0char mp[num][num]; // 存图int land = 0; // 连通块数量int flood = 0; // 沉没的连通块数量// dfs void dfs(int a, int b, int k) { if (mp[a][b] == &#39;.&#39;) return; if (vis[a][b]) return; if (mp[a + 1][b] == &#39;#&#39; &amp;amp;&amp;amp; mp[a - 1][b] == &#39;#&#39; &amp;amp;&amp;amp; mp[a][b + 1] == &#39;#&#39; &amp;amp;&amp;amp; mp[a][b - 1] == &#39;#&#39;) ++ans[k]; // 不被淹没的陆地数量 vis[a][b] = 1; // 标记已经找过该点 // 寻找附近点 dfs(a + 1, b, k); dfs(a - 1, b, k); dfs(a, b + 1, k); dfs(a, b - 1, k);}int main() { // 输入 cin &amp;gt;&amp;gt; n; for (int i = 0; i &amp;lt; n; ++i) { for (int j = 0; j &amp;lt; n; ++j) { cin &amp;gt;&amp;gt; mp[i][j]; } } // 遍历所有点 遇到陆地搜索 for (int i = 0; i &amp;lt; n; ++i) { for (int j = 0; j &amp;lt; n; ++j) { // 找到陆地就dfs该岛屿 如果所有陆地都被淹没 被淹没的岛屿数加1 if (mp[i][j] == &#39;#&#39; &amp;amp;&amp;amp; !vis[i][j]) { dfs(i, j, land); ++land; } } } // 如果被淹没的岛屿内没有不被淹没的陆地 沉没的岛屿数+1 for (int i = 0; i &amp;lt; land; ++i) { if (ans[i] == 0) ++flood; // ans[i]表示第i块岛屿上不被淹没的陆地数量 } cout &amp;lt;&amp;lt; flood &amp;lt;&amp;lt; endl; return 0;}倍数问题 直接暴力搜索通不过所有案例，需要优化。dp#include&amp;lt;iostream&amp;gt;#include&amp;lt;vector&amp;gt;#include&amp;lt;algorithm&amp;gt;using namespace std;const int maxn = 1e8;int n;int K;int num[maxn]; vector&amp;lt;int&amp;gt; res;int main() { // 输入 cin &amp;gt;&amp;gt; n &amp;gt;&amp;gt; K; for (int i = 0; i &amp;lt; n; ++i) { cin &amp;gt;&amp;gt; num[i]; } // 暴力搜索 int sum = 0; for (int i = 0; i &amp;lt; n; ++i) { for (int j = 0; j &amp;lt; n; ++j) { for (int k = 0; k &amp;lt; n; ++k) { if (i == j || i == k || j == k) continue; // 元素不能重复使用 if ((num[i] + num[j] + num[k]) % K == 0 ) { sum = num[i] + num[j] + num[k]; res.emplace_back(sum); } } } } cout &amp;lt;&amp;lt; max(res[0], res[res.size() - 1]); return 0;}付账问题 贪心+模拟，一眼就是贪心！#include&amp;lt;iostream&amp;gt;#include&amp;lt;algorithm&amp;gt;#include&amp;lt;cmath&amp;gt;using namespace std;typedef long long ll;ll arr[500010];int main() { // 输入 int n; ll s; cin &amp;gt;&amp;gt; n &amp;gt;&amp;gt; s; for (int i = 0; i &amp;lt; n; ++i) { cin &amp;gt;&amp;gt; arr[i]; } // 排序 sort(arr, arr + n); double avg = 1.0 * s / n; // 初次平均值 double sum = 0.0; // 求每项与平均差值的平方和 for (int i = 0; i &amp;lt; n; ++i) { if (arr[i] &amp;lt; s / (n - i)) { // 如果小于当前平均值 需要把钱全拿出 sum += (arr[i] - avg) * (arr[i] - avg); // 全拿出 直接计算平方和 s -= arr[i]; // 拿出a[i]后 还差多钱 更新s } else { // 不需要吧钱全部拿出的人 也就是钱数大于平均值 // 还差多少钱由剩下的人平摊 double cur_avg = 1.0 * s / (n - i); // 更新平均值 sum += (cur_avg - avg) * (cur_avg - avg) * (n - i); break; } } printf(&quot;%.4f&quot;, sqrt(sum / n)); return 0;}测试次数 参考 最优问题，dp或者贪心，每个子问题之间有联系，很可能是dp!#include&amp;lt;iostream&amp;gt;#include&amp;lt;string&amp;gt;#include&amp;lt;algorithm&amp;gt;using namespace std;int dp[1005][10]; // dp[i][j]表示剩余i层 手机j个是的最少测试次数// 每一层都可以作为第一次摔 设第一次摔选在了第k层// 如果碎了 上面的层不在考虑 手机少了一个 即dp[k-1][j-1]// 如果不碎 下面的层不再考虑 手机还是那么多 即dp[i-k][j]// 因此 从k层开始摔 运气最坏需要 max(dp[k-1][j-1], dp[i-k][j]) + 1 次测试// 因为k有多种选择 所以最好的结果就是 dp[i,j] = min(dp[i,j],...) 每次取最小int main() { int n = 1000, m = 3; // dp数组初始化 for (int i = 1; i &amp;lt;= n; ++i) { dp[i][1] = i; // 1个手机时 多少层就需要测试多少次 } // 遍历顺序 从前往后 先手机 再楼层 for (int j = 2; j &amp;lt;= m; ++j) { // 手机数 1个手机时初始化dp了 所以从2开始 for (int i = 1; i &amp;lt;= n; ++i) { // 楼层数 dp[i][j] = 2e9; // 求最小 可以初始化为一个很大的值 for (int k = 2; k &amp;lt;= i; ++k) { // 假设从第k层开始摔 dp[i][j] = min(dp[i][j], 1 + max(dp[k - 1][j - 1], dp[i - k][j])); } } } cout &amp;lt;&amp;lt; dp[n][m]; return 0;}递增三元组 直接暴力循环，可以用二分优化，降低复杂度。#include&amp;lt;iostream&amp;gt;using namespace std;int n;int a[100005];int b[100005];int c[100005];int main() { // 输入 cin &amp;gt;&amp;gt; n; for (int i = 0; i &amp;lt; n; ++i) { cin &amp;gt;&amp;gt; a[i]; } for (int i = 0; i &amp;lt; n; ++i) { cin &amp;gt;&amp;gt; b[i]; } for (int i = 0; i &amp;lt; n; ++i) { cin &amp;gt;&amp;gt; c[i]; } int cnt = 0; for (int i = 0; i &amp;lt; n; ++i) { for (int j = 0; j &amp;lt; n; ++j) { for (int k = 0; k &amp;lt; n; ++k) { if (a[i] &amp;lt; b[j] &amp;lt; c[k]) ++cnt; } } } cout &amp;lt;&amp;lt; cnt; return 0;}螺旋折线 参考上面比较巧妙的解法。#include&amp;lt;iostream&amp;gt;#include&amp;lt;algorithm&amp;gt;#include&amp;lt;cmath&amp;gt;using namespace std;typedef long long ll;int main() { // 输入 int x, y; cin &amp;gt;&amp;gt; x &amp;gt;&amp;gt; y; // 判断点所在的正方形 ll n = max(abs(x), abs(y)); // 计算之前正方形的长度和 ll sumn = 4 * (n - 1) * n; // 等差数列 d=8 // 计算点（-n, -n) 到(x, y)的距离 ll sum = 0; ll px = -n, py = -n; ll d1 = x - px, d2 = y - py; if (y &amp;gt; x) { // 如果y&amp;gt;x 结果加上距离 sum += (d1 + d2); } else { // 如果y&amp;lt;x 结果等于 sum += (8 * n - d1 - d2); } cout &amp;lt;&amp;lt; sum; return 0;}日志统计 很明显的双指针法！#include&amp;lt;iostream&amp;gt;#include&amp;lt;algorithm&amp;gt;using namespace std;typedef pair&amp;lt;int, int&amp;gt; p; const int N = 100005;int n, d, k;p logs[N]; // pair + 数组构成二维数组 不是第一次见了！int cnt[N]; // 记录一个id获得的赞数bool hot[N]; // 用来标记是否是热帖int main() { // 输入 cin &amp;gt;&amp;gt; n &amp;gt;&amp;gt; d &amp;gt;&amp;gt; k; for (int i = 0; i &amp;lt; n; ++i) { cin &amp;gt;&amp;gt; logs[i].first &amp;gt;&amp;gt; logs[i].second; } // 以时间排序 pair默认以first排序 sort(logs, logs + n); // 这题很明显双指针 一个区间范围 i在前j在后 for (int i = 0, j = 0; i &amp;lt; n; ++i) { int t = logs[i].second; // t表示i时刻的id ++cnt[t]; // 在i时刻id号为t的获得了一个攒 while (logs[i].first - logs[j].first &amp;gt;= d) { // 如果两个点赞的时间范围超出d 早期的赞无效 --cnt[logs[j].second]; ++j; // 后面的指针向前移动 // 这个循环 直到最后一个赞不过期为止 } if (cnt[t] &amp;gt;= k) hot[t] = true; // 热帖标记 } for (int i = 0; i &amp;lt; N; ++i) { // 这个遍历就相当于以id从小到大的顺序排序 if (hot[i]) cout &amp;lt;&amp;lt; i &amp;lt;&amp;lt; endl; } return 0;}最大乘积 即便是枚举，也可能分不清楚情况（没错，就是我…），所以不要轻视枚举，能够有条理的枚举出所有情况，也需要什么清晰的思维。小朋友崇拜圈 dfs!#include&amp;lt;iostream&amp;gt;using namespace std;int n, cnt, ans; // n是输入 cnt记录搜索的次数 ans是最大环数int arr[100005]; // 输入数组void dfs(int x, int id, int cnt) { if (cnt &amp;gt; n) return; // 搜索所有小朋友 返回 if (x == id) { // x表示搜索到的小朋友编号 如果x==传入的小朋友编号 形成一个环 ans = max(ans, cnt); // 更新最大值 搜索次数就是最大圈的人数 return; // 这里要return,不然死循环 } dfs(arr[x], id, cnt + 1); // 继续搜索 cnt+1}int main() { // 输入 cin &amp;gt;&amp;gt; n; for (int i = 1; i &amp;lt;= n; ++i) { cin &amp;gt;&amp;gt; arr[i]; } // 搜索每个小朋友崇拜的对象 崇拜的对象都在右手边 for (int i = 1; i &amp;lt;= n; ++i) { dfs(arr[i], i, 1); // 搜索arr[i]小朋友崇拜的对象 i为编号 1为搜索的次数 } cout &amp;lt;&amp;lt; ans; return 0;}" }, { "title": "第十届蓝桥杯真题题解", "url": "/posts/lanqiao10/", "categories": "题解", "tags": "蓝桥杯, 题解, 算法", "date": "2022-04-02 12:13:31 +0800", "snippet": "研究生组：试题A：立方和 暴力搜索。#include&amp;lt;iostream&amp;gt;using namespace std;int main() { long long sum = 0; for (int i = 1; i &amp;lt;= 1; i++) { //下面代码是对个位数进行判断 if (i % 10 == 2 || i % 10 == 0 || i % 10 == 1 || i % 10 == 9) { cout &amp;lt;&amp;lt; i &amp;lt;&amp;lt; endl; sum = sum + i * i * i; continue; } //下面代码是对十位数进行判断 if (i &amp;gt;= 10) { if ((i / 10) % 10 == 2 || (i / 10) % 10 == 0 || (i / 10) % 10 == 1 || (i / 10) % 10 == 9) { sum = sum + i * i * i; cout &amp;lt;&amp;lt; i &amp;lt;&amp;lt; endl; continue; } } //下面代码是对百位数进行判断 if (i &amp;gt;= 100) { if ((i / 100) % 10 == 2 || (i / 100) % 10 == 0 || (i / 100) % 10 == 1 || (i / 100) % 10 == 9) { cout &amp;lt;&amp;lt; i &amp;lt;&amp;lt; endl; sum = sum + i * i * i; continue; } } //下面代码是对千位数进行判断 if (i &amp;gt;= 1000) { if ((i / 1000) % 10 == 2 || (i / 1000) % 10 == 0 || (i / 1000) % 10 == 1 || (i / 1000) % 10 == 9) { cout &amp;lt;&amp;lt; i &amp;lt;&amp;lt; endl; sum = sum + i * i * i; continue; } } } cout &amp;lt;&amp;lt; sum &amp;lt;&amp;lt; endl; return 0;}试题B：字串数字 暴力搜索，相当于26进制，字符串操作。#include&amp;lt;iostream&amp;gt;#include&amp;lt;cmath&amp;gt;#include&amp;lt;string&amp;gt;using namespace std;int main() { string s; cin &amp;gt;&amp;gt; s; long long sum = 0; for (int i = 0; i &amp;lt; s.length(); ++i) { sum += (s[i] - &#39;A&#39; + 1) * pow(26, s.length() - 1 - i); } cout &amp;lt;&amp;lt; sum; return 0;}试题C：质数 暴力搜索，遇到一个质数计数加1，输出第2019个即可。#include&amp;lt;iostream&amp;gt;using namespace std;// 判断是否是质数bool Prime(int a) { int nums = 0; for (int i = 1; i &amp;lt;= a; ++i) { if (a % i == 0) ++nums; } if (nums &amp;gt; 2) return false; else return true;}int main() { int inf = 0x3f3f3f3f; int count = 0; for (int i = 2; i &amp;lt;= inf; ++i) { if (Prime(i)) ++count; if (count == 2019) { cout &amp;lt;&amp;lt; count &amp;lt;&amp;lt; endl; cout &amp;lt;&amp;lt; i; break; } } return 0;}试题D：最短路 dijkstra，算法模板。#include&amp;lt;iostream&amp;gt;using namespace std;int ver[20][20]; // 顶点 ver[i][j]表示i j之间的距离int dist[20]; // 距离 dist[i]表示i到起点的最短距离bool known[20]; // 标记 是否被处理过int n = 19; // 题目顶点数// dijkstraint Dijkstra() { memset(dist, 0x3f, sizeof(dist)); // 距离初始化为inf dist[1] = 0; // 第一个顶点距离为0 自己到自己的距离 // 遍历所有顶点 for (int i = 0; i &amp;lt; n; ++i) { int t = -1; // 遍历寻找距离最近的下一个顶点 for (int j = 1; j &amp;lt;= n; ++j) { if (!known[j] &amp;amp;&amp;amp; (t == -1 || dist[t] &amp;gt; dist[j])) t = j; } // 更新最小距离 for (int j = 1; j &amp;lt;= n; ++j) { dist[j] = min(dist[j], dist[t] + ver[t][j]); } // 更新标记 known[t] = true; } return dist[19];}// 初始化边void Add(int a, int b, int c) { ver[a][b] = ver[b][a] = c;}// 单源最短路径问题：给定一个加权图和一个特定顶点作为输入// 找到从输入到图中任意一个顶点的最短加权路径int main() { memset(ver, 0x3f, sizeof(ver)); // 根据图中的边初始化 Add(1, 2, 2); Add(1, 3, 1); Add(1, 4, 1); Add(1, 5, 1); Add(2, 7, 1); Add(2, 10, 2); Add(3, 6, 3); Add(3, 7, 3); Add(3, 4, 3); Add(4, 5, 1); Add(4, 7, 2); Add(4, 8, 1); Add(4, 9, 2); Add(5, 8, 1); Add(5, 9, 3); Add(6, 7, 1); Add(6, 10, 1); Add(7, 9, 3); Add(7, 11, 2); Add(8, 9, 1); Add(8, 12, 2); Add(9, 13, 3); Add(10, 19, 2); Add(11, 12, 3); Add(11, 14, 1); Add(11, 16, 2); Add(12, 13, 1); Add(12, 18, 1); Add(13, 17, 1); Add(13, 19, 1); Add(13, 14, 2); Add(14, 16, 1); Add(15, 16, 1); Add(15, 17, 1); Add(15, 18, 3); Add(18, 19, 1); cout &amp;lt;&amp;lt; Dijkstra() &amp;lt;&amp;lt; endl; return 0;}试题E：RSA解密 几何题，用暴力搜索时间很慢，需要扩展欧几里何、快速幂、快速乘。// 放个思路 这个算不出来#include&amp;lt;iostream&amp;gt;#include&amp;lt;cmath&amp;gt;using namespace std;typedef long long ll;// 互质表示两个数的最大公约数为1int gcd(int a, int b) { return b ? gcd(b, a % b) : a;}bool Prime(int a) { int count = 0; for (int i = 1; i &amp;lt;= a; ++i) { if (a % i == 0) ++count; } if (count &amp;gt; 2) return false; else return true;}int main() { ll n = 1001733993063167141; int d = 212353; int c = 20190324; // 找到那两个质数 ll p = 0, q = 0; for (ll i = 1; i &amp;lt;= n; ++i) { if (Prime(i) &amp;amp;&amp;amp; Prime(n / i)) { p = i; q = n / i; break; } } ll p = 7, q = 143104856151881020; // 计算e ll e = 0; if (gcd(d, (p - 1) * (q - 1)) == 1) { for (ll i = 1; i &amp;lt;= n; ++i) { if ((p - 1) * (q - 1) % (i * d) == 1) { e = i; break; } } } // 解密 ll x = 0; x = pow(c, e); x = x % n; cout &amp;lt;&amp;lt; x; return 0;}试题F：Fibonacci数列与黄金分割 这题需要找规律，那么大的数算不出来，大于20之后结果就一样了。#include&amp;lt;iostream&amp;gt;using namespace std;typedef long long ll;int dp[25];int main() { dp[1] = 1; dp[2] = 2; for (int i = 3; i &amp;lt; 25; ++i) { dp[i] = dp[i - 1] + dp[i - 2]; } double ans = 0.0; ans = (double)dp[23] / (double)dp[24]; printf(&quot;%.8f&quot;, ans); return 0;}试题G：扫地机器人 二分+贪心，较难。试题H：修改数组 直接暴力会超时，并查集。[试题I：灵能传输] 后面看[试题J：空间跳跃] 后面看大学组：试题B：矩形切割 暴力搜索。#include&amp;lt;iostream&amp;gt;using namespace std;int main() { int count = 0; int length = 2019; int wide = 324; while (true) { if (length == 1 &amp;amp;&amp;amp; wide == 1) break; if (length - wide &amp;gt; wide) { length = length - wide; wide = wide; ++count; } else if (length == wide) { ++count; break; } else { int temp = length; length = wide; wide = temp - wide; ++count; } } cout &amp;lt;&amp;lt; count; return 0;}试题E：最大降雨量 填空题答案都出来了，还编什么程序？// 求七周能量中位数的最大值 要保证每一周的能量的中位数最大// 从大往小开始 同时也要消耗最小值 比如1 2 3 46 47 48 49// 按照上述类推 结果为34 试题F：旋转 暴力搜索。#include &amp;lt;cstdio&amp;gt;#include &amp;lt;cstring&amp;gt;#include &amp;lt;iostream&amp;gt;#include &amp;lt;algorithm&amp;gt;using namespace std;const int N = 110;int n, m;int a[N][N];int main(){ cin &amp;gt;&amp;gt; n &amp;gt;&amp;gt; m; for (int i = 1; i &amp;lt;= n; i++) for (int j = 1; j &amp;lt;= m; j++) cin &amp;gt;&amp;gt; a[i][j]; for (int i = 1; i &amp;lt;= m; i++) { // 这里不知道为啥 明明一样缺输出不来 for (int j = n; j; j--) { cout &amp;lt;&amp;lt; a[j][i] &amp;lt;&amp;lt; &quot; &quot;; cout &amp;lt;&amp;lt; endl; } } return 0;}试题G：外卖店优先级 题目怎么说就怎么写，pair，按照时间排序。#include&amp;lt;iostream&amp;gt;#include&amp;lt;algorithm&amp;gt;using namespace std;const int maxn = 100010;int n, m, t; // 输入int last[maxn]; // 记录上一次出现订单的时间int v[maxn]; // 表示某家点的分数pair&amp;lt;int, int&amp;gt; order[maxn]; // 存放订单bool res[maxn]; // 判断某家店是否在优先缓存中int main() { //初始化 cin &amp;gt;&amp;gt; n &amp;gt;&amp;gt; m &amp;gt;&amp;gt; t; for (int i = 1; i &amp;lt;= m; ++i) { cin &amp;gt;&amp;gt; order[i].first &amp;gt;&amp;gt; order[i].second; } for (int i = 1; i &amp;lt;= max(n, m); ++i) { last[i] = 0; v[i] = 0; res[i] = false; } // 按照订单时间升序 sort(order + 1, order + 1 + m); // 处理数据 依次遍历每个订单 for (int i = 1; i &amp;lt;= m; ++i) { int name = order[i].second; // 获得订单的店名 int ti = order[i].first; // 获得订单的时间 int ans = 1; // 订单数量 // 同时刻同家店订单处理 while ((name = order[i + 1].second) &amp;amp;&amp;amp; (ti == order[i + 1].first)) { ++i; ++ans; } if (ti - last[name] &amp;gt; 0) // 如果本次获得订单的时间与上次获得订单的时间有间隔 优先分数要降 v[name] -= (ti - last[name] - 1); last[name] = ti; // 更新上次获得订单的时间 if (v[name] &amp;lt; 0) v[name] = 0; // 最低分为0 if (v[name] &amp;lt;= 3) res[name] = false; // 低于三分移出优先缓存 v[name] += (ans * 2); // 订单数*每单加的分数 if (v[name] &amp;gt; 5) res[name] = true; // 如果大于5分 放进优先缓存中 } // 判断t时刻的优先缓存中的数量 for (int i = 1; i &amp;lt;= n; ++i) { if (t &amp;gt; last[i]) v[i] -= (t - last[i]); // 如果t时刻比上次出现订单的时刻大 要减分 // 更新优先级 if (v[i] &amp;lt;= 3) res[i] = false; if (v[i] &amp;gt; 5) res[i] = true; } // 输出 int cnt = 0; for (int i = 1; i &amp;lt;= n; ++i) { if (res[i]) ++cnt; } cout &amp;lt;&amp;lt; cnt; return 0;}试题H：人物相关性分析 字符串处理！试题I：等差数列 求差值的最大公约数，数学思维。#include &amp;lt;iostream&amp;gt;#include &amp;lt;algorithm&amp;gt;using namespace std;const int N = 100010;int a[N];int n;int gcd(int a, int b) { return b ? gcd(b, a % b) : a;}int main(){ cin &amp;gt;&amp;gt; n; for (int i = 0; i &amp;lt; n; i++) cin &amp;gt;&amp;gt; a[i]; sort(a, a + n); int d = 0; for (int i = 1; i &amp;lt; n; i++) d = gcd(d, a[i] - a[i - 1]); if (!d) printf(&quot;%d\\n&quot;, n); else printf(&quot;%d\\n&quot;, (a[n - 1] - a[0]) / d + 1); return 0;}试题C：数列求值 数很大，只需要对结果取后四位就行了，注意题目中给的条件。#include&amp;lt;iostream&amp;gt;using namespace std;int dp[20190325];int ans;int main() { dp[1] = 1; dp[2] = 1; dp[3] = 1; for (int i = 4; i &amp;lt;= 20190324; ++i) { dp[i] = (dp[i - 1] + dp[i - 2] + dp[i - 3]) % 10000; } cout &amp;lt;&amp;lt; dp[20190324]; return 0;}试题D：数的分解 暴力搜索，填空题不用担心超时，注意数不能相等，最后结果为什么除以6？解释#include&amp;lt;iostream&amp;gt;using namespace std;// 判断是否包含2或4(常见判断是否包含某个数字)bool NotInclude24(int a) { while (a) { if (a % 10 == 2 || a % 10 == 4) return false; else a /= 10; } return true;}int main() { int count = 0; for (int i = 1; i &amp;lt;= 2019; ++i) { for (int j = 1; j &amp;lt;= 2019; ++j) { for (int k = 1; k &amp;lt;= 2019; ++k) { if (i == j || i == k || j == k) continue; // 数字各不相同 if (i + j + k == 2019 &amp;amp;&amp;amp; NotInclude24(i) &amp;amp;&amp;amp; NotInclude24(j) &amp;amp;&amp;amp; NotInclude24(k)) ++count; } } } cout &amp;lt;&amp;lt; count / 6; return 0;}试题E：迷宫 明显dfs！试题G：完全二叉树权值 完全二叉树不等于满二叉树，不要混淆！还有就是数字范围的时候，很大直接long long。#include&amp;lt;iostream&amp;gt;#include&amp;lt;cmath&amp;gt;using namespace std;const int n = 101000;const int inf = 1e9 + 7;typedef long long ll;int arr[n];int main() { ll n, deep, maxsum = -inf, ans; // 输入 cin &amp;gt;&amp;gt; n; for (int i = 1; i &amp;lt;= n; ++i) { cin &amp;gt;&amp;gt; arr[i]; } // 计算深度 for (int i = 1; ; ++i) { if (pow(2, i) - 1 &amp;gt;= n) { deep = i; break; } } for (int i = 1; i &amp;lt;= deep; ++i) { ll sum = 0; for (int j = pow(2, i - 1); j &amp;lt;= pow(2, i) - 1 &amp;amp;&amp;amp; j &amp;lt;= n; ++j) { sum += arr[j]; // 计算当前深度的权值和 } if (sum &amp;gt; maxsum) { maxsum = sum; // 更新最大值 ans = i; // 因为输出层数最低的最大值 所以依次遍历即可 } } cout &amp;lt;&amp;lt; ans; return 0;}试题I：后缀表达式 坑，别忘了分类讨论，这样不会的题也可能通多部分样例。#include&amp;lt;iostream&amp;gt;#include&amp;lt;algorithm&amp;gt;#include&amp;lt;cmath&amp;gt;using namespace std;const int maxn = 100010;int n, m;int arr[200010];// 大坑 后缀表达式可以通过调整位置相当于加小括号 比如1-（2-3） -可以变成+//int main() {// // 输入// cin &amp;gt;&amp;gt; n &amp;gt;&amp;gt; m;// for (int i = 1; i &amp;lt;= n + m + 1; ++i) {// cin &amp;gt;&amp;gt; arr[i];// }//// int res = 0;// sort(arr + 1, arr + n + m + 1); // 排序// for (int i = m + 1; i &amp;lt;= m + n + 1; ++i) {// // n个加号加n+1个排序后的大值// res += arr[i];// }//// for (int i = 1; i &amp;lt;= m; ++i) {// // m个可以减去排序后的小值// res -= arr[i];// }//// cout &amp;lt;&amp;lt; res;// return 0;//}int main() { cin &amp;gt;&amp;gt; n &amp;gt;&amp;gt; m; int k = n + m + 1; for (int i = 1; i &amp;lt;= k; ++i) { cin &amp;gt;&amp;gt; arr[i]; } int res = 0; if (m &amp;lt;= 0) { // 如果没有- 直接所有数相加 for (int i = 1; i &amp;lt;= k; ++i) { res += arr[i]; } } else { // 排序后 加上最大值 减去最小值 sort(arr + 1, arr + k + 1); res = arr[k] - arr[1]; for (int i = 2; i &amp;lt;= k - 1; ++i) { res += abs(arr[i]); } } cout &amp;lt;&amp;lt; res; return 0;}试题I：糖果 状压dp。试题J：组合数问题 看了题解挺难的，不知道为啥暴力搜索结果会不一样。#include&amp;lt;iostream&amp;gt;#include&amp;lt;vector&amp;gt;#include&amp;lt;cmath&amp;gt;using namespace std;typedef long long ll;const int mod = 1e9 + 7;ll t, k;ll arr[100005][2];// 计算组合数的函数int C(ll a, ll b) { ll ans = 1; for (ll i = 0; i &amp;lt; b; ++i) { ans *= (a - i) / (b - i); } return ans;}int main() { // 输入 cin &amp;gt;&amp;gt; t &amp;gt;&amp;gt; k; for (int i = 0; i &amp;lt; t; ++i) { for (int j = 0; j &amp;lt; 2; ++j) { cin &amp;gt;&amp;gt; arr[i][j]; } } vector&amp;lt;ll&amp;gt; res; // 依次遍历每组询问 for (int num = 0; num &amp;lt; t; ++num) { int ans = 0; for (ll i = 1; i &amp;lt;= arr[num][0]; ++i) { for (ll j = 0; j &amp;lt;= min(i, arr[num][1]); ++j) { if (C(i, j) % k == 0) ++ans; } } res.push_back(ans); } for (ll i = 0; i &amp;lt; res.size(); ++i) { cout &amp;lt;&amp;lt; res[i] % mod &amp;lt;&amp;lt; endl; } return 0;}" }, { "title": "网页资料202204", "url": "/posts/web-sources-202204/", "categories": "其它", "tags": "总结, 网页资料", "date": "2022-04-01 12:17:43 +0800", "snippet": "C++ cin.get()用法C++ pair及sort排序BFS！DFS！C strcmp()函数C strcat()函数C++ sprintf函数的用法C++ find()函数用法unordered_map赋值C++ 左值和右值C++ substr()函数C++ 宽字符类型的定义及使用相对路径和绝对路径？C++ 队列（queue）、双端队列（deque）与栈（stack）由LeetCode C++ sort函数第三个参数cmp必须声明为static 引发的思考" }, { "title": "批处理文件后缀名", "url": "/posts/file-extention/", "categories": "其它", "tags": "文件后缀", "date": "2022-03-31 15:42:27 +0800", "snippet": "更改单个文件后缀名： 直接重命名，加上自己想要的后缀名即可。更改文件夹内多个文件的后缀名： bat文件更改修改文件类型为文件的后缀名： 在要更改的文件夹打开cmd，输入以下命令：批量给文件加后缀名。" }, { "title": "C++Primer5 第16章 模板", "url": "/posts/C++Primer16/", "categories": "笔记, C++", "tags": "笔记, C++Primer5, C++", "date": "2022-03-30 21:23:53 +0800", "snippet": "函数模板template &amp;lt;typename T&amp;gt;int compare(const T &amp;amp;v1, const T &amp;amp;v2) { if (v1 &amp;lt; v2) return -1; if (v2 &amp;lt; v1) return 1; return 0;}compate(1, 0); // 实例化模板定义时，模板参数列表不能为空。模板编译当编译器遇到一个模板定义时，它并不生成代码。只有我们实例化出模板的一个特定版本时，编译器才会生成代码。 通常我们将函数声明和类定义放在头文件中，而普通函数和类的成员函数的定义放在源文件中。但是函数模板和类模板的定义通常放在头文件中，这是因为为了生成一个实例化版本，编译器需要掌握函数模板和类成员模板的定义。大多数模板编译错误在实例化期间报告通常，编译器会在三个阶段报告错误： 第一个阶段是编译模板本身时，检查语法错误 第二个阶段是编译器遇到模板使用时，检查参数错误 第三个阶段是模板实例化时，只有这个阶段才会发现类型相关的错误，依赖于编译器如何管理实例化，这类错误可能在链接时才报告类模板与函数模板不同的是，编译器不能为类模板推断模板参数类型，需要显式指定。定义在类模板之外的成员函数必须以关键字template开始，后接模板参数。" }, { "title": "C++Primer5 第15章 面向对象程序设计", "url": "/posts/C++Primer15/", "categories": "笔记, C++", "tags": "笔记, C++Primer5, C++", "date": "2022-03-28 21:23:53 +0800", "snippet": "说明：OOP三大特性：封装（数据抽象）、继承、多态（多态绑定），封装第七章已经介绍，本章介绍继承和多态。OOP：概述1、通过继承联系在一起的类构成一种层次关系，基类负责定义所有类共同拥有的成员，每个派生类定义各自特有的成员。2、对于某些函数，基类希望它的派生类各自自定义自身的版本，此时基类将这些函数声明为虚函数。3、派生类必须通过使用类派生列表明确指出它是从哪些基类继承而来的。形式为class Bulk_quote : public Quote {}; 。4、派生类必须在其内部对所有重新定义的虚函数进行声明。派生类可以在这样的函数之前加上virtual，但是并不是非得这样做。C++11新标准允许显示的注明使用哪个成员函数改写基类的虚函数，具体措施为在该函数的形参列表之后增加一个override关键字。5、使用基类的引用或指针调用一个虚函数将发生动态绑定（多态）。定义基类和派生类定义基类1、基类通常都应该定义一个虚析构函数，即使该函数不执行任何实际操作。2、任何构造函数之外的非静态函数都可以是虚函数，virtual只能出现在类内部的声明语句之前而不能用于类外部的函数定义，如果基类把一个函数声明为虚函数，则该函数在派生类中隐式的也是虚函数。成员函数如果没有被声明为虚函数，其解析过程发生在编译时而非运行时。定义派生类派生类必须通过使用派生类列表明确指出它是从哪个基类继承而来。其中，访问说明符的作用是控制派生类从基类继承而来的成员是否对派生类用户可见。派生类中的虚函数派生类经常（但不总是）覆盖它的虚函数，如果没有覆盖，则该虚函数的行为类似于其它的普通函数，派生类会直接继承基类的版本。使用virtual或者override重写虚函数。派生类对象及派生类向基类的类型装换C++标准并没有明确规定派生类的对象在内存中如何分布，因此在一个对象中，继承自基类的部分和派生类自定义的部分不一定是连续存储的。在派生类中含有与其基类对应的部分，这一事实是继承的关键所在。派生类构造函数1、每个类控制它自己的成员初始化过程 尽管在派生类对象中含有从基类继承而来的成员，但是派生类并不能直接初始化这些成员。除非我们特别指出，否则派生类对象的基类部分会像数据成员一样执行默认初始化。如果想使用基类的其它构造函数，需要类名加圆括号的形式为构造和函数提供初始值。 Bulk_quote(const string &amp;amp;book, double p, size_t qty, double disc) : Quote(book, p), min_qty(qty), discount(disc) {}// 首先初始化基类的部分 然后按照声明顺序依次初始化派生类成员！ 2、遵循基类的接口 必须明确：每个类负责各自定义的接口。因此，派生类不能直接初始化基类的成员，尽管从语法上来说派生类可以给他的公有或受保护的基类成员幅值，但是最好不要这么做。派生类应该遵循基类的接口！继承和静态成员如果基类定义了一个静态成员，则在整个继承体系中只存在该成员的唯一定义。静态成员遵循通用的访问控制规则。派生类的声明派生类的声明与其它类相同，声明中包含类名但是不包含它的派生列表。 声明语句的作用是要程序知道某个名字的存在以及该名字表示一个什么样的实体，因此派生列表和定义有关的其它细节必须和类的主体一起出现。被用作基类的类如果我们想把某个类作为基类，则该类必须已经定义而非仅仅声明。 派生类继承基类的成员，当然要知道它们具体是什么。防止继承的发生如果某些类不希望被其它类继承，C++11提供了final关键字，置于类名后。类型转换与继承静态类型与动态类型表达式的静态类型在编译时总是已知的，它是变量声明时的类型或表达式生成的类型；动态类型则是变量或表达式表示的内存中的对象的类型，动态类型直到运行时才可知。如果表达式既不是引用也不是指针，则它的动态类型和静态类型永远一致。不存在从基类向派生类的隐式类型转换，在对象之间不存在类型转换1、为什么派生类可以向基类转换，反之不行？ 派生类之所以能向基类转换，是因为每个派生类对象都包含了一个基类部分，而基类的引用或指针可以绑定到该基类部分上。一个基类对象可以独立存在，也可以作为派生类对象的一部分存在，因此，基类的对象可能不是派生类对象的一部分，所以不存在基类向派生类的隐式转换。2、派生类像基类的自动类型转换只对指针或引用类型有效，在派生类类型和基类类型之间不存在这样的转换。3、当我们用一个派生类对象为一个基类对象初始化或赋值时，只有该派生类独享中的基类部分会被拷贝、移动或赋值，派生类部分会被忽略掉。总结：存在继承关系的类型之间的转换规则 从派生类向基类的转换只对引用和指针类型有效 基类向派生类不存在隐式类型转换 和任何其它成员一样，派生类向基类的类型转换也可能会由于访问受限而变得不可行。 注意：尽管自动类型转换只对指针和引用类型有效，但是继承体系中的大多数类仍然定义了拷贝控制成员，因此，我们通常能够将一个派生类对象拷贝、移动、幅值给一个基类对象，但只能处理派生类对象的基类部分。虚函数1、所有虚函数都必须有定义？ 因为我们知道运行时才能知道到底调用了哪个版本的虚函数。2、C++多态 多态的根本在于：引用或指针的静态类型和动态类型不同。而静态类型和动态类型不同必须调用虚函数（调用非虚函数在编译时就可确定），因此，多态的条件是当前仅当通过引用或指针调用虚函数时。3、派生类中的虚函数基类中的虚函数在派生类中隐含的也是一个虚函数，覆盖某个虚函数时，该函数在基类中的形参必须与派生类中的形参严格匹配。 和其他函数一样，虚函数也可以有默认实参，但是实参值的确定由本次调用的静态类型决定，因此如果使用默认参数，基类和派生类最好一致。4、回避虚函数的机制我们可以通过作用域运算符来强迫执行虚函数的某个版本，而避免其进行动态绑定。使用场景通常是一个派生类的虚函数调用它覆盖的基类的虚函数时（如果没有明确指出，则运行时解析为调用自身，导致无限递归）。抽象基类纯虚函数：在函数声明语句的分号之前书写=0就可以将一个虚函数说明为纯虚函数，=0只能出现在类内部的虚函数声明处。 纯虚函数无需定义，也可以提供定义，但是只能在类外部。class Disc_quote : public Quote {public: Disc_quote() = default; Disc_quote(const string &amp;amp;book, double price, size_t qty, double disc) : Quote(book, price), quantity(qty), discount(disc) { } double net_price(size_t) const = 0; // 纯虚函数protected: size_t quantity = 0; double discount = 0.0;};抽象基类：含有纯虚函数的类是抽象基类，抽象基类负责定义接口，后续的其它类可以覆盖该接口，我们不能创建一个抽象基类的对象。派生类构造函数只初始化它的直接基类： 每个类各自控制其对象的初始化过程。因此，及时Bulk_quote没有自己的数据成员，仍然需要像原来一样提供一个接受四个参数的构造函数。 调用过程：该构造函数将它的实参传递给基类Disc_quote的构造函数，然后Disc_quote的构造函数继续调用Quote的构造函数。 初始化过程：Quote首先初始化bulk的bookNo和price成员，当其构造函数结束后，运行Disc_quote的构造函数并初始化quantity和discount成员，最后运行Bulk_quote的构造函数，该函数无需执行实际的初始化。class Bulk_quote : public disc_quote {public: Bult_quote() = default; Bulk_quote(const string &amp;amp;book, double price, size_t qty, double disc) : Disc_quote(book, price, qty, disc) { } // 覆盖基类中的纯虚函数 double net_price(size_t) const override;};访问控制与继承 每个类控制自己的成员初始化过程 每个类控制自己的成员对于派生类来说是否可访问protected成员一个类声明protected成员是希望与它的派生类共享这些成员，但是派生类的成员或友元只能通过派生类对象来访问基类的protected成员，派生类对于一个基类对象中的protected成员没有任何访问权限。 为什么？如果能访问的话，只需要定义一个新的Sneaky类，就可以规避掉protected提供的访问保护了！class Base {protected: int prot_mem; // protected成员};class Sneaky : public Base { friend void clobber(Sneaky&amp;amp;); //能访问Sneaky::prot_mem friend void clobber(Base&amp;amp;) //不能访问Base::prot_mem int j;};void clobber(Sneaky &amp;amp;s) { // 正确 派生类对象访问继承而来的基类的protected成员 s.j = s.prot_mem = 0;}void clobber(Base &amp;amp;b) { // 错误 clobber不能访问Base的protected成员 // 即派生类无法访问 只能由派生类对象访问 b.prot_mem = 0;}public、private、protected继承派生访问说明符对于派生类的成员（及友元）能否访问其直接基类的成员没什么影响。对基类成员的访问权限只与基类中的访问说明符有关。派生访问说明符的作用是控制派生类用户（包括派生类的派生类在内）对于基类成员的访问权限。 每个类控制自己的成员访问权限，也就是说派生类可以按照基类的访问说明符来进行访问。但派生类可以通过派生访问说明符来改变继承而来的成员访问权限，从而影响派生类的派生类对派生类的访问。比如原本public成员通过private继承，那么在派生类内该成员变成private的，因此派生类的派生类无法访问该成员，但是并不影响派生类来访问该成员，因为该成员再派生类的基类中是public的！ 一句话：能否访问看基类访问权限，基类访问权限看派生访问说明符！友元和继承友元关系不能传递，同样也不能继承。 归根结底就是每个类控制自己的成员的访问权限。所以，每个类内的声明或者其它操作只对自己有用，管不到派生类。class Base { friend class Pal; // Pal在访问Base时具有特殊权限 但是访问其派生类时并不具有};class Pal {public: int f(Base b) { return b.prot_mem; } // 正确 友元 int f2(Sneaky s) { return s.j; } // 错误 非派生类友元 // 正确 对基类的访问权限由基类控制 其派生类的基类部分也是如此 int f3(Sneaky s) { return s.prot_mem; }};改变个别成员的可访问性class Base {public: size_t size() const { return n; }protected: size_t n;private: int priv_mem;};class Derived : private Base { // private继承public: using Base::size; // 通过using改变为public权限 using Base::priv_mem; // 错误 只能改变它可以访问的成员protected: using Base::n; // 通过using改变为protected权限}; 因为Derived使用了private继承，因此其成员是其私有成员。 用using声明语句改变可访问性后，Derived用户可以访问其size成员，而其派生类可以访问n成员了。 using声明语句名称的访问权限由using之前的访问说明符决定。 之能为可以访问到的成员提供using声明，访问都访问不到，如何改变？class和struct的区别 默认的成员访问说明符不同，class为private，struct为public 默认的派生访问说明符不同，calss为private，struct为publiccalss Base { /*...*/ };struct D1 : Base { /*...*/ }; // 默认public继承class D2 : Base { /*...*/ }; // 默认private继承继承中的类作用域当存在继承关系时，派生类的作用域嵌套在其基类的作用域之内，如果一个名字在派生类的作用域内无法正确解析，继续在外层的作用域寻找该名字定义。1、在编译时进行名字查找这意味着一个对象、引用或指针的静态类型决定了该对象的哪些成员可见。2、派生类的成员隐藏同名基类的成员，通过作用域运算符来使用隐藏的成员 除了覆盖继承而来的虚函数之外，派生类最好不要重用基类成员名字。名字查找与继承：调用p-&amp;gt;mem或p.mem的过程！ 首先确定p的静态类型。因为调用的是一个成员，所以必须为类类型。 在p的静态类型对应的类中查找mem。如果找不到，则依次在直接基类中查找直到继承链的顶端，如果仍找不到，则编译器报错。 一旦找到mem，就进行常规的类型检查以确认对于找到找到的mem，当前调用是否合法。 如果调用合法，则编译器根据是否是虚函数产生不同的代码：如果mem是虚函数且通过引用和指针进行调用，则在运行时根据动态类型决定到底该调用哪个版本；如果是对象调用，则产生一个常规的函数调用。一如往常，名字查找先于类型检测！ 即使形参列表不一致，派生类仍将隐藏基类成员。为什么基类和派生类的虚函数必须有相同的形参？ 因为加入基类和派生类的虚函数接受的形参列表不同（派生类会隐藏而非覆盖虚函数，此时派生类内会拥有两个活多个同名函数），则我们无法通过基类的引用或指针调用派生类的虚函数了。构造函数与拷贝控制虚析构函数继承关系对基类拷贝控制最直接的影响是基类通常应该定义一个虚析构函数，这样我们就可以动态分配继承体系中的对象了。 如果基类的析构函数不是虚函数，则delete一个指向派生类对象的基类指针将产生未定义的行为（指针静态类型与被删除对象动态类型不符）。 虚析构函数将阻止移动操作，即使=default指定，也不会合成移动操作。" }, { "title": "第十一届蓝桥杯真题题解", "url": "/posts/lanqiao11/", "categories": "题解", "tags": "蓝桥杯, 题解, 算法", "date": "2022-03-27 22:46:25 +0800", "snippet": "研究生组：试题A：约数个数 暴力搜索。#include&amp;lt;iostream&amp;gt;using namespace std;int main() { int n; cin &amp;gt;&amp;gt; n; int count = 0; for (int i = 1; i &amp;lt;= n; ++i) { if (n % i == 0) { ++count; } } cout &amp;lt;&amp;lt; count; return 0;}试题B：寻找2020 读文件，然后暴力搜索。#include&amp;lt;iostream&amp;gt;#include&amp;lt;fstream&amp;gt;using namespace std;char text[500][500];void ReadText() {//将文本内容复制到数组text中 // 流对象 要有头文件 ifstream fin; // 打开文件 检查是能够打开 fin.open(&quot;2020.txt&quot;, ios::in); if (!fin.is_open()) { cout &amp;lt;&amp;lt; &quot;can not open the file!&quot; &amp;lt;&amp;lt; endl; } // 以行读取 int line = 0; while (fin.getline(text[line], sizeof(text[line]))) { ++line; } // 关闭文件 fin.close();}int main(){ int i, j = 0, count = 0; ReadText(); //求每行的2020 for (i = 0; i &amp;lt; 500; i++) for (j = 0; j &amp;lt; 500; j++) if (text[i][j + 3] != NULL) { if (text[i][j] == &#39;2&#39; &amp;amp;&amp;amp; text[i][j + 1] == &#39;0&#39; &amp;amp;&amp;amp; text[i][j + 2] == &#39;2&#39; &amp;amp;&amp;amp; text[i][j + 3] == &#39;0&#39;) { count++; j = j + 1; } } else { break; } //求每列的2020 for (j = 0; j &amp;lt; 500; j++) for (i = 0; i &amp;lt; 500; i++) if (text[i + 3][j] != NULL) { if (text[i][j] == &#39;2&#39; &amp;amp;&amp;amp; text[i + 1][j] == &#39;0&#39; &amp;amp;&amp;amp; text[i + 2][j] == &#39;2&#39; &amp;amp;&amp;amp; text[i + 3][j] == &#39;0&#39;) { count++; i = i + 1; } } else { break; } //求对角线的2020 for (i = 0; i &amp;lt; 500; i++) for (j = 0; j &amp;lt; 500; j++) if (text[i + 3][j + 3] != NULL) { if (text[i][j] == &#39;2&#39; &amp;amp;&amp;amp; text[i + 1][j + 1] == &#39;0&#39; &amp;amp;&amp;amp; text[i + 2][j + 2] == &#39;2&#39; &amp;amp;&amp;amp; text[i + 3][j + 3] == &#39;0&#39;) count++; } else { break; } cout &amp;lt;&amp;lt; count; return 0;}试题C：平面分割 找规律，不要乱找，控制变量按照顺序一个个来，大问题分成小问题，然后举简单例子递推，暴力搜索，可参考这个。#include&amp;lt;iostream&amp;gt;using namespace std;int main() { // 递推找规律 f(i)=f(i-1)+i 也就是当前分割的平面数=上次分割的平面数+当前的所有直线数 // 可以这样想：0条直线为1个平面 以后每多i条直线就累加i个平面 int count = 1; for (int i = 1; i &amp;lt;= 20; ++i) { count += i; } // 直线的规律好找 但是如果直线和圆混在一起可能就有点慌乱了 // 可以在直线的基础上添加圆 然后找规律 // 两线一圆8个平面 两线两圆14个平面 两线三圆22个平面 // 一个圆可以与直线、圆各有两个交点 所以每加一个圆 加的平面数=2*加之前的所有直线和圆的个数 for (int i = 1; i &amp;lt;= 20; ++i) { count += 2 * (20 + i - 1); // i = 1时 只有一个圆 只能与直线相交 } cout &amp;lt;&amp;lt; count; return 0;}试题D：蛇形填数 找规律，矩阵的下标有一定的关系，然后算出来就行了。其它解法#include&amp;lt;iostream&amp;gt;using namespace std;int main() { // 要求的数字时主对角线上的数字 // 如果在第i行 那么就是第2*i-1个斜行 第i个斜行有i个数字 而主对角线上的数字恰好是中间那个 // 所以累加1~(2i-1-1) 然后加上(2i-1)/2+1个数字就行了 int num = 0; for (int i = 1; i &amp;lt;= 2 * 20 - 1 - 1; ++i) { num += i; } num += (2 * 20 - 1) / 2 + 1; cout &amp;lt;&amp;lt; num; return 0;}试题E：七段码 dfs搜索，并查集判断。试题F：成绩分析 虽然写的很烂，但还是要坚持用STL。#include&amp;lt;iostream&amp;gt;#include&amp;lt;vector&amp;gt;#include&amp;lt;algorithm&amp;gt;using namespace std;int main() { int n; // 考试人数 cin &amp;gt;&amp;gt; n; vector&amp;lt;int&amp;gt; score; for (int i = 0; i &amp;lt; n; ++i) { int m; cin &amp;gt;&amp;gt; m; score.push_back(m); } sort(score.begin(), score.end()); double sum = 0; for (int i = 0; i &amp;lt; n; ++i) { sum += score[i]; } printf(&quot;%d\\n&quot;, score[n - 1]); printf(&quot;%d\\n&quot;, score[0]); printf(&quot;%.2f\\n&quot;, sum / n); return 0;}试题G：回文日期 虽然没有什么特别难的算法，但是一道综合题，基础牢固思路清晰才能更快地写出来！#include&amp;lt;iostream&amp;gt;#include&amp;lt;string&amp;gt;#include&amp;lt;vector&amp;gt;using namespace std;const int s = 1000, e = 8999; // 范围vector&amp;lt;int&amp;gt; arr; // 存储满足条件的整数int month[13] = { 0,31,28,31,30,31,30,31,30,30,31,30,31 };// 判断是否满足日期格式bool Check(int yy, int mm, int dd) { // 满足条件是月份在1-12 日期小于当月的最大日期 要判断是否为闰年 if (mm &amp;gt; 1 &amp;amp;&amp;amp; mm &amp;lt;= 12) { if (yy % 400 || (yy % 4 &amp;amp;&amp;amp; yy % 100 != 0)) month[2] = 29; // 判断是够是闰年 if (month[mm] &amp;gt;= dd) return true; else return false; } return false;}// 预处理回文日期void Preprocess() { for (int i = s; i &amp;lt;= e; ++i) { string s = to_string(i); // 转为string // 0123 3210 满足回文格式 for (int j = 3; j &amp;gt;= 0; --j) { s += s[j]; } int mm = (s[4] - &#39;0&#39;) * 10 + (s[5] - &#39;0&#39;); // 月 int dd = (s[6] - &#39;0&#39;) * 10 + (s[7] - &#39;0&#39;); // 日 if (Check(i, mm, dd)) { // 如果满足格式要求 存起来 注意转换成int int k = stoi(s); // 转int arr.push_back(k); // 统一存起来 } month[2] = 28; // 这里是重置month[2] 因为前面可能是闰年 把month[2]改成29了 }}// 找到第一个比输入大的回文日期int UpperBound(int key) { // 二分查找 int l = 0, r = arr.size(); while (l &amp;lt; r) { int mid = (l + r) &amp;gt;&amp;gt; 1; if (arr[mid] &amp;gt; key) r = mid - 1; else l = mid + 1; } return l;}// 寻找满足条件ababbaba格式的回文日期int ababbaba(int index) { for (int i = index; i &amp;lt; arr.size(); ++i) { string s = to_string(arr[i]); // 直接转换成字符串可以逐位比较 // 1212这样格式的才能满足ababbaaba if (s[0] == s[2] &amp;amp;&amp;amp; s[1] == s[3]) return i; } return 0;}int main() { int n; cin &amp;gt;&amp;gt; n; Preprocess(); // 预处理找到满足格式的回文日期 int index = UpperBound(n); // 找到大于n的回文日期 cout &amp;lt;&amp;lt; arr[index] &amp;lt;&amp;lt; endl; index = ababbaba(index); // 找到满足题目条件的回文日期 cout &amp;lt;&amp;lt; arr[index]; return 0;}试题H：作物杂交 背包问题，树状dp，纵向dfs，横向遍历。#include&amp;lt;iostream&amp;gt;#include&amp;lt;vector&amp;gt;using namespace std;const int inf = 0x3f3f3f3f; // 定义最大值常量typedef pair&amp;lt;int, int&amp;gt; p; // 自定义数据类型p 有两个int 用来表示咋交方案int N, M, K, T, a, b, c;// 开一个类型为p的二维数组 e[i]中的元素为pair 表示可以由pair杂交成u e[u]可能有多个方案合成vector&amp;lt;p&amp;gt; e[2022]; // Time[i]表示每个作物成熟的时间 Now[i]即现有的作物 dp[i]为dp数组 表示目标作物W为i时的最小时间为dp[i]int Time[2022], Now[2022], dp[2022];// dfs从后往前搜索 即根据目标种子深度搜索合成方案 然后取所有方案中的最小数void dfs(int u) { if (dp[u] != 0) return; // 说明作物u已经到了最短时间了 直接返回 int minv = inf; // 初始化 for (int i = 0; i &amp;lt; e[u].size(); ++i) { // 对于每个作物u 搜索它的可合成方案（可能有多个合成方案） int a = e[u][i].first, b = e[u][i].second; // 取出合成所用的a b物种 dfs(a), dfs(b); // 搜索父母物种 // 核心公式 c=a+b 那么c的时间就是获得a,b的最大时间 加上a,b的最大成长时间 // 已经有的种子时间为0 没有的需要合成 因为是两种杂交 所以要等最长的时间才能成熟 minv = min(minv, max(dp[a], dp[b]) + max(Time[a], Time[b])); } if (minv != inf) dp[u] = minv; // 成功搜索 及时更新}int main() { memset(dp, 0, sizeof(dp)); // 初始化为0 都是正数 不可能小于0 cin &amp;gt;&amp;gt; N &amp;gt;&amp;gt; M &amp;gt;&amp;gt; K &amp;gt;&amp;gt; T; // 输入第一行 题目参数 for (int i = 1; i &amp;lt;= N; ++i) { cin &amp;gt;&amp;gt; Time[i]; // 输入第二行 种子的成熟日期 } for (int i = 1; i &amp;lt;= M; ++i) { cin &amp;gt;&amp;gt; Now[i]; // 输入第三行 现有的种子 } while (K--) { cin &amp;gt;&amp;gt; a &amp;gt;&amp;gt; b &amp;gt;&amp;gt; c; // 输入接下来的K行 表示合成方案 e[c].push_back({ a, b }); // ab=c 用二维数组连接 vector+pair } dfs(T); // 以目标作物进行搜索 向下搜索 cout &amp;lt;&amp;lt; dp[T]; // 输出结果 return 0;}试题I：子串分值和 暴力搜索会超时，flag[str[j] - &#39;a&#39;]存放相同字符的数量很妙。#include &amp;lt;iostream&amp;gt;#include &amp;lt;string&amp;gt;using namespace std;int flag[26]; int num;int main(){ string str; cin &amp;gt;&amp;gt; str; long long sum = 0; for (int i = 0; i &amp;lt; str.length(); ++i) { for (int j = i; j &amp;lt; str.length(); ++j) { ++flag[str[j] - &#39;a&#39;]; // str[j] - &#39;a&#39;很妙 if (flag[str[j] - &#39;a&#39;] == 1) { ++num; } sum += num; } memset(flag, 0, sizeof(flag)); num = 0; } cout &amp;lt;&amp;lt; sum; return 0;}试题J：荒岛探测 可以做但没必要，有点难，先放过自己（其实是我太菜）。。。大学组：试题B：门牌制作 和12届那个数卡片一样的题目，直接搜索就行了。#include&amp;lt;iostream&amp;gt;using namespace std;int main() { long long count = 0; for (int i = 1; i &amp;lt;= 2020; ++i) { // 这里注意不要直接用i运算 因为i值会改变 然后死循环 用临时变量存放 int temp = i; // 如果不是一位数 取模判断 然后/10降位 while (temp / 10 != 0) { if (temp % 10 == 2) ++count; temp /= 10; } // 如果是一位数 取模判断 if (temp % 10 == 2) ++count; } cout &amp;lt;&amp;lt; count; return 0;}试题G：单词分析 存储相同字符的数量，直接循环。#include&amp;lt;iostream&amp;gt;using namespace std;int flag[26]; // 用于存放每个字母出现的数量int main() { string s; cin &amp;gt;&amp;gt; s; memset(flag, 0, sizeof(flag)); for (int i = 0; i &amp;lt; s.length(); ++i) { ++flag[s[i] - &#39;a&#39;]; } int maxnum = 0; for (int i = 0; i &amp;lt; 26; ++i) { if (flag[i] &amp;gt; maxnum) maxnum = flag[i]; } char a = &#39;a&#39;; for (int i = 0; i &amp;lt; 26; ++i) { if (flag[i] == maxnum) { a += i; break; } } printf(&quot;%c\\n%d&quot;, a, maxnum); return 0;}试题H：数字三角形 dp，自己写的不知道为啥结果不一样，可能是因为没加限制条件。// 这个对于题目给的案例不对#include&amp;lt;iostream&amp;gt;using namespace std;int num[105][105]; // dp[i][j]表示到达（i,j）位置上的最大和int dp[105][105];int main() { int N; // 三角形的行数 cin &amp;gt;&amp;gt; N; // 输入第一行 memset(dp, 0, sizeof(dp)); // 初始化dp数组 // 接下来需要输入N行是表示三角形 for (int i = 1; i &amp;lt;= N; ++i) { for (int j = 1; j &amp;lt;= i; ++j) { // 三角形数第i行有i+1个数 cin &amp;gt;&amp;gt; num[i][j]; } } // 开始找最大值 for (int i = N; i &amp;gt;= 1; i--) { for (int j = 1; j &amp;lt;= i; j++) { dp[i][j] = max(dp[i + 1][j], dp[i + 1][j + 1]) + num[i][j]; } } cout &amp;lt;&amp;lt; dp[1][1]; return 0;}试题B：既约分数 最大公约数，还真是喜欢考，还要注意最小公倍数。#include&amp;lt;iostream&amp;gt;using namespace std;int gcd(int a, int b) { return b ? gcd(b, a % b) : a;}int main() { int count = 0; for (int i = 1; i &amp;lt;= 2020; ++i) { for (int j = 1; j &amp;lt;= 2020; ++j) { if (gcd(i, j) == 1) { ++count; } } } cout &amp;lt;&amp;lt; count; return 0;}试题D：跑步锻炼 日期处理，暴力搜索。#include&amp;lt;iostream&amp;gt;using namespace std;int month[13] = { 0,31,28,31,30,31,30,31,31,30,31,30,31 };// 判断是否是闰年bool Judge(int year) { return (year % 4 == 0 &amp;amp;&amp;amp; year % 100 != 0) || year % 400 == 0;}int main() { int monthStart = 1, day = 0, week = 0, weeks = 6; // monthStart表示总的月初数 因为从1月1号开始 所以初始值为1 // day表示总得天数 week表示总的周1但不是月初数 weeks表示当前为周六 for (int i = 2000; i &amp;lt;= 2020; ++i) { // 遍历年 if (Judge(i)) month[2] = 29; else month[2] = 28; // 遍历月 for (int j = 1; j &amp;lt;= 12; ++j) { ++monthStart; if (i == 2020 &amp;amp;&amp;amp; j == 10) break; // 如果到了最后一天 直接结束循环 // 遍历天数 for (int k = 1; k &amp;lt;= month[j]; ++k) { ++day; weeks = (++weeks) % 7; // 从周日开始 如果模7余1 则为星期一 if (weeks == 1 &amp;amp;&amp;amp; (k + 1) % month[j] != 1) ++week; // 如果是周一且不是月初 } } } // 最后的总天数 cout &amp;lt;&amp;lt; day + week + monthStart; return 0;}试题I：平面切分 几何体，需要递推，先判断是否相交，相交的再判断是否有重点。#include&amp;lt;iostream&amp;gt;#include&amp;lt;vector&amp;gt;#include&amp;lt;cmath&amp;gt;using namespace std;const int maxn = 1010, inf = 0x3f3f3f3f;int n, ans;int a[maxn], b[maxn]; // 分别存储A和B// 点对象struct Point { double x, y;};// 判断是否是重点 注意浮点数的比较bool IsEqual(Point e1, Point e2) { return (abs(e1.x - e2.x) &amp;lt;= 1e-2 &amp;amp;&amp;amp; abs(e1.y - e2.y) &amp;lt;= 1e-2);}// 求交点Point CrossPoint(int m, int n) { double x1 = a[m], x2 = a[n], y1 = b[m], y2 = b[n]; // 平行无交点 if (x1 == x2) return Point{ inf,inf }; Point cp = Point{}; cp.x = (y2 - y1) / (x1 - x2); cp.y = (x1 * y2 - x2 * y1) / (x1 - x2); return cp;}int main() { cin &amp;gt;&amp;gt; n; for (int i = 1; i &amp;lt;= n; ++i) { cin &amp;gt;&amp;gt; a[i] &amp;gt;&amp;gt; b[i]; } // n==1时两个平面 ans = 2; for (int i = 2; i &amp;lt;= n; ++i) { vector&amp;lt;Point&amp;gt; v; bool flag = false; for (int j = 1; j &amp;lt; i; ++j) { // i为新加入的点，与之前的点做划分 // 判断直线i j是否存在交点 Point now = CrossPoint(i, j); // 直线i j不存在交点 if (now.x == inf || now.y == inf) continue; // 直线i j存在交点 for (int k = 0; k &amp;lt; v.size(); ++k) { // 判重点 if (IsEqual(now, v[k])) flag = true; } if (!flag) v.push_back(now); } ans += v.size() + 1; } cout &amp;lt;&amp;lt; ans; return 0;}试题J：字串排序 最后一题，还是挺难的。冒泡排序的次数就是字符串的最大逆序对，所以需要求最大逆序数，然后从第一个字符开始固定，从小到大搜索。" }, { "title": "第十二届蓝桥杯真题题解", "url": "/posts/lanqiao12/", "categories": "题解", "tags": "蓝桥杯, 题解, 算法", "date": "2022-03-26 21:47:02 +0800", "snippet": "研究生组：试题A：卡片#include&amp;lt;iostream&amp;gt;using namespace std;int main() { int a[10]; // 定义一个数组用来存放每张卡片的数量 for (int i = 0; i &amp;lt; 10; ++i) a[i] = 2021; // 初始数量为2021 // 思路 // 可以假设数字能够拼到n 我们从1一直遍历到n // 每遍历一个数字 就可以减去拼成这个数字所用的卡片 直到数组中某个卡片数量为0 // 注意：我们判断数组中某个卡片为0时 int count = 1; // 从1开始拼数字 while (true) { // 这里应该说是核心了 // 怎么判断每个数字所用的卡片？ // 无论位数多少，我们只要根据%10的值就可以知道用的卡片了 // 但是高位数需要不断/10来变成低位数 // 怎么使所用卡片的数量-1？ // 将数组中对应的值-1就行了 int x = count; // 这个x要用来作为每个数字的副本 因为要对每个数字操作 while (x) { // 如果卡片数量是0 就要结束循环 if (a[x % 10] == 0) { // 注意：我们是先判断 再-1 所以如果=0 代表这个数字拼不出来 输出上个数字 cout &amp;lt;&amp;lt; count - 1 &amp;lt;&amp;lt; endl; return 0; } --a[x % 10]; // 相应的卡片数量-1 x /= 10; // 相当于从各位开始判断 所以每次/10 如果是各位数 就判断结束了 开始下一个数字 } ++count; // 开始拼下一个数字 }}// 巧妙解法：在所有的数字卡片中 总是1先用完 因为数字都是从1开始拼int main() { int count = 0; int i; for (i = 0; i &amp;lt; 10000; ++i) { if (i % 10 == 1) ++count; if ((i / 10) % 10 == 1) ++count; if ((i / 100) % 10 == 1) ++count; if ((i / 1000) % 10 == 1) ++count; if (i / 10000 == 1) ++count; if (count == 2021) break; } cout &amp;lt;&amp;lt; i &amp;lt;&amp;lt; endl; return 0;}试题B：直线#include&amp;lt;iostream&amp;gt;#include&amp;lt;cmath&amp;gt;#include&amp;lt;set&amp;gt;using namespace std;class Node {public: int x, y;};class Line {public: int a, b, c; // 直线一般方程的系数 // 重载操作符 bool operator&amp;lt;(const Line&amp;amp; p) const { if (a == p.a) { if (b == p.b) { return c &amp;lt; p.c; } else { return b &amp;lt; p.b; } } return a &amp;lt; p.a; } bool operator== (const Line&amp;amp; p) const { return a == p.a &amp;amp;&amp;amp; b == p.b &amp;amp;&amp;amp; c == p.c; }};// 求最大公约数 就是把方程化成最简形式int gcd(int a, int b) { // 辗转相除法 return b == 0 ? a : gcd(b, a % b);}int gcdd(int a, int b, int c) { // 三个系数求最大公约数 化简 return gcd(gcd(a, b), gcd(b, c));}int main() { Node p[1000]; int cnt = 0; set&amp;lt;Line&amp;gt; se; int n = 20, m = 21; for (int i = 0; i &amp;lt; n; ++i) { for (int j = 0; j &amp;lt; m; ++j) { p[cnt] = { i, j }; // 所有点的坐标 ++cnt; } } for (int i = 0; i &amp;lt; cnt; ++i) { for (int j = i + 1; j &amp;lt; cnt; ++j) { // 遍历所有点的两两组合 int a = p[i].y - p[j].y; // 系数 int b = p[j].x - p[i].x; int c = p[i].y * (p[i].x - p[j].x) - p[i].x * (p[i].y - p[j].y); // 求三个系数的最大公约数 int t = gcdd(fabs(a), fabs(b), fabs(c)); // 化简插入set集合中 se.insert({ a / t, b / t, c / t }); } } // set不允许有重复的元素 所以size()就是最终的直线数 cout &amp;lt;&amp;lt; se.size(); return 0;}试题C：货物摆放#include&amp;lt;iostream&amp;gt;#include&amp;lt;algorithm&amp;gt;using namespace std;typedef long long ll; // 数比较大16位 用long longint main() { ll yueShu[10000]; // 定义一个数组存放约数 ll cnt = 0; // 约数个数 也是数组下标 ll n = 2021041820210418; // 待求解的数 for (ll i = 1; i &amp;lt;= n / i; ++i) { // 这里注意i的停止范围不是n 而是n/i if (n % i == 0) { // 模为0 表示i是n的约数 存入数组 数组下标后移一位 yueShu[cnt] = i; ++cnt; if (i * i != n) { // 这里是避免重复的约数放进数组 // 比如4=2*2 放进去一个2就行了 // 如果i是约数 那么n/i就是另一个约数 除了上面说的重复的情况 yueShu[cnt] = n / i; ++cnt; } } } int ans = 0; // 存储摆放货物的方法数 // 需要双重循环 如果n能够除尽两个约数 就是一种摆放方式 ans+1 // 这里要注意i&amp;amp;j的下标 上面cnt是从0开始的 这里也要从0开始 但cnt-1 所以&amp;lt;cnt for (int i = 0; i &amp;lt; cnt; ++i) { for (int j = 0; j &amp;lt; cnt; ++j) { if (n % (yueShu[i] * yueShu[j]) == 0) ++ans; } } cout &amp;lt;&amp;lt; ans; return 0;}试题D：路径 Dijkstra！#include&amp;lt;iostream&amp;gt;using namespace std;typedef long long ll;const int inf = 0x3f3f3f3f;const int n = 2025;int edges[n][n];int d[n];bool vis[n];int gcd(int a, int b) { // 辗转相除法求最大公约数 // 首先判断b是否为0 因为要做除数 return b == 0 ? a : gcd(b, a % b);}int lcm(int a, int b) { // 在最大公约数的基础上求最小公倍数 都是两行代码 理解原理之后记着就行了 return a / gcd(a, b) * b;}int main() { memset(edges, inf, sizeof(edges)); // edges所有元素初始化inf // 建立邻接矩阵 for (int i = 1; i &amp;lt; n; ++i) { // 当前结点设为0 edges[i][i] = 0; for (int j = i + 1; j &amp;lt; n; ++j) { int w = lcm(i, j); // i j之间的权值距离 edges[i][j] = edges[j][i] = w; } } memset(d, inf, sizeof(d)); // d数组所有元素初始化为inf memset(vis, false, sizeof(vis)); // vis数组所有元素初始化为false d[1] = 0; // Dijkstra for (int i = 1; i &amp;lt; n; ++i) { int x = 0; // 找到下一个未确定的最短路径的点 for (int j = 1; j &amp;lt; n; ++j) { if (!vis[j] &amp;amp;&amp;amp; d[j] &amp;lt; d[x]) x = j; } vis[x] = 1; // 标记为已确定 for (int j = max(1, x - 21); j &amp;lt;= min(n, x + 21); ++j) { d[j] = min(d[j], d[x] + edges[x][j]); } } cout &amp;lt;&amp;lt; d[2021]; return 0;}试题E：回路计数 DP，难！试题F：时间显示#include&amp;lt;iostream&amp;gt;using namespace std;int main() { long long int n; cin &amp;gt;&amp;gt; n; n %= 1000 * 60 * 60 * 24; int hours = n / (60 * 60 * 1000); n %= (60 * 60 * 1000); int mins = n / (60 * 1000); n %= 60 * 1000; int secs = n / 1000; printf(&quot;%02d:%02d:%02d\\n&quot;, hours, mins, secs); return 0;}试题G：砝码称重 DP，难！试题H：异或数列 技巧性题目，不要太纠结，看看怎么做就行了，考试的时候未必能想到。试题I：双向排序 暴力循环，vector容器，sort()排序，注意边界元素的值。#include&amp;lt;iostream&amp;gt;#include&amp;lt;vector&amp;gt;#include&amp;lt;algorithm&amp;gt;using namespace std;const int maxn = 1e6+1;int main() { vector&amp;lt;int&amp;gt; vec(maxn); int n, m; cin &amp;gt;&amp;gt; n &amp;gt;&amp;gt; m; for (int i = 0; i &amp;lt; n; ++i) { vec[i] = 1 + i; } for (int i = 0; i &amp;lt; m; ++i) { int p, q; cin &amp;gt;&amp;gt; p &amp;gt;&amp;gt; q; if (!p) { sort(vec.begin(), vec.begin() + q, greater&amp;lt;int&amp;gt;()); } else { // 在这里调试了半天 迭代器指向的位置要对 sort(vec.begin() + q - 1, vec.begin() + n); } } for (int i = 0; i &amp;lt; n; ++i) { cout &amp;lt;&amp;lt; vec[i] &amp;lt;&amp;lt; &quot; &quot;; } return 0;}试题J：分果果 动态规划，单调栈？难度较大。大学组:试题A：ASC#include&amp;lt;cstdio&amp;gt;using namespace std;int main() { // 字符型变量存储的不是字符 而是ASCII值 直接以整数形式输出即可 printf(&quot;%d&quot;, &#39;L&#39;); return 0;}试题B：空间#include&amp;lt;iostream&amp;gt;using namespace std;int main() { // 1MB=1024KB 1KB=1024B 1B=8b cout &amp;lt;&amp;lt; 256 * 1024 * 1024 / (32 / 8); return 0;}试题D：相乘#include&amp;lt;iostream&amp;gt;using namespace std;int main() { const int n = 1e9 + 7; // 数比较大 直接用long long for (long long i = 1; i &amp;lt;= n; ++i) { if (i * 2021 % n == 999999999){ cout &amp;lt;&amp;lt; i; } } return 0;}试题G：最少砝码 推导和数学证明#include&amp;lt;iostream&amp;gt;using namespace std;int main() { // 贪心思路：每当当前砝码的称重范围不足时 我们都要加入新的砝码 // 我们希望加入的那个砝码能够最大c程度的扩充砝码称重范围 // 递推找思路： // n == 1时 所加砝码重量为1 当前砝码为1 总重量为1 // n == 2时 所加砝码重量为1+2=3 当前砝码为1 3 总重量为4 // n == 3时 所加砝码为4+5=9 当前砝码为1 3 9 总重量为14 // 最大程度扩大范围 当前重量为i 下一次称重重量为i+1 所以加i + (i+1) long long n; cin &amp;gt;&amp;gt; n; // 输入 int weight = 1; // 加入的砝码重量 int count = 1; // 当前砝码数量 int total = 1; // 能够称出的最大重量 while (total &amp;lt; n) { // 最大重量小于输入时 需要加砝码 ++count; // 砝码数量+1 weight *= 3; total += weight; } cout &amp;lt;&amp;lt; count; return 0;}试题H：杨辉三角形 数学，找规律，二分查找。#include&amp;lt;iostream&amp;gt;using namespace std;typedef long long ll;int n;// 计算C(a, b)ll C(int a, int b) { ll res = 1; for (int i = a, j = 1; j &amp;lt;= b; --i, ++j) { res = res * i / j; if (res &amp;gt; n) return res; // 大于n就无意义了 } return res;}int main(){ cin &amp;gt;&amp;gt; n; for (int k = 16; ~k; k--) { // 二分法查找数值 右边界取n和l最大的 防止越界 // res表示所找元素值在的行数 int l = 2 * k, r = max(n, l), res = -1; while (l &amp;lt;= r) { int mid = l + r &amp;gt;&amp;gt; 1; if (C(mid, k) &amp;gt;= n) res = mid, r = mid - 1; else l = mid + 1; } if (C(res, k) == n) return cout &amp;lt;&amp;lt; (res + 1) * res / 2 + k + 1 &amp;lt;&amp;lt; &#39;\\n&#39;, 0; } return 0;}试题I：左孩子右兄弟 dfs，递归，上面的链接讲的很详细，这里代码加点自己的注释。#include&amp;lt;iostream&amp;gt;#include&amp;lt;vector&amp;gt;using namespace std;vector&amp;lt;int&amp;gt; f[100050]; // 这个f[i]类似一个哈希表 记录以i结点为父亲的所有孩子结点// 递归思路：树的最大高度=父节点孩子的数目+以它的孩子为父节点的子树的最大深度int dfs(int node) { int count = 0; // 存储每一个结点的最大孩子数目 if (f[node].size() == 0) return 0; // 没有孩子就return for (int i = 0; i &amp;lt; f[node].size(); ++i) { // 遍历node结点的所有孩子 找到拥有最大深度的子结点 递归就发生在此处 // f[node][i] 表示结点node的第i个子节点 count = max(count, dfs(f[node][i])); } // 递归出口 该结点的兄弟结点数 + 拥有最大深度的子节点 return count + f[node].size(); }int main() { int n; // 结点个数 int t; // 父节点编号 cin &amp;gt;&amp;gt; n; for (int i = 2; i &amp;lt;= n; ++i) { // 根节点为1 所以从第二个结点开始 cin &amp;gt;&amp;gt; t; // i结点的父亲为t结点 所以f[t].size()可以找出t的子节点数目 f[t].push_back(i); } cout &amp;lt;&amp;lt; dfs(1); // 从根节点可以深度搜索 return 0;}试题J：括号序列 动态规划，难，上面是题解链接，后续再看吧。这个思路很清晰，只不过是python。" }, { "title": "C++Primer5 第14章 重载运算符和类型转换", "url": "/posts/C++Primer14/", "categories": "笔记, C++", "tags": "笔记, C++Primer5, C++", "date": "2022-03-25 23:35:10 +0800", "snippet": "说明：通过重载类间运算符完成类对象之间的类型转换。基本概念1、重载运算符函数的参数数量与该运算符作用的运算对象数量一样多。注意：如果是成员函数，因为this绑定到左侧运算对象，所以成员运算符的参数数量比运算对象的数量少一个。2、对于一个运算符函数来说，它或者是类的成员，或者至少含有一个类类型的参数。 如果都是内置类型的话，运算符的含义无法改变，就无意义了。3、选择作为成员函数或者非成员函数？在某些时候别无选择，因为有的运算符必须作为成员；其它情况下，运算符作为普通函数比作为成员函数更好。 为什么更好？因为作为成员函数，它的左侧运算对象必须是运算符所属类的一个对象，左侧运算对象调用运算符函数完成运算。 string s = &quot;world&quot;; // 如果operator+是成员函数的话string t = s + &quot;!&quot;; // 正确 s.operator+(&quot;!&quot;)string u = &quot;hi&quot; + s; // 错误 &quot;hi&quot;.operator+(s) 幅值=、下标[]、调动()、成员访问箭头-&amp;gt;运算符必须是成员； 复合赋值运算符一般来说应该是成员，但并非必须； 改变对象运算状态或者与给定类型密切相关的运算符，如递增、递减和解引用运算符，通常应该是成员； 具有对称性的运算符可能转换任意一端的运算对象，如算术、相等性、关系和位运算符等，通常是非成员函数。输入和输出运算符重载输出运算符«ostream &amp;amp;operator&amp;lt;&amp;lt;(ostream &amp;amp;os, const Sales_data &amp;amp;item{ os &amp;lt;&amp;lt; item.isbn &amp;lt;&amp;lt; &quot; &quot; ; return os;} 第一个形参是一个非常量ostream对象的引用，之所以是非常量，是因为向流写入内容会改变其状态，该形参是引用是因为我们无法直接赋值一个ostream对象。 第二个参数是常量引用，引用是因为我们希望避免复制实参，常量是因为打印对象不会改变对象的内容。 为了与其它输出运算符保持一致，operator«返回它的ostream形参。 1、输出运算符因避免格式化操作，主要负责打印内容而非控制格式。 2、必须是非成员函数，否则，它的左侧运算对象是类的一个对象！重载输入运算符»istream &amp;amp;operator&amp;gt;&amp;gt;(istream &amp;amp;is, Salse_data &amp;amp;item) { double price; // 不需要初始化 因为我们会读入它 is &amp;gt;&amp;gt; items.bookNo &amp;gt;&amp;gt; item.units_sold &amp;gt;&amp;gt; price; // 输入检查！！！ if (is) { items.revenue = item.units_sold * price; } else { item = Sales_data(); // 输入失败 对象被赋予默认状态 } return is;} 第一个参数是读取流的引用 第二个参数非常量，因为目的就是将数据读入这个对象中 返回某个给定流的引用 注意：必须处理输入可能失败的情况，重载输出运算符不用。 输入错误可能有类型错误或者读到文件末尾或其它错误。算术和关系运算符1、因左侧和右侧运算对象可以进行转换，一般为非成员函数。因不需要改变运算对象的状态，所以形参都是常量引用。2、如果类定义了算术运算符，一般也会定义一个对应的符合赋值运算符，此时，最有效的方法就是使用复合赋值运算符来定义算术运算符。 为什么？因为算术运算符会把运算结果存到一个临时的局部变量中，再返回这个局部变量的副本，而是用复合赋值运算符则可避免该消耗。赋值运算符赋值运算符必须定义成成员函数，符合赋值运算符可以不是，但是还是倾向于把包括它在内的所有赋值运算符都定义在类的内部。下标运算符如果一个类包含下标运算符，通常会定义两个版本：一个返回普通引用，另一个是类的常量成员并且返回常量引用。 为什么返回引用？因为这样下标可以出现在赋值运算符的任意一端。 为什么定义常量版本？因为如果下标运算符作用于一个常量对象时，需要返回常量引用以确保不会给返回的对象赋值。class StrVec {public: // 普通引用版本 string &amp;amp;operator[](size_t n) { return elements[n]; } // 常量成员且返回常量引用版本 const string &amp;amp;operator[](size_t n) const { return elements[n]; }private: string *elements; // 指向数组首元素的指针};递增和递减运算符1、定义递增和递减运算符应该同时定义前置版本和后置版本，因为改变的是所操作对象的状态，所以应该被定义为类的成员。2、定义前置递增、递减运算符： 为了和内置版本一致，应该返回递增或递减后对象的引用 工作机理都需要检查索引值是否有效，若无异常，则返回引用StrBlobPtr&amp;amp; StrBlobPtr::operator++() { // 如果curr已经指向了容器的尾后位置 无法递增 check(curr, &quot;increment past end of StrBlobPtr&quot;); ++curr; return *this;};StrBlobPtr&amp;amp; StrBlobPtr::operator--() { --curr; // 如果curr是0 无法递减 check(curr, &quot;decrement past begin of StrBlobPtr&quot;); return *this;};3、区分前置、后置运算符：为了解决这个问题，后置版本接受一个额外的（不被使用的）int类型的形参。当我们使用后置运算符时，编译器为这个形参提供一个值为0的实参。一般我们不适用这个额外的形参，它的唯一作用就是区分前置和后置版本，而不是参与运算。不用它，所以无需命名。为了与内置类型保持一致，后置运算符返回对象原值而非引用。后置运算符用各自的前置版本来完成，且无需检查有效性。class StrBlobPtr {public: StrBlobPtr operator++(int); StrBlobPtr operator--(int);};成员访问运算符函数调用运算符1、类定义了调用运算符，则该类的对象称为函数对象。struct AbsInt { int operator()(int val) const { return val &amp;lt; 0 ? -val : val; }};int i = -42;AbsInt obj;int absi = obj(i); // 将i传给obj.operator() 即调用成员函数2、lambda是函数对象" }, { "title": "LeetCode100题记录", "url": "/posts/leetcode100/", "categories": "思考", "tags": "总结, LeetCode, 算法", "date": "2022-03-25 00:00:00 +0800", "snippet": "就在刚刚，力扣终于突破三位数了，完整刷完了100道题，虽然远远未达到预期计划，但是还是要记录一下，并且顺着总结一下刷题中出现的问题以及后续规划。LeetCode100开始：力扣是从去年十一月份开始刷的，除去中间疫情严重时期封校以及寒假的时间，到现在也有四个月了，但是从记录上也可以看到整体刷题时间也就两个月多一点，说明有将近一半时间没能刷题。。。总结：坚持，坚持，还是坚持。自己数据结构和算法本就是一块白板，如果再不多刷题，估计秋招面试会崩掉。虽然在没有刷题的时候干了其他事，也看了不少其它书籍，但是自己明显对刷题的重视度不够，而且不够坚定，坚持不下来每天做题，刷题需要一种状态，只有每天都去做，才能渐入佳境，慢慢有所感悟。还有一个就是自己编程能力着实差，有些题目有想法缺实现不出来，更不用说看完不知所以的题目了，不过虽然才刷了100道题目，但进步还是有的，之前感觉难的有些题目现在感觉也能看懂了，看懂题解就是胜利！哈哈，真够菜的。。。后续计划：距离秋招还有4、5个月，现在必须坚持每天刷题目了。目前先将剑指offer、代码随想录剩余部分刷完，然后再LeetCode Hot100，完成这些之后看自己的情况再做针对性的练习吧。题目在于精不在于多，不要过度在于速度，要反复的刷一些经典题，针对自己的短板刷题，做过的题拿出来能ac，就很成功了。" }, { "title": "C++Primer5 第13章 拷贝控制", "url": "/posts/C++Primer13/", "categories": "笔记, C++", "tags": "笔记, C++Primer5, C++", "date": "2022-03-06 23:35:10 +0800", "snippet": "说明：类的拷贝、赋值、移动、销毁等操作。类的拷贝控制操作： 构造：拷贝构造函数、移动构造函数。定义了用同类型的另一个对象初始化本对象时作什么； 赋值：拷贝赋值运算符、移动赋值运算符。定义了将一个对象赋予同类型的另一个对象时做什么。 析构：析构函数。定义了当此类型对象销毁时做什么。拷贝、赋值与销毁拷贝构造函数定义：如果一个构造函数的第一个参数是自身类类型的引用，且任何额外参数都有默认值，则此构造函数是拷贝构造函数。 拷贝构造函数的第一个参数必须是引用类型。拷贝构造函数被用来初始化非引用类类型参数，如果其参数不是引用类型，则调用永远也不会成功：为了调用拷贝给构造函数，需要先拷贝它的实参，但为了拷贝实参，又需要调用拷贝构造函数，如此循环。 第一个参数可以为非const引用，但是几乎总是一个const引用。 拷贝构造函数会被隐式地使用，因此不应该是explicit的。class Foo {public: Foo(); // 默认构造函数 Foo(const Foo&amp;amp;); // 拷贝构造函数};合成拷贝构造函数1、与合成默认构造函数不同，即使我们定义了其它构造函数，编译器也会为我们合成一个拷贝构造函数。2、一般情况下，合成拷贝构造函数会将其参数的成员逐个拷贝到正在创建的对象中。3、每个参数成员的类型决定了它如何拷贝：对类类型的成员，会使用其拷贝构造函数来拷贝；内置类型的成员则直接拷贝。拷贝初始化直接初始化与拷贝初始化的差异： 直接初始化：实际上是要求编译器使用普通的函数匹配来选择与我们提供的参数最匹配的构造函数。 拷贝初始化：我们要求编译器将右侧运算对象拷贝到正在创建的对象中，如果需要的话还要进行类型转换。拷贝初始化通常是依靠拷贝构造函数和移动构造函数来完成。什么时候使用拷贝构造函数？拷贝初始化发生时。 使用=定义变量 将一个对象作为实参传递给一个非引用类型的形参 从一个返回类型为非引用类型的函数返回一个对象 用{}初始化一个数组中的元素或一个聚合类中的成员 某些类类型还会对它们所分配的对象使用拷贝初始化拷贝初始化的限制如果我们希望使用一个explicit构造函数，就必须显式的使用。 简而言之就是不要使用隐式转化，需要同类型之间进行拷贝。void f(vector&amp;lt;int&amp;gt;);f(10); // 错误 vector接受大小参数的构造函数是explicitf(vector&amp;lt;int&amp;gt;(10)); // 正确 使用int生成临时对象拷贝赋值运算符是什么？ 拷贝赋值运算符是函数命名为operator=的，并接受与类相同类型的参数。class Foo {public: Foo&amp;amp; operator=(const Foo&amp;amp;); // 拷贝赋值运算符};什么时候使用？ 发生赋值时使用此运算符。合成拷贝赋值运算符？ 将右侧对象的每个非static成员赋予左侧运算对象的对应成员，使用该成员的拷贝赋值运算符。什么时候生成? 在类没有定义拷贝赋值运算符是自己生成。析构函数是什么? 是类的一个成员函数，由~加类名构成，无返回值，不接受参数。class Foo {public: ~Foo(); // 析构函数};完成什么工作? 在一个构造函数中，成员初始化是在函数执行之前完成的，按照他们在类中出现的顺序进行初始化。在一个析构函数中，首先执行函数体，然后销毁成员，按照成员初始化顺序的逆序销毁。 构造函数有初始化列表来控制成员初始化。而析构函数是隐式的，成员销毁时发生什么完全依赖于成员的类型。销毁类类型的成员需要执行成员自己的析构函数，内置类型没有析构函数，因此销毁内置类型成员什么也不需要做。什么时候调用析构函数？ 变量离开作用域时被销毁。 当一个对象被销毁时，其成员被销毁。 容器（标准库和数组）被销毁时，其元素被销毁。 动态分配的对象，delete时被销毁。 临时对象，创建它的完成表达式结束时被销毁。合成析构函数？ 当一个类未定义自己的析构函数时，编译器生成合成析构函数。注意：析构函数本身并不直接销毁成员！！！成员是在析构函数之后隐含的析构阶段中销毁的。在整个对象销毁过程中，析构函数体是作为成员销毁步骤之外的另一部分而进行的。三/五法则需要析构函数的类也需要拷贝和赋值操作。需要拷贝操作的类也需要赋值操作，反之亦然。使用=default我们可以通过将拷贝控制成员定义为=default来限时地要求编译器生成合成的版本。 使用=default修饰成员的声明时，合成的函数将隐式的声明成内联的（就像其它任何类内声明的成员函数一样）。如果我们不希望合成的成员函数是内联的，应该只对成员的类外定义使用=default，如下。 只能对具有合成版本的成员函数使用，即默认构造函数和拷贝控制成员（拷贝构造，拷贝赋值运算符，析构函数）。class Sales_data {public: // 拷贝控制成员 Sales_data() = default; Sales_data(const Sales_data&amp;amp;) = default; Sales_data&amp;amp; operator = (const Sales_data&amp;amp;); ~Sales_data(); = default;};Salse_data&amp;amp; Sales_data::operator=(const Sales_data&amp;amp;) = default; // 类外定义使用 非内联阻止拷贝有时候，我们不需要拷贝和赋值操作，因此需要阻止拷贝。但是即使不定义拷贝控制成员，编译器仍然会自动生成，所以还是得定义。在C++11，我们可以将拷贝构造函数和拷贝赋值运算符声明为删除的函数来阻止拷贝。删除的函数：我们虽然声明了它们，但是不能以任何方式使用它们。Struct NoCopy { NoCopy() = default; // 使用合成的默认构造函数 NoCopy(const NoCopy&amp;amp;) = delete; // 阻止拷贝 NoCopy&amp;amp; operator=(const NoCopy&amp;amp;) = delete; // 阻止赋值 ~NoCopy() = default; // 使用合成的析构函数 // ...};=default与=delete的不同 =delete必须出现在函数第一个声明的时候。 我们可以为任何函数指定=delete，而智能对编译器可以合成的默认构造函数或拷贝控制成员使用=default。当我们希望引导函数匹配过程时，删除函数有时是有用的。析构函数不能是删除的成员我们不能删除析构函数，因为那样无法销毁此类型的对象了。合成的拷贝控制成员可能是删除的本质上，当不可能拷贝、赋值、或销毁类的成员时，类的合成拷贝控制成员就被认为是删除的。注意：旧标准类是将其声明为private来阻止拷贝的。拷贝控制与资源管理赋值运算符的编写 将一个对象赋予它自身，赋值运算符也必须能够正确工作。 大多数赋值运算符组合了析构函数和拷贝构造函数的工作。首先：将右侧运算对象拷贝到一个局部临时对象中；然后：销毁左侧运算对象的现有成员；最后：将数据从临时对象拷贝到左侧运算对象成员中。交换操作为什么要定义类自己的swap函数？ 因为标准库的std::swap()进行了不必要的拷贝。// std::swap() 一次拷贝 两次赋值HasPtr temp = v1; // 创建v1的值的一个临时副本v1 = v2; // 将v2的值赋给v1v2 = temp; // 将保存的v1的值v2理论上，这些内存分配是不必要的，我们希望swap交换指针，而不是分配新副本（指针副本远比数据副本小得多）。string* temp = v1.ps; // 为指针创建副本v1.ps = v2.ps;v2.ps = temp;因此，编写的swap函数应该是这样的：class HasPtr { friend void swap(HasPtr&amp;amp;, HasPtr&amp;amp;); // ...private: int i; string ps;};inlinevoid swap(HasPtr &amp;amp;lhs, HasPtr &amp;amp;rhs) { using std::swap; swap(lha.ps, rhs.ps); // 交换指针 而不是string数据 swap(lhs.i, rhs.i); // 交换int成员} friend是为了访问类的私有成员。 inline是为了优化代码，这本就是swap存在的目的。应该调用类自己的swap，而不是std::swap正确的swap函数如下：void swap(Foo &amp;amp;lhs, Foo &amp;amp;rhs) { using std::swap(); swap(lhs.h, rhs.h); // 使用HasPtr版本的swap } 注意：如果类未定义自己的swap，则调用标准库版本，如果定义自己的swap，则优先调动类swap版本。原因在p616。 为什么第一个swap没有隐藏第二个swap？p706。对象移动新标准的一个最主要的特性是可以移动而非拷贝对象的能力。 标准库容器，shared_ptr类既支持移动也支持拷贝，IO类和unique_ptr类可以移动但是不能拷贝。有些拷贝是不必要的。右值引用1、右值引用就是必须绑定到右值上的引用，用&amp;amp;&amp;amp;表示。2、左值有持久的状态看，而右值要么是字面常量，要么是在表达式求值过程中创建的临时对象。变量时左值，我们不能将一个右值引用直接绑定到一个变量上，即使这个变量是右值引用类型也不行。3、可以使用move将一个左值显式的转换为对应的右值引用类型。 move告诉编译器，我们有一个左值，希望像一个右值一样处理它。使用move就意味着承诺：除了对rr1赋值和销毁外，不再使用它。int &amp;amp;&amp;amp;rr3 = std::move(rr1); // ok移动构造函数和移动赋值运算符移动构造函数1、如果类能同时支持移动和拷贝操作，将受益（避免不必要的拷贝），而为了支持移动操作，必须定义移动构造函数和移动赋值运算符。2、移动构造函数与拷贝构造函数的不同： 移动构造函数第一个参数也是引用，其余额外参数有默认值。但是移动构造函数是右值引用，拷贝构造函数是左值引用。 与拷贝构造函数不同，移动构造函数不分配任何新内存。 它接管指定类中的内存，接管内存之后，将给定对象中的指针都置为nullptr，这样就完成了从给定对象的移动操作。此对象仍然会存在，但最终被销毁。 3、由于移动操作“窃取”资源，它通常不分配任何资源，因此，移动操作通常不会抛出任何异常。 指定noexcept让一个函数不抛出异常。需要注意的是，在声明和定义中都需要指定，如下。class StrVec {public: StrVec(StrVec&amp;amp;&amp;amp;) noexcept; // 移动构造函数 没const // ...};StrVec::Strvec(StrVec &amp;amp;&amp;amp;s) noexcept : 初始化 { 函数体 };4、为什么需要noexcept？ 以vector举例，vector使用push_back时可能要分配新内存，在分配新内存后，将旧空间移拷贝到新内存中，如果这个过程中出现了异常，vector可以释放新内存，然后保存原有的旧元素不变。但是移动操作没有新内存，所以移动过程中不能出现异常，否则可能会释放当前内存导致意想不到的问题。移动赋值运算符类似拷贝赋值运算符，移动赋值运算符必须能够正确处理自赋值。StrVec&amp;amp; StrVec::operator=(StrVec &amp;amp;&amp;amp;rhs) noexcept { // 直接检测自赋值 if (this != &amp;amp;rsh) { free(); // 释放已有元素 elements = rhs.elements; // 从rhs接管资源 rhs.elements = nullptr; // 将rhs置为可析构状态 } return *this;}为什么要检测自赋值？ 因为我们不能在使用右侧资源对象的资源之前就释放左侧资源对象（二者可能是相同的资源）。移后源对象必须可析构有时在移动操作之后，源对象可能会被销毁。所以移后源对象必须保持有效地、可析构的状态，但是用户不能对其值进行任何假设（我们不知道其中是否有值，其值时什么）。合成的移动操作只有当一个类未定义任何自己版本的拷贝控制成员，且类的每个非static数据成员都可以移动时，编译器才会为它生成合成的移动操作。更新后的三五法则： 一般来说，如果一个类定义了任何一个拷贝操作，它就应该定义所有五个操作。因为拷贝一个资源可能会导致一些额外开销，而移动操作必须也要定义拷贝操作，否则被认为是删除的。移动右值，拷贝左值，但如果没有移动构造参数，右值也被拷贝1、如果既有拷贝又有移动操作，编译器使用普通的函数匹配规则来确定使用哪个操作。左值优先拷贝，右值优先移动。2、用拷贝构造函数代替移动构造函数几乎肯定是安全的，因此无移动操作时，右值也可以被拷贝。不要随意使用移动操作由于一个移后源对象具有不确定的状态，对其调用std::move是危险的，当我们调用move时，必须确定移后源对象绝对没有其它用户。右值引用和成员函数如果一个成员函数同时声明拷贝和移动版本，它也能从中受益。void push_back(const X&amp;amp;); // 拷贝void push_back(X&amp;amp;&amp;amp;); // 移动 注意：当我们希望用移动操作“窃取”实参时，通常传递一个右值引用，实参不能是const的。而使用左值引用拷贝一个对象时，不应该改变原对象，因此应该是const的。引用限定符可以使&amp;amp;或&amp;amp;&amp;amp;，分别指出this可以指向一个 左值和一个右值。引用限定符只能用于非static成员函数，且必须出现在函数的声明和定义中。如果同为const成员函数，则在const之后。 如果一个成员函数有引用限定符，则具有相同参数列表的所有函数都应该有引用限定符。" }, { "title": "网页资料202203", "url": "/posts/web-sources-202203/", "categories": "其它", "tags": "总结, 网页资料", "date": "2022-03-01 00:00:00 +0800", "snippet": "看书过程中总是有一些不熟悉、或之前看过却想不起来的琐碎知识点，看了忘，忘了看，不如在搜索的时候，把一些好的资源链接直接copy下来，这样也可以利用琐碎时间浏览一下加深印象。2022年3月份网页资料：仅部分，有些是图片形式，以后全部整成链接。static用法 rand()函数emplace_back与push_back()区别stoito_stringunordered_mapdequeprintf()sort()abort()try-catch静态、动态类型memset()gcd &amp;amp;&amp;amp; lcm0x3f3f3f3flong &amp;amp;&amp;amp; shortrange for对象数组.hsetunordered_setheap区assign()C++四种类型转换C++__cplusplusC++读写文件并查集基础 and 一个有趣的讲解C++ vector中使用pair 及 pair的基本用法总结" }, { "title": "C++Primer5 第12章 动态内存", "url": "/posts/C++Primer12/", "categories": "笔记, C++", "tags": "笔记, C++Primer5, C++", "date": "2022-02-26 16:24:51 +0800", "snippet": "说明：动态内存的使用以及使用智能指针来管理动态内存。动态内存与智能指针1、动态内存的管理是通过一对运算符来完成的： new：在动态内存中为对象分配空间并返回一个指向该对象的指针，我们可以选择对对象进行初始化； delete：接受一个动态内存的指针，销毁该对象，然后释放与之关联的内存。2、动态内存使用容易出现问题： 内存泄露：忘记释放内存； 空悬指针：有时候尚有指针引用内存的情况下我们释放了内存，产生引用非法内存指针； 同一块内存释放两次，自由空间可能会被破坏。3、标准库提供了智能指针来管理动态对象： shared_ptr：允许多个指针指向同一个对象； unique_ptr：“独占”所指向的对象； weak_ptr：伴随类，是一种弱引用，指向shared_ptr所管理的对象。// 智能指针支持的操作shared_ptr&amp;lt;T&amp;gt; sp;unique_ptr&amp;lt;T&amp;gt; up; // 空智能指针 指向类型T的对象p; // 用作条件判断 若p指向一个对象 则为true*p; // 解引用 获得它指向的对象p-&amp;gt;mem; // 指针对象调动成员p.get(); // 返回p保存的指针 小心使用swap(p, q);p.swap(q); // 交换p q中的指针shared_ptr类智能指针也是模板，创建智能指针时，必须提供类型信息。默认初始化的智能指针保存着一个空指针。智能指针与普通指针的使用方式类似，可以解引用，可以当做条件（是否为空指针）判断。// shared_ptr独有的操作make_shared&amp;lt;T&amp;gt;(args); // 返回一个shard_ptr 对象类型为T 初始值为argsshare_pet&amp;lt;T&amp;gt; p(q); // p是q的拷贝 递增q中的引用计数p = q; // 递增p的引用计数 递减q的引用计数 指针必须能相互转换p.unique(); // 若p.use_count()为1 返回true 否则falsep.use_count(); // 返回与p共享的指针数量 可能很慢 主要用于调试make_shared函数最安全的分配和使用动态内存的方法是调用make_shared()标准库函数。// 指向一个值为42的int的shared_ptrshared_pte&amp;lt;int&amp;gt; p = make_shared&amp;lt;int&amp;gt;(42); // 指定类型和初始值// 使用autoauto p = make_shared&amp;lt;int&amp;gt;(42); // 简洁shared_ptr的拷贝和赋值每个share_ptr都会记录有多少个shared_ptr指向相同的对象。引用计数：每个shared_ptr都有一个关联的计数器。 无论何时拷贝一个shared_ptr，计数器都会递增； 给shared_ptr赋予一个新值或是shared_ptr被销毁时，计数器会递减； 一旦一个shared_ptr的计数器变为0，它就会自动释放所管理的对象。shared_ptr自动销毁所管理的对象，还会自动释放所关联的内存shared_ptr是通过调用析构函数来完成销毁操作的。当动态对象不再被使用时，shared_ptr类会自动释放动态对象。保证shared_ptr在无用时不再保留非常重要，如果忘记，会浪费内存。使用了动态生存期的类使用动态内存有以下三种原因： 不知道自己需要使用多少对象，如容器类； 不需要所需对象的准确类型； 程序需要在多个对象间共享数据。直接管理内存使用new动态分配和初始化对象在自由空间分配的内存时无名的，new无法为分配的对象命名，而是返回一个指针。默认情况下，动态分配的对象是默认初始化的，这意味着内置类型和组合类型的值将是未定义的，而类类型对象将用默认构造函数进行初始化。int* p = new int; // 未未定义值int* ps = new string; // 空stringint* p2 = new int(); // 直接初始化 值为0动态分配const对象合法，但是必须指定初始值：const int* p = new const int(1024);内存耗尽placement new表达式允许向new传递额外的参数：int* p = new int; // 如果内存不够分配失败 抛出bad_alloc异常int* p2 = new (nothrow) int; // 如果分配失败 new返回一个空指针 不抛出异常释放动态内存delete表达式执行两个动作：销毁指针指向的对象，释放内存。传递给delete的指针必须指向动态分配的内存，或者一个空指针。一个const对象的值不能被改变，但本身可以被销毁。内置指针管理的动态内存在被显式释放前一直都会存在。空悬指针：指向一个曾经保存数据对象但现在已经无效的内存的对象。shared_ptr与new结合使用可以使用new返回的指针来初始化智能指针，但是我们必须将shared_ptr显式绑定到一个想要返回的指针上。 接受指针参数的智能指针构造函数是explicit的，因此，我们不能将一个内置指针隐式的转换为一个智能指针，必须、只能使用直接初始化形式来初始化一个智能指针。shared_ptr&amp;lt;int&amp;gt; p(new int(1024));shared_ptr&amp;lt;int&amp;gt; p = new int(1024); // 错误 不能隐式转换！！！不要混合使用普通指针和智能指针… 将一个shared_ptr绑定到一个普通指针时，就将内存管理的责任交给了这个shared_ptr。一旦这样做了，就不应该使用内存指针来访问shared_ptr所指向的内存。…也不要使用get初始化另一个智能指针或为智能指针赋值。 只有确认代码不会delete指针的情况下才能使用get。其它shared_ptr操作reset会更新引用计数，如果需要的话，会释放p指向的对象，常与unique一起使用：// 指定唯一客户if (!p.unique()) { p.reset(new string(*p)); // 重新指向 变成唯一}*p += nuwVal; // 唯一用户 可以进行操作智能指针和异常如果使用智能指针，即使程序块过早结束，智能指针也能确保在内存不在需要时将其释放。而直接管理的内存在发生异常时不会自动释放。voif f() { shared_ptr&amp;lt;int&amp;gt; sp(new int(42)); // 异常} // 函数结束后 shared_ptr自动释放内存 sp在销毁前会检查引用计数，如果是唯一指针，则释放内存。智能指针和哑类并不是所有类都定义了自己的析构函数，比如为C和C++两种语言设计的类，这些类分配资源，但是没有定义析构函数释放这些资源。一个可行的方法就是用智能指针。使用自己的释放操作使用shared_ptr管理未定义析构函数的类，需要定义一个删除器来代替delete，这个函数可以完成对shared_ptr中保存的指针进行释放的操作。unique_ptr1、某个时刻只能有一个unique_ptr指向给定对象，当unique_ptr被销毁时，它所指向的对象也被销毁。2、定义一个unique_ptr时，需要将其绑定到一个new返回的指针上，且使用直接初始化。3、unique_ptr拥有它指向的独享，因此不支持普通的拷贝或赋值操作。unique_ptr&amp;lt;int&amp;gt; p(new int(1024)); // 创建unique_ptrunique_ptr&amp;lt;int&amp;gt; p2(p); // 错误unique_ptr&amp;lt;int&amp;gt; p3 = p2; // 错误4、可以调用release或reset将指针的所有权从一个unique_ptr转移给另一个unique_ptr。unique_ptr&amp;lt;string&amp;gt; p2(p1.release()); // release放弃对指针控制 并返回指针 把p1置为空 然后p2接手返回的指针 从而完成转移p2.reset(p2.release()); // 释放p2内存 指向p3p2.release(); // 错误 p2不会释放内存 并且丢失了指针5、例外：我们可以拷贝或赋值一个将要销毁的unique_ptr： 编译器知道要返回的代码即将被销毁，执行一种特殊的“拷贝”。unique_ptr&amp;lt;int&amp;gt; clone(int p) { return unique_ptr&amp;lt;int&amp;gt;(new int(p)); // 正确}6、向unique_ptr传递删除器：unique_ptr&amp;lt;objT, delT&amp;gt; p(new objT, fcn); // 需要制定删除器的类型shared_ptr&amp;lt;objT&amp;gt; p(new objT, fcn); // 注意区别// 使用类型为delT的对象来释放objT对象 它会调用fcn类型对象weak_ptr1、weak_ptr是一种不控制所指向对象生存期的智能指针，它指向由一个shared_ptr管理的对象。不会改变shared_ptr的引用计数。一旦最后一个指向对象的shared_ptr被销毁，对象就会被释放。即使有weak_ptr指向对象，对象也还是会被释放。因此为“弱”共享对象。auto p = make_shared&amp;lt;int&amp;gt;(42);weak_ptr&amp;lt;int&amp;gt; wp(p); // 初始化weak_ptr2、由于对象可能不存在，不能用weak_ptr直接访问对象，必须调用lock。此函数检查weak_ptr指向的对象是否仍存在，存在，返回shared_ptr。if(shared_ptr&amp;lt;int&amp;gt; np = wp.lock()){ // lock返回true才会进入循环体}动态数组首先应该明确：尽量使用标准库容器而不是动态分配的数组，使用容器更为简单，更不容易出错，且可能有更好的性能。 使用容器类可以使用默认的拷贝、赋值、和析构操作，分配动态数组需要自己定义。然后就是两个操作符：int* p = new int[size]; // 创建delete [] p; // 删除" }, { "title": "C++Primer5 第11章 关联容器", "url": "/posts/C++Primer11/", "categories": "笔记, C++", "tags": "笔记, C++Primer5, C++", "date": "2022-02-12 23:17:16 +0800", "snippet": "说明：关联容器时按照关键字来保存和访问的。本章主要介绍STL库关联容器。标准库提供八个关联容器，它们的不同体现在三个维度上： set（只保存关键字）或者map（保存键值对）。 关键字是否可重复，即multi。 元素是否有序，即unordered。map // 保存键值对set // 保存关键字multimap // 关键字可重复的mapmultiset // 关键字可重复的setunordered_map // 无序mapunordered_set // 无序setunordered_multimap // 无序 关键字可重复mapunordered_multiset // 无序 关键字可重复set使用关联容器map即为关联数组，和普通数组不同的地方在于其下标不必是整数，我们通过一个关键字而不是位置来查找值。set是关键字的简单集合，当判断一个值是否存在时，最有用。关联容器概述1、关联容器不支持顺序容器的位置相关的操作，如push_back等。关联容器的迭代器都是双向的。 由关键字存储，这些操作无意义。2、map和set的关键字必须唯一，如果有相同的，会覆盖，multi允许重复关键字。3、对于有序容器，关键字类型必须定义元素比较的方法。默认情况下，使用关键字类型的&amp;lt;运算符来比较两个关键字。4、为了使用自己定义的类型，需要提供比较操作的类型：应该是一种函数指针类型。bool cmp(const Sales_data&amp;amp; lhs, const Sales_data&amp;amp; rhs){ return lhs.isbn() &amp;lt; rhs.isbn();}// 使用cmp操作类型对关联容器的元素进行排序multiset&amp;lt;Sales_data, decltype(cmp)*&amp;gt; bookstore(cmp);5、pair类型的数据成员是public的，分别为first second，通过成员访问符号来访问它们。pair的默认构造函数对数据成员进行值初始化。关联容器操作关联容器迭代器1、我们不能改变一个元素的关键字，因此关联容器的关键字是const的。2、当解引用一个关联容器迭代器时，我们得到一个类型为容器的value_type的值的引用。对于map，该类型为pair类型，first保存const关键字，second保存值。对于set，该类型和关键字类型一致。auto map_iter = wordCount.begin();cout &amp;lt;&amp;lt; map_iter-&amp;gt;first;cout &amp;lt;&amp;lt; map_iter-&amp;gt;second;map_iter-&amp;gt;fitst = &quot;new key&quot;; // 错误 关键字为const++map_iter-&amp;gt;second; // 正确 可以通过迭代器改变元素3、遍历关联容器：map和set类型支持begin和end操作，因此和其他容器一样，可以通过这些函数获得迭代器，然后用迭代器遍历关联容器。4、我们通常不对关联容器使用泛型算法。一般的，使用关联容器定义的成员函数比使用泛型算法快的多，比如.count()和.find()成员函数。添加元素1、关联容器的insert成员向容器中添加一个元素或一个元素范围。对于map和set，插入一个已经存在的元素对容器没有任何影响。2、insert（或emplace）返回的值依赖于容器类型和参数。 对于不包含重复关键字的容器，添加单一元素返回一个pair，告诉我们插入操作是否成功。pair的first成员是一个迭代器，指向具有指定关键字的元素；second成员是一个bool值，指出元素是插入成功还是已经存在于容器中。成功为true，否则为false。 对允许重复的容器，接受单个元素的insert操作返回一个指向新元素的迭代器，无须返回一个bool值，因为总是插入一个新元素。auto ret = wordCount.insert({ word, 1 });if (!ret.second){ // 如果插入失败 即容器内已经存在该元素 ++ret.first-&amp;gt;second; // 递增计数器}删除元素c.erase(k); // 从c中删除指定关键字为k的元素 返回删除元素的数量c.erase(p); // 从c中删除迭代器p指定的元素 p必须指向一个真是存在的元素 // 返回一个指向p之后元素的迭代器c.erase(b, e); // 删除迭代器b e范围中的元素 返回emap的下标操作 map和unordered_map支持下标运算。使用下标运算符，如果元素未在容器内，将自动插入一个新的元素，并进行值初始化。 set不支持下标运算，因为元素本身就是关键字，因此获取一个和关键字相关联的值的操作无意义。 multimap和unordered_multimap不能进行下标操作，因为可能含有重复元素。访问元素1、如果不需要计数，最好使用find，否则使用count。c.find(k); // 返回一个迭代器 指向第一个关键字为k的元素 不存在返回endc.count(k); // 返回关键字为k的元素的数量2、使用find替代map中的下标操作。 有时，我们只是想知道一个给定关键字是否在map中，而不想改变map。下标运算符可能会插入元素，所以应该使用find替代。3、在multimap或multiset中查找元素string searchItem = (&quot;Alain de Botton&quot;); // 要查找的作者auto nums = authors.count(searchItem); // 元素的数量auto iter = authors.find(searchItem); // 此作者的第一本数while (nums){ cout &amp;lt;&amp;lt; iter-&amp;gt;second &amp;lt;&amp;lt; endl; ++iter; // 从这里可以看出find指向所有关键字 只是返回第一个 --nums; }无序容器1、无序容器不是使用比较运算符来组织元素，而是使用一个哈希函数和关键字类型的==运算符。无序日过去提供了和有序容器相同的操作。2、无序容器在存储在组织为一组桶，每个桶保存零个或多个元素。使用哈希函数将元素映射到桶。为了访问一个元素，首先计算元素的哈希值，它指定应该搜索哪一个桶。无序容器的性能依赖于哈希函数的质量和桶的数量和大小。相关管理操作：p395.3、我们可以直接定义关键字时内置类型（包括指针类型），string还是智能指针类型的无序容器。但是不能直接定义自定义类型的无序容器。我们需要提供函数来替代==运算符和哈希值计算函数，通过重载方式。" }, { "title": "C++Primer5 第10章 泛型算法", "url": "/posts/C++Primer10/", "categories": "笔记, C++", "tags": "笔记, C++Primer5, C++", "date": "2022-01-31 17:55:17 +0800", "snippet": "说明：本章主要讲述泛型算法和迭代器的更多细节。标准库并未给每个容器添加大量功能，而是提供了一组泛型算法，这些算法中的大多数都独立于任何特定的容器。概述1、大多数算法都是定义在algorithm头文件中，numeric中定义的有一组数值泛型算法。2、一般情况下，这些算法并不直接操作容器，而是遍历由两个迭代器指定的一个元素范围来进行操作。3、迭代器令算法不依赖于容器，但是算法依赖于容器元素类型的操作。 比如find算法用元素类型的==运算符与给定元素值比较，有些元素还要求元素类型支持&amp;lt;运算符。4、算法永远不会执行容器的操作！！！ 算法可能修改容器的值，在容器内移动元素，但永远不会直接添加或删除元素，也不会改变底层容器的大小。初始泛型算法理解算法的一个基本方法就是了解它们是否读取元素、改变元素或是重排元素。只读算法find// find返回第一个指向给定值元素的迭代器 没找到就返回endauto result = find(vec.begin(), vec.end(), val); // 迭代器范围+要寻找的值count// 返回容器内某个元素出现的次数int num = count(vec.begin(), vec.end(), val); // 迭代器范围+查找的元素accumulate// 定义在numeric头文件中 容器求和算法// 第三个参数决定了函数中使用哪个加法运算符以及 返回值的类型！int sum = accumulate(vec.begin, vec.end(), 0); // 迭代器范围+和的初值string sum = accumulate(v.begin(), v.end(), string(&quot;&quot;)); // 连接元素到string上string sum = accumulate(v.begin(), v.end(), &quot;&quot;); // 错误 const char*无+运算符equal// 确定两个序列是否保存相同的值 // 使用单一迭代器表示第二个序列的算法 都假设第二个序列至少与第一个序列一样长equal(v1.begin(), v1.end(), v2.begin()); // 迭代器范围+第二个容器的首迭代器写容器元素算法fill// fill将给定的值赋予输入序列中的每个元素fill(vec.begin(), vec.end(), val); // 迭代器范围+给定值vector&amp;lt;int&amp;gt; v;fill_n(v.begin(), 10, 0); // 向指定位置添加10个0 错误！！！因为容器为空 语句未定义back_inserter插入迭代器是一种向容器中添加元素的迭代器，不如back_insert，定义在头文件iterator中。 back_intserter接受一个指向容器的引用，返回一个与该容器绑定的插入迭代器。当我们通过此迭代器赋值时，赋值运算符会调用push_back将一个具有给定值的元素添加到容器中。vector&amp;lt;int&amp;gt; v;fill_n(back_inserter(v), 10, 0); // 正确 每次赋值都会在v上调用push_backcopy拷贝算法将输入范围中的元素拷贝到目的序列中。 传递考别的目的序列至少要包含与输入序列一样多的元素。int a1[] = { 0, 1, 2, 3, 4 };int a2[sizeof(a1)/sizeof(*a1)]; // a2和a1一样大// copy返回的是目的位置迭代器的值（递增后） 即a2的尾后迭代器auto ret = copy(begin(a1), end(a1), a2); // 把a1的内容拷贝给a2replacereplace算法读入一个序列，并将其中所有等于给定值的元素改为另一个值。replace(lst.begin(), lst.end(), 0, 42); // 迭代器范围+指定值+修改后的值// 如果希望保留原序列不变 需要备份replace_copy(lst.begin(), lst.end(), back_insert(vec), 0, 42);// 调用后lst未改变 vec包含lst的一个拷贝 原来在lst中值为0的元素在vec中变为42重排容器元素的算法sortuniqueunique重排容器的元素，将不重复的元素出现在容器的开始部分，返回的迭代器指向最后一个不重复元素之后的位置（即第一个有重复的元素），此位置之后的元素仍存在，但我们不知道它们的值。sort(word.begin(), word.end()); // 字典序排序auto end_unique = unique(word.begin, word.end()); // 指向不重复区域后一个位置迭代器word.erase(end_unique, word.end()); // 使用容器成员删除重复单词定制操作标准库允许我们使用自己定义的操作来代替默认运算符。谓词谓词是一个可调用的表达式，返回结果是一个能用作条件的值（即返回布尔值的函数）。一元谓词只接受单一参数，二元谓词接受两个参数。stable_sortsort(word.begin(), word.end()); // 按照字典序排序stable_sort(word.begin(), word.end(), isShorter); // 在字典序排序的基础上按照长度排序lambda表达式lambda介绍1、我们可以向一个算法传递任何类型的可调用对象。 对于一个对象或一个表达式，如果可以对其使用调用运算符，则称它是可调用的。2、目前使用过的可调用对象有哪些？ 函数 函数指针 重载了函数调用运算符的类 lambda表达式3、lambda表达式形式：一个lambda表达式表示一个可调用的代码单元，可以理解为一个未命名的内联函数。[捕获列表](参数列表) -&amp;gt; 返回类型 { 函数体 }lambda和函数的异同？ 调用方式相同，都使用调用运算符() 与函数不同，lambda可能定义在函数内部 与函数不同，lambda必须使用位置返回类型，即-&amp;gt; lambda可以忽略参数列表和返回类型，但必须永远包含捕获列表和函数体 与函数不同，lambda不能由默认参数向lambda传递参数与普通函数类似，实参初始化形参，但是不能有默认实参。使用捕获列表lambda通过将函数内部的局部对象包含在捕获列表中来指出将会使用这些变量。 先捕获，后使用！ 捕获列表只用于局部非static对象，lambda可以直接使用局部static对象和函数之外声明的名字。调用find_iffind_if用来查找第一个具有特定大小的元素，对输入序列中的每个元素调用给定的这个谓词（实质上就是一个函数），它返回第一个使谓词返回非0值的元素，如果不存在，返回尾后迭代器。find_if(word.begin(), word.end(), 谓词); // 迭代器范围+查找条件（谓词）auto wc = find_if(word.begin(), word.end(), [sz](const string&amp;amp; a) { return a.size() &amp;gt;= sz; }); // 返回第一个不小于sz的stringfor_each算法接受一个可调用对象，并对输入序列中每个元素调用此对象。for_each(wc, word.end(), [](const string&amp;amp; s){ cout &amp;lt;&amp;lt; s &amp;lt;&amp;lt; &quot;&quot;; });lambda捕获和返回值捕获与参数不同，被捕获的变量的值是在lambda创建时拷贝，而不是调用时拷贝。引用捕获当以引用捕获一个变量时，必须保证在lambda执行时变量时存在的。隐式捕获除了显示列出我们希望使用的变量之外，还可以让编译器根据lambda体中的代码来推断我们要使用哪些变量。应在捕获列表中写一个&amp;amp;或=，=表示采用值捕获方式，&amp;amp;表示采用引用捕获方式。如果希望对一部分变量采用值捕获，其它变量采用引用捕获，可以混合使用隐式捕获和显示捕获，但捕获的第一个元素必须是&amp;amp;或者=。for_each(word.begin(), word.end(), [&amp;amp;, c](const string&amp;amp; s){ os &amp;lt;&amp;lt; s &amp;lt;&amp;lt; c; }); // os引用捕获 c显示捕获可变lambda默认情况下，值捕获变量不会被改变其值。如果我们希望能改变一个被捕获的变量的值，就必须在菜蔬列表尾加上关键字mutable。void fcn(){ int val = 42; // 局部变量 auto f = [val] () mutable { return ++val; }; val = 0; auto j = f(); // j = 43 // 创建时拷贝 而不是调用时拷贝!!!}指定lambda返回类型当需要为lambda定义返回类型时，必须使用尾置返回类型。默认情况下，lambda有return之外的语句，则编译器假定次lambda返回void。transform(v.begin(), v.end(), v.begin(), [](int i) -&amp;gt; int // 尾置返回类型 { if(i &amp;lt; 0) return -i ; else reutrn i; });参数绑定何时用lambda，何时用函数？ 只在一两个地方使用的简单操作，可用lambda 需要在很多地方使用的操作，通常应该定义一个函数 如果一个操作需要很多语句，通常使用函数更好 如果捕获列表为空，用函数代替很简单，但是捕获局部变量的lambda，用函数替换并不容易标准库bind函数bind定义在头文件functional中，可将其看做一个通用的函数适配器。// 当我们调用newfunction时 newfunction会调用function 并传递给它arg_list的参数auto newfunction = bind(function, arg_list);bind的参数auto g = bind(f, a, b, _2, c, _1);// 新调用对象g会调用f// g会将arg_list传递给f 也就是a, b, _2, c, _1// _n是占位符 表示g的第n个参数// g将自己的第2个参数作为f的第三个参数传递给f 第一个参数作为f的第五个参数传递给f利用bind重排参数顺序// 利用bind颠倒函数的参数顺序sort(word.begin(), word.end(), isShorter); // 由短到长排序sort(word.begin(), word.end(), bind(isShorter, _2, _1)); // 由长到短排序再探迭代器除了容器定义的迭代器外，标准库在头文件iterator中还定义了额外几种迭代器。 插入迭代器：迭代器绑定到容器上，可用来向容器插入元素 流迭代器：绑定到输入输出流上，可以遍历关联的IO流 反向迭代器：由后向前移动 移动迭代器：不拷贝元素，而是移动元素泛型算法结构 五类迭代器 算法形参结构 算法命名规范特定容器算法list和forward_list定义了特有的成员函数形式的算法，其性能要比通用版本好的多。 对于链表，优先使用成员函数版本算法。" }, { "title": "C++Primer5 第9章 顺序容器", "url": "/posts/C++Primer9/", "categories": "笔记, C++", "tags": "笔记, C++Primer5, C++", "date": "2022-01-26 10:33:39 +0800", "snippet": "说明： 本章是第3章内容的扩展，是对标准库顺序容器的扩展；第11章将介绍标准库关联容器。 由于本章中设计大量的容器操作，短时间内不可能全部掌握，也没有必要死磕，重点要放在一些常用的操作，剩下的等用到时再查表就行了。顺序容器、关联容器区别？ 顺序容器提供控制元素存储和访问顺序的能力，这种顺序不依赖于元素的值，而是与元素加入容器时的位置想对应。而第11章中的有序和无序关联容器，则根据关键字的值来存储元素。顺序容器概述1、所有顺序容器都提供了两种能力，并且需要在两种能力中折中。 控制元素存储：向容器中添加、删除元素的代价。 控制访问顺序：非顺序访问容器中元素的代价。2、C++顺序容器类型：vector // 可变大小数组 // 支持快速随机访问 // 在尾部插入、删除速度快 在尾部之外的位置插入或删除元素可能很慢string // 与vector相似 专用于保存字符 // 支持快速随机访问 // 在尾部插入、删除速度快 在尾部之外的位置插入或删除元素可能很慢list // 单向链表 // 只支持单向顺序访问 不支持随机访问 // 任何位置插入、删除元素的操作速度都很快forward_list// 双向链表 // 只支持单向顺序访问 不支持随机访问 // 任何位置插入、删除元素的操作速度都很快 deque // 双端队列 // 支持快速随机访问 // 在头尾插入、删除元素很快 其它位置插入或删除元素可能很慢 array // 固定大小数组 // 支持快速随机访问 // 不能添加、删除元素3、C++应使用标准库容器，而非原始的数据结构，如内置数组等。 新标准库容器的性能几乎肯定与最精心优化过的同类数据结构一样好，通常会更好！4、通常，使用vector是最好的选择，除非你有很好的理由选择其它容器。容器库概览本节介绍对所有容器都使用的操作。顺序容器几乎可以保存任意类型的元素，其元素也可以是另一个容器。迭代器1、与容器一样，迭代器有着公共的接口：如果一个迭代器提供某个操作，那么所有提供相同操作的迭代器对这个操作的实现方式都是相同的。2、迭代器范围：[begin, end)，分别指向首元素和尾后元素。具有以下性质： 如果begin==end，则范围为空。 如果begin!=end，则范围至少包含一个元素，且begin指向第一个元素。 可以对begin递增若干次，使begin==end。容器类型成员size_type、iterator、const_iteratorstring::size_type;vector&amp;lt;int&amp;gt;::iterator;vector&amp;lt;int&amp;gt;::const_iterator;bengin和end成员rbegin、rend：反向迭代器cbegin、cend：const迭代器，当不需要写访问时，用这个容器定义和初始化1、默认初始化每个容器类型都定义了一个默认构造函数，除array之外，其它容器的默认构造函数都会创建一个指定类型的空容器，并且都可以接受指定容器大小和元素初始值的参数。2、拷贝初始化 直接拷贝初始化：两个容器的容器类型和元素类型都必须相同。 由迭代器指定元素范围拷贝：不要求容器类型相同，元素类型也可以不同，但必须能够隐式转换。此外，由于两个迭代器表示一个范围，也可以使用此种方法拷贝一个容器的子序列。vector&amp;lt;const char*&amp;gt; vec = { &quot;a&quot;, &quot;an&quot;, &quot;the&quot; };forward_list&amp;lt;string&amp;gt; words(vec.begin(), vec.end()); // 正确 const char*转换string 3、列表初始化{}进行列表初始化()提供容器大小和元素初始值（可选），进行值初始化。 只有顺序容器的构造函数才接受大小参数，并联容器不支持！！！4、标准库array具有固定大小 与内置数组一样，array的大小也是类型的一部分，定义array使，要指定元素类型和大小。 与内置数组不同的是，我们可以对array进行拷贝或对象赋值操作！ 由于右边运算对象的大小和左边运算对象的大小不同，因此array不支持assign，也不允许用花括号包围的值列表进行赋值。 array&amp;lt;int, 42&amp;gt; arr; // 42个默认初始化的intarray&amp;lt;int, 10&amp;gt; digits = { 0,1,2,3,4,5,6,7,8,9 };array&amp;lt;int, 10&amp;gt; copy = digits; // 正确 只要数组类型匹配即可digits = {0}; // 错误赋值和swap1、拷贝赋值和列表赋值c1 = c2; // 将c1的内容替换为c2中元素的拷贝 左边容器将与右边容器相等c1 = { a, b, c }; // 赋值后 c1的大小变为32、assign赋值不适用于并联容器和array。seq.assign(b, e); // seq中的元素替换为迭代器b和e所表示范围中的元素seq.assign(n, t); // 将seq中的元素替换为n个值为t的元素3、使用swapswao(c1, c2); // 在泛型编程中非常重要 统一使用非成员版本！！！c1.swap(c2); // 早期标准库只提供成员版本除array外，swap不对任何元素进行拷贝、删除或插入操作，因此可以保证在常数时间内完成。通常比拷贝赋值快得多！容器大小操作size：返回容器中元素的数目。empty：size=0，返回true，也就是判断容器中有无元素。max_size：返回一个大于或等于该类型容器所能容纳的最大元素数的值。但是容器不一定保证能达到该大小，可能还未达到该大小的时候，就已经无法继续分配内存空间了。关系运算符1、每个容器类型都支持==和!=，除了无序关联容器外的所有容器都支持关系运算符（&amp;gt;、&amp;gt;=、&amp;lt;、&amp;lt;=）。关系运算符两边的运算对象必须是相同类型的容器，且必须保存相同类型的元素。容器的比较方式和string一样。2、容器的相等运算符实际上是使用元素的相等运算符实现的，而其它关系运算符是使用元素的&amp;lt;运算符。如果元素类型不支持所需运算符，那么相应容器也就不能使用相应的关系运算。vector&amp;lt;Sales_data&amp;gt; A,B;if (A &amp;lt; B) // 错误 Sales_data没有&amp;lt;运算符顺序容器操作插入元素push_back1、除array和forward_list之外，每个顺序容器都支持push_back。2、用一个对象来初始化容器时，或者将一个对象插入到容器中，实际上放入到容器中的是对象值的一个拷贝，而不是对象本身。正如值传递一样，我们对容器中元素的任何改变不会影响到原始对象。push_frontlist、forward_list、和deque支持push_front，将元素插入到容器头部。insertvector、string、deque、list都支持insert成员，forward_list提供了特殊版本的insert。1、每个insert都接受一个迭代器作为其第一个参数，迭代器指定了在容器什么位置放置新元素，它可以指向容器中任何位置，包括容器尾部之后的下一个位置。insert将元素插入到迭代器指定的位置之前。2、我们可以将元素insert到容器的开始位置，而不用担心容器是否支持push_front，但这样做可能很耗时。3、insert可以插入范围内元素：vec.insert(vec.end(), 10, &quot;anna&quot;); // 插入若干个元素到指定位置之前list.insert(list.begin(), v.end()-1, v.end()); // 插入迭代器范围内的元素 不能指向相同容器4、使用insert的返回值：可以使用insert的返回值在容器中的一个特定位置反复插入元素，每次将元素插入到指定迭代器之前，然后返回的迭代器恰好指向这个新元素！list&amp;lt;string&amp;gt; lst;auto iter = lst.begin();while (cin &amp;gt;&amp;gt; word) iter = lst.insert(iter, word); // 等价于调用push_frontemplace1、当我们使用emplace成员函数时，将参数传递给元素类型的构造函数，利用这些参数在容器管理的内存空间中直接构造元素。也就是说，使用emplace_back时，会在容器管理的内存空间中直接创建对象，而调用push_back时则会创建一个局部临时对象，并将其压入容器。// 在c的末尾插入一个Sales_data对象c.emplace_back(&quot;123&quot;, 25, 15.99); // 使用三个参数的Sales_date构造函数c.push_back(&quot;123&quot;, 25, 15.99); // 错误 没有接受三个参数的push_back版本c.push_back(Sales_data(&quot;123&quot;, 25, 15.99)); // 正确 创建一个临时对象传递给push_back2、因为emplace函数在容器中直接构造元素，所以传递给emplace函数的参数必须与元素类型的构造函数相匹配，也就是说，要有相应类型的构造函数能够根据参数创建对象。访问元素如果容器中没有元素，访问操作的结果是未定义的。前面已经知道可以通过解引用迭代器返回容器元素。下面说的访问成员函数返回的都是引用。front和back包括array在内的每个顺序容器都有一个front成员函数，而除forward_list之外的所有顺序容器都有一个back成员函数，因为单向链表只允许单向顺序访问。下标运算符和atat和下标只适用于string、vector、deque和array，也就是支持随机访问的容器。c.front();c.end();c[n];c.at(n);删除操作pop_front和pop_back()与访问成员函数类似，不能对一个空容器执行弹出操作。erase从容器内部删除一个或指定范围内的元素，返回指向删除的最后一个元素之后位置的迭代器。list&amp;lt;int&amp;gt; lst = { i, j };lst.erase(i); // 返回指向j的迭代器clear删除容器中的所有元素，也可以以begin和end获得的迭代器调用erase。特殊forward_list操作定义了insert_after、emplace_after、erase_after来代替相应的成员函数，并定义before_begin首前元素。改变容器大小resize来增大和缩小容器，如果当前大小大于缩减后的，那么容器后部的元素会被删除；如果小于扩增后的，会将新元素添加到容器后补。list&amp;lt;int&amp;gt; lst(10, 42);lst.resize(15); // 将5个值为0的元素添加到lst的末尾lst.resize(25, -1); // 将10个-1添加到lst的末尾lst.resize(5); // 删除lst后部20个元素容器操作可能使迭代器生效使用失效的迭代器、指针或引用是严重的运行时错误，因此必须保证每次改变容器的操作之后都正确地重新定位（更新）迭代器。1、调用erase之后，不必递增迭代器，因为erase返回的迭代器已经指向容器中的下一个元素。2、调用insert之后，迭代器要递增两次，因为insert在指定元素之前插入。3、循环过程中必须反复调用end，因为插入删除元素会使原来的end失效。vector对象如何增长减少容器空间重新分配策略：当不得不获得新的内存时，vector和string通常分配比新的空间需求更大的内存空前，预留这些空间以备用。reserve和resize1、reserve永远不会减少容器占用的内存空间，至少分配和需求一样大的空间，可能更大。2、resize只改变容器中元素的数目，而不是容器的容量。capacity和size1、size指定已经保存的元素的数目。2、capacity是在不分配新的内存空间下它最多可以保存多少元素。shrink_to_fit将capacity减少为与size相同大小，退还多余的内存，只是一个请求，标准库并不保证退还。额外的string操作构造string的其它方法string s(cp, n); // s是cp数组中前n个字符的拷贝string s(s2, pos2); // s是string s2从下标pos2开始的字符的拷贝string s(s2, pos2, len2); // s是string s2从下标pos2开始的len2个字符的拷贝s.substr(pos, n); // 返回一个string 包含s中从pos开始的n个字符的拷贝改变string的其它方法s.append(args); // 将args追加到s s.replace(range, args); // 删除s范围range内的字符 替换为args // range可以是一个下标和一个长度 也可以是一对指向s的迭代器string搜索操作1、find函数完成最简单的搜索，查找参数指定的字符串，若找到，返回第一个匹配位置的下标，否则返回npos，npos为unsigned并且初始化为-1，这意味着npos十分大。 搜索对大小写敏感。2、更复杂的问题就是查找与给定字符串中任何一个字符匹配的位置。string numbers(&quot;0123456789&quot;), name(&quot;r2dw&quot;);auto pos = name.find_first_of(numbers); // 从name中定位第一个数字！3、指定从哪里开始搜索，可以传递给find一个可选的开始位置，指定从哪个位置开始搜索。一个常用的技巧就是在字符串中循环的搜索子字符串出现的所有位置！！！string s = &quot;abababab&quot;;size_t pos = 0;//int index = s.find(&#39;a&#39;, pos); // 从pos处查找指定字符//cout &amp;lt;&amp;lt; index;while ((pos = s.find(&#39;a&#39;, pos)) != string::npos) { cout &amp;lt;&amp;lt; &quot;index is &quot; &amp;lt;&amp;lt; pos &amp;lt;&amp;lt; &quot;, element is &quot; &amp;lt;&amp;lt; s[pos] &amp;lt;&amp;lt; endl; ++pos; // 移动到下一个字符 避免无限循环}4、可以使用rfind进行逆向搜索。compare函数s.compare();s2; //比较s和s2pos1, n1, s2; // s从pos1开始的n1个字符与s2比较pos1, n1, s2, pos2, n2; // 同理cp; // cp是以空字符结尾的字符数组pos1, n1, cp; // 同理pos1, n1, cp, n2; // 与指针cp指向的地址开始的n2个字符进行比较数值转换to_string(val); // 一组重载函数 返回数值val的string表示 val可以使任意算术类型stoi(s, p, b); // 将字符串s从位置p处以b进制转换为int string str = &quot;1010&quot;;int a = stoi(str, 0, 2); // a=10容器适配器标准库定义了三个顺序容器适配器：stack、queue和priority_queue。一个适配器就是一种机制，可以使某些事物的行为看起来像另外一种事物一样。定义适配器每个适配器都定义两个构造函数：默认构造函数和拷贝构造函数。栈适配器stack类型定义在相应头文件中。// 栈默认基于deque实现 也可以在list和vector上实现s.push(); s.pop();s.emplace();s.top(); // 栈顶元素队列适配器queue和priority_queue定义在queue头文件中。q.push();q.pop();p.front();q.back(); // queue由deque实现 因此只适用于queueq.top(); // 返回最高优先级元素 有优先级 只适用于priority_queue" }, { "title": "MarthorCup大数据挑战赛总结", "url": "/posts/MarthorCup-conclusion/", "categories": "思考", "tags": "大数据, MarthorCup, 总结, 比赛", "date": "2022-01-20 15:30:21 +0800", "snippet": "这次比赛和上次有些不同，上次是数学建模，这次是大数据，搞数据挖掘，之前从没做过类似的，难度还是挺大的。煎熬的过程： 比赛时间一共一个月，最后也是提交论文。这期间西安爆发了严重的疫情，所有人都在宿舍就地隔离，封闭久了，心情影响还是挺大的，容易放飞自我，实际上，自己真就是放飞自我了，学习效率及其低下。比赛结束前十天和同门一起开始搞得，既然报名了，就努力一下，不要放弃嘛，期间意识到自己着实菜，虽然看了一些经验贴，但还是无从着手，还是要感谢翔宇和衍绪让我抱大腿。意想不到的结果： 吸取上次比赛教训，这次写论文时间留的充足，最后提交之后也挺满意的，最起码尽了自己最大的努力。结果挺进复赛了，进复赛即使弃赛也是二等奖。复赛：放弃还是冲一波？ 复赛说实话挺难的，毕竟PK的对手都很强，好在只有5天的时间，我们虽然嘴上说着想弃赛，但是又不甘心，所以还是冲了一波。模型结果达不到预期！ 第一问也是回归预测问题，用了初赛的模型，重新构造了一些特征，对数据做些处理，但是比赛给的数据着实迷，有些很坑的地方，模型结果一直达不到预期，期间还有个问题就是对于问题的定位，刚开始想的先二分类，结果忙了一天搞不出来，在这种比赛中能够准确的定位问题的类型还是很重要的！最后结果差强人意，但是没时间了，只能开写论文。看不懂题目怎么办？ 第二问啥也没给让构建门店经营模型，即使构建出来了，怎么评价模型好坏？讨论了半天还是没有找到一个合适的解题方向，最后选择贴合题意，然后自圆其说。这样可能结果不是很好，但是最起码不会落个没有逻辑、思路不清的地步。毕竟是酌情给分，只有有理有据，还是能拿一些分的！最后的比赛结果是一等奖，前十名进去答辩，遗憾的是差一点然后没进去。不过总的结果已经很满意了，加油，继续干，尽力去做，总不至于太差！" }, { "title": "C++Primer5 第8章 IO库", "url": "/posts/C++Primer8/", "categories": "笔记, C++", "tags": "笔记, C++Primer5, C++", "date": "2022-01-15 21:21:27 +0800", "snippet": "说明：本章介绍IO库的基本内容(IO类，文件输入输出，string流)。第14章介绍如何编写自己的输入输出运算符；第17章介绍如何控制输出格式以及如何对文件进行随机访问。IO类1、标准库定义了常用的IO类型： iostream定义了用于读写流的基本类型。 fstream定义了读写命名文件的类型。 sstream定义了读写内存string对象的类型。类fstream和stringstream都是继承自类iostream，输入类都继承自istream，输出类都继承自ostream。2、概念上，设备类型和字符大小都不会影响我们要执行的IO操作，标准库使我们能忽略这些类型不同的流之前的差异，这是通过继承机制实现的。我们通常可以将一个派生类当做基类对象来使用。 我们可以用»读取数据，而不用管是从一个控制台窗口，一个磁盘文件，还是一个string读取。也不用管读取的字符能是存入一个char对象内，还是需要一个wchar_t对象来存储。IO对象无拷贝和赋值 不能拷贝对象，也就无法把函数的返回类型和形参设置为流类型。 进行IO操作的函数以引用方式传递和返回流，读写一个IO操作会改变其状态，因此不能是const的。条件状态1、IO操作一个与生俱来的问题就是可能发生错误。一个流一旦发生错误，其上后续的IO操作都将失败。确定一个流状态的最简单的方法是将它当作一个条件来使用：while (cin &amp;gt;&amp;gt; word) // 输入操作成功 流保持有效状态，则条件为真。 // ok:读操作成功 进行后续操作...2、管理条件状态： 使用good和fail是确定流的总体状态的方法。 流对象的rdstate成员返回一个iostate值，对应流的当前状态。 setstate操作将给定条件位置位，表示发生了对应错误。 不接受参数的clear版本清除所有错误标志，执行clear后，调用good会返回true。auto old_state = cin.rdstate(); // 记住cin的当前状态cin.clear(); // 清除cin所有错误标志 使cin有效process_input(cin); // 使用cincin.setstate(old_state); // 将cin改为原有的状态管理输出缓冲1、每个输出流都管理一个缓冲区，用来保存程序读写的操作。 有了缓冲制，操作系统就可以将程序的多个输出操作组合成单一的系统级写操作。由于设备的写操作很耗时，所以上述操作可以带来很大的性能提升。cout &amp;lt;&amp;lt; &quot;please enter a vlur: &quot;; // 可能立即打印出来 也可能被OS保存到缓冲区中随后打印2、导致缓冲区刷新的原因： 程序正常结束，作为main函数的return操作的一部分，缓冲刷新被执行； 缓冲区满时，需要刷新缓冲，而后新的数据才能继续写入缓冲区； 可以使用操纵符endl等来显示刷新缓冲区； 在每个输出操作之后，可以使用操纵符unitbuf设置流的内部状态，来清空缓冲区； 一个输出流可能被关联到另一个流，当读写被关联的流时，关联到的流的缓冲区会被刷新。cout &amp;lt;&amp;lt; &quot;hi&quot; &amp;lt;&amp;lt; endl; // 输出hi和一个换行 然后刷新缓冲区cout &amp;lt;&amp;lt; &quot;hi&quot; &amp;lt;&amp;lt; flush; // 输出hi 然后刷新缓冲区cout &amp;lt;&amp;lt; &quot;hi&quot; &amp;lt;&amp;lt; ends; // 输出hi和一个空字符 然后刷新缓冲区cout &amp;lt;&amp;lt; unitbuf; // 所有输出操作后都立即刷新缓冲区 // 任何输出都立即刷新 无缓冲cout &amp;lt;&amp;lt; nounitbuf; // 回到正常的缓冲方式3、如果程序崩溃，输出缓冲区不会被刷新 当调试一个已经崩溃的程序时，需要确认你认为已经输出的数据确实已经刷新了。否则，可能要花费很多时间追踪代码为什么没有执行上，而实际上代码已经执行了，只是程序崩溃后缓冲区没有刷新，输出数据被挂起没有打印而已。4、当一个输入流被关联到一个输出流时，任何试图从输入读取数据的操作都会先刷新关联的输出流。标准库将cout和cin关联在一起，因此：cin &amp;gt;&amp;gt; val; // 导致cout的缓冲区被刷新文件输入输出1、fstream除了继承自iostream类型的行为之外，还有一些新的成员：fstream fstrm; // 创建一个未绑定的文件流fstream fstrm(s); // 创建一个fstream 并打开名为s的文件fstream fstrm(s, mod); // 同上 但按照指定mod打开文件fstrm.open(s); // 打开名为s的文件 并与fstrm绑定fstrm.close(s); // 关闭绑定的文件fstrm.is_open(); // 返回bool 指出相关联的文件是否成功打开且尚未关闭2、文件模式：in; // 以读方式打开out; // 以写方式打开app; // 每次写操作前都定位到文件末尾ate; // 打开文件后立即定位到文件末尾trunc; // 截断文件binary; // 以二进制方式进行IO 只有对ofstream或fstream设定out模式。 只有对ifstream或fstream设定in模式。 只有当out也被设定时才可设定trunc模式。 只要trunc模式没被设定，就可以设定app模式。 默认情况下，即使没有指定trunc，以out模式打开的文件也会被截断。 ate和binary模式可用于任何类型的文件流对象，且可以和其它任何文件模式组合使用。 以out模式打开文件会丢弃已有数据，因此，保留ofstream打开的文件中已有数据的唯一方法是显示指定app或in模式。 每次调用open时会确定文件模式，因此，每次打开文件，都要设定模式。ofstream out(&quot;file1&quot;); // 隐含的以输出模式打开并截断文件ofstream out(&quot;file2&quot;, ofstream::out | ofstream::app); // 显示指定app保存文件内容string流注意：本章没有例题，真正的读写文件还是得编代码去实践！！！做了课后习题去尝试着对文件进行简单的操作。" }, { "title": "C++Primer5 第7章 类", "url": "/posts/C++Primer7/", "categories": "笔记, C++", "tags": "笔记, C++Primer5, C++", "date": "2022-01-12 19:49:51 +0800", "snippet": "说明：主要讲抽象数据类型，即类的相关知识，第13章，14章继续深入。定义抽象数据类型定义和声明成员函数定义和声明成员函数的方式与普通函数差不多，成员函数的声明必须在类的内部，定义可以在类的内部，也可以在类的外部。 定义在类内部的函数是隐式的inline函数。引入this 成员函数通过一个名为this的额外的隐式参数来访问调用它的那个对象。当我们调用一个成员函数时，用调用该函数的对象地址初始化this。total.isbn();Sales_data::isbn(&amp;amp;total); // 伪代码 用来说明调用成员函数的实际执行过程 在成员函数内部，我们可以直接使用调用该函数的对象的成员，而无须通过成员访问运算符来做到这一点，正是因为this所指的正是这个对象。任何类成员的直接访问都被看做this的隐式引用，也就是说，isbn成员函数使用bookNo成员对象时，它隐式的使用this指向的成员，就像我们书写了this-&amp;gt;bookNo一样。 this指向了调用成员函数的类对象，那么这个类对象的成员自然就可以使用了。 this总是指向调用成员函数的对象，所以this是一个常量指针，也就不允许改变this中保存的地址。引入const成员函数C++允许把const关键字放在成员函数的参数列表之后，此时，紧跟在参数列表后面的const表示this是一个指向常量的指针，此种成员函数称之为常量成员函数。也就意味着在对应成员函数内不会改变this所指的对象。string isbn() const { return bookNo; }string Sales_data::isbn(const Sales_data *const this){ return this-&amp;gt;bookNo; // 伪代码 说明this和const成员函数} 常量对象，常量对象的引用或指针都只能调用常量成员函数。（因为对象不能被改变！）类作用域和成员函数为什么类内定义在成员变量前面的成员函数能够调用成员变量？ 因为编译器分两步处理类：首先编译成员变量的声明，然后才轮到成员函数体。在类的外部定义成员函数和其他函数一样，成员函数的定义必须和它的声明匹配，也就是说，返回类型、参数列表和函数名都得与类内部的声明保持一致，如果被声明为常量成员函数，那么它的定义也必须在参数列表后明确指定const属性。同时，类外部定义的成员的名字必须包含它所属的类名。定义一个返回this对象的函数Sales_data&amp;amp; Sales_data::combine(const Sales_data&amp;amp; rhs) { sold += rhs.sold; revenue += rhs.revenue; return *this; // 返回调用该函数的对象}total.combine(trans); // 该调用的结果为更新total当前的值// 上述解释为：// 1 total对象的地址赋给this指针// 2 sold隐式使用this直线的成员 也就是total的成员 // 3 rhs引用trans实参// 4 返回this指向的对象*this 也就是调用成员函数的对象totalthis-&amp;gt;sold += trans.sold; this-&amp;gt;revenue += trans.sold;return total; 构造函数1、构造函数的任务就是初始化类对象的数据成员，无论何时只要类的对象被创建，就会执行构造函数。2、构造函数的名字和类名相同，构造函数没有返回类型，构造函数可以重载。3、不同于其它成员函数，构造函数不能被声明为const的，当我们创建类的一个const对象时，直到构造函数完成初始化过程，对象才能真正取得其”常量“属性，因此构造函数在const对象的构造过程中可以向其写值。4、如果类没有显示的定义构造函数，编译器会为我们隐式的定义一个默认构造函数，即合成默认构造函数。5、对于一个普通的类来说，必须定义自己的默认构造函数！ 一旦我们定义了其它构造函数，编译器就不会为我们定义默认构造函数，如果我们使用了默认初始化，可能因为没有默认构造函数而出错。 对于某些类来说，合成的默认构造函数可能执行错误的操作，比如定义在函数体内的内置类型或复合类型被默认初始化，将会出现未定义错误。 有的编译器不能为某些类合成默认构造函数。比如类中包含一个其它类的成员且这个成员的类型没有默认构造函数，那么编译器就无法初始化该成员。6、=default显示声明默认构造函数Sales_data() = default;7、构造函数初始值列表：负责为新创建对象的一个或几个数据成员赋初值。Sales_data(const string&amp;amp; s, unsigned n, double p) : bookNo(s), sold(n), revenue(p*n) { }拷贝、赋值和析构函数如果我们不定义这些函数，编译器将替我们合成它们。一般来说，编译器生成的版本将对对象的每个成员执行拷贝、赋值和销毁操作。访问控制与封装在C++中，用访问说明符来加强类的封装性： 定义在public说明符之后的成员在整个程序内可被访问，public成员定义类的接口。 定义在private说明符之后的成员可以被类的成员函数访问，但是不能被使用该类的代码访问，private部分封装了类的实现细节。struct和class定义类的唯一区别就是默认的访问权限，一个默认public，另一个默认private。友元类可以允许其它类或者函数访问它的非公有成员，方法是令他们成为类的友元，需要在函数声明语句前面添加一个friend关键字。友元声明只能定义在类的内部，单数类内出现的具体文职不限，一般来说，最好在类定义开始或结束前集中声明友元。友元的声明仅仅指定了访问的权限，而非一个通常意义上的函数声明，如果我们希望类的用户能够调用某个友元函数，那么我们就必须在友元声明之外再专门对函数进行一个声明。class Sales_data { friend Sales_data add(const Sales_data&amp;amp;. const Sales_data&amp;amp;); // 友元声明 };Sales_data add(const Sales_data&amp;amp;. const Sales_data&amp;amp;); // 非成员函数的声明为了使友元对用户可见，我们通常把友元的声明和类本身放置在同一个头文件中。封装的好处 确保用户代码不会无意间破坏封装对象的状态。 被封装的类的具体实现细节可随时改变，而无须调整用户级别的代码（只要类的接口不变，用户代码就无须改变）。类的其它特性类成员再探1、可变数据成员有时我们希望修改类的某个数据成员，及时是在一个const成员函数类，可以通过在变量的声明中加入mutable关键字做到这一点。一个可变数据成员永远不会是const，即时他是const对象的成员，因此，一个const成员函数可以改变一个可变成员的值。mutable size_t access_ctr; // 任何成员函数内都可改变它的值2、类内初始值必须使用=的初始化形式，或者花括号括起来的直接初始化形式。返回*this的成员函数1、一个const成员函数如果以引用的形式返回*this，那么它的返回类型将是常量引用。2、通过区分成员函数是否是const的，可以对其进行重载。 一方面，只能在一个常量对象上调用const成员函数；另一方面，虽然可以在非常量对象上调用常量版本或非常量版本，但非常量版本明显是一个更好的匹配。类类型1、每个类定义了唯一的类型。即时两个类的成员列表完全一致，它们也是完全不同的类型，对于一个类来说，它的成员和其他任何类的成员都不是一回事。2、对于一个类来讲，我们在创建它的对象之前该类必须被定义过，而不能仅仅被声明。否则，编译器就无法了解这样的类需要多少存储空间。友元再探1、如果一个类指定了友元类，则友元类的成员函数可以访问此类包括非公有成员在内的所有成员。2、每个类负责控制自己的友元类或友元函数，即友元不具有传递性。3、友元声明的作用是影响访问权限，它本身并非普通意义上的声明。struct X { friend void f(); // 友元函数可以定义在类的内部 友元只是影响访问权限 并不具备说明功能 X() { f(); }; // 错误 f还没有被声明 void g(); void h();};void X::g() { return f(); } // 错误 f还没有声明void f(); // 声明fvoid X::h() { return f(); } // 正确 现在f的声明在作用域内了类的作用域一个类就是一个作用域 该事实可以很好的解释在类外定义成员函数时必须同时提供类名和函数名。名字查找和类的作用域1、一般程序的名字查找过程： 首先，在名字所在的块中寻找其声明语句，只考虑在名字的使用之前出现的声明。 如果没找到，继续查找外层作用域。 如果最终没有找到匹配的声明，程序报错。2、类内名字查找过程有所区别： 首先，编译成员的声明。 直到类全部可见后才编译函数体。 编译器处理完类中的全部声明后才会处理成员函数的定义，因此成员函数可以使用类内定义的任何名字。 需要注意的是：这种两阶段的处理方式只适用于成员函数定义中使用的名字，成员函数声明中使用的名字包括返回类型或参数列表中使用的名字，都必须在使用前确保可见。typedef double money;string bal;calss Account {public: money balance() { return bal; }private: money bal;};// 1 看到money函数后 在类内寻找money的声明 只考虑在使用money前的声明 （因为是函数声明）// 类内找不到声明 回到类外作用域去寻找money声明 也即是typedef处的声明// 2 balance函数体在类可见后才被处理 所以return bal是类内的bal 而非外层作用域那个3、类型名要特殊处理在类中，如果成员使用了外层作用域的某个名字，而该名字代表一个类型，则类不能在之后重新定义该名字。以为这时候可能会出现类型名歧义：一个名字对应两种类型！ 类型名的定义通常出现在类的开始处，这样就可以避免上述错误。typedef double money;class Account {public: money balance() { return bal; }private: typedef double money; // 错误 即时与外层定义一致 money bal;};4、成员函数普通块作用域内的名字查找： 首先，在成员函数内查找该名字的声明，只考虑使用之前的声明。 如果在成员函数内没有找到，在类内继续查找，考虑类内所有成员。 如果类内扔未找到，在成员函数（可能定义在类外）定义之前的作用域内查找。int height;class Screen{ void func(int height) { cursor = width * height; } % 哪个height? int cursor = 0; int height = 0, width = 0;};// 两种方式都能强制访问void Screen::func(int height) { cursor = width * Screen::height; cursor = width * this-&amp;gt;height; cursor = width * ::height; // 强制访问外层作用域的名字 还是不要重名！！！}// 1 func函数体内找 从使用处向前找// 2 func函数所在的类中找 查找类内所有名字、// 3 func函数定义之前的所有外层作用域内找首先在函数作用域内查找该名字的声明，函数的参数位于函数作用域内，因此height使用的是func的形参height，也就是说函数的参数隐藏了同名的成员height。因此发生意想不到的错误！ 尽管类的成员被隐藏，但我们仍然可以通过加上类的名字或显示的使用this指针来强制访问成员。但即使这样，函数的参数也不应该与类成员同名！！！构造函数再探构造函数初始值列表1、如果成员是const、引用或者属于未提供默认构造函数的类类型，我们必须通过构造函数初始值列表为这些成员提供初值。2、使用构造函数初始值的好处： 初始化和赋值关系到底层效率。前者直接初始化数据成员，后者先初始化数据成员再赋值。 更重要的是，一些数据成员必须被初始化！比如1中所讲。3、成员的初始化顺序与它们在类中定义的顺序一致，初始值列表的初始化顺序不会影响实际的初始化顺序。一般对初始化顺序无要求，但如果一个成员用另一个成员来初始化，那么就要格外注意顺序。 尽量使构造函数的初始值的顺序与成员声明的顺序保持一致，如果可能，尽量避免使用某些成员初始化其它成员，这样就不用考虑初始化顺序了。4、如果一个构造函数为所有参数都提供了默认实参，则它实际定义了默认构造函数。唯一不同的是：接受实参的构造函数用实参来初始化成员，而默认构造函数使用编译器为类自动合成的默认构造函数初始化成员。委托构造函数 P261使用类的其它构造函数来执行自己的初始化过程，要求参数列表必须和另外一个构造函数相匹配。受委托的构造函数的初始值列表和函数体被依次执行，然后控制权才会交换给委托者的函数体。C++11默认构造函数的作用1、如果定义了其它构造函数，最好也提供一个默认构造函数。=default=2、如果想定义一个使用默认构造函数进行初始化的对象，要特别注意：Sales_data obj(); // 错误 声明了一个函数而非对象Sales_data obj; // 正确 不要带小括号！！！隐式的类类型转换1、只接受一个实参的构造函数可以隐式的转换为类类型，这种构造函数可以称为转换构造函数。string null_book = &quot;9-999-99999-9&quot;;item.combine(null_book); // 等价于item.combine(Sales_data(null_book)) 临时类对象！// combine接受一个Sales_data类 而null_book确实一个string// Sales_data类中有接受单个string的构造函数 所以null_bool可隐式转换为Sales_data临时对象2、只允许一步类类型转换 编译器置换自动地执行一步类型转换。item.combine(&quot;9-999-99999-9&quot;); // 错误 需要先转换为string 再转换为临时类对象item.combine(string(&quot;9-999-99999-9&quot;)); // 正确 显示转换为string 隐式转换为临时类对象item.combine(Sales_data(&quot;9-999-99999-9&quot;)); // 正确 隐式转换为string 显示转换为...3、印制构造函数定义的隐式类型转换可通过关键字explicit阻止隐式类型转换。只对一个实参的构造函数有效，多个实参的构造函数不能用于隐式类型转换，也就无须声明explicit。只允许在类内声明函数时使用explicit关键字。explicit构造函数只能用于直接初始化()，不能拷贝初始化=！尽管编译器不会将explicit声明的构造函数用于隐式转换，但我们可以使用这样的构造函数显示地强制进行转换。explicit Sales_data(const string&amp;amp; s) : bookNo(s) {} // 函数 别习惯性的加逗号！item.combine(null_book); // 正确 实参是一个显示构造的类对象item.combine(static_cast&amp;lt;Sales_data&amp;gt;(cin)); // 正确 强制类型转换标准库中含有显示构造函数的类： 接受一个单参数的const char*的string构造函数不是explicit的。 接受一个容量参数的vector构造函数不是explicit的。聚合类 P266字面值常量类 P267类的静态成员有的时候类需要它的一些成员与类本身直接相关，而不是与类的各个对象保持关联。 这样每个对象不用存储公共数据，如果数据发生了修改，每个对象都能用新值。1、声明静态成员在成员的声明之前加上关键字static使其与类关联在一起。类的静态成员存在与任何对象之外，对象中不包含任何与静态成员有关的数据。 类的静态成员属于类的共有部分，是独立的，而不是某个对象的，但是所有对象都能调用静态成员。类似的，静态成员函数也不属于任何对象，它们不包含this指针。静态成员函数不能声明成const的（它的作用就是数据发生修改，对象都能使用），也不能在静态成员函数内使用this指针。2、使用类的静态成员使用作用域运算符直接访问静态成员。虽然不属于类的某个对象，但是我们仍然可以通过类的对象、引用或指针来访问静态成员。成员函数不用通过作用域运算符也能直接使用静态成员。static void rate() { } // 仅用来说明问题 double r = Account::rate(); // 使用作用域运算符访问void Account::calculate() { rate(); } // 直接访问静态成员3、定义静态成员static关键字只出现在类内部的声明语句中，在类外部定义，不能重复使用static。一般来讲，不能在类的内部初始化静态成员，必须在类的外部定义和初始化静态成员。和其他对象一样，一个静态数据成员只能定义一次。类似于全局变量，静态数据成员定义在任何函数之外，一旦定义，就将一直存在程序的整个生命周期内。和其它成员一样，静态成员也能访问私有成员。double Account::interestRate = initRate();// 从类名开始 这条定义语句剩余的部分就都位于类的作用域之内了 因此可以直接使用成员函数4、静态成员能用于某些场景，而普通成员不能 静态数据成员可以使不完全类型（只声明未定义）。特别的，静态数据成员可以使类类型，而普通成员只能声明它所属类的指针或引用。 静态成员可以作为默认实参。非静态数据成员不可以，因为它的值本身属于对象的一部分。" }, { "title": "C++Primer5 第6章 函数", "url": "/posts/C++Primer6/", "categories": "笔记, C++", "tags": "笔记, C++Primer5, C++", "date": "2022-01-03 22:13:44 +0800", "snippet": "说明：本章讲述函数的定义和声明、函数传参、返回类型、重载函数、函数匹配以及函数指针。函数基础1、函数的定义包括一下部分：返回类型、函数名字、0个或多个形参组成的列表或函数体。2、函数的调用完成两项工作：一是实参初始化函数对应的形参；二是将控制权转移给被调用函数，此时，主调函数的执行被暂时中断，被调函数开始执行。3、遇到return语句时函数结束执行过程。也是完成两项工作，一是返回return语句中的值，如果有的话；二是将控制权从被调函数移回主调函数。4、实参的类型必须和形参类型一致（但是可以执行隐式类型转换），就想初始值的类型必须和初始化对象的类型匹配一样。5、函数的形参列表可以为空，但不能省略，形参用逗号分隔，每个形参都是含有一个声明符的声明，即时两个形参的类型一样，也必须把两个类型都写出来。6、在C++中，名字有作用域，对象有生存周期。形参和函数体内定义的变量为局部变量，局部变量仅在函数的作用域可见，同时还会隐藏外层作用域中同名的其他所有声明。在所有函数体之外定义的对象在程序启动时被创建，直到程序结束时才会销毁。7、有些时候，有必要令全局变量的生命周期贯穿在函数调用及之后的时间，可以定义为static类型。局部静态变量在程序执行路径第一次经过对象定义语句时初始化，直到程序终止才被销毁，在此期间对象所在的函数结束执行也不会对它有影响。int count_calls() { static int ctr = 0; return ++ctr;}int main() { for (int i = 0; i != 10; ++i) { // 如果不是static类型 输出全是1 因为每次调用函数都会初始化变量ctr // statci类型的话 再次调用函数时 ctr已经存在了 并且是前一次函数返回的值 cout &amp;lt;&amp;lt; count_calls() &amp;lt;&amp;lt; endl; } return 0;}8、与变量类似，函数应该在头文件中声明而在源文件中定义。这样可以确保同一函数的所有声明保持一致，而且想要改变函数借口，只需改变一条声明语句即可。参数传递和其他变量一样，形参的类型决定了形参和实参的交互方式。如果形参是引用类型，它将绑定到对应的实参上，否则，将实参的值拷贝后赋给形参，即引用传递和值传递。值传递初始值会拷贝给一个变量，对变量的改动不会影响初始值。引用传递尽量使用引用传递，如果无需改变引用形参的值，最好将其声明为常量引用。const形参和实参当用实参初始化形参时会忽略掉顶层const，换句话说：当形参有顶层const时，传给它常量对象或者非常量对象都是可以的。我们可以使用非常量初始化一个底层const对象，但是反过来不行。把函数不会改变的形参定义为普通引用是一个比较常见的错误： 误导调用者，使人感觉函数可以修改它的实参的值。 非常量引用会极大的限制函数所能接受的实参类型，如上所述，我们不能用const对象、字面值或者需要类型转换的对象传递给普通的引用形参。 还有一个难以察觉的问题，假设其它参数将他们的形参定义为常量引用，那么上述find_char就无法在此类函数中正常使用。// 上述第二点int find_char(string&amp;amp; s, char c, int&amp;amp; occurs); // 不良设计 应为const string&amp;amp;find_char(&quot;Hello world&quot;, &#39;o&#39;, ctr); // 错误 字面值常量不能传给普通引用变量// 上述第三点bool is_sentence(const string&amp;amp; s){ int ctr = 0; // 下面错误 因为s是常量引用 而find_char被定义为只接受普通引用 return find_char(s, &#39;.&#39;, ctr) == s.size() - 1 &amp;amp;&amp;amp; ctr == 1; }所以要尽量使用常量引用数组形参1、尽管不能以值传递的方式传递数组，但是我们可以把形参写成类似数组的形式，如果我们给print函数传递一个数组，实参自动的转换为指向数组首元素的指针，数组的大小对函数的调用没有影响。void print(const int*); // 三种方式一样 形参都是int*类型void print(const int[]);void print(const int[10]);2、C++允许将变量定义为数组的引用，类似的，形参也可以是数组的引用。void print(int (&amp;amp;arr)[10]){ // 必须带括号 数组从数组名由内像外阅读 for (auto elem : arr) cout &amp;lt;&amp;lt; elem &amp;lt;&amp;lt; endl;}含有可变形参的函数有时我们无法提前预知应该向函数传递几个实参。为了编写处理不同数量实参的函数，C++11提供了两种方法：如果所有的实参类型相同，可以传递一个名为initializer_list的标准库类型；如果实参的类型不同，可以编写一种特殊的函数，也就是可变参数模板（16.4节）。initializer_list：函数实参数量未知但全部实参类型相同，是标准库类型，定义在同名头文件中。与vector一样，initializer_list是一种模板类，但是其对象中的元素永远是常量值，我们无法改变。void error_msg(initializer_list&amp;lt;string&amp;gt; i1){ // 有begin和end成员 可以范围for语句处理 for (auto beg = i1.begin(); beg != i1.end(); ++beg) cout &amp;lt;&amp;lt; *beg &amp;lt;&amp;lt; &quot; &quot;; cout &amp;lt;&amp;lt; endl;}如果想向initializer_list形参中传递一个值的序列，必须把序列放在一对花括号内。// 下面是两个string对象 第一次调用传入三个值 第二次传入两个值if (expected != actual) error_msg({ &quot;functionX&quot;, expected, actual });else error_msg({ &quot;functionX&quot;, &quot;ok&quot; });省略符形参：为了便于让C++程序访问某些特殊的C代码设置的，应该仅仅用于C和C++通用的类型，应该注意的是：大多数类类型的对象在传递给省略符形参时都无法正确拷贝。void foo(parm_list, ...); // 对应于部分指定形参的实参是执行类型检查void foo(...); // 省略符形参所对应的实参无需类型检查。返回类型和return语句return语句终止当前正在执行的函数并将控制权返回到调动该函数的地方。无返回值函数1、返回void的函数不要求非得有return语句，因为在这类函数最后一句后面会隐式地执行return。2、void函数如果想在中间位置提前退出，可以使用return语句。3、返回值为void的函数可以使用return expression的形式，但是该语句必须是另一个返回void的函数，强行返回其它类型的表达式会产生错误。有返回值函数1、只要函数的返回类型不是void，则该函数内的每条return语句必须返回一个值。return语句的返回值的类型必须与函数的返回类型相同，或者能隐式的转换成函数返回类型。2、在含有return语句的循环后面，应该也有一天return语句，如果没有的话程序会出错！！！3、返回一个值的方式和初始化一个变量或形参的方式完全一样：返回的值用于初始化调用点的一个临时量，该临时量就是函数调用的结果。4、如果函数返回引用，则该引用仅是它所引对象的一个别名。// 无论是调用函数还是返回结果都不会真正拷贝string对象 而只是它的一个别名const string&amp;amp; shorterString(const string&amp;amp; s1, const string&amp;amp; s2){ return s1.size() &amp;lt;= s2.size() ? s1 : s2;}5、不要返回局部对象的引用或指针 函数完成后，它所占用的存储空间也随之被释放掉，因此，返回一个局部对象的引用或指针，会使引用和指针指向一个不存在的对象！const string&amp;amp; manip(){ string ret; if (!ret.empty()) return ret; // 错误 返回局部对象的引用 else return &quot;empty&quot;; // 错误 返回一个局部临时量}6、调用运算符的优先级与点运算符和箭头运算符相同，并且符合左结合率。因此，如果函数返回指针、引用、类的对象，我们能使用函数调用的结果访问结果对象的成员。auto sz=shorterString(s1,s2).size(); // 返回对象是string 所以可以调用size()7、调用一个返回引用的函数得到左值，其它返回类型得到右值。可以像使用其它左值那样来使用返回引用的函数的调用，特别是，我们能为返回类型是非常量引用的函数的结果幅值。char&amp;amp; getVal(string &amp;amp;str, size_t ix){ return str[ix];}int main(){ string s{&quot;a value&quot;}; cout &amp;lt;&amp;lt; s &amp;lt;&amp;lt; endl; getVal(s,0) = &#39;A&#39;; // 将s[0]的值改为A cout &amp;lt;&amp;lt; s &amp;lt;&amp;lt; endl;}8、函数可以返回花括号包围的值。C++11 类似于其它返回结果，可以用用此列表来初始化表示函数返回的临时对象。 如果函数返回的是内置类型，则花括号包围的列表最多包含一个值，而且该值所占空间不应该大于目标类型的空间。如果函数返回的是类类型，由类本身定义初始值如何使用。返回数组指针因为数组不能被拷贝，所以函数不能返回数组。不过，函数可以返回数组的指针或引用。1、使用类型别名typedef int arr[10]; // arr是一个类型别名 表示的类型为含有十个整数的数字using arr = int[10]; // 同上 C++11arr* func(int i); // func返回一个指向arr数组的指针2、声明一个返回数组指针的函数数组的维度必须跟在函数名字后面，且形参列表应该由于数组的维度。int (*func(int i))[10]; // func返回一个指针 指针指向整型数组 必须带小括号3、使用尾置返回类型 C++11尾置返回类型跟在形参列表后面并以一个-&amp;gt;符号开头，为了表示真正的返回类型跟在形参列表之后，我们在本应该出现返回类型的地方放置一个auto。auto func(int i) -&amp;gt; int (*)[10]; // 返回一个指针 该指针指向整型数组4、会用decltype如果我们已经知道函数返回的指针将指向哪个数组，就可以使用decltype声明返回类型。int odd = { 1, 3, 5, 7, 9 };int even = { 2, 4, 6, 8, 10 };decltype(odd) *arrptr(int i){ return (i % 2) ? &amp;amp;odd : &amp;amp;even; // 返回一个指向数组的指针 既然是指针 别忘了&amp;amp;}函数重载1、函数名字相同且形参列表不同，称为函数重载。函数名字仅仅是让编译器知道它调用的是哪个函数，而函数重载可以在一定程度上减轻起名字、记名字的负担。2、重载函数应该在形参数量或形参类型上有所不同。3、重载和const形参 顶层const不影响函数的对象，一个有顶层const的形参无法和另一个没有顶层const的形参区分。 如果形参是某种类型的指针或引用，则通过区分其指向的是常量对象还是非常量对象可以实现函数重载，此时的从const是底层的。因为底层const不能转换为其它类型，只能将const对象传递给const形参。虽然非常量可以转换为const，但是编译器会优先选用非常量版本的函数，所以可以区分。Record lookup(phone);Record lookup(const phone); // 重复声明函数 形参类型并不能区分Record lookup(Account&amp;amp;); // 函数作用于引用Record lookup(const Account&amp;amp;); // 函数作用于常量引用 底层const4、函数匹配是一个过程，在这个过程中可以把函数调用与一组重载函数的某个函数关联起来。5、调用函数重载时有三种可能的结果 编译器找到一个与实参最佳匹配的函数，并生成调用该函数的代码。 找不到任何一个函数与调用的实参匹配，发出无匹配的错误信息。 有多于一个函数可以匹配，但是每一个都不是明显的最佳选择，将发生错误。称为二义性调用。6、通常来说，不应该在局部作用域内声明函数，因为在内层作用域内声明名字，它将隐藏外层作用域中声明的同名实体（同名变量也可以隐藏函数），在不同作用域中无法重载函数名。 C++中，名字查找发生在类型检查之间。也就是说一旦名字发生重复，内层将隐藏外层。特殊用途语言特性默认实参1、可以为形参提供默认实参，但是一旦某个形参被赋予了默认值，它后面的所有形参都必须有默认值。2、函数调用时实参按其位置解析，默认实参负责填补函数调用缺少的尾部实参。string screen(size_t hz = 24, size_t wid=80, char backgrnd = &#39; &#39;); // 函数声明string window;window = screen(); // 等于调用screen(24,80,&#39; &#39;)window = screen(66); // 等于调动screen(66,80,&#39; &#39;)window = screen(66,256); // 等于调用screen(66,256,&#39; &#39;) 3、函数可以多次声明，但是在给定的作用域内，一个形参只能被赋予一次默认实参。4、局部变量不能作为默认实参。size_t wd;char def = &#39; &#39;;size_t ht();string screen(size_t = ht(), size_t = wd, char = def);string window = screen;void f2(){ def = &#39;*&#39;; // 改变默认实参的值 size_t wd = 100; // 隐藏了外层定义的wd 但是没有改变默认值 window = screen(); // 相当于调用screen(ht(), 80, &#39;*&#39;)}内联函数将函数指定为内联函数，通常就是将它在每个调用点处内联的展开。可以减少函数运行时的开销。 内联只是向编译器的一个请求，编译器可以选择忽略，就是内联不内联，编译器说的算。cout &amp;lt;&amp;lt; shorterString(s1, s2) &amp;lt;&amp;lt; endl;cout &amp;lt;&amp;lt; (s1.size() &amp;lt; s2.size() ? s1 : s2) &amp;lt;&amp;lt; endl; // 调用处内联展开constexpr函数1、字面值属于常量表达式，用字面值初始化的const对象也是常量表达式(非const对象不是)。2、constexptr函数的返回类型及所有形参的类型都得是字面值类型，而且函数体重必须有且只有一条return语句，但是它并一定返回查常量表达式。函数匹配1、确定候选函数 候选函数与被调用的函数同名 候选函数声明在函数调用点可见2、从候选函数中选出可行函数 可行函数形参数量与本次调用提供的实参数量相等 每个实参的类型与对应的形参类型相同，或者能转换成形参的类型3、寻找最佳匹配逐一检查函数调用提供的实参，寻找形参类型与实参类型最匹配的那个可行函数。有且只有一个函数满足以下条件，则匹配成功： 该函数每个实参的匹配都不劣于其它可行函数需要的匹配 至少有一个实参的匹配由于其它可行函数提供的匹配void f(int, int);void f(double double = 3.14);f(42, 2.56); // 二义性调用 报错函数指针1、函数指针指向的是函数而非对象，和其他指针一样，函数指针指向某种特定类型，函数的类型由它的形参类型和返回类型共同决定，与函数名无关。声明一个指向该函数的指针，只需要用指针替换函数名即可，注意指针加上()！bool lengthCompare(const string &amp;amp;, const string &amp;amp;);bool (const string &amp;amp;, const string &amp;amp;); // 上述函数类型vool (*pf)(const string &amp;amp;, const string &amp;amp;); // pf指向一个函数2、当我们把函数名作为一个值使用时，该函数自动地转换成指针。还能使用指向函数的指针调用该函数，无需提前解引用指针。pf = lengthCompare(); // pf指向该函数pf = &amp;amp;lengthCompare(); // 等价bool b1 = pf(&quot;hello&quot;, &quot;goodbye&quot;); // 调用函数bool b2 = (*pf)(&quot;hello&quot;, &quot;goodbye&quot;); // 等价调用3、指向不同函数类型的指针间不存在转换规则（即类型不能隐式转换，需要精确匹配），但是我们可以为函数指针赋一个nullptr或者值为0的整型常量表达式。4、形参可以是指向函数的指针，此时形参看起来是函数类型，实际上却是当成指针使用，我们可以直接把函数当做实参使用，此时它会自动转换为指针。bool useBigger(const string&amp;amp; s1, const string&amp;amp; s2m, bool (*pf)(const string&amp;amp;, const string&amp;amp;)); // 将形参定义成指向函数的指针useBigger(s1, s2, lengthCompare); // 自动将函数转换为指向该函数的指针5、和数组一样，decltype返回函数类型，不会将函数类型自动转换成指针类型。decltype(sumLength) *getFcn(const string &amp;amp;); // 牢记加上指针！！！6、和数组类似，虽然不能返回一个函数，但是可以返回一个指向函数的指针，最好使用类型别名。" }, { "title": "C++Primer5 第5章 语句", "url": "/posts/C++Primer5/", "categories": "笔记, C++", "tags": "笔记, C++Primer5, C++", "date": "2021-12-24 20:39:40 +0800", "snippet": "说明：本章主要讲述C++简单语句、条件语句、循环语句、跳转语句、以及用于异常处理的try语句。1、多余的空语句并非总是无害的，所以不要少写或者多写;。2、多个if-else语句中，会出现if多余else的问题（悬垂else问题），由于C++采取就近匹配准则，所以最好加上{}以控制执行路径，防止if-else的匹配与以及的编写意愿不同。switch语句1、case关键字和它对应的值一起被称为case标签，case标签必须是整型常量表达式。char ch = getval();int val = 42;switch(ch) { case 3.14: // 错误 非整数 case val: // 错误 非常量}2、任何两个case标签的值不能相同，否则会错误。3、如果某个case标签匹配成功，将从该标签开始往后顺序执行所有case分支。所以一般不要省略case分支最后的break语句，因为容易引发错觉（认为只执行匹配的case）。如果没有任何一个匹配的case，将执行default标签后面的语句。4、标签不应该孤零零的出现，它后面必须跟上一条语句或者另外一个case标签。如果switch结构以一个空的default标签作为结束，default标签后面必须跟上一个空语句或一个空块。5、如果需要为某个case分支定义并初始化一个变量，我们应该把变量定义在块内{}，从而保证后面的case标签都在变量的作用域之外，否则容易引发变量错误。迭代语句1、定义在while条件部分或者循环体内的变量每次迭代都经历从创建到销毁的过程。2、for语句定义的对象只能在for循环体内可见。3、和其他的声明一样，init-statement也可以定义多个对象，但是只能有一条声明语句，因此，所有变量的基础类型必须相同。4、for语句头能省略掉init_statement、condition、expression中的一个或者全部。5、do while语句应该在括号包围起来的条件后面用一个分号表示语句结束。因为对于do while来说先执行语句或者块，后判断条件，所以不允许在条件部分定义变量。6、break语句负责终止离它最近的while、do while、for或switch语句，并从这些语句之后的第一条语句开始继续执行。7、continue语句终止最近的循环中的当前迭代并立即开始下一次迭代。8、不要在程序中使用goto语句！try语句块和异常处理在C++中，异常处理包括： throw表达式，异常检测部分使用throw表达式来表示它遇到了无法处理的问题。我们说throw引发了异常。 try语句块，异常处理部分使用try语句块处理异常。try语句块以关键字try开始，并以一个或多个catch子句处理。 一套异常类，用于在throw表达式和相关的catch子句之间传递异常的具体信息。throw语句程序的异常检测部分用throw表达式引发一个异常，throw表达式包含关键字throw和紧跟其后的一个表达式，其中表达式的类型就是抛出的异常类型。if (items1.isbn() != items2.isbn()) // 不一样就抛出异常 该异常是类型runtime_error的对象 throw runtime_error(&quot;Data must refer to same ISBN&quot;);try语句块跟在try语句块之后的是一个或多个catch子句。catch子句包括三部分：关键字catch、括号内一个对象的声明（称为异常声明）、以及一个块。当选中了某个catch子句处理异常之后，就执行与之对应的块。catch一旦完成，程序跳转到try语句块最后一个catch子句之后的那条语句继续执行。while (cin &amp;gt;&amp;gt; item1 &amp;gt;&amp;gt; item2){ try{ // 执行添加两个sales_item对象的代码 // 如果添加失败 代码抛出一个runtime_error异常 } catch (runtime_error err) { // 提醒用户两个对象输入必须一致 询问是否重新输出 cout &amp;lt;&amp;lt; err.what() &amp;lt;&amp;lt; &quot;\\nTry again? Entry y or n&quot; &amp;lt;&amp;lt; endl; char c; cin &amp;gt;&amp;gt; c; if (!cin || c == &#39;n&#39;) break; // 跳出while循环 }}函数在寻找处理代码的过程中退出在复杂的系统中，程序在遇到抛出异常的代码前，其执行路径可能已经经过了多个try语句块。寻找处理代码的过程与函数调用链刚好相反，沿着程序的执行路径逐层回退，知道找到适当类型的catch子句为止。如果最终还是没有找到匹配的catch子句，程序赚到名为terminate的标准库函数，该函数的行为和系统有关，一般情况下，执行该函数将导致程序非正常退出。如果一段程序没有try语句块并且发生了异常，系统会调用terminate函数并终止当前程序的执行。标准异常C++定义了标准库异常类。P176" }, { "title": "C++Primer5 第4章 运算符", "url": "/posts/C++Primer4/", "categories": "笔记, C++", "tags": "笔记, C++Primer5, C++", "date": "2021-12-22 17:16:13 +0800", "snippet": "说明：本章主要介绍由语言本身定义、用于内置类型运算对象的运算符，以及简要介绍几种标准库定义的运算符。基础1、左值和右值？ 这个好像比较混乱，目前的理解就是左值是一个有名称、占据内存空间的变量，而右值是一个临时对象，使用一次就销毁，不能被程序的其它部分访问。但是右值引用可以使临时变量拥有名称，使程序的其它部分得以访问，并且该临时变量变成了左值。后续遇到问题再深究吧，这里书上讲的不太清楚！2、求值顺序： 优先级规定了运算对象的组合方式，但是没有说明运算对象按照什么方式求值。在大多数情况下，不会明确指定求值的顺序。 有四种运算符明确规定了运算对象的求值顺序：与&amp;amp;&amp;amp;、或||、条件?:、逗号，。int i = f1() * f2(); // 我们知道f1和f2一定会在*之前被调用，但是我们无法知道二者的调用顺序，即先调用f1还是先调用f2完全由编译器决定。算术运算符1、整数相除结果还是整数，如果商含有小数，直接弃除。2、取余运算的运算对象必须是整数类型。 在C++中如果是负数取模：A/B=A-A/B*B，其只（A/B）要去尾取整。逻辑和关系运算符1、短路求值：当且仅当左侧运算对象无法确定表达式的结果时才会计算右侧运算对象的值，比如逻辑与和逻辑或。2、进行比较时，如果比较对象不是布尔类型，不要使用true和false进行比较，会转换1和0。赋值运算符1、赋值运算符的左侧运算对象必须是一个可修改的左值。（字面值、算数表达式等右值不行）2、赋值运算符的优先级低于比较运算符，条件语句中要加上括号。3、复合赋值运算符只求值一次，普通运算符求值两次：一次作为右边表达式的一部分求值，另一次是作为赋值运算符的左侧运算对象求值。递增和递减运算符1、除非必须，否则不适用后置版本的递增和递减运算符。 前置版本简单，把值+1后直接返回改变后的值。 后置版本为了返回为修改前的值，需要将原始值存储下来，效率较低。2、如果既使对象+1或-1又要使用它原来的值，就是用后置版本。成员访问运算符1、解引用运算符的优先级低于点运算符。*p.size(); // 错误 p是指针 没有size成员 要变成(*p).size() 简化为p-&amp;gt;size()2、箭头运算符作用于指针类型的运算对象，结果是一个左值。点运算符，如果成员所属的对象是左/右值，结果就相应是左/右值。条件运算符可以嵌套，但是不要超过两层，否则代码可读性急剧下降。位运算符建议仅将位运算符用于处理无符号类型，因为符号位如何处理没有明确的规定。sizeof运算符1、sizeof返回一条表达式或一个类型名字所占的字节数。sizeof(type);sizeof expr; // 返回的是表达式结果类型的大小 但是sizeof并不实际计算运算对象的值2、执行sizeof会得到整个数组的大小，所以可以巧妙得到数组的元素个数。sizeof(a)/sizeof(*a);逗号运算符逗号运算符含有两个对象，按照从左到右的顺序依次求值。类型转换算数类型隐式转换。数组转换为指针。常量整数值0和字面值nullptr可以转换成空指针。指针的算数类型0和nullptr可以转换为布尔类型false。显示转换（强制类型转换）: 虽然有时不得不转换，但是这种方法本质上是危险的，尽量不用。static_cast：任何具有明确定义的类型装换，只要不包含底层const，都可以使用。int j;double slope = static_cast&amp;lt;double&amp;gt;(j) / i;const_cast：只改变运算对象的底层const，注意只改变const属性，其它类型转换不行。const char *pc;char *p = const_cast&amp;lt;char*&amp;gt; pc;const_cast&amp;lt;string&amp;gt;(pc); // 错误 只改变const属性dynamic_cast：用于类继承层次间的指针或引用转换，主要用于安全地向下转型，即基类对象的指针或引用转换为同一继承层次下的其它指针或引用。 至于向上转型（即派生类指针或引用类型转换为其基类类型），其本身就是安全的，普通的转换（隐式转换）已经能够达到目的，尽管可以使用dynamic_cast，但是没有必要，毕竟使用强制类型转换也是需要开销的。reinterpret_cast：不太明白，但是比较危险，遇到再说！注意：旧式的强制类型转换不那么清晰明了，容易被看漏，一旦转换出现问题，追踪起来也很困难。type (expr); // 函数形式的强制类型转换(type) expr; // C语言风格的强制类型转换" }, { "title": "C++Primer5 第3章 字符串、向量和数组", "url": "/posts/C++Primer3/", "categories": "笔记, C++", "tags": "笔记, C++Primer5, C++", "date": "2021-12-18 21:42:04 +0800", "snippet": "说明：本章主要介绍数组以及两种标准库容器string和vector。命名空间的using声明1、作用域操作符::含义：编译器从操作符左侧名字所示的作用域中寻找右侧那个名字。2、头文件不应该包含using声明，因为头文件的内容会拷贝到所有引用它的文件中去，可能会引发名字冲突。标准库类型stringstring表示可变长的字符序列，使用string类型必须包含string头文件。定义和初始化string对象string s1; // 默认初始化 s1为空串string s2(s1); // 直接初始化string s2 = s1; // 拷贝初始化string s3(&quot;value&quot;); // 注意：字面值最后的那个空字符不拷贝进去！！！string s3 = &quot;value&quot;; // 拷贝初始化string s4(n, &#39;c&#39;); // 那个字符c组成的字符串string对象上的操作1、读写string对象: 读取操作时，string对象会自动忽略开头的空白（空格符、换行符、制表符等）并从第一个真正的字符开始读起，直到遇到下一个空白为止。2、读取位置数量的string对象:string word;while(cin &amp;gt;&amp;gt; word); // 文件读完或者控制台程序结束按键结束 也可以设置个按键来控制结束3、使用getline读取一整行：希望在最终得到的字符串中保留输入时的空白字符。 getline(cin, str)：参数是一个输入流和一个string对象，函数从给定的输入流中读入内容，知道遇到换行符为止，然后把所读的内容存入到那个string对象中去。 注意：触发getline函数返回的那个换行符被丢弃了，所以得到的string对象中不包含换行符！string str;while(getline(cin, str));4、empty()函数返回字符串是否为空；size()函数返回string对象的长度（对象中字符的个数）。 注意：size()函数返回的是string::size_type类型，是一种无符号类型数，即size()函数返回的是一种无符号类型数。因此，如果一个表达式中有了size()函数就不要再使用int了，因为负整数会自动变成一个很大的无符号类型整数！！！string word = &quot;hello&quot;;auto len = word.size();cout &amp;lt;&amp;lt; len &amp;lt;&amp;lt; endl; // 输出5decltype(word.size()) a = -1; // 不要混用！cout &amp;lt;&amp;lt; a &amp;lt;&amp;lt; endl; // 输出184467443709551615！5、比较string对象： 字符串相等：长度和字符全相等。 字符串比较：按照字典顺序（A65，a97)比较第一个相异字符。 如果较多字符和较长字符对应位置完全相同，较短字符&amp;lt;较长字符。6、字符串相加： 字符串相加等于串接字符串。 字符串字面值并不是string对象，所以字面值和string对象相加时，必须确保每个+运算符两侧至少有一个string对象（为了自动类型转换为string）。建议使用C++版本的C标准库头文件：name.h变成了cname。7、处理每个字符？用range-for循环！C++11string str(&quot;some string&quot;)for (auto c : str) cout &amp;lt;&amp;lt; c &amp;lt;&amp;lt; endl;range-for循环改变字符串中的字符必须把循环变量定义成引用类型！string s(&quot;hello world!&quot;);for (auto &amp;amp;c : s) c = toupper(c); // 转换成大写形式cout &amp;lt;&amp;lt; s &amp;lt;&amp;lt; endl;8、只处理一部分字符？下标[]运算符，需要保证合法！标准库类型vector使用vector，必须包含头文件。注意：vector是模板而非类型，由vector生成的类型必须包含元素的类型，比如vector&amp;lt;int&amp;gt;。根据模板创建类或函数的过程称为实例化。定义和初始化vector对象1、默认初始化：vector&amp;lt;int&amp;gt; v1; // 默认初始化 不含任何元素vector&amp;lt;int&amp;gt; v2(v1); // 拷贝 类型必须相同vector&amp;lt;int&amp;gt; v3 = v1; // 拷贝 类型必须相同2、列表初始化：三个特例： 拷贝初始化时(=)，只能提供一个初始值。 如果是一个类内初始值（类内初始化），只能使用拷贝初始化或使用花括号的形式初始化。 如果提供的是初始元素值的列表，只能把初始值放在花括号里进行列表初始化，而不能放在圆括号里。 vector&amp;lt;int&amp;gt; v1{1, 2, 3};vector&amp;lt;int&amp;gt; v2(1, 2, 3); // 错误！！！ 列表初始化还是元素数量？ 如果是()，提供的值是用来构造vector对象的，即元素数量。 如果是{}，表示想列表初始化vector对象，但是，如果提供的值又不能用来列表初始化，那么只能考虑用这样的值来构造vector对象了！为了区分，养成好习惯，只用()构造对象，用{}初始化对象。vector&amp;lt;string&amp;gt; v1{&quot;hi&quot;}; // 列表初始化vector&amp;lt;string&amp;gt; v2{10}; // 10个默认初始化的对象，容易混淆，是吧？向vector中添加元素vector对象能够高效增长： C++标准要求vector能在运行时高效快速的添加元素，因此在定义vector对象时设定大小就没什么必要了，事实上如果这么做性能可能会更差！只有所有元素的值都一样才设定大小和初始值，否则更有效的方法就是定义一个空的vector对象，然后在运行时添加元素。不能使用range-for循环向vector对象添加元素： range-for循环不应改变其所遍历序列的大小。vector对象的下标运算符可用于访问已存在的元素，而不能用来添加元素！迭代器介绍使用迭代器1、如果容器为空，begin和end返回的是同一个迭代器，都是尾后迭代器。2、所以检查容器非空，可以看begin和end的返回结果是否一致。string s(&quot;some string&quot;);if(s.begin() != s.end()) // 检查容器是否为空 其实可以直接用empty() auto it = s.begin();要养成使用迭代器和!=的习惯： 只有string和vector等一些标准库类型有下标运算符。类似的，所有标准库容器的迭代器都定义了==和!=，而它们中的大多数没有定义&amp;lt;运算符，所以使用迭代器和!=，就不用在意是那种类型的容器。for (auto it = s.begin(); it != s.end(); ++it) // 用迭代器和!=而不是&amp;lt;3、我们不知道迭代器的精准类型（也无需知道），用iterator来表示。vector&amp;lt;int&amp;gt;::iterator it;string::iterator it2;4、解引用和成员访问运算符简化为-&amp;gt;。(*it).empty();it-&amp;gt;empty();迭代器运算iter + n; // 迭代器运算必须指向同一个容器的元素&amp;gt; &amp;gt;= &amp;lt; &amp;lt;=; // 迭代器指向的容器位置在另一个迭代器所指位置之前 则前者小于后者数组与vector相同的地方是： 数组也是存放类型相同的容器，需要通过其所在位置访问。 元素是对象，不存在引用。不同的是： 数组的大小固定，不能随意向数组中添加元素。 数组不允许相互拷贝和赋值。 标准库类型限定使用的下标必须是无符号类型，而内置数组无此要求。定义和初始化数组1、数组是一种复合类型，定义数组的时候必须指定数组的类型，不允许用auto关键字由初始值的列表推断类型。2、对数组的元素进行列表初始化时，允许忽略数组的维度。3、字符数组可以使用字符串字面值来初始化但是要注意字面值的结尾处还有一个空字符。char a1 = &quot;C++&quot;;char a2[6] = &quot;daniel&quot;; // 错误 没有空间存放空字符&#39;\\0&#39;4、要理解数组声明的含义，最好的办法就是从数组的名字开始由内向外的顺序阅读。int (*Parray)[10] = &amp;amp;arr; // Parrar是一个指针 指向大小为10的数组 数组元素为intint *(&amp;amp;array)[10] = ptrs; // array是数组的引用 该数组含有是个指针指针和数组1、用到数组名字的时候，编译器会自动地将其替换为一个指向数组首元素的指针。string *p2 = nums; // 等价于p2 = &amp;amp;nums[0];2、在一些情况下数组的操作实际上是指针的操作。int a[] = { 1, 2, 3 };auto a2(a); // a2是一个整型指针 指向a的第一个元素decltypr(a) a3 = { 4, 5, 6 }; // a返回的类型是由3个整数构成的数组注意：使用decltype关键字时上述转换不会发生！3、指针也是迭代器，vector和string迭代器支持的操作，数组的指针都支持。int *p = arr;++p; // p指向arr[1]int num2 = *p; // 如果指针指向了一个元素 允许解引用该指针标准库函数begin()和end(): begin函数返回数组首元素的指针，end函数返回尾后指针，函数定义在iterator头文件中。int a[];int *beg = begin(a); // 指向a首元素的指针int *end = end(a); // 指向b首元素的指针4、下标和指针内置数组使用下标运算符时，编译器会自动将数组的名字转换为指向首元素的指针。int a = { 0, 2, 4, 6, 8 };int i = a[2]; // a转换成指向数组首元素的指针 a[2]得到a+2的元素int *p = a;i = *(p + 2); // 等价于i = a[2]int k = p[-2]; // p[-2]就是a[0]那个元素 证明了下标是有符号类型C风格字符串 尽管C++支持C风格字符串，但是C++程序中最好不要使用它们，因为不仅不方便，而且极易引发程序漏洞。传入C标准库string函数的指针必须指向以空字符作为结束的数组！strlen(p); // 返回p的长度 空字符不计算在内strcmp(p1, p2); // 比较p1和p2的相等性 相等返回0 大于返回正值 小于返回负值strcat(p1, p2); // p2附加到p1后面 返回p1strcpy(p1, p2); // 将p2拷贝给p1 返回p1char ca[] = { &#39;C&#39;, &#39;+&#39;, &#39;+&#39; };cout &amp;lt;&amp;lt; strlen(ca) &amp;lt;&amp;lt; endl; // 严重错误 ca没有以空字符结束与旧代码的接口1、混用string对象和C风格字符串。 允许使用以空字符结束的字符数组来初始化string对象或为string对象赋值。 允许string对象和以空字符结束的字符数组相加，但是两个对象不能全是。上述性质反过来不成立，不能用string对象代替C风格字符串。string提供了一个c_str()成员函数来实现通过string对象初始化字符数组。string s(&quot;hello world&quot;); // 允许字符串字面值初始化string对象char *str = s; // 错误 不能用string对象初始化char*char *str = s.c_str(); // 正确2、允许使用数组来初始化vector对象，只需要知名拷贝区域的首元素地址和尾后地址。int arr[];vector&amp;lt;int&amp;gt; vec(begin(arr), end(arr));多维数组1、多维数组就是数组的数组。2、使用range-for语句处理多维数组，除了最内层的循环外，其它所有循环的控制变量都应该是引用类型，以避免数组自动转换为指针。// 区别就是管理数组索引的任务交给了系统来完成。size_t cnt = 0;for (auto &amp;amp;row : arr){ for (auto &amp;amp;col : row){ // 这里用引用是因为要改变值 最内层可以不用引用类型 col = cnt; ++cnt; }}" }, { "title": "C++Primer5 第2章 变量和基本类型", "url": "/posts/C++Primer2/", "categories": "笔记, C++", "tags": "笔记, C++Primer5, C++", "date": "2021-12-12 15:14:26 +0800", "snippet": "说明：本章主要介绍基本内置数据类型。基本内置类型 算数类型：整型、浮点型、字符型、布尔 空类型：void算数类型1、算数类型的大小在不同机器上有所差别，C++规定了最小值。 char：8位，C++32、64位机器均为1个字节。 int：16位，C++32、64位机器均为4个字节。 long long ：64位，C++32、64位机器均为8个字节。 float：6位有效数字，C++中默认保留6位有效数字，4个字节。 double：10位有效数字，C++中默认保留6位有效数字，8个字节 C++中32位机器所有指针类型为4个字节，64位机器为8个字节。2、字与字节。 字节：可寻址的最小内存块，byte，一个字节8bite。 字：存储的基本单元，word，一个字32bite或64bite，即4或8字节。3、带符号类型可以表示正数、负数和0，无符号类型只能表示正数或0。如何选择类型： 明确知晓不可能为负时，选择无符号数。 整型一般用int，不够用long long。 在算数表达式中不要使用类型char和bool，只有存放数据时才使用它们。因为char根据机器不同可能有符号，也可能没符号。 浮点数用double，精度高且和float计算代价差不多，甚至还更快。 类型转换1、数据类型不同时，C++会隐式转换（如果可以转换的话），所以需要特别注意隐式类型转换，防止得不到自己想要的结果。2、赋给一个无符号类型一个超出它表示范围的值时，结果是初始值对无符号类型表示数值总数取模后的余数。unsigned a = 10;int c = -42;cout &amp;lt;&amp;lt; a + c &amp;lt;&amp;lt; e;// int是4个字节// 4294967264 负数变成无符号数：对2^32取模后加上负数自身切勿混用带符号整数和无符号整数： 带符号整数会自动的转换成无符号整数，出现异常结果。字面值常量1、转义序列：某些特殊字符如退格、引号、反斜线等需要用\\来使用。变量变量提供一个具名的、可供程序操作的存储空间。C++中每个变量都有数据类型，数据类型决定着变量所占内存空间的大小和布局方式、该空间能存储的值的范围，以及变量能参与的运算。C++变量和对象一般可以互换使用。变量定义1、在C++中，初始化和赋值是两个完全不同的操作。 初始化不是赋值，初始化的含义是创建变量时赋予其一个初始值，而赋值的含义是把对象的当前值擦除，用一个新值替代。2、列表初始化，用{}来初始化变量。C++11 用于内置类型时，使用列表初始化且列表初始值存在丢失风险时，编译器会报错。int a = 10;int b = { 10 };int c{ 10 };int d(10);double f = 3.14159; int e{ f }; // 报错 转换未执行 因为存在丢失信息的风险 （）和 = 可以正常执行cout &amp;lt;&amp;lt; e &amp;lt;&amp;lt; endl;3、默认初始化，如果定义变量为指定初值，变量被默认初始化。 定义在任何函数体之外的变量（全局变量）被初始化为0。 定义在函数体内部的内置变量不被初始化，发生未定义行为错误。 类的对象为初始化，其值由类决定（比如默认构造函数）。变量声明和定义的关系1、声明使得名字为程序所知，定义负责创建与名字关联的实体。变量可以多次声明，但只能定义一次。2、声明一个变量而非定义，在变量前添加extern，且不要显式初始化，一旦显式初始化，extern就没有作用了，即变量变成定义了。extern int i;静态类型： C++是一种静态类型语言，含义是在编译阶段检查类型。程序越复杂，静态类型检查越有助于发现问题，这要求我们使用变量之前必须先声明其类型。标识符1、C++标识符有字母、数字、下划线组成，不能以数字开头，对大小写敏感。2、C++库保留了一些名字，用户自定义的标识符中不能连续出现两个下划线，也不能以下划线紧接大写字母开头，此外，定义在函数体外的标识符不能以下划线开头。名字的作用域1、名字的有效作用域始于名字的声明语句，以声明语句所在的作用域末端为结束。当你第一次使用变量时再定义它： 更容易找到变量的定义；可以给一个比较合理的初始值。2、全局作用域的名字在整个程序范围内都可使用，块作用域离开块就无法使用，但在其嵌套的内层作用域中可以访问，也可以重新定义。 如果函数有可能用到全局变量，不宜再定义一个同名的局部变量。复合类型复合类型是指基于其它类型定义的类型，比如引用和指针。引用1、引用即别名，一旦初始化，就和初始化对象一直绑定在一起，无法重新绑定对象，所以引用必须初始化。2、引用并非对象，它只是为一个已经存在的对象所起的另外一个名字，所以不能定义引用的引用。3、引用只能绑定在对象身上，不能与某个字面值或者表达式的计算结果绑定在一起。int i = 10;int &amp;amp;r = i; // 绑定在i上double dval = 3.14; // 错误int &amp;amp;dval2 = dval; // 错误指针1、指针本身就是一个对象，允许对指针进行赋值和拷贝，在指针的生命周期内可以先后指向几个不同的对象。2、指针无须在定义时赋初值，和其他内置类型一样，在块作用域内如果没有被初始化，将拥有一个不确定的值。int ival = 42;int *p = &amp;amp;ival; // 需要使用取地址符&amp;amp;cout &amp;lt;&amp;lt; *p; // 使用解引用符*来访问指针对象3、生成空指针的方法int *p1 = nullptr; // C++11 最好使用这个int *p2 = 0;int *p3 = NULL;4、任何非0指针对应的条件值都是true，两个类型相同的合法指针，可以用==和!=来比较。5、void*指针可以存放任意对象的地址，但我们不知道地址中到底是什么类型的对象。理解符合类型的声明1、同一条定义语句中，基本数据类型只有一个，但是声明符的形式可以不同。int i = 1024, *p = &amp;amp;i, &amp;amp;r = i;2、多个变量的定义中，类型修饰符*或&amp;amp;只是修饰变量，而不是数据类型。int* p1, p2; // p1是指向int的指针，p2不是。3、指向指针的指针。int val = 1024;int *pi = &amp;amp;val; // pi指向一个int型的数int **ppi = &amp;amp;pi; // ppi指向一个int型的指针cout &amp;lt;&amp;lt; val &amp;lt;&amp;lt; *pi &amp;lt;&amp;lt; **ppi &amp;lt;&amp;lt;endl; // 输出都是val的值4、引用本身不是一个对象，所以不能定义指向引用的指针，但是可以定义指向指针的引用。int i = 42;int *p;int* &amp;amp;r = p; // r是一个对指针的引用r = &amp;amp;i; // r引用了一个指针 给r赋值&amp;amp;i就是令p指向i*r = 0; // 解引用r得到i 也就是p指向的对象 比较复杂的指针和引用声明时，从右往左阅读。const限定符1、const对象必须要初始化，因为一旦创建其值后就不能更改。2、const对象默认状态下仅在文件内有效，当多个文件中出现了同名的const变量时，等同于在不同文件中分别定义了独立的变量。3、为了只定义一个而在多出声明并使用，对于const变量不管是声明还是定义都添加extern关键字，这样只需定义一次即可。extern const int bufSize = fcn(); // 一个文件定义extern const int bufSize; // 另一个文件声明并使用const的引用1、对常量的引用，不能用作修改它所绑定的对象。const int ci = 1024;const int &amp;amp;r1 = ci; // 常量对象的引用必须加const 变成常量引用r1 = 42; // 错误 不能修改绑定的对象 因为是const对象int &amp;amp;r2 = ci; // 错误 让一个非常量引用指向一个const对象 2、引用的类型必须与其所引用的对象类型一致。例外：允许为一个常量引用绑定一个非常量的对象、字面值，甚至是一个一般表达式，double val = 3.14;const int &amp;amp;ri = val;int &amp;amp;ri = val; // 非法 1是类型不一致 2是ri绑定在临时对象上 引用修改的不是val值// 编译器将上述转换为下面的语句const int temp = val; // val为double而ri引用的是int 所以会生成一个临时对象const int &amp;amp;ri = temp; // ri绑定到临时对象上面3、常量引用仅对引用可参与的操作做出了限定，对于引用的对象本身是不是一个常量未做限定，因为对象可能是个非常量，可以通过其它途径改变它的值。int i = 42;int &amp;amp;r1 = i; // 引用r1绑定到i上const int &amp;amp;r2 = i; // r2也绑定在对象i上 但不允许通过r2修改i的值r1 = 0; // 但是可以其它途径修改r2 = 0; // 错误 常量引用指针和const1、指向常量的指针不允许修改其所指对象的值。2、常量指针（引用）必须初始化，且指针（地址）不允许改变，即不能指向其它变量。顶层const1、顶层const：指针本身是个常量；底层const：指针所指的对象是一个常量。更一般的，顶层const可以表示任意的对象是常量，底层const与指针和引用等符合类型的基本类型部分有关关。指针类型既可以是顶层const也可以是底层const。2、拷贝操作时顶层const不受什么影响，因为拷贝并不会改变被拷贝对象的值。比如常量指针，指针（绑定的地址）不能改变，但是指针指向的值可以改变。3、拷贝操作时底层const有所限制，具有相同的底层const或者两个对象的数据类型能够相互转换，一般来说，非常量可以转换为常量，反之则不行。比如指向常量的指针，不能改变指针指向的对象的值。处理类型类型别名1、typedef关键字声明类型别名。typedef double wages; // wages是double的同义词typedef wages base, *p; // base是double的同义词 p是double*的同义词2、别名声明来定义类型的别名。C++11using SI = Sales_item; // 把等号左侧的类型规定成等号右侧的类型auto类型说明符使用auto也能在一条语句中声明多个变量，因为一条声明语句只能有一个基本数据类型，所以该语句中的所有变量初始基本数据类型都必须一样。C++11auto i = 0, *p = &amp;amp;i;auto sz = 0, pi = 3.14; // 错误decltype类型指示符C++11引入第二种类型说明符decltype，作用是选择并返回操作数的数据类型。在此 过程中，编译器分析表达式并得到它的类型，但不实际计算表达式的值。decltype(f()) sum = x; // sum的类型就是函数f的返回类型1、如果decltype使用的表达式是一个变量，则返回该变量的类型。2、如果decltype使用的表达式不是一个变量，则返回表达式结果对应的类型。3、表达式的类型是解引用操作，将得到引用类型int *p = &amp;amp;i;decltype(*p); // 得到int&amp;amp; 而非int4、decltype中的变量加了一对或多对括号，得到引用类型。因为变量可以作为赋值语句左值。int i;decltype((i)); // 得到int&amp;amp; 必须初始化自定义数据类型1、类定义的最后不要忘了加分号。2、为了确保各个文件中类的定义一致，类通常被定义在头文件中，而且类所在头文件的名字应该与类的名字一样。比如库string在名为string的头文件中。3、头文件保护符#define把一个名字设定为预处理变量，#ifdef当且仅当变量已定义时为真，#ifndef当且仅当变量未定义时为真，一旦结果为真，执行知道遇到#endif为止。#ifndef SALES_DATA_H#define SALES_DATA_H...#endif" }, { "title": "C++Primer5 第1章 开始", "url": "/posts/C++Primer1/", "categories": "笔记, C++", "tags": "笔记, C++Primer5, C++", "date": "2021-12-07 23:14:26 +0800", "snippet": "说明：第一章介绍C++的大部分基础内容，看完后可以编写运行一个简单的程序，所以这部分笔记主要记述一些重要的点(note部分)。类型： 一种类型不仅定义了数据的内容，还定义了这类数据上可以进行的运算。编译器： 编译器没有能力检查一个程序是否按照你的意愿运行，但可以检查形式上的错误，比如syntax error、type error、declaration error。因为单个错误尝尝具有传递效应，所以按照错误报告的顺序来逐个修正错误，是一种好习惯；另外，最好每修正一个错误后就重新编译代码。" }, { "title": "题解说明", "url": "/posts/solution-begin/", "categories": "题解", "tags": "C++, 题解, 算法", "date": "2021-12-01 00:00:00 +0800", "snippet": "作为一个非科班小白，在刷题过程中难免会遇到很多问题，虽然遇到问题之后会即时的去搜索学习，但是好记性不如烂笔头，更何况自己的记性还不好。。。哈哈哈，所以还是要记录下来，总结归纳，没事的时候看一下，这样才能不断精进。" }, { "title": "亚太数学建模比赛总结", "url": "/posts/APMCM-conclusion/", "categories": "思考", "tags": "数学建模, 亚太杯, 总结, 比赛", "date": "2021-11-30 15:30:21 +0800", "snippet": "和同门（衍绪、翔宇）一起报名参加了2021年亚太杯数学建模比赛，就比赛过程中的一些问题和感想做个总结。调试代码的能力： 大佬除外，大部分参加的同学应该都是现学现用，根据题目找到方法，然后调代码，跑结果。比赛用python语言写的，一边搜索资料，一篇调代码。第二问世用halcon写的，一个图像处理软件，因为题目是图像边缘处理，这个是我搜索资料的过程中找到的，之前完全没有用过，但是最后还是选用这个了，因为第二问效果挺好的。能够根据自己的想法找到代码调通，或者直接写出代码，这就是真正的动手能力，没有其它捷径，只能多学多练多做。写论文： 我们最后一天的晚上才开始写论文，这导致后面时间有点紧，所以三个人通宵了。虽然一晚上肝完了，但是写出来的效果肯定不是太好，这种比赛论文尤为重要，后面要是参加类似的比赛，一定要理清自己的思路，好好写论文，包装美化也是一种水平！最后，付出还是有回报的，第一次参加数模比赛， 最后获得了三等奖。虽然不够看，但总比没有强，继续努力，后面拿大奖！" }, { "title": "C语言谭浩强笔记", "url": "/posts/C-tanhaoqiang/", "categories": "笔记, C", "tags": "笔记, C", "date": "2021-11-26 00:00:00 +0800", "snippet": "Chapter1 程序设计和 C 语言计算机程序计算机语言 机器语言 汇编语言 高级语言 C语言的发展及特点C语言的特点： 语言简洁紧凑，使用方便灵活 运算符丰富 数据类型丰富 具有结构化的控制语句 语法限制不严格，程序设计自由度大 可以对底层硬件进行操作 用C语言写的程序可移植性好 代码质量高，执行效率高最简单的C语言程序C语言程序的结构： 一个程序由一个或多个源程序文件组成：预处理指令、全局声明、函数定义等。 函数是C语言的主要组成部分：包括函数首部和函数体。运行C程序的步骤和方法 输入和编辑源程序 编译源程序 连接处理 运行程序程序执行的任务 问题分析 设计算法 编写程序 编辑、编译和连接程序 运行程序，分析结果 编写程序文档Charpter2 算法——程序的灵魂算法一个程序主要包括两方面的信息： 对数据的描述。要用到哪些数据以及数据的类型和组织形式即数据结构。 对操作的描述。要求计算机进行操作的步骤即算法。算法 + 数据结构 = 程序计算机算法可分为两大类别：数值运算和非数值运算算法。算法的特性 有穷性。即有限的操作步骤。 确定性。步骤明确。 有零个或多个输入。 有一个或多个输出。 有效性。怎样表示一个算法 自然语言。文字描述通俗易懂但冗长且容易出现歧义。 流程图。顺序结构、分支结构、循环结构。 N-S流程图。删除了流程线和箭头。 伪代码表示。 计算机语言表示。结构化程序设计方法机构化程序设计方法的思路是：把一个复杂问题的求解过程分阶段进行，每个阶段处理的问题控制在人们容易理解和处理的范围内。具体有一下方法： 自顶而下 逐步细化 模块化设计 结构化编码自顶而下，逐步细化：考虑周全，结构清晰，层次分明，用工程的方法设计程序。自下而上，逐步积累：适合用于施工阶段。模块化设计：要注意模块的独立性，即使用一个模块完成一项功能，耦合性越少越好。chapter3 顺序结构设计设计举例数据的表现形式及其运算常量和变量常量 整型常量 实型常量：十进制小数形式、指数形式 字符常量：普通字符、转义字符 字符串常量：单&#39;&#39;只能包含一个字符，&quot;&quot;可以包含一个字符串 符号常量：用#define指令，指定用一个符号名称代表一个变量变量变量必须先定义，后使用，在定义时指定变量的名字和类型常变量const int a = 3;常变量是有名字的不变量，而常量是没有名字的不变量，有名字就便于在程序中引用标识符C语言规定边师傅只能有字母、数字、下划线组成，且第一个标识符不能是数字数据类型有基本类型（整型和浮点型）、枚举类型enum、空类型void、派生类型，不同类型的数据在内存中占用的存储单元长度是不同的整型数据补码：将此数的绝对值写成二进制形式，然后对后面所有的二进位取反再加1有基本整型int、短整型short int、长整型long int、双长整型long long int sizeof是测量类型和变量长度的运算符在类型前面加上修饰符unsigned，表示指定该变量为无符号整数类型，只有正值，不能赋予负值，用%u格式输出字符型数据字符变量用类型复char来定义，用%c格式输出浮点型数据float 型、double型、long double型，用%f、%lf格式输出运算符和表达式%取余，要求运算对象为整数，结果也为整数自增自减运算符只能用于变量，不能用于常量和表达式一个字符既可以以字符形式输出（在0-127范围内）、也可以以整数形式输出强制类型转换运算符，(int)(x+y)，（类型名）（表达式）C语句C语句的作用和分类控制语句：if else\\for\\while\\do while\\continue\\break\\switch\\return\\goto函数调用语句：一个函数调用加一个分号组成表达式语句：一个表达式加一个分号组成空语句：单独一个分号，作为流程的转换点或者空循环体复合语句：用{}把一些语句括起来幅值语句变量能够作为左值，常量、算数表达式、赋值表达式不能作为左值数据的输入输出print函数输出数据print(格式控制，输出表列)格式控制：格式声明（%和格式字符组成）、普通字符输出表列：可以使常量、变量、表达式格式字符：%d %f %m.nf %lf %c %s %e %m.ne %o %x %u...如果想要输出%，要用连续的两个%%表示scanf函数输入数据scanf(格式控制，地址表列)如果在格式控制字符串中除了格式声明以外还有其他字符，则在输入数据时在对应的位置上应输入与这些字符相同的字符。scanf(&quot;%a=f,b=%f,c=%f&quot;,&amp;amp;a,&amp;amp;b,&amp;amp;c);应该输入：a=1,b=3,c=2回车字符数据的输入输出putchar(c)表示输入字符变量c的值，是一个字符getchar()只能接受一个字符，想要输入多个字符就要用到多个getchar函数Chapter4 选择结构程序设计选择结构C语言有两种选择语句： if语句，用来实现两个分支的选择机构 switch语句，用来实现多分支的选择语句if语句if（表达式1）语句1else if（表达式2）语句2else（表达式3）语句3if语句的表达式可以是关系表达式、逻辑表达式和数值表达式关系运算符和关系表达式逻辑运算符和逻辑表达式优先级为：非&amp;gt;算数运算符&amp;gt;关系运算符&amp;gt;与和或&amp;gt;幅值运算符条件运算符和条件表达式表达式1？表达式2：表达式3 唯一的三目运算符，可以嵌套switchswitch(表达式){case 常量1：语句1；break;case 常量2：语句2；break;default: 语句n;}说明：Chapter5 循环结构程序设计while循环while(表达式){ 语句；}do-while循环do{ 语句；}while（表达式）；for循环for(循环变量赋初值；循环条件；循环变量增值){ 语句；}for语句循环功能强大，有些需要注意的点： 表达式1和表达式3可以是简单的表达式，也可以是逗号表达式，在逗号表达式内按自左向右顺序求解，逗号表达式的值为最右边的表达式的值for(i=1;i&amp;lt;=100;i++,i++)sum=sum+ifor（i=1;i&amp;lt;=100;i=i+2）sum=sum+i 表达式2一般为关系表达式或者是逻辑表达式，但也可以是数值表达式或字符表达式，只要其值为非零，就可以执行循环体for(;(c=getchar())!=&#39;\\n&#39;;) printf(&quot;%c&quot;, c);上面代码的意思是每读入一个字符就输出一个字符，知道输入一个换行字符为止改变循环执行的状态break用来跳出循环体，即提前结束循环continue用来提前结束本次循环，接着执行下次循环Chapter6 数组处理批量数据数组是一组有序数据的组合用一个数组名和下标来唯一确定数组中的元素数组中的每个元素都属于统一类型将数组和循环结合起来，可以有效处理大量的数据定义和引用数组定义数组：类型符 数组名【常量表达式】int a[10] 数组名遵循标识符命名规则 数组下标从0开始 常量表达式可以是常量或者符号常量，但是不允许做动态定义 如果在被调用的函数中定义数组，其长度可以是变量或非常量表达式，因为n的值会从实参传来void function(int n){ int a[2*n];}引用数组:数组名【下标】一维数组的初始化：定义数组的同时可以给数组元素赋值 对全部元素赋值int a[10] = {0,1,2,3,4,5,6,7,8,9}; 对一部分元素赋值，未赋值的自动初始为0 想使数组元素全部为零，可以直接int a[10] = {0};定义和引用二维数组定义二维数组：类型说明符 数组名【常量表达式】【常量表达式】 二维数组排列的顺序是按行存放的引用二维数组：数组名【下标】【下标】二维数组的初始化： 分别给二维数组赋值，一个花括号对应一行int a[2][3] = { {1,2,3},{4,5,6} }; 可以将所以数据写到一个花括号中，按照内存顺序进行赋值 可以对部分元素赋值 对全部元素赋值，第一维长度可以不指定，第二维长度不能省字符数组C语言中没有字符串类型，字符串是存放在字符型数组中的定义字符数组：char a[10];字符数组初始化：引用元素：for循环遍历字符串和字符串结束标志： 实际工作中，更关心的是字符串的有效长度而不是字符数组的长度 C语言个UI订乐一个字符串结束标志，以\\0作为结束标志 C语言在字符数组存储字符常量时自动加一个\\0作结束符 通过\\0放在不同位置，可以控制字符串的输出字符数组的输入输出： 逐个字符输入输出，用%c 将整个字符串一次输入输出，用%s 如果数组长度大于字符串的实际长度，遇到\\0结束输出 可以用scanf输入一个字符串,数组名代表该数组的起始位置，不用加&amp;amp;，但是数组元素需要加&amp;amp;，如&amp;amp;a[i]scanf(&quot;%s&quot;,c);字符串处理函数： 输出字符串函数puts(字符数组) 输入字符串函数gets(字符数组) 字符串连接函数strcat(字符数组1，字符数组2)，将2接到1的后面 字符串复制函数strcpy(字符数组1，字符串2)，将字符串2复制到字符数组1中，字符数组1 必须是数组，2可以是字符串也可以是字符数组，strncpy可以将字符串2中的前面n个字符复制到字符数组1中 字符串比较函数strcmp(字符串1，字符串2),以第一对不相同的字符的比较结果为准，如果是两个因为字母比较，在英文字典中位置靠后的比较大，小写字母大于大写字母。字符串1=2，返回0；1&amp;gt;2,返回正整数&amp;gt;0；1&amp;lt;2，返回负整数&amp;lt;0 测试字符串长度的函数strlen(字符数组)，不包括\\0 转换为小写的函数strlwr(字符串) 转换为大写的函数strupr(字符串)Chapter7 函数每个函数用来实现特定的功能，方便调用，函数不能嵌套定义，但是可以互相调用定义函数包含函数的名字，函数的类型（即返回值的类型），函数参数德玛名字和类型以及函数的功能无参函数：类型名 函数名（）{ 函数体}有参函数：类型名 函数名（形式参数表列）{ 函数体}空函数:函数体是空的，没有任何实际作用，可以在准备扩充功能的地方使用调用函数 函数名（实参表列）：括号不能省略，参数之间逗号间隔 实际参数可以使常量、变量和表达式，但是要有确定的值 实参与形参的类型应该相同或赋值兼容 返回值的类型要和函数类型一致，以函数类型为准 只能由实参传给形参，单向传递 调用的函数必须是已经定义的函数，调用前使用函数声明 函数不能嵌套定义，但是可以嵌套调用 直接或者间接的调用函数本身，称为递归调用 数组元素的作用和变量相当，一般来说，凡是变量出现的地方，都可以用数组元素代替，数组元素只能作为函数实参 数组名可以作为实参和形参，传递的是数组第一个元素的地址 用数组名作为函数参数，应该在主调函数和被调用函数分别定义数组 形参数组可以不指定大小，跟一个【】 在函数内部或者复合语句内部定义的变量称为局部变量，哪里定义哪里使用 在函数外部定义的变量为全局变量，在本文件内都可以使用，第一个字母大写 如果变量同名，在局部变量的作用范围内，全局变量被屏蔽不起作用 static全局变量，只能在本文件中被引用 extern全局变量，可以在不同文件中引用 内部函数与外部函数与上面全局变量意义一样Chapter8 指针这部分内容复杂琐碎，后面会多看几遍，就先不总结了Chapter9 建立数据类型结构体变量结构体：由不同数据类型组成的组合型数据结构，数组智能存放同类型数据struct 结构体名{ 成员表列}； 成员表列也称为域表，成员命名规则与变量名相同 成员可以属于另一个结构体类型定义结构体类型变量： 先声明结构体类型，再定义该类型的变量，大程序用的多，随时指定 在声明类型的同时定义变量，小程序使用较为方便 不指定类型名而直接定义结构体类型变量，不常用结构体类型的成员名可以与程序中的变量名相同，但二者不代表同一对象对于结构体变量中的成员可以单独使用，作用相当于普通变量结构体变量的初始化和引用： 在定义结构体变量时可以对它的成员初始化struct Student b = {.name = &quot;Zhou ShenShen&quot;} 可以引用结构体变量中成员的值，.是成员运算符，在所有运算符中优先级最高结构体变量名.成员名 只能对最低级的成员进行赋值或存取以及运算，需要一级一级的找到最低级成员 对结构体的成员可以像普通变量一样进行各种运算 同类型的结构体变量可以相互赋值 可以尹艳红结构体变量成员的地址，也可以引用结构体变量的地址结构体数组定义结构体数组：struct 结构体名{ 成员表列}数组名【数组长度】;声明一个结构体类型结构体类型 数组名【数组长度】;结构体指针结构体指针：指向结构体变量的指针，一个结构体变量的起始位置就是这个结构体变量的指针 指向结构体变量的指针，stu.num = (*p),num = p-&amp;gt;num 指向结构体数组的指针，指针类型和结构体变量基类型必须相同 用结构体变量和结构体变量的指针做函数参数链表链表：动态的进行存储分配的一种数据结构链表有头指针、结点、表尾，必须依靠指针变量才能实现，一个节点中包含一个指针变量，用它存放下一个结点的位置共用体类型共用体类型：几个不同的变量共享同一段内存的结构union 共用体名{ 成员表列}变量表列； 共同体变量所占的内存长度等于最长的成员的长度 不能引用共用体变量，只能引用共用体变量的成员 一个内存段可以用来存放几种不同类型的成员，但是一瞬时只能存放其中的一个，而不同同时存放几个 可以对共用体变量初始化，但是初始化表只能有一个变量 共用题变量起作用的是最后一次被赋值的成员 共同体变量和它的各成员的地址都是同一地址 不能引用或者对共用体变量幅值 共用体类型可以出现在结构体类型定义中，亦可以定义共用体数组枚举类型枚举类型：一个变量只有集中可能地值enum [枚举名]{枚举元素列表}； 枚举元素为常量，不可赋值 每一个枚举元素都代表一个整数，从0,1,2,3，… 枚举元素可以用来作判断比较typedef声明新类型名 先按定义变量的方法写出定义体（如int i;） 将变量名换成新类型名（将i换成Count） 在最前面加上typedef（typedef int Count） 然后可以用新类型名去定义变量Chapter10 文件操作C文件程序文件：源程序文件.c 目标文件.obj 可执行文件.exe数据文件：文本文件（ASCII文件）和二进制文件 文本文件：字节和字符一一对应，一个字节代表一个字符，便于对字符进行逐个处理，也便于输出字符，但一般占存储空间多，而且花费转换时间 二进制文件：可以节省外存空间和转换时间，每一个字节不一定代表一个字符，在读写过程中常用二进制文件，无需转换文件名：包络文件路径 文件名主干 文件后缀D:\\CC\\temp\\file1.dat文件缓冲区：系统自动地在内存区为程序中每一个正在使用的文件开辟一个文件缓存区文件类型指针：每个被使用的文件都在内存中开辟了一个相应的文件信息区，用来存放文件相关的信息（文件名、文件状态和文件当前位置等）。这些信息保存在一个结构体变量中，该结构体变量由系统声明的，取名为 FILE FILE *fp;定义fp是一个指向FILE类型数据的指针变量，通过文件指针变量fp能够找到与它相关联的文件，n个文件应设n个指针用来实现对n个文件的访问打开和关闭文件打开文件：是指为文件建立相应的信息区和文件缓冲区fopen(文件名，使用文件方式)；fopen(&quot;file.dat&quot;, &quot;r&quot;);关闭文件：是指撤销文件信息区和文件缓冲区，使文件指针变量不再指向改文件fclose(文件指针)；fclose(fp);文件检查：文件打开时进行文件检查，如果不存在文件或者其它则报错if((fp = fopen(&quot;file1.dat&quot;, &quot;r&quot;)) == NULL){ printf(&quot;can not open the file\\n&quot;); exit(0);//程序中止函数 在stdlib.h头函数中}顺序读写数据文件向文件读写字符：fgetc(fp); 从fp指向的文件中读入一个字符fputc(ch,fp); 把字符ch写到fp所指向的文件中 feof(fp)：可以检查到文件读写位置标记是否移到文件的末尾，即文件是否结束向文件读写字符串：fgets(str, n, fp);//从fp文件中读入一个长度为n-1的字符串,存到字符数组str中fputs(str, fp)//把str所指向的字符串写到fp指向的文件中 fgets fputs以指定的文件为读写对象 gets puts以终端为读写对象格式化读写文件：fprintf(文件指针，格式化字符串，输出表列)；fprintf(fp, &quot;%d,%6.2f&quot;, i, f);fscanf(文件指针，格式化字符串，输出表列)；fscanf(fp,&quot;%d,%f&quot;, &amp;amp;i, &amp;amp;f);二进制方式读写一组数据：fread(buffer,size,count,fp);fwrite(buffer,size,count,fp);//buffer：是一个地址，比如数组首位置//size：要读写的字节数//count：要读多少个数据项（每个数据项长度为size）//fp：FILE类型指正for (i=0; i&amp;lt;10; i++){ fread(&amp;amp;stud[i],sizeof(struct Student_type),1,fp); //每次读入结构体数组stu的一个元素}随机读写数据文件文件位置标记：系统为每个文件设置了一个文件读写位置标记，用来指示接下来要读写的下一个位置文件位置标记的定位： rewind(fp)函数使文件位置标记指向开头 fseek函数改变文件位置标记fseek(文件类型指针，位移量，起始点)；//起始点用0、1、2代替，分别表示文件开始位置、当前位置、文件末尾位置//位移量以起始点为基点，向前移动的字节数，位移量应是long型数据fseek(fp,100L,0);//将文件位置标记向前移到离文件开头100个字节处fseek(fp,50L,1);//将文件位置标记向前移到离当前位置50个字节处fseek(fp,-10L,2);//将文件位置标记从文件末尾处向后退10个字节 ftell函数测定文件位置标记的当前位置i = ftell(fp);//变量i存放文件当前位置文件读写的出错检测 ferror(fp)函数：返回值为0表示未出错 clearerr(fp)函数：使文件错误标志和文件结束标志置为0，假设在调用一个输入输出函数时出现错误，ferror函数值为一个非零值，应该立即调用clearerr函数使其置零，以便进行下一次检测 " }, { "title": "C语言翁凯笔记", "url": "/posts/C-wengkai/", "categories": "笔记, C", "tags": "笔记, C", "date": "2021-11-16 00:00:00 +0800", "snippet": "笔记记在本子上了，不是很多，这里做一下总结吧。总结前前后后大概花了有两个多周的时间把翁凯的c程序设计入门课程看完了，学习到了很多的东西，算是重新学习了一下c语言，毕竟本科学的不行，并且已经过去了好几年。翁凯老师讲的很好，深入浅出，从中学习到了一些编程的基础知识，通过对例题的程序编写提高了自己的写代码能力，算是刚刚入门吧，虽然之前学习了python，但是通过这个课程系统的学习，发现程序还是有很多共同之处的，我也意识到了c语言更加接近底层。不足应该说指针以前的东西都听懂了，并且因为敲代码较多，所以对于简单的问题可以用代码来实现。但是指针之后就有些不太懂了，一方面是内容变复杂了，另一方面是这阶段的例题少，自己偷懒敲代码也少。计划学习一个东西最快的方法就是在实践中去学习，编程语言更是如此。接下来准备认真看一下谭浩强老师的c语言教材，系统的学习以下c语言，重点放在指针及后面的内容。要多敲代码，每个例题要彻底弄明白。" }, { "title": "博客分类测试", "url": "/posts/MyBlog-cate/", "categories": "项目, MyBlog", "tags": "test, blog", "date": "2021-11-14 00:00:00 +0800", "snippet": "问题：名称问题、评论系统、谷歌分析 名称问题还是没有解决，找不到哪里出了问题。 评论系统昨天摸索的时候disqus插件可以使用，但是disqus需要翻墙才能使用，而且个人不太喜欢disqus的ui，所以先不使用吧。 谷歌分析就更用不上了，想要网站浏览情况的话可以去百度统计看。后续：名称问题得到解决，谷歌分析加上了，尝试了几个常用的评论系统，发现都不太好用，而且自己暂时不太想实现评论功能，做个单纯的个人网页记录自己学习技术的历程就好了，后续如果有需要可以再添加评论给功能。" }, { "title": "博客bug说明", "url": "/posts/MyBlog-bug/", "categories": "项目, MyBlog", "tags": "bug, blog", "date": "2021-11-13 18:08:03 +0800", "snippet": "目前网页存在的bug：分类、标签点击链接出现404 。后续：文件路径没有设置好，调整后功能就可以正常使用啦！" }, { "title": "博客功能测试", "url": "/posts/MyBlog-test/", "categories": "项目, MyBlog", "tags": "test, blog", "date": "2021-11-13 17:07:44 +0800", "snippet": "这是一个测试文档，用来测试网页是否存在问题。" } ]
