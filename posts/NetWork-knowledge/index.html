<!DOCTYPE html><html lang="zh-CN" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="天前"><meta name="hour-prompt" content="小时前"><meta name="minute-prompt" content="分钟前"><meta name="justnow-prompt" content="刚刚"><meta name="generator" content="Jekyll v4.3.3" /><meta property="og:title" content="计网相关知识整理" /><meta property="og:locale" content="zh_CN" /><meta name="description" content="基础" /><meta property="og:description" content="基础" /><link rel="canonical" href="https://shenshenzhou.github.io/posts/NetWork-knowledge/" /><meta property="og:url" content="https://shenshenzhou.github.io/posts/NetWork-knowledge/" /><meta property="og:site_name" content="ShenshenZhou" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-07-19T20:06:20+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="计网相关知识整理" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="EbIRAK-yj0lEMVk1uQwtW66urJnY8yfKtT112zfnTfA" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-07-19T20:06:20+08:00","datePublished":"2022-07-19T20:06:20+08:00","description":"基础","headline":"计网相关知识整理","mainEntityOfPage":{"@type":"WebPage","@id":"https://shenshenzhou.github.io/posts/NetWork-knowledge/"},"url":"https://shenshenzhou.github.io/posts/NetWork-knowledge/"}</script><title>计网相关知识整理 | ShenshenZhou</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="ShenshenZhou"><meta name="application-name" content="ShenshenZhou"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://fastly.jsdelivr.net"><link rel="dns-prefetch" href="https://fastly.jsdelivr.net"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://fastly.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://fastly.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="zh-CN"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/images/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">ShenshenZhou</a></div><div class="site-subtitle font-italic">好好学习 天天向上</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>首页</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>分类</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>标签</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>归档</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>关于</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/ShenshenZhou" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['15797870468','163.com'].join('@')" aria-label="email" class="order-4" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-5" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> 首页 </a> </span> <span>计网相关知识整理</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> 文章</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="搜索..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >取消</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>计网相关知识整理</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> ShenshenZhou </span> 发表于 <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="2022-07-19, 20:06 +0800" >2022-07-19<i class="unloaded">2022-07-19T20:06:20+08:00</i> </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="37398 字">207 分钟 阅读</span></div></div><div class="post-content"><h1 id="基础">基础</h1><h2 id="tcpip-网络模型有哪几层">TCP/IP 网络模型有哪几层？</h2><p><strong>首先，需要明确，为什么要有TCP/IP网络模型？</strong></p><p>因为如果要对同一台设备上的进程间进行通信，有很多种方式，比如管道、消息队列、共享内存、信号等，但是对不同设备上的进程间通信，就需要网络通信，而设备是多种多样的，所以就要兼容这些设备，就协商出了一套<strong>通用的网络协议</strong>。</p><p>网络协议是分层的，每一层都有各自的作用和职责。</p><h3 id="应用层">应用层</h3><p>向用户提供应用服务并规定应用程序间通信的相关细节。比如HTTP、FTP、Telnet、DNS、SMTP等。</p><p>应用层是工作在操作系统中的用户态，传输层及以下则工作在内核态。</p><h3 id="传输层">传输层</h3><p>应用层的数据包会传给传输层，传输层是为应用层提供网络支持的。</p><p>在传输层会有两个传输协议，分别是 TCP 和 UDP。</p><p><strong>TCP</strong> 是可靠传输。TCP 相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等。</p><p><strong>UDP</strong> 是不可靠传输，只负责发送数据包，不保证数据包是否能抵达对方，但它实时性更好，传输效率也高。</p><p><strong>TCP段</strong>：应用需要传输的数据可能会非常大，如果直接传输就不好控制，因此当传输层的数据包大小超过 MSS（TCP 最大报文段长度） ，就要将数据包分块，这样即使中途有一个分块丢失或损坏了，只需要重新发送这一个分块，而不用重新发送整个数据包。在 TCP 协议中，每个分块称之为一个 TCP 段。</p><p><strong>端口</strong>：当设备作为接收方时，传输层则要负责把数据包传给应用，但是一台设备上可能会有很多应用在接收或者传输数据，因此需要用一个编号将应用区分开来，这个编号就是端口。</p><h3 id="网络层">网络层</h3><p>传输层值负责应用之间的通信，而网络层负责将数据从一各设备传输到另一个设备。</p><p>网络层最常使用的是 <strong>IP 协议</strong>，IP 协议会将传输层的报文加上 IP 头部组装成 IP 报文，如果 IP 报文大小超过 MTU（最大传输单元）就会再次进行分片。</p><p>IP协议主要有两个功能：</p><ul><li>寻址。通过IP地址确定数据包传输的目的地址。<li>路由。数据包到达一各节点后通过路由算法决定下一步的路径。</ul><h3 id="网络接口层">网络接口层</h3><p><strong>网络接口层</strong>在 IP 报文的前面加上 MAC 头部，并封装成数据帧（Data frame）发送到网络上。</p><h3 id="每一层的数据封装格式">每一层的数据封装格式</h3><p><img data-proofer-ignore data-src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%B5%AE%E7%82%B9/%E5%B0%81%E8%A3%85.png" alt="img" /></p><p>网络接口层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message），可以统称为数据包。</p><h2 id="键入网址到网页显示期间发生了什么">键入网址到网页显示，期间发生了什么？</h2><p>1、浏览器做的第一步工作是解析 URL，生成HTTP请求消息</p><p>2、生成HTTP消息后，通过DNS查询服务器域名对应的IP地址</p><p>3、获取到 IP 后，就可以把 HTTP 的传输工作通过调用socket库交给操作系统中的协议栈</p><p>4、TCP通过三次挥手建立连接，将数据封装成TCP数据包交给IP，IP封装成IP数据包交个网卡驱动</p><p>5、网卡驱动接受IP包，将其装交给网卡，网卡将包转换为电信号，通过网线发送出去</p><p>6、数据包通过交换机到达路由器，通过多个路由器的转发到达服务器</p><p>7、服务器逐层拆解数据包，根据请求响应资源，然后再发给客户端，客户端接受数据并在浏览器显示。</p><p>8、请求操作完成，客户端向服务器发起四次挥手断开连接。</p><h1 id="http">HTTP</h1><h2 id="http-常见面试题">HTTP 常见面试题</h2><h3 id="http-基本概念">HTTP 基本概念</h3><p>==HTTP 是什么？==</p><p>HTTP 是超文本传输协议，也就是<strong>H</strong>yperText <strong>T</strong>ransfer <strong>P</strong>rotocol。</p><p>超文本：互联网早期的文本只是简单的字符文字，而超文本是文字、图片、音频、视频、超链接等混合体。</p><p>传输：就是在两点之间传送数据。</p><p>协议：计算机之间通信约定的规范。</p><p>==HTTP 常见的状态码有哪些？==</p><p><img data-proofer-ignore data-src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81.png" alt=" 五大类 HTTP 状态码 " /></p><p><code class="language-plaintext highlighter-rouge">1xx</code> 类状态码属于<strong>提示信息</strong>，是协议处理中的一种中间状态，实际用到的比较少。</p><p><code class="language-plaintext highlighter-rouge">2xx</code> 类状态码表示服务器<strong>成功</strong>处理了客户端的请求。</p><ul><li>「<strong>200 OK</strong>」是最常见的成功状态码，表示一切正常。如果是非 <code class="language-plaintext highlighter-rouge">HEAD</code> 请求，服务器返回的响应头都会有 body 数据。<li>「<strong>204 No Content</strong>」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。<li>「<strong>206 Partial Content</strong>」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。</ul><p><code class="language-plaintext highlighter-rouge">3xx</code> 类状态码表示客户端请求的资源发生了变动，需要客户端用新的URL重新请求资源，即<strong>重定向</strong>。</p><ul><li>「<strong>301 Moved Permanently</strong>」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。<li>「<strong>302 Found</strong>」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。</ul><p>301 和 302 都会在响应头里使用字段 <code class="language-plaintext highlighter-rouge">Location</code>，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。</p><ul><li>「<strong>304 Not Modified</strong>」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。</ul><p><code class="language-plaintext highlighter-rouge">4xx</code> 类状态码表示客户端发送的<strong>报文有误</strong>，服务器无法处理。</p><ul><li>「<strong>400 Bad Request</strong>」表示客户端请求的报文有错误，但只是个笼统的错误。<li>「<strong>403 Forbidden</strong>」表示服务器禁止访问资源，并不是客户端的请求出错。<li>「<strong>404 Not Found</strong>」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。</ul><p><code class="language-plaintext highlighter-rouge">5xx</code> 类状态码表示客户端请求报文正确，但是<strong>服务器处理时内部发生了错误</strong>，属于服务器端的错误码。</p><ul><li>「<strong>500 Internal Server Error</strong>」，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。<li>「<strong>501 Not Implemented</strong>」表示客户端请求的功能还不支持。<li>「<strong>502 Bad Gateway</strong>」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。<li>「<strong>503 Service Unavailable</strong>」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。</ul><p>==HTTP 常见字段有哪些？==</p><p><strong>Host字段</strong>：客户端发送请求时，用来指定服务器的域名。</p><p><strong>Content-Length字段</strong>：表明服务器返回时，本次回应的数据长度。</p><p><strong>Connection 字段</strong>：用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。</p><p><strong>Content-Type 字段</strong>：用于服务器回应时，告诉客户端，本次数据是什么格式</p><p><strong>Content-Encoding 字段</strong>：表示服务器返回的数据使用了什么压缩格式</p><h3 id="get-与-post">Get 与 Post</h3><p>==GET 和 POST 有什么区别？==</p><p>GET 是从服务器获取指定的资源，比如文本、图片、视频等。</p><p>POST 是根据请求负荷（报文body）对指定的资源做出处理，具体的处理方式视资源类型而不同</p><p>==GET 和 POST 方法都是安全和幂等的吗？==</p><p>安全和幂等的概念：</p><ul><li>在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。<li>所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。</ul><p><strong>GET</strong> 方法就是安全且幂等的，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。因此，浏览器可以缓存get请求，也可以把get请求保存为书签。</p><p><strong>POST</strong> 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是<strong>不安全</strong>的，且多次提交数据就会创建多个资源，所以<strong>不是幂等</strong>的。浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签。</p><p>==GET 请求可以带 body 吗？==</p><p>理论上，任何请求都可以带 body 的，但是get的规范定义是请求资源，所以不需要用到body。</p><h3 id="http-缓存技术">HTTP 缓存技术</h3><p>==HTTP 缓存有哪些实现方式？==</p><p>对于一些具有重复性的 HTTP 请求，我们可以把「请求-响应」的数据都<strong>缓存在本地</strong>，那么下次就直接读取本地的数据，这样可以提高HTTP的性能。</p><p>HTTP 缓存有两种实现方式，分别是<strong>强制缓存和协商缓存</strong>。</p><p>==什么是强制缓存？==</p><p>强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。</p><ul><li><code class="language-plaintext highlighter-rouge">Cache-Control</code>， 是一个相对时间；<li><code class="language-plaintext highlighter-rouge">Expires</code>，是一个绝对时间；</ul><p>如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，<strong>Cache-Control的优先级高于 Expires</strong> 。Cache-control 选项更多一些，设置更加精细，所以建议使用 Cache-Control 来实现强缓存。具体如下：</p><ul><li>当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 响应头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；<li>浏览器再次请求访问服务器中的该资源时，会先<strong>通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期</strong>，如果没有，则使用该缓存，否则重新请求服务器；<li>服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。</ul><p>==什么是协商缓存？==</p><p>通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。</p><p>协商缓存可以基于两种头部来实现。</p><p>第一种：请求头部中的 <code class="language-plaintext highlighter-rouge">If-Modified-Since</code> 字段与响应头部中的 <code class="language-plaintext highlighter-rouge">Last-Modified</code> 字段实现，这两个字段的意思是：</p><ul><li>响应头部中的 <code class="language-plaintext highlighter-rouge">Last-Modified</code>：标示这个响应资源的最后修改时间；<li>请求头部中的 <code class="language-plaintext highlighter-rouge">If-Modified-Since</code>：当资源过期了，发现响应头中具有 Last-Modified 声明，则再次发起请求的时候带上If-Modified-Since的时间，服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。</ul><p>第二种：请求头部中的 <code class="language-plaintext highlighter-rouge">If-None-Match</code> 字段与响应头部中的 <code class="language-plaintext highlighter-rouge">ETag</code> 字段，这两个字段的意思是：</p><ul><li>响应头部中 <code class="language-plaintext highlighter-rouge">Etag</code>：唯一标识响应资源；<li>请求头部中的 <code class="language-plaintext highlighter-rouge">If-None-Match</code>：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。</ul><p>第一种实现方式是基于时间实现的，第二种实现方式是基于一个唯一标识实现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。</p><p>注意：协商缓存这两个字段都需要配合强制缓存中 Cache-control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求。</p><h3 id="http-特性">HTTP 特性</h3><p>==HTTP（1.1） 的优点有哪些？==</p><p>HTTP 最凸出的优点是「<strong>简单、灵活和易于扩展、应用广泛和跨平台</strong>」。</p><p>简单：HTTP 基本的报文格式就是 <code class="language-plaintext highlighter-rouge">header + body</code>，头部信息也是 <code class="language-plaintext highlighter-rouge">key-value</code> 简单文本的形式，易于理解，降低了学习和使用的门槛。</p><p>灵活和易于扩展：HTTP协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员自定义和扩充。</p><p>应用广泛和跨平台：可以用在不同操作系统以及手机上的各种应用中。</p><p>==HTTP（1.1） 的缺点有哪些？==</p><p>有无状态、明文传输的双刃剑，同时还有一大缺点「不安全」。</p><p>无状态：</p><p>无状态的<strong>好处</strong>，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担。无状态的<strong>坏处</strong>，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦，没操作一次都要验证信息。比较简单的解决方式是<strong>cookie</strong>技术。</p><p><code class="language-plaintext highlighter-rouge">Cookie</code> 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。具体过程是：客户端第一次请求后，服务器在响应中添加cookie后返回，然后客户端如果保存了cookie，在第二次请求时就会带上cookie，服务器通过检查cookie来辨认客户端。</p><p>明文传输：</p><p>明文意味着在传输过程中的信息，是可方便阅读的，也方便调试。但是这样会引发信息安全问题。</p><p>不安全：比较严重的缺点，可以用HTTPS的方式解决。</p><ul><li>通信使用明文（不加密），存在窃听风险。比如，<strong>账号信息容易泄漏导致被盗号。</strong><li>不验证通信方的身份，存在冒充风险。比如，<strong>访问假的淘宝、拼多多导致被骗钱。</strong><li>无法证明报文的完整性，存在篡改风险。比如，<strong>网页上植入垃圾广告影响使用体验</strong></ul><p>==HTTP/1.1 的性能如何？==</p><p>长连接：HTTP/1.1 提出了<strong>长连接</strong>的通信方式，好处是减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。</p><p>管道连接：因为使用了长连接的方式，所以管道网络传输成为了可能，也就是在发送请求的时候，不必等到请求相应就可以发送另一个请求，从而减少整体的响应时间。但是没有默认开启，浏览器也很少有支持的。</p><p>队头阻塞：「请求 - 应答」的模式加剧了 HTTP 的性能问题，容易引发队头阻塞问题。即顺序发送的请求序列中一个请求被阻塞后，后面的所有请求也一同被阻塞了，导致客户端一直请求不到数据。</p><p>总之 HTTP/1.1 的性能一般般，后续的 HTTP/2 和 HTTP/3 就是在优化 HTTP 的性能。</p><h3 id="https-与-http">HTTPS 与 HTTP</h3><p>==HTTP 与 HTTPS 有哪些区别？==</p><ol><li>HTTP 是明文传输，存在安全问题，HTTPS 针对此问题在 TCP 和 HTTP 之间加入了 SSL/TLS 安全协议。<li>HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。<li>HTTP 的端口号是 80，HTTPS 的端口号是 443。<li>HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。</ol><p>==HTTPS 是如何解决HTTP的安全问题的？==</p><p>安全问题主要有三个：明文传输导致的窃听风险，不验证通信方身份导致的冒充风险，无法证明报文的完整性导致的被攥改风险。解决方法分别如下：</p><ul><li>信息加密：使用混合加密的方式对传输的信息进行加密<li>身份证书：使用数字证书验证通信方身份<li>校验机制：使用摘要算法来保证校验数据的完整性</ul><p><strong>混合加密：</strong></p><p>HTTPS 采用的是对称加密和非对称加密结合的「混合加密」方式：</p><ul><li>在通信建立前采用<strong>非对称加密</strong>的方式交换「会话秘钥」，后续就不再使用非对称加密。<li>在通信过程中全部使用<strong>对称加密</strong>的「会话秘钥」的方式加密明文数据。</ul><p>采用「混合加密」的方式的原因：</p><ul><li><strong>对称加密</strong>只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。<li><strong>非对称加密</strong>使用两个密钥：公钥和私钥，公钥可任意分发而私钥保密，解决了密钥交换问题但速度慢。</ul><p>非对称加密常用算法有RSA和ECDHE（椭圆曲线加密）。</p><p><strong>摘要算法</strong>：</p><p>用摘要算法（哈希函数）来计算出内容的哈希值，这个<strong>哈希值是唯一的，且无法通过哈希值推导出内容</strong>。客户端将内容和哈希值一同发送出去，服务端收到后对内容也计算出一个哈希值，计较两个哈希值是否相同就可以判断内容是否被篡改。</p><p>但哈希算法并不能保证内容+哈希值不会被其他人替换。可以使用非对称加密算法来解决这个问题：</p><ul><li><strong>公钥加密，私钥解密</strong>。这个目的是为了<strong>保证内容传输的安全</strong>，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；<li><strong>私钥加密，公钥解密</strong>。这个目的是为了<strong>保证消息不会被冒充</strong>，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。</ul><p>一般我们不会用非对称加密来加密实际的传输内容，因为非对称加密的计算比较耗费性能的。</p><p>数字签名算法就是通过「私钥加密，公钥解密」的非对称加密方式，来确认消息的身份。不过私钥加密内容不是内容本身，而是对内容的哈希值加密。私钥是由服务端保管，然后服务端会向客户端颁发对应的公钥。如果客户端收到的信息，能被公钥解密，就说明该消息是由服务器发送的。</p><p><strong>数字证书</strong>：</p><p>使用加密算法可以对信息进行加密，对信息完整性进行校验，但是还有一个问题，就是身份验证问题，也就是要确保公钥的身份正确，因为公钥也可能会被伪造。</p><p>通过CA（数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。</p><p>==HTTPS 是如何建立连接的？其间交互了什么？==</p><p>SSL/TLS 协议基本流程：</p><ul><li>客户端向服务器索要并验证服务器的公钥。<li>双方协商生产「会话秘钥」。<li>双方采用「会话秘钥」进行加密通信。</ul><p>前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段。SSL/TLS 协议建立的详细流程（基于RSA的HTTPS）：</p><p><strong>1. ClientHello</strong></p><p>首先，由客户端向服务器发起加密通信请求，也就是 <code class="language-plaintext highlighter-rouge">ClientHello</code> 请求。</p><p>在这一步，客户端主要向服务器发送以下信息：</p><p>（1）客户端支持的 SSL/TLS 协议版本，如 TLS 1.2 版本。</p><p>（2）客户端生产的随机数（<code class="language-plaintext highlighter-rouge">Client Random</code>），后面用于生成「会话秘钥」条件之一。</p><p>（3）客户端支持的密码套件列表，如 RSA 加密算法。</p><p><strong>2. SeverHello</strong></p><p>服务器收到客户端请求后，向客户端发出响应，也就是 <code class="language-plaintext highlighter-rouge">SeverHello</code>。服务器回应的内容有如下内容：</p><p>（1）确认 SSL/ TLS 协议版本，如果浏览器不支持，则关闭加密通信。</p><p>（2）服务器生产的随机数（<code class="language-plaintext highlighter-rouge">Server Random</code>），也是后面用于生产「会话秘钥」条件之一。</p><p>（3）确认的密码套件列表，如 RSA 加密算法。</p><p>（4）服务器的数字证书。</p><p><strong>3.客户端回应</strong></p><p>客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。</p><p>如果证书没有问题，客户端会<strong>从数字证书中取出服务器的公钥</strong>，然后使用它加密报文，向服务器发送如下信息：</p><p>（1）一个随机数（<code class="language-plaintext highlighter-rouge">pre-master key</code>）。该随机数会被服务器公钥加密。</p><p>（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。</p><p>（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。</p><p>上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。</p><p>服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。</p><p><strong>4. 服务器的最后回应</strong></p><p>服务器收到客户端的第三个随机数（<code class="language-plaintext highlighter-rouge">pre-master key</code>）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。</p><p>然后，向客户端发送最后的信息：</p><p>（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。</p><p>（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。</p><p>至此，整个 SSL/TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。</p><p>==客户端校验数字证书的流程是怎样的？==</p><p>CA 签发证书的过程：</p><ul><li>首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；<li>然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；<li>最后将 Certificate Signature 添加在文件证书上，形成数字证书；</ul><p>客户端校验服务端的数字证书的过程：</p><ul><li>首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；<li>通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；<li>最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。</ul><h3 id="http11http2http3-演变">HTTP/1.1、HTTP/2、HTTP/3 演变</h3><p>==HTTP/1.1 相比 HTTP/1.0 提高了什么性能？==</p><p>HTTP/1.1 相比 HTTP/1.0 性能上的改进：</p><ul><li>使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。<li>支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。</ul><p>但 HTTP/1.1 还是有性能瓶颈：</p><ul><li>请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。<li>服务器是按请求的顺序响应的，如果服务器响应慢，会导致客户端一直请求不到数据，出现队头阻塞；<li>请求只能从客户端开始，服务器只能被动响应。<li>没有请求优先级控制</ul><p>==HTTP/2 做了什么优化？==</p><p>HTTP/2 相比 HTTP/1.1 性能上的改进：</p><p><strong>1. 头部压缩</strong></p><p>HTTP/2 会<strong>压缩头部</strong>（Header），如果你同时发出多个请求，他们的头部是一样的或是相似的，那么，协议会帮你消除重复的部分。这就是所谓的 <code class="language-plaintext highlighter-rouge">HPACK</code> 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就<strong>提高速度</strong>了。</p><p><strong>2. 二进制格式</strong></p><p>HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了<strong>二进制格式</strong>，头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧（Headers Frame）和数据帧（Data Frame）。这样收到报文之后可以直接进行解析，<strong>增加了数据传输的效率</strong>。</p><p><strong>3. 数据流</strong></p><p>在 HTTP/2 中每个请求或响应的所有数据包，称为一个数据流（<code class="language-plaintext highlighter-rouge">Stream</code>）。每个数据流都标记着一个独一无二的编号（Stream ID），<strong>不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ）</strong>，因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息</p><p>客户端和服务器<strong>双方都可以建立 Stream</strong>， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。</p><p>客户端还可以<strong>指定数据流的优先级</strong>。优先级高的请求，服务器就先响应该请求。</p><p><strong>4. 多路复用</strong></p><p>HTTP/2 是可以在一个连接中并发多个请求或回应，而不用按照顺序一一对应。移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，<strong>降低了延迟，大幅度提高了连接的利用率</strong>。</p><p><strong>5. 服务器推送</strong></p><p>HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以<strong>主动</strong>向客户端发送消息。</p><p>==HTTP/2 有什么缺陷？==</p><p>HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 <strong>HTTP/2 队头阻塞</strong>问题。</p><p>==HTTP/3 做了哪些优化？==</p><p>HTTP/2 队头阻塞的问题是因为 TCP，所以 HTTP/3 把 HTTP 下层的 <strong>TCP 协议改成了 UDP</strong>！</p><p>因为UDP是不可靠传输，所以使用QUIC协议来实现类似TCP的可靠性传输。QUIC 有以下 3 个特点：</p><p><strong>1、无队头阻塞</strong></p><p>QUIC 有自己的一套机制可以保证传输的可靠性的。<strong>当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题</strong>。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。</p><p><strong>2、更快的连接建立</strong></p><p>对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。</p><p>HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS/1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商</p><p>注意：SSL/TLS 1.2 需要 4 握手，需要 2 个 RTT 的时延，SSL/TLS 1.3 优化了过程，只需要 1 个 RTT 往返时延，也就是只需要 3 次握手。</p><p><strong>3、连接迁移</strong></p><p>基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接，那么<strong>当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接</strong>。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。</p><p>而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过<strong>连接 ID</strong>来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<strong>连接迁移</strong>的功能。</p><p><img data-proofer-ignore data-src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/27-HTTP3.png" alt="HTTP/1 ~ HTTP/3" /></p><h2 id="http11如何优化">HTTP/1.1如何优化？</h2><p>第一个思路是，通过缓存技术来避免发送 HTTP 请求。客户端收到第一个请求的响应后，可以将其缓存在本地磁盘，下次请求的时候，如果缓存没过期，就直接读取本地缓存的响应数据。如果缓存过期，客户端发送请求的时候带上响应数据的摘要，服务器比对后发现资源没有变化，就发出不带包体的 304 响应，告诉客户端缓存的响应仍然有效。</p><p>第二个思路是，减少 HTTP 请求的次数，有以下的方法：</p><ol><li>将原本由客户端处理的重定向请求，交给代理服务器处理，这样可以减少重定向请求的次数；<li>将多个小资源合并成一个大资源再传输，能够减少 HTTP 请求次数以及 头部的重复传输，再来减少 TCP 连接数量，进而省去 TCP 握手和慢启动的网络消耗；<li>按需访问资源，只访问当前用户看得到/用得到的资源，当客户往下滑动，再访问接下来的资源，以此达到延迟请求，也就减少了同一时间的 HTTP 请求次数。</ol><p>第三思路是，通过压缩响应资源，降低传输资源的大小，从而提高传输效率，压缩方式可分为有损压缩（比如webP格式图片）和无损压缩（比如gzip）。</p><h1 id="tcp">TCP</h1><h2 id="tcp-三次握手与四次挥手">TCP 三次握手与四次挥手</h2><h3 id="tcp基本认识">TCP基本认识</h3><p>==TCP 头格式==</p><p><img data-proofer-ignore data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzYuanBn?x-oss-process=image/format,png" alt="TCP 头格式" /></p><p><strong>序列号</strong>：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。<strong>用来解决网络包乱序问题。</strong></p><p><strong>确认应答号</strong>：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。<strong>用来解决丢包的问题。</strong></p><p><strong>控制位：</strong></p><ul><li><strong><em>ACK</em></strong>：该位为 <code class="language-plaintext highlighter-rouge">1</code> 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 <code class="language-plaintext highlighter-rouge">SYN</code> 包之外该位必须设置为 <code class="language-plaintext highlighter-rouge">1</code> 。<li><strong><em>RST</em></strong>：该位为 <code class="language-plaintext highlighter-rouge">1</code> 时，表示 TCP 连接中出现异常必须强制断开连接。<li><strong><em>SYN</em></strong>：该位为 <code class="language-plaintext highlighter-rouge">1</code> 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。<li><strong><em>FIN</em></strong>：该位为 <code class="language-plaintext highlighter-rouge">1</code> 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 <code class="language-plaintext highlighter-rouge">FIN</code> 位为 1 的 TCP 段。</ul><p>==为什么需要 TCP 协议 ？==</p><p><code class="language-plaintext highlighter-rouge">IP</code> 层是「不可靠」的，它不保证网络包的交付、不保证网络包的顺序、也不保证网络包中的数据的完整性。如果需要保障网络数据包的可靠性，那么就需要由传输层的 <code class="language-plaintext highlighter-rouge">TCP</code> 协议来负责。因为 TCP 是一个工作在<strong>传输层</strong>的<strong>可靠</strong>数据传输的服务，它能确保接收端接收的网络包是<strong>无损坏、无间隔、非冗余和按序的。</strong></p><p>==什么是 TCP ？==</p><p>TCP 是<strong>面向连接的、可靠的、基于字节流</strong>的传输层通信协议。</p><ul><li><strong>面向连接</strong>：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；<li><strong>可靠的</strong>：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；<li><strong>字节流</strong>：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方程序不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。</ul><p>==如何唯一确定一个 TCP 连接呢？==</p><p>TCP 四元组可以唯一的确定一个连接，四元组包括如下：源地址、源端口、目的地址、目的端口</p><p>源地址和目的地址的字段（32位）是在 <strong>IP 头部</strong>中，作用是通过 IP 协议发送报文给对方主机。</p><p>源端口和目的端口的字段（16位）是在 <strong>TCP 头部</strong>中，作用是告诉 TCP 协议应该把报文发给哪个进程。</p><p>==UDP 和 TCP 有什么区别呢？分别的应用场景是？==</p><p>UDP 是面向无连接的、不可靠的传输层控制协议。UDP 协议非常简单，头部只有 <code class="language-plaintext highlighter-rouge">8</code> 个字节：</p><ul><li>目标和源端口：主要是告诉 UDP 协议应该把报文发给哪个进程。<li>包长度：该字段保存了 UDP 首部的长度跟数据的长度之和。<li>校验和：校验和是为了提供可靠的 UDP 首部和数据而设计，防止收到在网络传输中受损的 UDP包。</ul><p><strong>TCP 和 UDP 区别：</strong></p><p><em>1. 连接</em></p><ul><li>TCP 是面向连接的传输层协议，传输数据前先要建立连接。<li>UDP 是不需要连接，即刻传输数据。</ul><p><em>2. 服务对象</em></p><ul><li>TCP 是一对一的两点服务，即一条连接只有两个端点。<li>UDP 支持一对一、一对多、多对多的交互通信</ul><p><em>3. 可靠性</em></p><ul><li>TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。<li>UDP 是尽最大努力交付，不保证可靠交付数据。</ul><p><em>4. 拥塞控制、流量控制</em></p><ul><li>TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。<li>UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。</ul><p><em>5. 首部开销</em></p><ul><li>TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 <code class="language-plaintext highlighter-rouge">20</code> 个字节，如果使用了「选项」字段则会变长的。<li>UDP 首部只有 8 个字节，并且是固定不变的，开销较小。</ul><p><em>6. 传输方式</em></p><ul><li>TCP 是流式传输，没有边界，但保证顺序和可靠。<li>UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。</ul><p><em>7. 分片不同</em></p><ul><li>TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要重传丢失的这个分片。<li>UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。</ul><p><strong>TCP 和 UDP 应用场景：</strong></p><p>由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：</p><ul><li><code class="language-plaintext highlighter-rouge">FTP</code> 文件传输；<li>HTTP / HTTPS；</ul><p>由于 UDP 面向无连接，尽最大努力交付，再加上UDP简单高效，因此经常用于：</p><ul><li>包总量较少的通信，如 <code class="language-plaintext highlighter-rouge">DNS</code> ；<li>视频、音频等多媒体通信；<li>广播通信；</ul><p>==为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？==</p><p>因为TCP 有<strong>可变长</strong>的「选项」字段，因此其头部长度也是可变的；而UDP 头部长度则是<strong>固定</strong>的，无需多一个字段去记录 UDP 的首部长度。</p><p>==为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？==</p><p>TCP计算负载数据的长度：<code class="language-plaintext highlighter-rouge">TCP数据长度=IP总长度-IP首部长度-TCP首部长度</code>，其中 IP 总长度 和 IP 首部长度，在 IP 首部格式已知。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度。</p><p>UDP也可以算出来，可能是为了内存对齐（4字节的整数倍）吧，所以才补充了包长度字段。</p><h3 id="tcp连接建立">TCP连接建立</h3><p>==TCP 三次握手过程和状态变迁==</p><p>TCP通过三次握手来建立连接，过程如下：</p><p><img data-proofer-ignore data-src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.drawio.png" alt="TCP 三次握手" /></p><ul><li><p>一开始，客户端和服务端都处于 <code class="language-plaintext highlighter-rouge">CLOSED</code> 状态。先是服务端主动监听某个端口，处于 <code class="language-plaintext highlighter-rouge">LISTEN</code> 状态</p><li><p>客户端会随机初始化序列号（<code class="language-plaintext highlighter-rouge">client_isn</code>），将此序列号置于 TCP 首部的「序列号」字段中，同时把 <code class="language-plaintext highlighter-rouge">SYN</code> 标志位置为 <code class="language-plaintext highlighter-rouge">1</code> ，表示 <code class="language-plaintext highlighter-rouge">SYN</code> 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 <code class="language-plaintext highlighter-rouge">SYN-SENT</code> 状态。</p><li>服务端收到客户端的 <code class="language-plaintext highlighter-rouge">SYN</code> 报文后，首先服务端也随机初始化自己的序列号（<code class="language-plaintext highlighter-rouge">server_isn</code>），将此序列号填入 TCP 首部的「序列号」字段中，其次把 TCP 首部的「确认应答号」字段填入 <code class="language-plaintext highlighter-rouge">client_isn + 1</code>, 接着把 <code class="language-plaintext highlighter-rouge">SYN</code> 和 <code class="language-plaintext highlighter-rouge">ACK</code> 标志位置为 <code class="language-plaintext highlighter-rouge">1</code>。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 <code class="language-plaintext highlighter-rouge">SYN-RCVD</code> 状态。<li>客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 <code class="language-plaintext highlighter-rouge">ACK</code> 标志位置为 <code class="language-plaintext highlighter-rouge">1</code> ，其次「确认应答号」字段填入 <code class="language-plaintext highlighter-rouge">server_isn + 1</code> ，最后把报文发送给服务端，这次报文可以携带应用数据，之后客户端处于 <code class="language-plaintext highlighter-rouge">ESTABLISHED</code> 状态。<li>服务器收到客户端的应答报文后，也进入 <code class="language-plaintext highlighter-rouge">ESTABLISHED</code> 状态。</ul><p>一旦完成三次握手，双方都处于 <code class="language-plaintext highlighter-rouge">ESTABLISHED</code> 状态，此时连接就已建立完成，客户端和服务端就可以相互发送数据了。<strong>第三次握手是可以携带数据的，前两次握手是不可以携带数据的</strong></p><p>==如何在 Linux 系统中查看 TCP 状态？==</p><p>TCP 的连接状态查看，在 Linux 可以通过 <code class="language-plaintext highlighter-rouge">netstat -napt</code> 命令查看。</p><p>==为什么是三次握手？不是两次、四次？==</p><p><strong>原因一：避免历史连接</strong></p><p>什么情况下可能会出现历史连接问题？</p><p>客户端连续发送多次 SYN 建立连接的报文，在<strong>网络拥堵</strong>情况下一个「」比「最新的 SYN 」 报文早到达了服务端，这个时候可能会与旧SYN报文建立连接，这就是历史连接问题。</p><p>三次握手怎么避免历史连接？</p><p>如果使用的是三次握手，当服务器接收到旧 SYN 报文之后，会回一个<code class="language-plaintext highlighter-rouge">SYN + ACK</code> 报文给客户端，客户端收到后可以根据自身的上下文，判断这是一个历史连接（序列号过期或超时），那么客户端就会发送 <code class="language-plaintext highlighter-rouge">RST</code> 报文给服务端，表示中止这一次连接，然后再与最新SYN报文建立连接。</p><p>两次握手为什么无法阻止历史连接？</p><p>因为如果是两次握手的话，服务器在收到SYN报文后，就进入 ESTABLISHED 状态，这意味着可以给客户端发送数据，但是此时客户端还没有进入ESTABLISHED 状态。如果这次是历史连接，客户端判断此次连接为历史连接后回复 RST 报文来断开连接，但是服务端在第一次握手的时候就进入 ESTABLISHED 状态，所以它是可以发送数据的，因为它并不知道这个是历史连接，它只有在收到 RST 报文后，才会断开连接。</p><p>也就是说在两次握手的情况下，<strong>「被动发起方」没有中间状态给「主动发起方」来阻止历史连接</strong>，导致「被动发起方」可能建立一个历史连接，造成资源浪费。</p><p><strong>原因二：同步双方初始序列号</strong></p><p>TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，作用是：</p><ul><li>接收方可以去除重复的数据；<li>接收方可以根据数据包的序列号按序接收；<li>可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；</ul><p>四次握手其实也能够可靠的同步双方的初始化序号，但由于<strong>第二步和第三步可以优化成一步</strong>，所以就成了「三次握手」。而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。（需要一个应答来回，才能确保双方的初始化序列号都能被可靠同步）</p><p><strong>原因三：避免资源浪费</strong></p><p>在两次握手中，如果客户端的 <code class="language-plaintext highlighter-rouge">SYN</code> 阻塞了，就会重复发送多次 <code class="language-plaintext highlighter-rouge">SYN</code> 报文，那么服务器在收到请求后就会<strong>建立多个冗余的无效链接，造成不必要的资源浪费。</strong></p><p><strong>总结：</strong>TCP 建立连接时，通过三次握手能防止简历历史连接，能减少不必要的资源开销，能帮助双方同步初始化序列号。不使用「两次握手」和「四次握手」的原因：</p><ul><li>「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；<li>「四次握手」：三次握手就已经可以建立可靠连接，所以不需要使用更多的通信次数。</ul><p>==为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？==</p><p>主要原因有两个方面：</p><ul><li>为了防止历史报文被下一个相同四元组的连接接收（主要方面）；<li>为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；</ul><p>具体来说，如果在建立连接过程中出现了网络阻塞，就会出现历史SYN报文，此时如果服务端的进程重启，会发送RST报文来断开连接。然后，客户端与服务端重新建立连接，因为客户端和服务端的初始化序列号一样，所以会建立和上一个相同的连接。等到连接建立完成后，被阻塞的数据包到达服务端周后，会被当做数据正常接收，就会造成数据错乱。</p><p>如果每次建立连接客户端和服务端的初始化序列号都「不一样」，就有大概率因为历史报文的序列号「不在」对方接收窗口，从而很大程度上避免了接受历史报文。注意并不是完全避免</p><p>==初始序列号 ISN 是如何随机产生的？==</p><p>随机数是会<strong>基于时钟计时器递增</strong>的，所以基本不可能会随机成一样的初始化序列号。</p><p>==既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？==</p><p>首先要区分一下MTU和MSS：</p><ul><li><code class="language-plaintext highlighter-rouge">MTU</code>：一个网络包的最大长度，以太网中一般为 <code class="language-plaintext highlighter-rouge">1500</code> 字节；<li><code class="language-plaintext highlighter-rouge">MSS</code>：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；</ul><p><strong>IP层没有超时重传机制</strong>，如果在IP层分片，那丢失某片后，需要依靠TCP的超时重传整个TCP报文，效率低。</p><p>因此，为了达到最佳的传输效率，TCP 协议在<strong>建立连接的时候通常要协商双方的 MSS 值</strong>，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。经过 TCP 层分片后，如果一个 TCP 分片丢失后，<strong>进行重发时也是以 MSS 为单位</strong>，而不用重传所有的分片，大大增加了重传的效率。</p><p>==第一次握手丢失了，会发生什么？==</p><p>当客户端想和服务端建立 TCP 连接的时候，首先第一个发的就是 SYN 报文，然后进入到 <code class="language-plaintext highlighter-rouge">SYN_SENT</code> 状态。在这之后，如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发<strong>「超时重传」</strong>机制，重传 SYN 报文。在 Linux 里，户端的 SYN 报文最大重传次数默认值一般是5（由 <code class="language-plaintext highlighter-rouge">tcp_syn_retries</code>内核参数控制），每次超时等待的时间是上一次的2倍，重传五次后仍然无回应会断开TCP连接。</p><p>所以，总耗时是 1+2+4+8+16+32=63 秒，大约 1 分钟左右。</p><p>==第二次握手丢失了，会发生什么？==</p><p>当服务端收到客户端的第一次握手后，就会回 SYN-ACK 报文给客户端，这个就是第二次握手，此时服务端会进入 <code class="language-plaintext highlighter-rouge">SYN_RCVD</code> 状态。第二次握手的 <code class="language-plaintext highlighter-rouge">SYN-ACK</code> 报文其实有两个目的 ：</p><ul><li>第二次握手里的 ACK， 是对第一次握手的确认报文；<li>第二次握手里的 SYN，是服务端发起建立 TCP 连接的报文；</ul><p>所以，第二次握手丢失，客户端没有收到服务端的确认报文，会认为自己的SYN报文丢失了，然后触发超时重传机制；而服务端的请求报文丢失，就得不到客户端的确认报文，也会触发超时重传机制。</p><p>在 Linux 下，SYN-ACK 报文的最大重传次数由 <code class="language-plaintext highlighter-rouge">tcp_synack_retries</code>内核参数决定，默认值是 5。</p><p>==第三次握手丢失了，会发生什么？==</p><p>客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 <code class="language-plaintext highlighter-rouge">ESTABLISH</code> 状态。</p><p>因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。</p><p>注意：ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的请求报文。</p><p>==什么是 SYN 攻击？如何避免 SYN 攻击？==</p><p><strong>SYN 攻击</strong>：</p><p>TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 <code class="language-plaintext highlighter-rouge">SYN</code> 报文，服务端每接收到一个 <code class="language-plaintext highlighter-rouge">SYN</code> 报文，就进入<code class="language-plaintext highlighter-rouge">SYN_RCVD</code> 状态，但服务端发送出去的 <code class="language-plaintext highlighter-rouge">ACK+SYN</code> 报文，无法得到未知 IP 主机的 <code class="language-plaintext highlighter-rouge">ACK</code> 应答，久而久之就会<strong>占满服务端的半连接队列</strong>，使得服务器不能为正常用户服务。</p><p><strong>避免 SYN 攻击方式一</strong></p><p>其中一种解决方式是通过修改 Linux 内核参数，<strong>控制半连接队列大小和当队列满时做相应的处理</strong>，比如队列满后超出处理能力时，对新的SYN直接回报RST，丢弃连接。</p><p><strong>避免 SYN 攻击方式二</strong></p><p>开启tcp_syncookies功能</p><p>Linux 内核的 <code class="language-plaintext highlighter-rouge">SYN</code> 队列（半连接队列）与 <code class="language-plaintext highlighter-rouge">Accpet</code> 队列（全连接队列）是如何工作的？</p><ul><li>当服务端接收到客户端的 SYN 报文时，会将其加入到内核的「 SYN 队列」；<li>接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文；<li>服务端接收到 ACK 报文后，从「 SYN 队列」移除放入到「 Accept 队列」；<li>应用通过调用 <code class="language-plaintext highlighter-rouge">accpet()</code> socket 接口，从「 Accept 队列」取出连接。</ul><p>当半连接队列占满后，服务器后续收到SYN包后计算出一个 <code class="language-plaintext highlighter-rouge">cookie</code> 值，放在 SYN + ACK 中发出，服务端接收到客户端的应答报文时，取出改制验证，检查这个 ACK 包的合法性。如果合法，直接放入到「 Accept 队列」。</p><p><strong>避免 SYN 攻击方式三</strong></p><p>减少SYN+ACK重传次数</p><p>当服务端受到 SYN 攻击时，就会有大量处于 SYN_REVC 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。</p><p>可以减少SYN+ACK的重传次数，使TCP连接更快的断开。</p><h3 id="tcp连接断开">TCP连接断开</h3><p>==TCP 四次挥手过程和状态变迁==</p><p>双方都可以主动断开连接，断开连接后主机中的「资源」将被释放，四次挥手的过程如下：</p><p><img data-proofer-ignore data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzMwLmpwZw?x-oss-process=image/format,png" alt="客户端主动关闭连接 —— TCP 四次挥手" /></p><ul><li>客户端打算关闭连接，此时会发送一个 TCP 首部 <code class="language-plaintext highlighter-rouge">FIN</code> 标志位被置为 <code class="language-plaintext highlighter-rouge">1</code> 的报文，也即 <code class="language-plaintext highlighter-rouge">FIN</code> 报文，之后客户端进入 <code class="language-plaintext highlighter-rouge">FIN_WAIT_1</code> 状态。<li>服务端收到该报文后，就向客户端发送 <code class="language-plaintext highlighter-rouge">ACK</code> 应答报文，接着服务端进入 <code class="language-plaintext highlighter-rouge">CLOSED_WAIT</code> 状态。<li>客户端收到服务端的 <code class="language-plaintext highlighter-rouge">ACK</code> 应答报文后，之后进入 <code class="language-plaintext highlighter-rouge">FIN_WAIT_2</code> 状态。<li>等待服务端处理完数据后，也向客户端发送 <code class="language-plaintext highlighter-rouge">FIN</code> 报文，之后服务端进入 <code class="language-plaintext highlighter-rouge">LAST_ACK</code> 状态。<li>客户端收到服务端的 <code class="language-plaintext highlighter-rouge">FIN</code> 报文后，回一个 <code class="language-plaintext highlighter-rouge">ACK</code> 应答报文，之后进入 <code class="language-plaintext highlighter-rouge">TIME_WAIT</code> 状态<li>服务器收到了 <code class="language-plaintext highlighter-rouge">ACK</code> 应答报文后，就进入了 <code class="language-plaintext highlighter-rouge">CLOSED</code> 状态，至此服务端已经完成连接的关闭。<li>客户端在经过 <code class="language-plaintext highlighter-rouge">2MSL</code> 一段时间后，自动进入 <code class="language-plaintext highlighter-rouge">CLOSED</code> 状态，至此客户端也完成连接的关闭</ul><p>每个方向都需要一个FIN和一个ACK，所以是四次挥手，主动关闭连接的，才有TIME_WAIT状态。</p><p>==为什么挥手需要四次？==</p><p>服务端通常需要等待完成数据的发送和处理，所以服务端的 <code class="language-plaintext highlighter-rouge">ACK</code> 和 <code class="language-plaintext highlighter-rouge">FIN</code> 一般都会分开发送，从而比三次握手导致多了一次。</p><ul><li>关闭连接时，客户端向服务端发送 <code class="language-plaintext highlighter-rouge">FIN</code> 时，仅仅表示客户端不再发送数据了但是还能接收数据。<li>服务器收到客户端的 <code class="language-plaintext highlighter-rouge">FIN</code> 报文时，先回一个 <code class="language-plaintext highlighter-rouge">ACK</code> 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 <code class="language-plaintext highlighter-rouge">FIN</code> 报文给客户端来表示同意现在关闭连接。</ul><p>==第一次挥手丢失了，会发生什么？==</p><p>当客户端（主动关闭方）调用 close 函数后，就会向服务端发送 FIN 报文，试图与服务端断开连接，此时客户端的连接进入到 <code class="language-plaintext highlighter-rouge">FIN_WAIT_1</code> 状态。</p><p>正常情况下，如果能及时收到服务端（被动关闭方）的 ACK，则会很快变为 <code class="language-plaintext highlighter-rouge">FIN_WAIT2</code>状态。如果第一次挥手丢失了，那么客户端迟迟收不到被动方的 ACK 的话，也就会触发超时重传机制，重传 FIN 报文，重发次数由 <code class="language-plaintext highlighter-rouge">tcp_orphan_retries</code> 参数控制。当客户端重传 FIN 报文的次数超过 <code class="language-plaintext highlighter-rouge">tcp_orphan_retries</code> 后，就不再发送 FIN 报文，直接进入到 <code class="language-plaintext highlighter-rouge">close</code> 状态。</p><p>==第二次挥手丢失了，会发生什么？==</p><p>当服务端收到客户端的第一次挥手后，就会先回一个 ACK 确认报文，此时服务端的连接进入到 <code class="language-plaintext highlighter-rouge">CLOSE_WAIT</code> 状态。在前面我们也提了，<strong>ACK 报文是不会重传的</strong>，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。</p><p>==第三次挥手丢失了，会发生什么？==</p><p>当服务端（被动关闭方）收到客户端（主动关闭方）的 FIN 报文后，内核会自动回复 ACK，同时连接处于 <code class="language-plaintext highlighter-rouge">CLOSE_WAIT</code> 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。</p><p>此时，内核是没有权利替代进程关闭连接，必须由进程主动调用 close 函数来触发服务端发送 FIN 报文。</p><p>服务端处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文，同时连接进入 LAST_ACK 状态，等待客户端返回 ACK 来确认连接关闭。如果迟迟收不到这个 ACK，服务端就会重发 FIN 报文，重发次数仍然由 <code class="language-plaintext highlighter-rouge">tcp_orphan_retrie</code>s 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。</p><p>==第四次挥手丢失了，会发生什么？==</p><p>当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 <code class="language-plaintext highlighter-rouge">TIME_WAIT</code> 状态。在 Linux 系统，TIME_WAIT 状态会持续 2MSL 后才会进入关闭状态。</p><p>如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由前面介绍过的 <code class="language-plaintext highlighter-rouge">tcp_orphan_retries</code> 参数控制。</p><p>==为什么 TIME_WAIT 等待的时间是 2MSL？==</p><p><code class="language-plaintext highlighter-rouge">MSL</code> 是 Maximum Segment Lifetime，<strong>报文最大生存时间</strong>，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 <code class="language-plaintext highlighter-rouge">TTL</code> 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。</p><p>MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 <strong>MSL 应该要大于等于 TTL 消耗为 0 的时间</strong>，以确保报文已被自然消亡。</p><p><strong>TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了</strong>。</p><p>TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以<strong>一来一回需要等待 2 倍的时间</strong>。</p><p><code class="language-plaintext highlighter-rouge">2MSL</code> 的时间是从<strong>客户端接收到 FIN 后发送 ACK 开始计时的</strong>。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 <strong>2MSL 时间将重新计时</strong>。</p><p>==为什么需要 TIME_WAIT 状态？==</p><p><strong>主动发起关闭连接的一方，才会有 <code class="language-plaintext highlighter-rouge">TIME-WAIT</code> 状态。</strong></p><p>需要 TIME-WAIT 状态，主要是两个原因：</p><ul><li>防止历史连接中的数据，被后面相同四元组的连接错误的接收；<li>保证「被动关闭连接」的一方，能被正确的关闭；</ul><p><strong>原因一：</strong></p><p>序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据。假设 TIME-WAIT 没有等待时间或时间过短，被延迟的数据包抵达后会发生什么呢？</p><p>在关闭之前发送的报文被延迟后，服务端断开之后又以相同的四元组重新打开了新连接，被延迟的数据包到达了客户端，而且该数据报文的序列号刚好在客户端接收窗口内，因此客户端会正常接受这个报文，但是这个报文是历史数据，这样就会残生数据错乱的问题。</p><p>而设置2MSL时长的TIME_WAIT，足以让两个方向上的数据包都被丢弃，是的原来连接的数据包在网络中都自然消失，再出现的数据包一定是建立连接所产生的。</p><p><strong>原因二：</strong></p><p>IME-WAIT 作用是等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。</p><p>如果客户端（主动关闭方）最后一次 ACK 报文（第四次挥手）在网络中丢失了，那么按照 TCP 可靠性原则，服务端（被动关闭方）会重发 FIN 报文。假设客户端没有 TIME_WAIT 状态，而是在发完最后一次回 ACK 报文就直接进入 CLOSED 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会回 RST 报文。服务端收到这个 RST 并将其解释为一个错误（Connection reset by peer），这对于一个可靠的协议来说不是一个优雅的终止方式。</p><p>为了防止这种情况出现，客户端必须等待足够长的时间确保对端收到 ACK，如果对端没有收到 ACK，那么就会触发 TCP 重传机制，服务端会重新发送一个 FIN，这样一去一来刚好两个 MSL 的时间。</p><p>==TIME_WAIT 过多有什么危害？==</p><ul><li>第一是内存资源占用；<li>第二是对端口资源的占用，一个 TCP 连接至少消耗「发起连接方」的一个本地端口；</ul><p>客户端（发起连接方）受端口资源限制：客户端TIME_WAIT过多，就会导致端口资源被占用，因为端口就 65536 个，被占满就会导致无法创建新的连接。</p><p>服务端（被动连接方）受系统资源限制：由于一个四元组表示 TCP 连接，理论上服务端可以建立很多连接，因为服务端只监听一个端口，不会因为 TCP 连接过多而导致端口资源受限。但是 TCP 连接过多，会占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等。</p><p>==如果已经建立了连接，但是客户端突然出现故障了怎么办？==</p><p>TCP 有一个机制是<strong>保活机制</strong>。这个机制的原理是这样的：定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。</p><p>如果开启了 TCP 保活，需要考虑以下几种情况：</p><ul><li>第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 <strong>TCP 保活时间会被重置</strong>，等待下一个 TCP 保活时间的到来。<li>第二种，对端程序崩溃并且已经重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，<strong>会产生一个 RST 报文</strong>，这样很快就会发现 TCP 连接已经被重置。<li>第三种，是对端程序由于崩溃或其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，没有响应，连续几次，达到保活探测次数后，<strong>TCP 会报告该 TCP 连接已经死亡</strong>。</ul><p>==如果已经建立了连接，但是服务端的进程崩溃会发生什么？==</p><p>使用 kill -9 来模拟进程崩溃的情况，发现在 kill 掉进程后，服务端会发送 FIN 报文与客户端进行四次挥手。</p><h3 id="socket编程">Socket编程</h3><p>==针对 TCP 应该如何 Socket 编程？==</p><p><img data-proofer-ignore data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzM0LmpwZw?x-oss-process=image/format,png" alt="基于 TCP 协议的客户端和服务器工作" /></p><ul><li>服务端和客户端初始化 <code class="language-plaintext highlighter-rouge">socket</code>，得到文件描述符；<li>服务端调用 <code class="language-plaintext highlighter-rouge">bind</code>，将绑定在 IP 地址和端口;<li>服务端调用 <code class="language-plaintext highlighter-rouge">listen</code>，进行监听；<li>服务端调用 <code class="language-plaintext highlighter-rouge">accept</code>，等待客户端连接；<li>客户端调用 <code class="language-plaintext highlighter-rouge">connect</code>，向服务器端的地址和端口发起连接请求；<li>服务端 <code class="language-plaintext highlighter-rouge">accept</code> 返回用于传输的 <code class="language-plaintext highlighter-rouge">socket</code> 的文件描述符；<li>客户端调用 <code class="language-plaintext highlighter-rouge">write</code> 写入数据；服务端调用 <code class="language-plaintext highlighter-rouge">read</code> 读取数据；<li>客户端断开连接时，会调用 <code class="language-plaintext highlighter-rouge">close</code>，那么服务端 <code class="language-plaintext highlighter-rouge">read</code> 读取数据的时候，就会读取到了 <code class="language-plaintext highlighter-rouge">EOF</code>，待处理完数据后，服务端调用 <code class="language-plaintext highlighter-rouge">close</code>，表示连接关闭。</ul><p>这里需要注意的是，服务端调用 <code class="language-plaintext highlighter-rouge">accept</code> 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作<strong>监听 socket</strong>，一个叫作<strong>已完成连接 socket</strong>。成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。</p><p>==listen 时候参数 backlog 的意义？==</p><p>Linux内核中会维护两个队列：</p><ul><li>半连接队列（SYN 队列）：接收到一个 SYN 建立连接请求，处于 SYN_RCVD 状态；<li>全连接队列（Accpet 队列）：已完成 TCP 三次握手过程，处于 ESTABLISHED 状态；</ul><p>backlog 是已完成连接建立的队列长度，通常认为 backlog 是 accept 队列。但是上限值是内核参数 somaxconn 的大小，也就说 accpet 队列长度 = min(backlog, somaxconn)。</p><p>==accept 发生在三次握手的哪一步？==</p><ul><li>客户端的协议栈向服务器端发送了 SYN 包，并告诉服务器端当前发送序列号 client_isn，客户端进入 SYN_SENT 状态；<li>服务器端的协议栈收到这个包之后，和客户端进行 ACK 应答，应答的值为 client_isn+1，表示对 SYN 包 client_isn 的确认，同时服务器也发送一个 SYN 包，告诉客户端当前我的发送序列号为 server_isn，服务器端进入 SYN_RCVD 状态；<li>客户端协议栈收到 ACK 之后，使得应用程序从 <code class="language-plaintext highlighter-rouge">connect</code> 调用返回，表示客户端到服务器端的单向连接建立成功，客户端的状态为 ESTABLISHED，同时客户端协议栈也会对服务器端的 SYN 包进行应答，应答数据为 server_isn+1；<li>ACK 应答包到达服务器端后，服务器端的 TCP 连接进入 ESTABLISHED 状态，同时服务器端协议栈使得 <code class="language-plaintext highlighter-rouge">accept</code> 阻塞调用返回，这个时候服务器端到客户端的单向连接也建立成功。至此，客户端与服务端两个方向的连接都建立成功。</ul><p>客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。</p><p>==客户端调用 close 了，连接时断开的流程是什么？==</p><ul><li>客户端调用 <code class="language-plaintext highlighter-rouge">close</code>，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报文，进入 FIN_WAIT_1 状态；<li>服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 <code class="language-plaintext highlighter-rouge">EOF</code> 到接收缓冲区中，应用程序可以通过 <code class="language-plaintext highlighter-rouge">read</code> 调用来感知这个 FIN 包。这个 <code class="language-plaintext highlighter-rouge">EOF</code> 会被<strong>放在已排队等候的其他已接收的数据之后</strong>，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，服务端进入 CLOSE_WAIT 状态；<li>接着，当处理完数据后，自然就会读到 <code class="language-plaintext highlighter-rouge">EOF</code>，于是也调用 <code class="language-plaintext highlighter-rouge">close</code> 关闭它的套接字，这会使得服务端发出一个 FIN 包，之后处于 LAST_ACK 状态；<li>客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态；<li>服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态；<li>客户端经过 <code class="language-plaintext highlighter-rouge">2MSL</code> 时间之后，也进入 CLOSE 状态；</ul><h2 id="tcp-重传滑动窗口流量控制拥塞控制">TCP 重传、滑动窗口、流量控制、拥塞控制</h2><h3 id="重传机制">重传机制</h3><p>常见的重传机制：</p><ul><li>超时重传<li>快速重传<li>SACK<li>D-SACK</ul><h4 id="超时重传">超时重传</h4><p>重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 <code class="language-plaintext highlighter-rouge">ACK</code> 确认应答报文，就会重发该数据，也就是我们常说的<strong>超时重传</strong>。</p><p>TCP在数据包丢失和确认应答丢失时都会触发超时重传机制。</p><p>==超时时间应该设置为多少呢？==</p><p><code class="language-plaintext highlighter-rouge">RTT</code> （往返时延）指的是<strong>数据发送时刻到接收到确认的时刻的差值</strong>，也就是包的往返时间。</p><p>超时重传时间是以 <code class="language-plaintext highlighter-rouge">RTO</code> （Retransmission Timeout 超时重传时间）表示。</p><ul><li>当超时时间 <strong>RTO 较大</strong>时，重发就慢，丢了老半天才重发，效率低，性能差；<li>当超时时间 <strong>RTO 较小</strong>时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。</ul><p>因此，超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。实际上「报文往返 RTT 的值」是经常变化的，因为我们的网络也是时常变化的。也就因为「报文往返 RTT 的值」 是经常波动变化的，所以「超时重传时间 RTO 的值」应该是一个<strong>动态变化的值</strong>。Linux超时重传次数一般默认五次，每次都是上次的两倍时间。</p><p>问题是：超时重发等待的时间可能较长，这个时候可以使用快速重传。</p><h4 id="快速重传">快速重传</h4><p>快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。</p><p>快速重传机制只解决了超时时间的问题，但是它并不知道该重传哪些TCP报文，因此就有<code class="language-plaintext highlighter-rouge">SACK</code>方法。</p><h4 id="sack-方法">SACK 方法</h4><p>SACK（选择性确认）需要在 TCP 头部「选项」字段里加一个 <code class="language-plaintext highlighter-rouge">SACK</code> 的东西，它将缓存的地图发送给发送方，这样发送方就知道哪些数据收到了，哪些数据没收到，然后<strong>只重传丢失的数据</strong>。</p><h4 id="d--sack">D- SACK</h4><p>主要使用 SACK 来告诉「发送方」有哪些数据被重复接收了。</p><p>接收方发给发送方的ACK丢失并且发送发超时后，发送方会重传数据包，接收方收到发送方重传的数据包，发现数据是重复收到的，于是恢复一个表示重复数据的SACK和当前ACK，告诉发送放当前ACK之前的所有数据都搜到了，刚才发的是重复数据。因此发送发就知道了，数据没有丢，是接受方的ACK确认报文丢了。</p><h3 id="滑动窗口">滑动窗口</h3><p>==为什么引入窗口的概念？==</p><p>TCP发送数据得到确认应答后才能继续发送下一个数据，这样的传输方式效率很低。</p><p>所以引入了窗口，窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值。</p><p>窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。</p><p>ACK即使丢失了，也不会进行数据重发，因为可以通过下一个确认应答进行确认， 只要发送发收到了后面的确认应答，就意味着在此之前的所有数据接收方都收到了，这个模式叫累计确认或累计应答。</p><p>==窗口大小由哪一方决定？==</p><p>TCP 头部有一个字段叫 <code class="language-plaintext highlighter-rouge">Window</code>，也就是窗口大小。<strong>这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。</strong>所以，窗口的大小通常是由接收方的窗口大小来决定的。</p><p>==发送方的滑动窗口==</p><p>发送方将窗口内的未发送数据全部发送出去之后，可用窗口的大小就变成0了，这表示可用窗口在没收到ACK确认之前无法继续发送数据。在收到ACK确认之后，如果发送窗口的大小没有变化， 则窗口向右滑动，滑动记录等于接收到的ACK数量，滑动窗口内的未发送数据又变成了可用窗口。</p><p>==接收方的滑动窗口==</p><p>接收窗口将其大小通告给发送方，然后接受相应的数据。</p><p>==接收窗口和发送窗口的大小是相等的吗？==</p><p>并不是完全相等，接收窗口的大小是<strong>约等于</strong>发送窗口的大小的。</p><p>因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据速度非常快的话，接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。</p><h3 id="流量控制">流量控制</h3><p>发送方不能无脑的发数据给接收方，要考虑接收方处理能力。如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。</p><p>为了解决这种现象发生，TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的<strong>流量控制</strong>。</p><p>简单来说就是保持接收方发送数据窗口大小不变，然后发送数据后等待确认应答，确认多少应答，就恢复多少的发送能力，如果达到发送窗口大小但还没有收到确认应答，就暂时停止发送数据。这样一来，发送数据量就能一直控制在一个阈值内，即实现了流量控制。</p><p>==操作系统缓冲区与滑动窗口的关系==</p><p>实际上，发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而<strong>操作系统的缓冲区，会被操作系统调整</strong>。</p><p>如果系统资源非常紧张的时候，操作系统可能会直接减少缓冲区的大小，这可能会引起丢包现象（接收方比较忙，暂时接受不了，会存在缓存中，但是操作系统又缩小了缓存，导致缓存保存不了，所以直接丢弃）。为了防止这种情况发生，TCP规定不允许同时减少缓存又收缩窗口，而是采用先收缩窗口，过段时间再减少缓存的策略。</p><p>==窗口关闭==</p><p>发送方的窗口大小由接收方来指定，如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是<strong>窗口关闭</strong>。</p><p>窗口关闭潜在的危险：当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，如果这个通告窗口的 ACK 报文在网络中丢失了，会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象。</p><p>==TCP 是如何解决窗口关闭时，潜在的死锁现象呢？==</p><p>为了解决这个问题，TCP 为每个连接设有一个持续定时器，<strong>只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。</strong>如果持续计时器超时，就会发送<strong>窗口探测 ( Window probe ) 报文</strong>，而对方在确认这个探测报文时，给出自己现在的接收窗口大小：</p><ul><li>如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；<li>如果接收窗口不是 0，那么死锁的局面就可以被打破了。</ul><p>窗口探测的次数一般为 3 次，如果 3 次过后接收窗口还是 0 的话，TCP就会发 <code class="language-plaintext highlighter-rouge">RST</code> 报文来中断连接。</p><p>==糊涂窗口综合症==</p><p>如果接收方来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。到最后，如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症。<code class="language-plaintext highlighter-rouge">TCP + IP</code> 头有 <code class="language-plaintext highlighter-rouge">40</code> 个字节，为了传输那几个字节的数据，要搭上这么大的开销，有点糊涂。</p><p>糊涂窗口综合症的现象可以发生在发送方和接收方：</p><ul><li>接收方可以通告一个小的窗口<li>而发送方可以发送小数据</ul><p>于是，要解决糊涂窗口综合症，就解决上面两个问题就可以了</p><ul><li>让接收方不通告小窗口给发送方<li>让发送方避免发送小数据</ul><p><strong>怎么让接收方不通告小窗口呢？</strong></p><p>当「窗口大小」小于 min( MSS，缓存空间/2 ) ，也就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通告窗口为 <code class="language-plaintext highlighter-rouge">0</code>，阻止发送方再发数据过来。等到接收方处理了一些数据后，窗口大小 &gt;= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来。</p><p><strong>怎么让发送方避免发送小数据呢？</strong></p><p>发送方通常的策略:使用 Nagle 算法，该算法的思路是延时处理，满足两个条件中的一个才可以发送数据：</p><ul><li>要等到窗口大小 &gt;= <code class="language-plaintext highlighter-rouge">MSS</code> 或是 数据大小 &gt;= <code class="language-plaintext highlighter-rouge">MSS</code><li>收到之前发送数据的 <code class="language-plaintext highlighter-rouge">ack</code> 回包</ul><p>只要没满足上面条件中的一条，发送方一直在囤积数据，直到满足上面的发送条件。</p><h3 id="拥塞控制">拥塞控制</h3><p>==为什么要有拥塞控制，不是有流量控制了吗？==</p><p>流量控制是避免发送方的数据填满接收方的缓存而重发浪费流量，拥塞控制是为了避免网络拥堵。</p><p>在<strong>网络出现拥堵</strong>时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，然后陷入恶性循环。</p><p>于是，就有了<strong>拥塞控制</strong>，控制的目的就是<strong>避免「发送方」的数据填满整个网络。</strong></p><p>==什么是拥塞窗口？和发送窗口有什么关系呢？==</p><p><strong>拥塞窗口 cwnd</strong>是发送方维护的一个的状态变量，它会根据<strong>网络的拥塞程度动态变化的</strong>。</p><p>由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。拥塞窗口 <code class="language-plaintext highlighter-rouge">cwnd</code> 变化的规则：</p><ul><li>只要网络中没有出现拥塞，<code class="language-plaintext highlighter-rouge">cwnd</code> 就会增大；<li>一旦网络中出现了拥塞，<code class="language-plaintext highlighter-rouge">cwnd</code> 就减少；</ul><p>==那么怎么知道当前网络是否出现了拥塞呢？==</p><p>只要「发送方」没有在规定时间内接收到 ACK 应答报文，即发生超时重传，就认为网络出现了拥塞。</p><p>==拥塞控制有哪些控制算法？==</p><p>塞控制主要是四个算法：</p><ul><li>慢启动<li>拥塞避免<li>拥塞发生<li>快速恢复</ul><h4 id="慢启动">慢启动</h4><p>TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量。慢启动的算法规则是：<strong>当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。</strong></p><p>慢启动算法发包的个数是指数性的增长。</p><p>==慢启动会一直涨吗，涨到什么时候会停止？==</p><p>有一个叫慢启动门限 <code class="language-plaintext highlighter-rouge">ssthresh</code> （slow start threshold）状态变量。</p><ul><li>当 <code class="language-plaintext highlighter-rouge">cwnd</code> &lt; <code class="language-plaintext highlighter-rouge">ssthresh</code> 时，使用慢启动算法。<li>当 <code class="language-plaintext highlighter-rouge">cwnd</code> &gt;= <code class="language-plaintext highlighter-rouge">ssthresh</code> 时，就会使用「拥塞避免算法」。</ul><p>一般来说 <code class="language-plaintext highlighter-rouge">ssthresh</code> 的大小是 <code class="language-plaintext highlighter-rouge">65535</code> 字节。</p><h4 id="拥塞避免">拥塞避免</h4><p>进入拥塞避免算法后，它的规则是：<strong>每当收到一个 ACK 时，cwnd 增加 1/cwnd。</strong></p><p>比如慢启动门限为8（此时可以一次发送8个数据），当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 <code class="language-plaintext highlighter-rouge">MSS</code> 大小的数据，变成了<strong>线性增长</strong>。</p><p>所以，拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。一直增长会导致网络慢慢进入阻塞的状态，于是就会出现丢包现象，就触发了重传机制，一旦触发重传机制，就进入了拥塞发生算法。</p><h4 id="拥塞发生">拥塞发生</h4><p>当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：</p><ul><li>超时重传<li>快速重传</ul><p>这两种使用的拥塞发生算法是不同的。</p><p>==发生超时重传的拥塞发生算法==</p><p>这个时候，ssthresh 和 cwnd 的值会发生变化：</p><ul><li><code class="language-plaintext highlighter-rouge">ssthresh</code> 设为 <code class="language-plaintext highlighter-rouge">cwnd/2</code>，<li><code class="language-plaintext highlighter-rouge">cwnd</code> 恢复为 cwnd 初始化值</ul><p>接着，就重新开始慢启动，慢启动是会突然减少数据流的。这个反映太强烈，会造成网络卡顿。</p><p>==发生快速重传的拥塞发生算法==</p><p>TCP 认为发生快速重传时丢包现象不严重，则 <code class="language-plaintext highlighter-rouge">ssthresh</code> 和 <code class="language-plaintext highlighter-rouge">cwnd</code> 变化如下：</p><ul><li><code class="language-plaintext highlighter-rouge">cwnd = cwnd/2</code> ，也就是设置为原来的一半;<li><code class="language-plaintext highlighter-rouge">ssthresh = cwnd</code>;<li>进入快速恢复算法</ul><h4 id="快速恢复">快速恢复</h4><p>快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像超时重传那么强烈。</p><p>快速恢复算法如下：</p><ul><li>拥塞窗口 <code class="language-plaintext highlighter-rouge">cwnd = ssthresh + 3</code> （ 3 的意思是确认有 3 个数据包被收到了）；<li>重传丢失的数据包；<li>如果再收到重复的 ACK，那么 cwnd 增加 1；<li>如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh（出发快速重传时的cwnd的一半）的值，原因是该 ACK 确认了新的数据，说明从 D-ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；</ul><p>也就是没有像「超时重传」那么强烈，而是还在比较高的值，后续呈线性增长。</p><h2 id="如何优化tcp">如何优化TCP</h2><h3 id="优化三次握手">优化三次握手</h3><ul><li>客户端优化：当客户端发起 SYN 包时，可以通过 <code class="language-plaintext highlighter-rouge">tcp_syn_retries</code> 控制其重传的次数。<li>服务端优化：调整SYN办理按揭队列长度，调整SYN+ACK报文的重传次数，调整全连接队列长度<li>绕过三次握手：TCP Fast Open功能可以绕过三次握手，减少HTTP请求时间，通过tcp_fastopen开启。</ul><h3 id="优化四次挥手">优化四次挥手</h3><ul><li>主动方优化：调整FIN报文重传次数，调整FIN_WAIT2状态的时间（close函数关闭会产生孤儿连接，shutdown函数则是直接关闭），调整孤儿连接的上限个数、调整time_wait状态的上限个数，复用time_wait状态的连接。<li>被动方优化：调整CLOSE_WAIT状态的个数，在LAST_ACK状态下控制FIN报文重传的次数。</ul><h3 id="tcp-传输数据的性能提升">TCP 传输数据的性能提升</h3><ul><li>扩大滑动窗口大小<li>调整发送缓冲、接收缓冲区范围<li>打开接受缓冲区动态调节<li>调整内存范围</ul><h2 id="如何理解是-tcp-面向字节流协议">如何理解是 TCP 面向字节流协议？</h2><p>TCP 是面向字节流的协议，UDP 是面向报文的协议？这里的<strong>「面向字节流」和「面向报文」</strong>该如何理解。</p><h3 id="如何理解字节流">如何理解字节流？</h3><p>==先来说说为什么 UDP 是面向报文的协议？==</p><p>当用户消息通过 UDP 协议传输时，<strong>操作系统不会对消息进行拆分</strong>，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是<strong>每个 UDP 报文就是一个用户消息的边界</strong>，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。</p><p>那收到了两个UDP报文，操作系统怎么区分开呢？</p><p>操作系统在收到 UDP 报文后，会将其插入到队列里，<strong>队列里的每一个元素就是一个 UDP 报文</strong>，这样当用户调用 recvfrom() 系统调用读数据的时候，就会从队列里取出一个数据，然后从内核里拷贝给用户缓冲区。</p><p>==再来说说为什么 TCP 是面向字节流的协议？==</p><p>当用户消息通过 TCP 协议传输时，<strong>消息可能会被操作系统分组成多个的 TCP 报文</strong>，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。因此，我们不能认为一个用户消息对应一个 TCP 报文，正因为这样，所以 TCP 是面向字节流的协议。</p><p>如果在发送的时候两个消息的某个部分被分到同一个 TCP 报文时，就出现了TCP 粘包问题，这时接收方不知道消息的边界的话，是无法读出有效的消息的。</p><h3 id="如何解决粘包">如何解决粘包？</h3><p>粘包的问题在于不知道用户消息的边界，如果知道了边界，就可以通过边界划分出有效的用户消息：</p><ul><li>固定长度的消息<li>特殊字符作为边界<li>自定义消息结构</ul><p>==固定长度的消息==</p><p>这种是最简单方法，即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。但是这种方式灵活性不高，实际中很少用。</p><p>==特殊字符作为边界==</p><p>我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。</p><p>比如HTTP通过设置回车符、换行符作为HTTP报文协议的边界</p><p>需要注意的是：如果消息内容里有特殊字符，需要对整个字符进行转移，避免被误当做消息边界。</p><p>==自定义消息结构==</p><p>我们可以自定义一个消息结构，由包头和数据组成，其中包头是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。当接收方接受到爆头之后就可以知道数据大小，然后读满数据组装成用户消息。</p><h2 id="syn-报文什么时候情况下会被丢弃">SYN 报文什么时候情况下会被丢弃？</h2><ul><li>开启 tcp_tw_recycle 参数，并且在 NAT 环境下，造成 SYN 报文被丢弃<li>TCP 两个队列满了（半连接队列和全连接队列），造成 SYN 报文被丢弃</ul><p>==tcp_tw_recycle==</p><p>在四次挥手中，如果主动断开连接放的TIME_WAIT状态过多，占满了所有端口资源，会导致无法创建新连接。Linux提供了两个系统参数来快速挥手处于TIME_WAIT状态的连接，这两个参数都是默认关闭：</p><ul><li>tcp_tw_reuse，如果开启该选项的话，连接发起方在调用 connect() 函数时，内核会随机找一个 TIME_WAIT状态超过 1 秒的连接给新的连接复用，所以该选项只适用于连接发起方。<li>tcp_tw_recycle，如果开启该选项的话，允许处于 TIME_WAIT 状态的连接被快速回收。</ul><p>要使得这两个选项生效，有一个前提条件，就是要打开 TCP 时间戳，即tcp_timestamps=1（默认为1）。</p><p><strong>tcp_tw_recycle 在使用了 NAT（网络地址转换） 的网络下是不安全的！</strong></p><p>对于服务器来说，如果同时开启recycle 和 timestamps 选项，则会开启「 per-host 的 PAWS 机制」。</p><p><strong>什么是PAWS机制？</strong></p><p>tcp_timestamps 选项开启之后， PAWS 机制会自动开启，它的作用是防止 TCP 包中的序列号发生绕回。</p><p>每个TCP包都会有自己唯一的序列号，序列号是有限的（32位），溢出之后会从0再次开始递增。某个数据包因网络或重发而延迟时，当它再次到达，可能会与当前数据包的序列号发生冲突，导致连接数据传输错误。</p><p>PAWS 就是为了避免这个问题而产生的，在开启 tcp_timestamps 选项情况下，一台机器发的所有 TCP 包都会带上发送时间戳，PAWS 要求连接双方维护最近一次收到的数据包的时间戳（Recent TSval），每收到一个新数据包都会读取数据包中的时间戳值跟 最近一次疏导的数据包的时间戳做比较，如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包。</p><p><strong>什么是 per-host 的 PAWS 机制呢？</strong></p><p>per-host 是对「对端 IP 做 PAWS 检查」，但是如果客户端网络环境是用了 NAT 网关，那么客户端环境的每一台机器通过 NAT 网关后，都会是相同的 IP 地址，服务端无法区分。</p><p>当客户端 A 通过 NAT 网关和服务器建立 TCP 连接，然后服务器主动关闭并且快速回收 TIME-WAIT 状态的连接后，客户端 B 也通过 NAT 网关和服务器建立 TCP 连接，注意客户端 A 和 客户端 B 因为经过相同的 NAT 网关，所以是用相同的 IP 地址与服务端建立 TCP 连接，如果客户端 B 的 timestamp 比 客户端 A 的 timestamp 小，那么由于服务端的 per-host 的 PAWS 机制的作用，服务端就会丢弃客户端主机 B 发来的 SYN 包。</p><p>因此，tcp_tw_recycle 在使用了 NAT 的网络下可能会丢弃SYN报文，在Linux4.12后取消了这个参数。</p><p>==TCP 两个队列满了==</p><p>服务端收到客户端发起的 SYN 请求后，内核会把该连接存储到半连接队列，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，内核会把连接从半连接队列移除<strong>，</strong>然后创建新的完全的连接，并将其添加到全连接队列，等待进程调用 accept函数时把连接取出来。</p><p>当服务器造成syn攻击，就有可能导致 <strong>TCP 半连接队列满了，这时后面来的 syn 包都会被丢弃</strong>。</p><p>但是，如果开启了syncookies 功能，即使半连接队列满了，也不会丢弃syn 包。</p><p>防御 SYN 攻击的方法：</p><ul><li>增大半连接队列；<li>开启 tcp_syncookies 功能<li>减少 SYN+ACK 重传次数</ul><p>在服务端并发处理大量请求时，如果 <strong>TCP accpet 队列过小，或者应用程序调用 accept() 不及时，就会造成 accpet 队列满了 ，这时后续的连接就会被丢弃</strong>，这样就会出现服务端请求数量上不去的现象。</p><p>解决方法：</p><ul><li>调大 accpet 队列的最大长度，调大的方式是通过<strong>调大 backlog 以及 somaxconn 参数。</strong><li>检查系统或者代码为什么调用 accept() 不及时；</ul><h2 id="已建立连接的tcp收到syn会发生什么">已建立连接的TCP，收到SYN会发生什么？</h2><p>一个已经建立的 TCP 连接，客户端中途宕机了，而服务端此时也没有数据要发送，一直处于 establish 状态，客户端恢复后，向服务端建立连接，此时服务端会怎么处理？</p><p>TCP 连接是由「四元组」唯一确认的，在这个场景下，只有源端口可能会不一样。</p><p><strong>1. 客户端的 SYN 报文里的端口号与历史连接不相同</strong></p><p>如果客户端恢复后发送的 SYN 报文中的源端口号跟上一次连接的源端口号不一样，此时服务端会认为是新的连接要建立，于是就会通过三次握手来建立新的连接。</p><p>此时旧连接处于establish状态的服务端，如果发送了数据包给客户端，由于客户端的连接已经被关闭，此时客户端会回RST报文，服务端收到后就会释放连接。</p><p>如果服务端一直没有发送数据包给客户端，在超过一段时间后， TCP 保活机制就会启动，检测到客户端没有存活后，接着服务端就会释放掉该连接。</p><p><strong>2. 客户端的 SYN 报文里的端口号与历史连接相同</strong></p><p>处于 establish 状态的服务端如果收到了客户端的 SYN 报文（注意此时的 SYN 报文是乱序的，因为 SYN 报文的初始化序列号是一个随机数），会回复一个携带了正确序列号和确认号的 ACK 报文，接着，客户端收到这个ACK，发现序列号并不是自己期望收到的，于是就会回 RST 报文，服务端收到后，就会释放掉该连接。</p><h2 id="四次挥手中收到乱序的-fin-包会如何处理">四次挥手中收到乱序的 FIN 包会如何处理？</h2><p>如果 FIN 报文比数据包先抵达客户端，此时 FIN 报文其实是一个乱序的报文，此时客户端的 TCP 连接并不会从 FIN_WAIT_2 状态转换到 TIME_WAIT 状态。</p><p><strong>在 FIN_WAIT_2 状态时，如果收到乱序的 FIN 报文，那么就被会加入到「乱序队列」，并不会进入到 TIME_WAIT 状态。</strong></p><p>等再次收到前面被网络延迟的数据包时，会判断乱序队列有没有数据，然后会检测乱序队列中是否有可用的数据，如果能在乱序队列中找到与当前报文的序列号保持顺序的报文，就会看该报文是否有 FIN 标志，如果发现有 FIN 标志，这时才会进入 TIME_WAIT 状态。</p><h2 id="在-time_wait-状态的-tcp-连接收到-syn-后会发生什么">在 TIME_WAIT 状态的 TCP 连接，收到 SYN 后会发生什么？</h2><p>这个问题场景是服务器发送FIN断开连接，然后处于TIME_WAIT状态时收到客户端的SYN请求，因为在HTTP1.1中，服务器无法主动发送请求，只能由客户端主动发送请求。</p><p>如果开启了时间戳机制的话，关键是要看 SYN 的「序列号和时间戳」是否合法，因为处于 TIME_WAIT 状态的连接收到 SYN 后，会根据其是否合法做出不同的处理。</p><ul><li><strong>合法 SYN</strong>：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要<strong>大</strong>，<strong>并且</strong> SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要<strong>大</strong>。<li><strong>非法 SYN</strong>：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要<strong>小</strong>，<strong>或者</strong> SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要<strong>小</strong>。</ul><p>==收到合法 SYN==</p><p>如果处于 TIME_WAIT 状态的连接收到「合法的 SYN 」后，就会重用此四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程。</p><p>==收到非法的 SYN==</p><p>如果处于 TIME_WAIT 状态的连接收到「非法的 SYN 」后，就会再回复一个第四次挥手的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号（ack num），就回 RST 报文给服务端。</p><p>==处于 TIME_WAIT 状态的连接，收到 RST 会断开连接吗？==</p><p>会不会断开，关键看 <code class="language-plaintext highlighter-rouge">tcp_rfc1337</code> 这个内核参数（默认情况是为 0）：</p><ul><li>如果这个参数设置为 0， 收到 RST 报文会提前结束 TIME_WAIT 状态，释放连接。<li>如果这个参数设置为 1， 就会丢掉 RST 报文。</ul><p>提前结束可能会存在潜在问题，所以设置成1比较安全。</p><h2 id="tcp-连接一端断电和进程崩溃有什么区别">TCP 连接，一端断电和进程崩溃有什么区别？</h2><p>==有keepalive 但是双方一直没有数据交互==</p><p>TCP keepalive就是TCP的保活机制。</p><p>两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。</p><ul><li>如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 TCP 保活时间会被重置，等待下一个 TCP 保活时间的到来。<li>如果对端主机崩溃并且已经重启，请求端会收到一个对其保活探测报文的RST响应报文，然后断开连接。<li>如果对端主机崩溃，或对端由于其他原因导致报文不可达（<strong>比如断电</strong>）。当 TCP 保活的探测报文发送给对端后，没有响应，连续几次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。</ul><p>所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活。</p><p><strong>那进程崩溃的情况呢？</strong></p><p>在进程崩溃后，服务端会发送 FIN 报文，与客户端进行四次挥手。</p><p>==没有开启 TCP keepalive，且双方一直没有数据交互的情况下，如果客户端的「主机崩溃」了，会发生什么。==</p><p>客户端主机崩溃了，服务端是<strong>无法感知到的</strong>，在加上服务端没有开启 TCP keepalive，又没有数据交互的情况下，服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态，直到服务端重启进程。</p><p>==有数据交互场景下的一些异常情况==</p><h5 id="客户端主机宕机又迅速重启会发生什么">客户端主机宕机，又迅速重启，会发生什么？</h5><p>在客户端主机宕机后，服务端向客户端发送的报文会得不到任何的响应，在一定时长后，服务端就会触发超时重传机制，重传未得到响应的报文。客户端主机重启完成后，收到之前TCP连接的报文，由于之前的TCP连接数据结构已经丢失，所以会回复RST报文，断开连接。</p><p><strong>客户端主机宕机，一直没有重启，会发生什么？</strong></p><p>这种情况，服务端超时重传报文的次数达到一定阈值后，会停止重传，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了。</p><h2 id="拔掉网线后-原本的-tcp-连接还存在吗">拔掉网线后， 原本的 TCP 连接还存在吗？</h2><p>TCP 连接的状态等信息在 Linux 内核中的一个名为 <code class="language-plaintext highlighter-rouge">struct socket</code> 的结构体。拔掉网线，操作系统并不会更新该结构体中的内容，所以TCP连接的状态也不会发生改变。</p><p>但是拔掉网线后会断网，此时需要看TCP连接中有没有数据传输。</p><p>==拔掉网线后，有数据传输==</p><p>在客户端拔掉网线后，客户端无法向服务端发送任何数据，服务端向客户端发送的数据报文就会得不到任何响应，在等待一定时长后，服务端会触发<strong>超时重传</strong>机制，重传未得到响应的数据报文。</p><p><strong>如果在服务端重传报文的过程中，客户端刚好把网线插回去了</strong>，由于拔掉网线并不会改变客户端的 TCP 连接状态，并且还是处于 ESTABLISHED 状态，所以这时客户端可以正常接收服务端发来的数据报文，然后客户端就会回 ACK 响应报文。此时，客户端和服务端的 TCP 连接依然存在的，就感觉什么事情都没有发生。</p><p>但是，<strong>如果如果在服务端重传报文的过程中，客户端一直没有将网线插回去</strong>，服务端超时重传报文的次数达到一定阈值（达到一定时间或者一定次数）后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。</p><p>而等客户端插回网线后，如果客户端向服务端发送了数据，由于服务端已经没有与客户端相同四元祖的 TCP 连接了，因此服务端内核就会回复 RST 报文，客户端收到后就会释放该 TCP 连接。</p><p>此时，客户端和服务端的 TCP 连接都已经断开了。</p><p>==拔掉网线后，没有数据传输==</p><p>针对拔掉网线后，没有数据传输的场景，还得看是否开启了 TCP keepalive 机制。</p><p>如果<strong>没有开启</strong> TCP keepalive 机制，在客户端拔掉网线后，并且双方都没有进行数据传输，那么客户端和服务端的 TCP 连接将会一直保持存在。</p><p>而如果<strong>开启</strong>了 TCP keepalive 机制，在客户端拔掉网线后，即使双方都没有进行数据传输，在持续一段时间后，TCP就会启动保活机制，发送探测报文，有三种情况（上面有）。</p><p>==TCP keepalive 机制具体是怎么样的？==</p><p>定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。</p><p>在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：</p><div class="language-text highlighter-rouge"><div class="code-header"> <span text-data=" Text "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>net.ipv4.tcp_keepalive_time=7200  保活时间
net.ipv4.tcp_keepalive_intvl=75  每次检测间隔
net.ipv4.tcp_keepalive_probes=9 最大的检测次数
</pre></table></code></div></div><p>也就是说在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接。</p><p>==TCP keepalive 机制探测的时间也太长了吧？==</p><p>TCP keepalive 是 <strong>TCP 层（内核态）</strong> 实现的，它是给所有基于 TCP 传输协议的程序一个兜底的方案。</p><p>实际上，我们应用层可以自己实现一套探测机制，可以在较短的时间内，探测到对方是否存活。比如类似HTTP中长连接的超时时间一样，设置一个定时器，如果一个请求之后规定的时间内没有发起新的请求，定时器的时间到了，然后触发回调函数来释放该连接。</p><h2 id="tcp-keepalive-和-http-keep-alive-是一个东西吗">TCP Keepalive 和 HTTP Keep-Alive 是一个东西吗？</h2><p><strong>这两个完全是两样不同东西</strong>，实现的层面也不同：</p><ul><li>HTTP 的 Keep-Alive，是由<strong>应用层（用户态）</strong> 实现的，称为 HTTP 长连接；<li>TCP 的 Keepalive，是由 <strong>TCP 层（内核态）</strong> 实现的，称为 TCP 保活机制；</ul><p>==HTTP 的 Keep-Alive==</p><p>由于 HTTP 是基于 TCP 传输协议实现的，客户端与服务端要进行 HTTP 通信前，需要先建立 TCP 连接，然后客户端发送 HTTP 请求，服务端收到后就返回响应，至此「请求-应答」的模式就完成了，随后就会释放 TCP 连接，这种短连接每次请求应答都要建立、释放连接，效率太低。于是HTTP 的 Keep-Alive 实现了长连接，可以使用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，避免了连接建立和释放的开销。</p><p>HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。</p><p><strong>如何使用HTTP的 Keep-Alive 功能？</strong></p><p>HTTP 1.0 中默认是关闭的，如果浏览器要开启 Keep-Alive，它必须在HTTP请求包头部中添加<code class="language-plaintext highlighter-rouge">connection: Keep-Alive</code>字段。从 HTTP 1.1 开始， 默认开启Keep-Alive，如果要关闭，需要在HTTP请求包头部添加<code class="language-plaintext highlighter-rouge">connection: close</code>字段。</p><p>==TCP 的 Keepalive==</p><p>CP 的 Keepalive 就是 <strong>TCP 的保活机制</strong>，如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。三种情况，前面有。</p><p><strong>如何使用TCP的Keepalive？</strong></p><p>应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 <code class="language-plaintext highlighter-rouge">SO_KEEPALIVE</code> 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。</p><h2 id="tcp-协议有什么缺陷">TCP 协议有什么缺陷？</h2><p>主要有四个方面：</p><ul><li>升级 TCP 的工作很困难；<li>TCP 建立连接的延迟；<li>TCP 存在队头阻塞问题；<li>网络迁移需要重新建立 TCP 连接；</ul><p>==升级 TCP 的工作很困难==</p><p>TCP 协议是在内核中实现的，应用程序只能使用不能修改，如果要想升级 TCP 协议，那么只能升级内核。这样TCP更新推广的速度就很慢。</p><p>==TCP 建立连接的延迟==</p><p>基于 TCP 实现的应用协议，都是需要先建立三次握手才能进行数据传输，比如 HTTP 1.0/1.1、HTTP/2、HTTPS。现在大多数网站都是使用 HTTPS 的，这意味着在 TCP 三次握手之后，还需要经过 TLS 四次握手后，才能进行 HTTP 数据的传输，这在一定程序上增加了数据传输的延迟。</p><p>==TCP 存在队头阻塞问题==</p><p>TCP 是字节流协议，<strong>TCP 层必须保证收到的字节数据是完整且有序的</strong>，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据，只有丢失的重传之后，应用层才可以从内核读取到数据。</p><p>==网络迁移需要重新建立 TCP 连接==</p><p>基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。那么<strong>当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接</strong>。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。</p><h3 id="如何基于-udp-协议实现可靠传输">如何基于 UDP 协议实现可靠传输？</h3><p>QUIC 协议就是基于UDP协议实现的可靠传输方案，已经应用在了HTTP/3。</p><h3 id="quic-是如何实现可靠传输的">QUIC 是如何实现可靠传输的？</h3><p>要基于 UDP 实现可靠传输协议，就要在应用层下功夫，也就是要设计好协议的头部字段</p><p>HTTP/3 的 UDP 报文头部与 HTTP 消息之间，共有 3 层头部：</p><p><img data-proofer-ignore data-src="https://docs.citrix.com/en-us/citrix-adc/media/http3-over-quic-protocol-works.png" alt="img" /></p><h4 id="packet-header">Packet Header</h4><p>Packet Header 首次建立时和日常传输数据时使用的Header是不同的，因此分为两种：</p><ul><li>Long Packet Header 用于首次建立连接。<li>Short Packet Header 用于日常传输数据。</ul><p><img data-proofer-ignore data-src="https://img-blog.csdnimg.cn/bcf3ccb6a15c4cdebe1cd0527fdd9a5e.png" alt="Packet Header" /></p><p>QUIC 也是需要三次握手来建立连接的，主要目的是为了协商连接 ID。协商出连接 ID 后，后续传输时，双方只需要固定住连接 ID，从而实现连接迁移功能。所以，你可以看到日常传输数据的 Short Packet Header 不需要在传输 Source Connection ID 字段了，只需要传输 Destination Connection ID。</p><p>Short Packet Header 中的 <code class="language-plaintext highlighter-rouge">Packet Number</code> 是每个报文独一无二的编号，它是<strong>严格递增</strong>的，也就是说就算 Packet N 丢失了，重传的 Packet N 的 Packet Number 已经不是 N，而是一个比 N 大的值。</p><p>Packet Number 单调递增有两个好处：</p><ul><li>可以更加精确计算 RTT，没有 TCP 重传的歧义性问题（TCP重传的序列号和丢失的相同，这样恢复的ACK也相同，无法判断出事原始报文的响应还是重传报文的相应，计算RTT不准确）；<li>可以支持乱序确认，当数据包丢失后，只要有新的已接收数据包确认，就可以滑动窗口；而 TCP 必须是顺序确认的，丢包时会导致窗口不滑动；</ul><h4 id="quic-frame-header">QUIC Frame Header</h4><p>一个 Packet 报文中可以存放多个 QUIC Frame。每一个 Frame 都有明确的类型，针对类型的不同，功能也不同，格式也不同。</p><p>Packet Number 是严格递增，即使重传报文的 Packet Number 也是递增的，既然重传数据包的 Packet N+M 与丢失数据包的 Packet N 编号并不一致，我们怎么确定这两个数据包的内容一样呢？</p><p>所以引入 Frame Header 这一层，<strong>通过 Stream ID + Offset 字段信息实现数据的有序性</strong>，通过比较两个数据包的 Stream ID 与 Stream Offset ，如果都是一致，就说明这两个数据包的内容一致。</p><h3 id="quic-是如何解决-tcp-队头阻塞问题的">QUIC 是如何解决 TCP 队头阻塞问题的？</h3><p>==什么是 TCP 队头阻塞问题？==</p><p>TCP 队头阻塞的问题要从两个角度看，一个是<strong>发送窗口的队头阻塞</strong>，另外一个是<strong>接收窗口的队头阻塞</strong>。</p><p><strong>发送窗口的队头阻塞：</strong></p><p>TCP 发送出去的数据，都是需要按序确认的，只有在数据都被按顺序确认完后，发送窗口才会往前滑动。<strong>如果某个数据包的ACK报文丢失了</strong>，发送方就要超时重传这个数据包，知道收到这个数据包的ACK，发送窗口才能往后移动，这样即使后面的数据包收到了ACK，也不无法移动，即队头阻塞。</p><p><strong>接收窗口的队头阻塞：</strong></p><p>接收方收到的数据范围必须在接收窗口范围内，如果收到超过接收窗口范围的数据，就会丢弃该数据，当接收窗口收到有序数据时，接收窗口才能往前滑动，然后那些已经接收并且被确认的「有序」数据就可以被应用层读取。但是，<strong>当接收窗口收到的数据不是有序的</strong>，缺失了某个数据包，发送窗口就无法向前滑动，只有出重传了这个数据包并且被接收方收到后，接收窗口才会向前滑动，然后应用层读取数据。</p><p>==HTTP/2 的队头阻塞==</p><p>HTTP/2 通过抽象出 Stream 的概念，实现了 HTTP 并发传输，一个 Stream 就代表 HTTP/1.1 里的请求和响应。HTTP/2连接中不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ），因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息，而同一 Stream 内部的帧必须是严格有序的。</p><p>但是 HTTP/2 多个 Stream 请求都是在一条 TCP 连接上传输， 共用同一个 TCP 滑动窗口，当发生数据丢失，滑动窗口也是无法往前移动的，此时就会阻塞住所有的 HTTP 请求，也会出现队头阻塞问题。</p><p>==没有队头阻塞的 QUIC==</p><p>QUIC 也借鉴 HTTP/2 里的 Stream 的概念，在一条 QUIC 连接上可以并发发送多个 HTTP 请求，但是 <strong>QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口</strong>。</p><h3 id="quic-是如何做流量控制的">QUIC 是如何做流量控制的？</h3><p>TCP 流量控制是通过让「接收方」告诉「发送方」，它（接收方）的接收窗口有多大，从而让「发送方」根据「接收方」的实际接收能力控制发送的数据量。</p><p><strong>QUIC 实现流量控制的方式</strong>：</p><ul><li>通过 window_update 帧告诉对端自己可以接收的字节数，这样发送方就不会发送超过这个数量的数据。<li>通过 BlockFrame 告诉对端由于流量控制被阻塞了，无法发送数据。</ul><p>QUIC 实现了两种级别的流量控制，分别为 Stream 和 Connection 两种级别：</p><ul><li><strong>Stream 级别的流量控制</strong>：Stream 可以认为就是一条 HTTP 请求，每个 Stream 都有独立的滑动窗口，所以每个 Stream 都可以做流量控制，防止单个 Stream 消耗连接（Connection）的全部接收缓冲。<li><strong>Connection 流量控制</strong>：限制连接中所有 Stream 相加起来的总字节数，防止发送方超过连接的缓冲容量。</ul><p>==Stream 级别的流量控制==</p><p>每个Stream都有一个滑动窗口进行流量控制，当单个stream中已接收并且已被上层读取的数据超出最大接受窗口的一半时，最大接受窗口向右移动对应的字节数，同时给对端发动窗口更新帧，发送方接受后，发送窗口的窗口也向右滑动。</p><p>==Connection 流量控制==</p><p>对于 Connection 级别的流量窗口，其接收窗口大小就是各个 Stream 接收窗口大小之和。</p><p>比如，所有stream的最大窗口数是某个值，那么整个connection的可用窗口就是所有stream的可用窗口之和。而每个stream的可用窗口取决于最大窗口数和最大接受偏移量的差值。</p><h3 id="quic-对拥塞控制改进">QUIC 对拥塞控制改进</h3><p>QUIC 协议当前默认使用了 TCP 的拥塞控制算法，但QUIC 是处于应用层的，应用层面就能实现不同的拥塞控制算法，这样不同于在内核和操作系统中不实现，部署相对简单，升级迭代快，灵活性得到了提高。</p><h3 id="quic-更快的连接建立">QUIC 更快的连接建立</h3><p>对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手（1RTT），再 TLS 握手（2RTT）。</p><p>HTTP/3 在传输数据前虽然需要 QUIC 协议握手，但这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」。 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。因此QUIC建立连接的速度更快。</p><h3 id="quic-是如何迁移连接的">QUIC 是如何迁移连接的？</h3><p>基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。那么<strong>当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接</strong>。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。</p><p>QUIC 协议没有用四元组的方式来绑定连接，而是通过<strong>连接 ID</strong>来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<strong>连接迁移</strong>的功能。</p><h1 id="ip">IP</h1><h2 id="ip-基础知识全家桶">IP 基础知识全家桶</h2><h3 id="ip-基本认识">IP 基本认识</h3><p>源IP地址和目标IP地址在传输过程中是不会变化的，只有源 MAC 地址和目标 MAC 一直在变化。这就是IP层和数据链路层的区别，IP层负责将数据包发送到最终的目的地址，数据链路层负责各个区间的通信传输。</p><h3 id="ip-地址的基础知识">IP 地址的基础知识</h3><p>每个设备只有配置了正确的IP地址，才能实现正常的通信，IP 地址（IPv4 地址）由 <code class="language-plaintext highlighter-rouge">32</code> 位正整数来表示，在计算机中以二进制的方式处理，使用点分十进制法来标记。</p><h4 id="ip-地址的分类">IP 地址的分类</h4><p>IP 地址分类成了 5 种类型，分别是 A 类、B 类、C 类、D 类、E 类。</p><p><img data-proofer-ignore data-src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/7.jpg" alt="IP 地址分类" /></p><p>==什么是 A、B、C 类地址？==</p><p>A、B、C 类地址有分类号、网络号和主机号三个部分，</p><ul><li>A类，分类号以0开头，主机号24位<li>B类，分类号以10开头，主机号16位<li>C类，分类号以110开头，主机号8位</ul><p>==A、B、C 分类地址最大主机个数是如何计算的呢？==</p><p>最大主机个数，需要看主机号的位数，然后减去2。</p><p>为什么减去2呢，因为在IP地址中，有两个IP地址是特殊的，分别是主机号全为1和全为0的地址。</p><ul><li>主机号全为 1 指定某个网络下的所有主机，用于广播<li>主机号全为 0 指定某个网络</ul><p>广播地址用于在<strong>同一个链路中相互连接的主机之间发送数据包</strong>。分为本地广播（本网络内的广播）和直接广播（不同网络之间的广播）。</p><p>==什么是 D、E 类地址？==</p><p>D 类和 E 类地址没有主机号，所以不可用于主机 IP，D 类常被用于<strong>多播</strong>，E 类是预留的分类，暂未使用。</p><p>==多播地址用于什么？==</p><p>多播用于<strong>将包发送给特定组内的所有主机。</strong></p><p>==IP 分类的优点与缺点==</p><p>优点：简单明了，可以很快的找出网络地址和主机地址。</p><p>缺点：同一网络下没有地址层次，缺少灵活性；还有就是不能很好的与现实网络匹配，C类地址包含的最大主机数太少，而B类地址包含的最大主机数又太多。</p><h4 id="无分类地址-cidr">无分类地址 CIDR</h4><p>为了解决IP分类地址的缺点，提出了无分类地址，这种方式不再有分类地址的概念，32 比特的 IP 地址被划分为两部分，前面是<strong>网络号</strong>，后面是<strong>主机号</strong>。</p><p>==怎么划分网络号和主机号的呢？==</p><p>表示形式 <code class="language-plaintext highlighter-rouge">a.b.c.d/x</code>，其中 <code class="language-plaintext highlighter-rouge">/x</code> 表示前 x 位属于<strong>网络号</strong>， x 的范围是 <code class="language-plaintext highlighter-rouge">0 ~ 32</code>，这就使得 IP 地址更加具有灵活性。比如 10.100.122.2/24，表示前24位为网络号，剩余的8位是主机号。</p><p><strong>子网掩码</strong>也可以划分网络号与主机号，掩码的意思就是掩盖掉主机号，剩余的就是网络号。将子网掩码和 IP 地址按位计算 AND，就可得到网络号。比如上述地址的子网掩码是255.255.255.0。</p><p>==为什么要分离网络号和主机号？==</p><p>因为两台计算机要通讯，首先要判断是否处于同一个广播域内，即网络地址是否相同。如果网络地址相同，表明接受方在本网络上，那么可以把数据包直接发送到目标主机。</p><p>路由器寻址工作中，也就是通过这样的方式来找到对应的网络号的，进而把数据包转发给对应的网络内。</p><p>==怎么进行子网划分？==</p><p>子网掩码除了可以划分出网络号和主机号，还可以<strong>划分子网</strong>。</p><p>子网划分实际上是将主机地址分为两个部分：子网网络地址和子网主机地址。</p><ul><li>未做子网划分的 ip 地址：网络地址＋主机地址<li>做子网划分后的 ip 地址：网络地址＋（子网网络地址＋子网主机地址）</ul><h4 id="ip-地址与路由控制">IP 地址与路由控制</h4><p>P地址的网络地址这一部分是用于进行路由控制。</p><p>路由控制表中记录着网络地址与下一步应该发送至路由器的地址。在主机和路由器上都会有各自的路由器控制表。工作原理是：在发送 IP 包时，首先要确定 IP 包首部中的目标地址，再从路由控制表中找到与该地址具有相同网络地址的记录，根据该记录将 IP 包转发给相应的下一个路由器。如果路由控制表中存在多条相同网络地址的记录，就选择相同位数最多的网络地址，也就是最长匹配。</p><p>==环回地址是不会流向网络==</p><p>环回地址是在同一台计算机上的程序之间进行网络通信时所使用的一个默认地址。</p><p>计算机使用一个特殊的 IP 地址 <strong>127.0.0.1 作为环回地址</strong>。与该地址具有相同意义的是一个叫做 <code class="language-plaintext highlighter-rouge">localhost</code> 的主机名。使用这个 IP 或主机名时，数据包不会流向网络。</p><h4 id="ip-分片与重组">IP 分片与重组</h4><p>每种数据链路的 MTU 之所以不同，是因为每个不同类型的数据链路的使用目的不同。使用目的不同，可承载的 MTU 也就不同。其中，我们最常见数据链路是<strong>以太网，它的 MTU 是 <code class="language-plaintext highlighter-rouge">1500</code> 字节</strong>。</p><p>当 IP 数据包大小大于 MTU 时， IP 数据包就会被分片，经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行，路由器是不会进行重组的。</p><h4 id="ipv6-基本认识">IPv6 基本认识</h4><p>IPv6 的地址是 <code class="language-plaintext highlighter-rouge">128</code> 位的，IPv6 除了有更多的地址之外，还有更好的安全性和扩展性。</p><p>==IPv6 的亮点==</p><ul><li>更多的可分配地址<li>IPv6 可自动配置，即使没有 DHCP 服务器也可以实现自动分配IP地址<li>IPv6 数据包头部长度采用固定的值 <code class="language-plaintext highlighter-rouge">40</code> 字节，去掉了包头校验和，简化了首部结构，减轻了路由器负荷，大大提高了传输的性能。<li>IPv6 有应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能，大大提升了安全性。</ul><p>==IPv6 地址的标识方法==</p><p>IPv4 地址长度共 32 位，是以每 8 位作为一组，并用点分十进制的表示方式。</p><p>IPv6 地址长度是 128 位，是以每 16 位作为一组，使用十六进制数表示，每组用冒号 「:」 隔开。</p><h3 id="ip-协议相关技术">IP 协议相关技术</h3><h4 id="dns-域名解析">DNS 域名解析</h4><p>为了方便记忆，我们访问网址的时候，使用的是域名，而不是IP地址，这背后需要DNS域名解析技术支撑，DNS可以将域名网址自动转换为具体的IP地址。</p><p>DNS中的域名是按照句点来分隔的，域名之间是层级关系，越靠右其层级越高。</p><p>==域名解析的工作流程==</p><ul><li>客户端首先会发送一个DNS请求，问当前域名的IP地址是什么，并发给本地DNS服务器<li>本地DNS服务器收到DNS请求后，如果在缓存里能够找到对应的域名，则直接返回IP地址。如果找不到，就循环他的根域名服务器。<li>根域名服务器收到本地DNS的请求后，给出顶级域名服务器地址，然后本地DNS去访问<li>顶级域名服务器收到本地DNS的请求后，给出全为DNS服务器的地址，然后本地DNS去访问<li>权威DNS服务器收到本地DNS请求后，经过查询给出域名的IP地址，然后告诉本地DNS<li>本地DNS将IP地址返回客户端</ul><p>访问的特点是：每层只负责给出下一层的地址，本地DNS逐次访问每层域名服务器，直到找到对应IP地址。</p><h4 id="arp-与-rarp-协议">ARP 与 RARP 协议</h4><p>在传输一个 IP 数据报的时候，确定了源 IP 地址和目标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下一跳。主机的路由表中可以找到下一跳的 IP 地址，然后通过 <strong>ARP 协议</strong>，求得下一跳的 MAC 地址。</p><p>==那么 ARP 又是如何知道对方 MAC 地址的呢？==</p><p>ARP 是借助 <strong>ARP 请求与 ARP 响应</strong>两种类型的包确定 MAC 地址的。</p><ul><li>主机会通过<strong>广播发送 ARP 请求</strong>，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。<li>当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包里的内容，如果 ARP 请求包中的目标 IP 地址与自己的 IP 地址一致，那么这个设备就将自己的 MAC 地址塞入 <strong>ARP 响应包</strong>返回给主机。</ul><p>==RARP 协议你知道是什么吗？==</p><p>ARP 协议是已知 IP 地址求 MAC 地址，那 RARP 协议正好相反，它是<strong>已知 MAC 地址求 IP 地址</strong>。</p><p>通常需要架设一台 <code class="language-plaintext highlighter-rouge">RARP</code> 服务器，在这个服务器上注册设备的 MAC 地址及其 IP 地址。然后再将这个设备接入到网络，接着：</p><ul><li>该设备会发送一条「我的 MAC 地址是XXXX，请告诉我，我的IP地址应该是什么」的请求信息。<li>RARP 服务器接到这个消息后返回「MAC地址为 XXXX 的设备，IP地址为 XXXX」的信息给这个设备。<li>最后，设备就根据从 RARP 服务器所收到的应答信息设置自己的 IP 地址。</ul><h4 id="dhcp-动态获取-ip-地址">DHCP 动态获取 IP 地址</h4><p>DHCP自动获取IP地址的流程：</p><ul><li>客户端首先发起 <strong>DHCP 发现报文（DHCP DISCOVER）</strong> 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 UDP <strong>广播</strong>通信，其使用的广播目的地址是 255.255.255.255（端口 67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。<li>DHCP 服务器收到 DHCP 发现报文时，用 <strong>DHCP 提供报文（DHCP OFFER）</strong> 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 <strong>IP 地址租用期</strong>。<li>客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 <strong>DHCP 请求报文（DHCP REQUEST</strong>进行响应，回显配置的参数。<li>最后，服务端用 <strong>DHCP ACK 报文</strong>对 DHCP 请求报文进行响应，应答所要求的参数。</ul><p>客户端收到 DHCP ACK 后，交互便完成了，客户端就能够在租用期内使用 DHCP 服务器分配的 IP 地址。</p><p>如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报文：</p><ul><li>服务器如果同意继续租用，则用 DHCP ACK 报文进行应答，客户端就会延长租期。<li>服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要停止使用租约的 IP 地址。</ul><p>==如果 DHCP 服务器和客户端不是在同一个局域网（链路）内，路由器又不会转发广播包怎么办？==</p><p>为了解决这一问题，出现了 <strong>DHCP 中继代理</strong>。有了 DHCP 中继代理以后，<strong>对不同网段的 IP 地址分配也可以由一个 DHCP 服务器统一进行管理。</strong></p><ul><li>客户端会向 DHCP 中继代理发送 DHCP 请求包，而 DHCP 中继代理在收到这个广播包以后，再以<strong>单播</strong>的形给 DHCP 服务器。<li>服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包广播给 客户端 。</ul><h4 id="nat-网络地址转换">NAT 网络地址转换</h4><p>NAT是为了缓解IPv4地址紧缺的问题，它是将私有IP地址转换为共有IP地址。为了区分不同的私有IP地址，需要将IP地址+端口号一起进行装换，具体实现就是将不同的私有IP地址转换成一个公有IP地址，但是它们的端口号不同，以此作为区分。NAT路由器会自动生成转换表。</p><p>==NAT的缺点？==</p><p>由于 NAT/NAPT 都依赖于自己的转换表，因此会有以下的问题：</p><ul><li>外部无法主动与 NAT 内部服务器建立连接，因为 NAPT 转换表没有转换记录。<li>转换表的生成与转换操作都会产生性能开销。<li>通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。</ul><p>==如何解决 NAT 潜在的问题呢？==</p><p>解决的方法主要有两种方法。</p><p><strong>第一种就是改用 IPv6</strong></p><p>IPv6 可用范围非常大，以至于每台设备都可以配置一个公有 IP 地址，但是IPv6还未普及。</p><p><strong>第二种 NAT 穿透技术</strong></p><p>NAT 穿透技术拥有这样的功能，它能够让网络应用程序主动发现自己位于 NAT 设备之后，并且会主动获得 NAT 设备的公有 IP，并为自己建立端口映射条目，注意这些都是 NAT设备后的应用程序自动完成的。</p><p>就是客户端主动从 NAT 设备获取公有 IP 地址，然后自己建立端口映射条目，然后用这个条目对外通信，就不需要 NAT 设备来进行转换了。</p><h4 id="icmp-互联网控制报文协议">ICMP 互联网控制报文协议</h4><p>ICMP报文是封装在IP包里面，它工作在网络层，是IP协议的助手。</p><p><code class="language-plaintext highlighter-rouge">ICMP</code> 主要的功能包括：确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。ICMP 包头的类型字段大致可以分为两大类：</p><ul><li>一类是用于诊断的查询消息，也就是「<strong>查询报文类型</strong>」<li>另一类是通知出错原因的错误消息，也就是「<strong>差错报文类型</strong>」</ul><p>==查询报文类型==</p><p><strong>回送消息</strong>用于进行通信的主机或路由器之间，判断所发送的数据包是否已经成功到达对端的一种消息，<code class="language-plaintext highlighter-rouge">ping</code> 命令就是利用这个消息实现的。</p><p>可以向对端主机发送<strong>回送请求</strong>的消息（<code class="language-plaintext highlighter-rouge">ICMP Echo Request Message</code>，类型 <code class="language-plaintext highlighter-rouge">8</code>），也可以接收对端主机发回来的<strong>回送应答</strong>消息（<code class="language-plaintext highlighter-rouge">ICMP Echo Reply Message</code>，类型 <code class="language-plaintext highlighter-rouge">0</code>）</p><p>==差错报文类型==</p><p><strong>目标不可达消息（Destination Unreachable Message） —— 类型为 <code class="language-plaintext highlighter-rouge">3</code></strong></p><p>IP 路由器无法将 IP 数据包发送给目标地址时，会给发送端主机返回一个<strong>目标不可达</strong>的 ICMP 消息，并在这个消息中显示不可达的具体原因，原因记录在 ICMP 包头的<strong>代码</strong>字段。</p><p><strong>原点抑制消息（ICMP Source Quench Message） —— 类型 <code class="language-plaintext highlighter-rouge">4</code></strong></p><p>当路由器向低速线路发送数据时，其发送队列的缓存变为零而无法发送出去时，可以向 IP 包的源地址发送一个 ICMP <strong>原点抑制消息</strong>。收到这个消息的主机借此了解在整个线路的某一处发生了拥堵的情况，从而增大 IP 包的传输间隔，减少网络拥堵的情况。</p><p><strong>重定向消息（ICMP Redirect Message） —— 类型 <code class="language-plaintext highlighter-rouge">5</code></strong></p><p>如果路由器发现发送端主机使用了「不是最优」的路径发送数据，那么它会返回一个 ICMP <strong>重定向消息</strong>给这个主机。在这个消息中包含了<strong>最合适的路由信息和源数据</strong>。这主要发生在路由器持有更好的路由信息的情况下。路由器会通过这样的 ICMP 消息告知发送端，让它下次发给另外一个路由器。</p><p><strong>超时消息（ICMP Time Exceeded Message） —— 类型 <code class="language-plaintext highlighter-rouge">11</code></strong></p><p>IP 包中有一个字段叫做 <code class="language-plaintext highlighter-rouge">TTL</code> （<code class="language-plaintext highlighter-rouge">Time To Live</code>，生存周期），它的<strong>值随着每经过一次路由器就会减 1，直到减到 0 时该 IP 包会被丢弃。</strong>此时，路由器将会发送一个 ICMP <strong>超时消息</strong>给发送端主机，并通知该包已被丢弃。</p><h4 id="igmp-因特网组管理协议">IGMP 因特网组管理协议</h4><p>IGMP工作在主机（组播成员）和最后一跳路由之间</p><ul><li>IGMP 报文向路由器申请加入和退出组播组，默认情况下路由器是不会转发组播包到连接中的主机，除非主机通过 IGMP 加入到组播组，主机申请加入到组播组时，路由器就会记录 IGMP 路由器表，路由器后续就会转发组播包到对应的主机了。<li>IGMP 报文采用 IP 封装，IP 头部的协议号为 2，而且 TTL 字段值通常为 1，因为 IGMP 是工作在主机与连接的路由器之间。</ul><h2 id="ping-的工作原理">ping 的工作原理</h2><p>ping命令使用了ICMP协议的查询报文类型，ping的发送和接收过程如下：</p><p><strong>ping 命令执行的时候，源主机首先会构建一个 ICMP 回送请求消息数据包。</strong></p><p>ICMP 数据包内包含多个字段，最重要的是两个：</p><ul><li>第一个是<strong>类型</strong>，对于回送请求消息而言该字段为 <code class="language-plaintext highlighter-rouge">8</code>；<li>另外一个是<strong>序号</strong>，主要用于区分连续 ping 的时候发出的多个数据包，每发出一个请求数据包，序号自动加1。</ul><p>此外，还会在报文的数据部分插入发送时间，这是为了计算往返时间RTT。</p><p><strong>然后，由 ICMP 协议将这个数据包连同目标主机的地址一起交给 IP 层。</strong></p><p>IP 层将以目标主机IP地址作为<strong>目的地址</strong>，本机 IP 地址作为<strong>源地址</strong>，<strong>协议</strong>字段设置为 <code class="language-plaintext highlighter-rouge">1</code> 表示是 <code class="language-plaintext highlighter-rouge">ICMP</code> 协议，再加上一些其他控制信息，构建一个 <code class="language-plaintext highlighter-rouge">IP</code> 数据包。</p><p><strong>接下来，需要加入 <code class="language-plaintext highlighter-rouge">MAC</code> 头部。</strong></p><p>如果在本地 ARP 映射表中查找目标主机IP地址所对应的 MAC 地址，则可以直接使用；如果没有，则需要发送 <code class="language-plaintext highlighter-rouge">ARP</code> 协议查询 MAC 地址，获得 MAC 地址后，由数据链路层构建一个数据帧，目的地址是 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址；还要附加上一些控制信息，然后将它们传送出去。</p><p>目标主机收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃。目标主机会构建一个 <strong>ICMP 回送响应消息</strong>数据包，回送响应数据包的<strong>类型</strong>字段为 <code class="language-plaintext highlighter-rouge">0</code>，<strong>序号</strong>为接收到的请求数据包中的序号，然后再发送出去给源主机。</p><p>在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 回送响应消息，则说明目标主机可达。</p><p>此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。</p><p>上面说的是同一个局域网里面的情况。如果跨网段的话，还会涉及网关的转发、路由器的转发等等。但是对于 ICMP 的头来讲，是没什么影响的。会影响的是根据目标 IP 地址，选择路由的下一跳，还有每经过一个路由器到达一个新的局域网，需要换 MAC 头里面的 MAC 地址。</p><p><strong>总结：ping是使用了ICMP协议里面的回应请求查询报文（类型为8）和回应响应查询报文（类型为0）。</strong></p><p>==traceroute —— 差错报文类型的使用==</p><p>一款充分利用 ICMP 差错报文类型的应用叫做 <code class="language-plaintext highlighter-rouge">traceroute</code>（在UNIX、MacOS中是这个命令，而在Windows中对等的命令叫做 tracert ）。</p><p><strong>traceroute 的第一个作用就是故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器。</strong></p><p>traceroute 的参数指向某个目的 IP 地址：<code class="language-plaintext highlighter-rouge">traceroute 192.168.1.100</code></p><p>它的原理就是利用 IP 包的生存期限 从 <code class="language-plaintext highlighter-rouge">1</code> 开始按照顺序递增的同时发送 UDP 包，强制接收 ICMP 超时消息的一种方法。比如，将 TTL 设置 为 <code class="language-plaintext highlighter-rouge">1</code>，则遇到第一个路由器，就牺牲了，接着返回 ICMP 差错报文网络包，类型是时间超时。接下来将 TTL 设置为 <code class="language-plaintext highlighter-rouge">2</code>，第一个路由器过了，遇到第二个路由器也牺牲了，也同时返回了 ICMP 差错报文数据包，如此往复，直到到达目的主机。不断重复这样的过程，traceroute 就可以拿到了所有的路由器 IP。</p><p>那发送方如何知道发出的 UDP 包是否到达了目的主机呢？</p><p>raceroute 在发送 <code class="language-plaintext highlighter-rouge">UDP</code> 包时，会填入一个不可能的端口号值作为 UDP 目标端口号（大于 <code class="language-plaintext highlighter-rouge">3000</code> ）。当目的主机，收到 UDP 包后，会返回 ICMP 差错报文消息，但这个差错报文消息的类型是「端口不可达」。所以，当差错报文类型是端口不可达时，说明发送方发出的 UDP 包到达了目的主机。</p><p><strong>traceroute 还有一个作用是故意设置不分片，从而确定路径的 MTU。</strong></p><p>因为有的时候我们并不知道路由器的 <code class="language-plaintext highlighter-rouge">MTU</code> 大小，以太网的数据链路上的 <code class="language-plaintext highlighter-rouge">MTU</code> 通常是 <code class="language-plaintext highlighter-rouge">1500</code> 字节，但是非以外网的 <code class="language-plaintext highlighter-rouge">MTU</code> 值就不一样了，所以我们要知道 <code class="language-plaintext highlighter-rouge">MTU</code> 的大小，从而控制发送的包大小。</p><p>首先在发送端主机发送 <code class="language-plaintext highlighter-rouge">IP</code> 数据报时，将 <code class="language-plaintext highlighter-rouge">IP</code> 包首部的分片禁止标志位设置为 1。根据这个标志位，途中的路由器不会对大数据包进行分片，而是将包丢弃。随后，通过一个 ICMP 的不可达消息将数据链路上 MTU*的值一起给发送主机，不可达消息的类型为「需要进行分片但设置了不分片位」。发送主机端每次收到 ICMP 差错报文时就减少包的大小，以此来定位一个合适的 <code class="language-plaintext highlighter-rouge">MTU</code> 值，以便能到达目标主机。</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/%E7%AC%94%E8%AE%B0/'>笔记</a>, <a href='/categories/%E8%AE%A1%E7%BD%91/'>计网</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/%E6%80%BB%E7%BB%93/" class="post-tag no-text-decoration" >总结</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" class="post-tag no-text-decoration" >计算机网络</a> <a href="/tags/%E5%85%AB%E8%82%A1/" class="post-tag no-text-decoration" >八股</a> <a href="/tags/http/" class="post-tag no-text-decoration" >HTTP</a> <a href="/tags/tcp/" class="post-tag no-text-decoration" >TCP</a> <a href="/tags/ip/" class="post-tag no-text-decoration" >IP</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> 本文由作者按照 <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> 进行授权</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">分享</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=计网相关知识整理 - ShenshenZhou&url=https://shenshenzhou.github.io/posts/NetWork-knowledge/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=计网相关知识整理 - ShenshenZhou&u=https://shenshenzhou.github.io/posts/NetWork-knowledge/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=计网相关知识整理 - ShenshenZhou&url=https://shenshenzhou.github.io/posts/NetWork-knowledge/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="分享链接" title-succeed="链接已复制！"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>最近更新</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/webserver-webbench/">Webserver压力测试</a><li><a href="/posts/Sort/">C++实现十大排序算法</a><li><a href="/posts/Redis-knowledge/">Redis相关知识整理</a><li><a href="/posts/MySQL-knowledge/">MySQL相关知识整理</a><li><a href="/posts/leetcode200/">LeetCode200题记录</a></ul></div><div id="access-tags"> <span>热门标签</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a> <a class="post-tag" href="/tags/%E6%80%BB%E7%BB%93/">总结</a> <a class="post-tag" href="/tags/c/">C++</a> <a class="post-tag" href="/tags/c-primer5/">C++Primer5</a> <a class="post-tag" href="/tags/%E7%AE%97%E6%B3%95/">算法</a> <a class="post-tag" href="/tags/%E8%93%9D%E6%A1%A5%E6%9D%AF/">蓝桥杯</a> <a class="post-tag" href="/tags/%E9%A2%98%E8%A7%A3/">题解</a> <a class="post-tag" href="/tags/%E5%85%AB%E8%82%A1/">八股</a> <a class="post-tag" href="/tags/linux/">Linux</a> <a class="post-tag" href="/tags/%E7%BD%91%E9%A1%B5%E8%B5%84%E6%96%99/">网页资料</a></div></div></div><script src="https://fastly.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">文章内容</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>相关文章</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/MySQL-knowledge/"><div class="card-body"> <span class="timeago small" >2022-07-15<i class="unloaded">2022-07-15T22:41:27+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>MySQL相关知识整理</h3><div class="text-muted small"><p> 基础 执行一条select语句，期间发生了什么？ 首先需要了解MySQL的内部架构，共分为两层：Server层和存储引擎层 Server层负责建立连接、分析和执行SQL，主要包络连接器、查询缓存、解析器、预处理器、优化器、执行器等核心功能模块。 存储引擎层负责数据的存储和提取。MySQL支持MyISAM、InnoDB、Memory等多个存储引擎，不同的存储引擎公用一个Serv...</p></div></div></a></div><div class="card"> <a href="/posts/Redis-knowledge/"><div class="card-body"> <span class="timeago small" >2022-07-16<i class="unloaded">2022-07-16T22:35:05+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Redis相关知识整理</h3><div class="text-muted small"><p> 认识Redis 什么是Redis Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此读写速度非常快，常用于缓存，消息队列、分布式锁等场景。 Redis 提供了多种数据类型来支持不同的业务场景并且对数据类型的操作都是原子性的，因为执行命令由单线程负责的，不存在并发竞争的问题。 除此之外，Redis 还支持事务 、持久化、Lua 脚本、多种集群方案（主从复制模式、...</p></div></div></a></div><div class="card"> <a href="/posts/OS-knowledge/"><div class="card-body"> <span class="timeago small" >2022-07-22<i class="unloaded">2022-07-22T11:48:55+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>OS相关知识整理</h3><div class="text-muted small"><p> 硬件结构 图灵机的基本组成、工作方式 图灵机的基本组成？ 有一条「纸带」，纸带由一个个连续的格子组成，每个格子可以写入字符，纸带就好比内存，而纸带上的格子的字符就好比内存中的数据或程序； 有一个「读写头」，读写头可以读取纸带上任意格子的字符，也可以把字符写入到纸带的格子； 读写头上有一些部件，比如存储单元、控制单元以及运算单元： 1、存储单元用于存放数据； 2、控制单元用...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Redis-knowledge/" class="btn btn-outline-primary" prompt="上一篇"><p>Redis相关知识整理</p></a> <a href="/posts/OS-knowledge/" class="btn btn-outline-primary" prompt="下一篇"><p>OS相关知识整理</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2024 <a href="https://github.com/ShenshenZhou">ShenshenZhou</a>. <span data-toggle="tooltip" data-placement="top" title="除非另有说明，本网站上的博客文章均由作者按照知识共享署名 4.0 国际 (CC BY 4.0) 许可协议进行授权。">保留部分权利。</span></p></div><div class="footer-right"><p class="mb-0"> 本站由 <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> 生成，采用 <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> 主题。</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">热门标签</h4><a class="post-tag" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a> <a class="post-tag" href="/tags/%E6%80%BB%E7%BB%93/">总结</a> <a class="post-tag" href="/tags/c/">C++</a> <a class="post-tag" href="/tags/c-primer5/">C++Primer5</a> <a class="post-tag" href="/tags/%E7%AE%97%E6%B3%95/">算法</a> <a class="post-tag" href="/tags/%E8%93%9D%E6%A1%A5%E6%9D%AF/">蓝桥杯</a> <a class="post-tag" href="/tags/%E9%A2%98%E8%A7%A3/">题解</a> <a class="post-tag" href="/tags/%E5%85%AB%E8%82%A1/">八股</a> <a class="post-tag" href="/tags/linux/">Linux</a> <a class="post-tag" href="/tags/%E7%BD%91%E9%A1%B5%E8%B5%84%E6%96%99/">网页资料</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://fastly.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">搜索结果为空</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://fastly.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://fastly.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
